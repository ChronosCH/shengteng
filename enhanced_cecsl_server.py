#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡ - ç®€åŒ–ç‰ˆæœ¬
ä¸“ç”¨äºæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
"""

import json
import time
import asyncio
import numpy as np
import logging
import uuid
import cv2
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# MindSpore
try:
    import mindspore as ms
    from mindspore import nn, ops, Tensor, load_checkpoint, load_param_into_net
    import mindspore.context as ms_context
    MINDSPORE_AVAILABLE = True
    print("MindSporeå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    MINDSPORE_AVAILABLE = False
    print(f"è­¦å‘Š: MindSpore æœªå®‰è£… ({e})ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨ç†")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„MindSporeç±»
    class MockCell:
        def __init__(self):
            pass
        def set_train(self, mode):
            pass
    
    class MockNN:
        Cell = MockCell
        SequentialCell = list
        Dense = lambda *args, **kwargs: None
        LayerNorm = lambda *args, **kwargs: None
        ReLU = lambda *args, **kwargs: None
        Dropout = lambda *args, **kwargs: None
        LSTM = lambda *args, **kwargs: None
        Tanh = lambda *args, **kwargs: None
    
    nn = MockNN()
    ms = None
    ops = None
    Tensor = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)


# æ•°æ®æ¨¡å‹
class EnhancedCECSLTestRequest(BaseModel):
    landmarks: List[List[float]]
    description: Optional[str] = None


class EnhancedCECSLTestResponse(BaseModel):
    success: bool
    message: str
    prediction: Optional[Dict] = None
    stats: Optional[Dict] = None


class VideoUploadResponse(BaseModel):
    success: bool
    task_id: str
    message: str
    status: str = "uploaded"


class VideoStatusResponse(BaseModel):
    task_id: str
    status: str  # "processing", "completed", "error"
    progress: Optional[float] = None
    result: Optional[Dict] = None
    error: Optional[str] = None


@dataclass
class EnhancedCECSLConfig:
    """å¢å¼ºç‰ˆCE-CSLæ¨¡å‹é…ç½®"""
    vocab_size: int = 1000
    d_model: int = 192
    n_layers: int = 2
    dropout: float = 0.3
    image_size: Tuple[int, int] = (112, 112)
    max_sequence_length: int = 64


class ImprovedCECSLModel:
    """æ”¹è¿›çš„CE-CSLæ‰‹è¯­è¯†åˆ«æ¨¡å‹ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, config: EnhancedCECSLConfig, vocab_size: int):
        self.config = config
        self.vocab_size = vocab_size
        print(f"åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹: vocab_size={vocab_size}")
    
    def set_train(self, mode):
        """è®¾ç½®è®­ç»ƒæ¨¡å¼"""
        pass
    
    def __call__(self, x):
        """æ¨¡æ‹Ÿæ¨ç†"""
        if MINDSPORE_AVAILABLE and isinstance(x, Tensor):
            # çœŸå®çš„MindSporeæ¨ç†
            return self._real_forward(x)
        else:
            # æ¨¡æ‹Ÿæ¨ç†
            return self._mock_forward(x)
    
    def _real_forward(self, x):
        """çœŸå®çš„å‰å‘ä¼ æ’­ï¼ˆå½“MindSporeå¯ç”¨æ—¶ï¼‰"""
        # è¿™é‡Œåº”è¯¥æ˜¯çœŸå®çš„MindSporeæ¨¡å‹æ¨ç†
        # ç”±äºæ¨¡å‹ç»“æ„å¤æ‚ï¼Œæš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿ
        batch_size = x.shape[0]
        return np.random.rand(batch_size, self.vocab_size).astype(np.float32)
    
    def _mock_forward(self, x):
        """æ¨¡æ‹Ÿå‰å‘ä¼ æ’­"""
        if isinstance(x, np.ndarray):
            batch_size = x.shape[0]
        else:
            batch_size = 1
        return np.random.rand(batch_size, self.vocab_size).astype(np.float32)


class VideoProcessingService:
    """è§†é¢‘å¤„ç†æœåŠ¡ï¼Œç”¨äºæå–æ‰‹éƒ¨å…³é”®ç‚¹"""
    
    def __init__(self):
        self.video_tasks = {}  # å­˜å‚¨è§†é¢‘å¤„ç†ä»»åŠ¡
        self.upload_dir = Path("temp/video_uploads")
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        
        # MediaPipe ç›¸å…³
        self.mp = None
        self.mp_hands = None
        self.hands = None
        
        # åˆå§‹åŒ–MediaPipe
        self._init_mediapipe()
    
    def _init_mediapipe(self):
        """åˆå§‹åŒ–MediaPipe"""
        try:
            import mediapipe as mp
            self.mp = mp
            self.mp_hands = mp.solutions.hands
            self.hands = self.mp_hands.Hands(
                static_image_mode=False,
                max_num_hands=2,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )
            logger.info("MediaPipe åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            logger.warning("MediaPipe ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå…³é”®ç‚¹æå–")
            self.mp = None
    
    async def save_uploaded_video(self, file: UploadFile) -> Tuple[str, str]:
        """ä¿å­˜ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶"""
        # ç”Ÿæˆå”¯ä¸€çš„ä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # ä¿å­˜æ–‡ä»¶
        file_extension = Path(file.filename).suffix if file.filename else ".mp4"
        video_path = self.upload_dir / f"{task_id}{file_extension}"
        
        with open(video_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        self.video_tasks[task_id] = {
            "status": "uploaded",
            "video_path": str(video_path),
            "progress": 0.0,
            "result": None,
            "error": None,
            "created_at": time.time()
        }
        
        return task_id, str(video_path)
    
    async def process_video(self, task_id: str, enhanced_service) -> None:
        """å¤„ç†è§†é¢‘ï¼Œæå–å…³é”®ç‚¹å¹¶è¿›è¡Œé¢„æµ‹"""
        try:
            task = self.video_tasks.get(task_id)
            if not task:
                return
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            task["status"] = "processing"
            task["progress"] = 0.1
            
            # æå–å…³é”®ç‚¹
            landmarks = await self._extract_landmarks(task["video_path"], task_id)
            task["progress"] = 0.7
            
            if not landmarks:
                task["status"] = "error"
                task["error"] = "æ— æ³•ä»è§†é¢‘ä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹"
                return
            
            # ä½¿ç”¨å¢å¼ºæœåŠ¡è¿›è¡Œé¢„æµ‹
            prediction_result = await enhanced_service.predict_from_landmarks(landmarks)
            task["progress"] = 0.9
            
            # å®Œæˆå¤„ç†
            task["status"] = "completed"
            task["progress"] = 1.0
            task["result"] = prediction_result
            
            logger.info(f"è§†é¢‘ {task_id} å¤„ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å¤±è´¥ {task_id}: {e}")
            if task_id in self.video_tasks:
                self.video_tasks[task_id]["status"] = "error"
                self.video_tasks[task_id]["error"] = str(e)
    
    async def _extract_landmarks(self, video_path: str, task_id: str) -> List[List[float]]:
        """ä»è§†é¢‘ä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹"""
        try:
            if not self.mp:
                # æ¨¡æ‹Ÿå…³é”®ç‚¹æå–
                return self._generate_mock_landmarks()
            
            landmarks_sequence = []
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return self._generate_mock_landmarks()
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            frame_count = 0
            
            while cap.isOpened():
                success, image = cap.read()
                if not success:
                    break
                
                # æ›´æ–°è¿›åº¦
                frame_count += 1
                progress = 0.1 + (frame_count / total_frames) * 0.6  # 0.1-0.7
                if task_id in self.video_tasks:
                    self.video_tasks[task_id]["progress"] = progress
                
                # è½¬æ¢BGRåˆ°RGB
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                
                # æ£€æµ‹æ‰‹éƒ¨
                results = self.hands.process(image)
                
                if results.multi_hand_landmarks:
                    # æå–ç¬¬ä¸€åªæ‰‹çš„å…³é”®ç‚¹
                    hand_landmarks = results.multi_hand_landmarks[0]
                    landmarks = []
                    for lm in hand_landmarks.landmark:
                        landmarks.extend([lm.x, lm.y, lm.z])
                    
                    landmarks_sequence.append(landmarks)
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ‰‹éƒ¨ï¼Œæ·»åŠ é›¶å‘é‡
                    landmarks_sequence.append([0.0] * 63)  # 21ä¸ªå…³é”®ç‚¹ * 3ä¸ªåæ ‡
            
            cap.release()
            
            if not landmarks_sequence:
                logger.warning("è§†é¢‘ä¸­æœªæ£€æµ‹åˆ°æ‰‹éƒ¨å…³é”®ç‚¹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return self._generate_mock_landmarks()
            
            return landmarks_sequence
            
        except Exception as e:
            logger.error(f"å…³é”®ç‚¹æå–å¤±è´¥: {e}")
            return self._generate_mock_landmarks()
    
    def _generate_mock_landmarks(self) -> List[List[float]]:
        """ç”Ÿæˆæ¨¡æ‹Ÿå…³é”®ç‚¹æ•°æ®"""
        # ç”Ÿæˆ30å¸§çš„æ¨¡æ‹Ÿå…³é”®ç‚¹æ•°æ®
        mock_landmarks = []
        for _ in range(30):
            # æ¯å¸§21ä¸ªå…³é”®ç‚¹ï¼Œæ¯ä¸ªå…³é”®ç‚¹3ä¸ªåæ ‡
            frame_landmarks = [float(np.random.rand()) for _ in range(63)]
            mock_landmarks.append(frame_landmarks)
        
        logger.info("ç”Ÿæˆæ¨¡æ‹Ÿå…³é”®ç‚¹æ•°æ®")
        return mock_landmarks
    
    def get_task_status(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return self.video_tasks.get(task_id)
    
    def cleanup_old_tasks(self, max_age_hours: int = 24):
        """æ¸…ç†æ—§ä»»åŠ¡"""
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        to_remove = []
        for task_id, task in self.video_tasks.items():
            if current_time - task["created_at"] > max_age_seconds:
                # åˆ é™¤è§†é¢‘æ–‡ä»¶
                try:
                    video_path = Path(task["video_path"])
                    if video_path.exists():
                        video_path.unlink()
                except Exception as e:
                    logger.warning(f"åˆ é™¤è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                
                to_remove.append(task_id)
        
        for task_id in to_remove:
            del self.video_tasks[task_id]
        
        if to_remove:
            logger.info(f"æ¸…ç†äº† {len(to_remove)} ä¸ªæ—§ä»»åŠ¡")


class EnhancedCECSLService:
    """å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡"""
    
    def __init__(self):
        # é»˜è®¤è·¯å¾„
        self.model_path = Path("training/output/enhanced_cecsl_final_model.ckpt")
        self.vocab_path = Path("training/output/enhanced_vocab.json")
        
        self.model = None
        self.vocab = None
        self.reverse_vocab = None
        self.config = None
        self.is_loaded = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "predictions": 0,
            "errors": 0,
            "total_inference_time": 0.0,
            "avg_inference_time": 0.0
        }
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æœåŠ¡"""
        try:
            logger.info("åˆå§‹åŒ–å¢å¼ºç‰ˆCE-CSLæœåŠ¡...")
            
            # è®¾ç½®MindSporeä¸Šä¸‹æ–‡
            if MINDSPORE_AVAILABLE:
                ms_context.set_context(mode=ms_context.GRAPH_MODE, device_target="CPU")
            
            # åŠ è½½è¯æ±‡è¡¨
            await self._load_vocabulary()
            
            # åˆ›å»ºæ¨¡å‹é…ç½®
            self.config = EnhancedCECSLConfig(
                vocab_size=len(self.vocab)
            )
            
            # åŠ è½½æ¨¡å‹
            await self._load_model()
            
            self.is_loaded = True
            logger.info("å¢å¼ºç‰ˆCE-CSLæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"å¢å¼ºç‰ˆCE-CSLæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_loaded = False
            return False
    
    async def _load_vocabulary(self) -> None:
        """åŠ è½½è¯æ±‡è¡¨"""
        try:
            if not self.vocab_path.exists():
                logger.error(f"è¯æ±‡è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {self.vocab_path}")
                await self._create_default_vocabulary()
                return
            
            with open(self.vocab_path, 'r', encoding='utf-8') as f:
                vocab_data = json.load(f)
            
            # æ£€æŸ¥è¯æ±‡è¡¨æ ¼å¼
            if 'word2idx' in vocab_data:
                self.vocab = vocab_data['word2idx']
            else:
                self.vocab = vocab_data
            
            self.reverse_vocab = {v: k for k, v in self.vocab.items()}
            logger.info(f"è¯æ±‡è¡¨åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(self.vocab)} ä¸ªè¯æ±‡")
            
        except Exception as e:
            logger.error(f"è¯æ±‡è¡¨åŠ è½½å¤±è´¥: {e}")
            await self._create_default_vocabulary()
    
    async def _create_default_vocabulary(self) -> None:
        """åˆ›å»ºé»˜è®¤è¯æ±‡è¡¨"""
        default_vocab = {
            "<PAD>": 0, "<UNK>": 1, "ä½ å¥½": 2, "è°¢è°¢": 3, "å†è§": 4,
            "æ˜¯": 5, "ä¸æ˜¯": 6, "å¥½": 7, "ä¸å¥½": 8, "æˆ‘": 9, "ä½ ": 10,
        }
        
        self.vocab = default_vocab
        self.reverse_vocab = {v: k for k, v in default_vocab.items()}
        logger.warning("ä½¿ç”¨é»˜è®¤è¯æ±‡è¡¨")
    
    async def _load_model(self) -> None:
        """åŠ è½½æ¨¡å‹"""
        try:
            if not MINDSPORE_AVAILABLE:
                logger.warning("MindSporeä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹")
                self.model = ImprovedCECSLModel(self.config, len(self.vocab))
                logger.info("æ¨¡æ‹Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ")
                return
            
            if not self.model_path.exists():
                logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                self.model = ImprovedCECSLModel(self.config, len(self.vocab))
                logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹")
                return
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = ImprovedCECSLModel(self.config, len(self.vocab))
            
            # å¦‚æœMindSporeå¯ç”¨ï¼Œå°è¯•åŠ è½½checkpoint
            try:
                from mindspore import load_checkpoint, load_param_into_net
                param_dict = load_checkpoint(str(self.model_path))
                load_param_into_net(self.model, param_dict)
                logger.info(f"MindSporeæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            except Exception as e:
                logger.warning(f"MindSporeæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.set_train(False)
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = ImprovedCECSLModel(self.config, len(self.vocab))
    
    async def predict_from_landmarks(self, landmarks: List[List[float]]) -> Dict:
        """ä»å…³é”®ç‚¹é¢„æµ‹æ‰‹è¯­"""
        start_time = time.time()
        
        try:
            if not self.is_loaded:
                raise RuntimeError("æœåŠ¡æœªåˆå§‹åŒ–")
            
            # é¢„å¤„ç†è¾“å…¥æ•°æ®
            input_data = self._preprocess_landmarks(landmarks)
            
            # æ¨¡å‹æ¨ç†
            if MINDSPORE_AVAILABLE and self.model and hasattr(self.model, '_real_forward'):
                prediction = await self._mindspore_inference(input_data)
            else:
                prediction = await self._mock_inference(input_data)
            
            # åå¤„ç†
            result_dict = self._postprocess_prediction(prediction)
            
            # åˆ›å»ºç»“æœ
            inference_time = time.time() - start_time
            result = {
                **result_dict,
                "inference_time": inference_time,
                "timestamp": time.time(),
                "status": "success"
            }
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_stats(inference_time, True)
            
            return result
            
        except Exception as e:
            inference_time = time.time() - start_time
            logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
            self._update_stats(inference_time, False)
            
            return {
                "text": "",
                "confidence": 0.0,
                "gloss_sequence": [],
                "inference_time": inference_time,
                "timestamp": time.time(),
                "status": "error",
                "error": str(e)
            }
    
    def _preprocess_landmarks(self, landmarks: List[List[float]]) -> np.ndarray:
        """é¢„å¤„ç†å…³é”®ç‚¹æ•°æ®"""
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            landmarks_array = np.array(landmarks, dtype=np.float32)
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å¸§æ•°
            target_frames = self.config.max_sequence_length
            if landmarks_array.shape[0] < target_frames:
                # é‡å¤æœ€åä¸€å¸§æ¥å¡«å……
                pad_frames = target_frames - landmarks_array.shape[0]
                last_frame = landmarks_array[-1:] if landmarks_array.shape[0] > 0 else np.zeros((1, landmarks_array.shape[1]))
                landmarks_array = np.concatenate([landmarks_array] + [last_frame] * pad_frames, axis=0)
            elif landmarks_array.shape[0] > target_frames:
                # æˆªæ–­
                landmarks_array = landmarks_array[:target_frames]
            
            # æ¨¡æ‹Ÿè½¬æ¢ä¸ºå›¾åƒç‰¹å¾ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            image_size = self.config.image_size[0] * self.config.image_size[1] * 3
            
            # å°†å…³é”®ç‚¹ç‰¹å¾æ˜ å°„åˆ°å›¾åƒç‰¹å¾ç©ºé—´
            if landmarks_array.shape[1] < image_size:
                # æ‰©å±•ç‰¹å¾ç»´åº¦
                scale_factor = image_size // landmarks_array.shape[1] + 1
                expanded = np.tile(landmarks_array, (1, scale_factor))[:, :image_size]
            else:
                expanded = landmarks_array[:, :image_size]
            
            # æ·»åŠ batchç»´åº¦
            batch_data = expanded[np.newaxis, :]  # (1, seq_len, feature_dim)
            
            return batch_data
            
        except Exception as e:
            logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ•°æ®
            image_size = self.config.image_size[0] * self.config.image_size[1] * 3
            return np.random.rand(1, self.config.max_sequence_length, image_size).astype(np.float32)
    
    async def _mindspore_inference(self, input_data: np.ndarray) -> np.ndarray:
        """MindSporeæ¨¡å‹æ¨ç†"""
        try:
            if MINDSPORE_AVAILABLE and Tensor:
                # è½¬æ¢ä¸ºTensor
                input_tensor = Tensor(input_data, ms.float32)
                # æ¨ç†
                output = self.model(input_tensor)
                # è½¬æ¢å›numpy
                if hasattr(output, 'asnumpy'):
                    return output.asnumpy()
                else:
                    return output
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿæ¨ç†
                return self.model(input_data)
            
        except Exception as e:
            logger.error(f"MindSporeæ¨ç†å¤±è´¥: {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿæ¨ç†
            return await self._mock_inference(input_data)
    
    async def _mock_inference(self, input_data: np.ndarray) -> np.ndarray:
        """æ¨¡æ‹Ÿæ¨ç†"""
        await asyncio.sleep(0.02)  # æ¨¡æ‹Ÿæ¨ç†æ—¶é—´
        
        if self.model:
            return self.model(input_data)
        else:
            vocab_size = len(self.vocab)
            # è¿”å›éšæœºé¢„æµ‹
            prediction = np.random.rand(vocab_size).astype(np.float32)
            # åº”ç”¨softmax
            exp_pred = np.exp(prediction - np.max(prediction))
            return exp_pred / np.sum(exp_pred)
    
    def _postprocess_prediction(self, prediction: np.ndarray) -> Dict:
        """åå¤„ç†é¢„æµ‹ç»“æœ"""
        try:
            # è·å–æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«
            if prediction.ndim == 1:
                probabilities = prediction
            else:
                probabilities = prediction.flatten()
            
            top_idx = np.argmax(probabilities)
            confidence = float(probabilities[top_idx])
            
            # è·å–å¯¹åº”çš„è¯æ±‡
            if top_idx in self.reverse_vocab:
                predicted_word = self.reverse_vocab[top_idx]
            else:
                predicted_word = "<UNK>"
            
            # è·å–top-5é¢„æµ‹ç”¨äºglossåºåˆ—
            top5_indices = np.argsort(probabilities)[-5:][::-1]
            gloss_sequence = []
            for idx in top5_indices:
                if idx in self.reverse_vocab and probabilities[idx] > 0.1:
                    gloss_sequence.append(self.reverse_vocab[idx])
            
            return {
                "text": predicted_word,
                "confidence": confidence,
                "gloss_sequence": gloss_sequence
            }
            
        except Exception as e:
            logger.error(f"åå¤„ç†å¤±è´¥: {e}")
            return {
                "text": "<UNK>",
                "confidence": 0.0,
                "gloss_sequence": []
            }
    
    def _update_stats(self, inference_time: float, success: bool) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["predictions"] += 1
        if not success:
            self.stats["errors"] += 1
        
        self.stats["total_inference_time"] += inference_time
        self.stats["avg_inference_time"] = (
            self.stats["total_inference_time"] / self.stats["predictions"]
        )
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
enhanced_service = EnhancedCECSLService()
video_service = VideoProcessingService()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡",
    description="åŸºäºè®­ç»ƒå¥½çš„enhanced_cecsl_final_model.ckptæ¨¡å‹çš„Web API",
    version="1.0.0"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æœåŠ¡"""
    logger.info("å¯åŠ¨å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡...")
    success = await enhanced_service.initialize()
    if success:
        logger.info("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ")
    else:
        logger.warning("âš ï¸ æœåŠ¡å¯åŠ¨å¼‚å¸¸ï¼Œä½†å°†ç»§ç»­è¿è¡Œï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
    
    # å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡
    async def periodic_cleanup():
        while True:
            await asyncio.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
            video_service.cleanup_old_tasks()
    
    asyncio.create_task(periodic_cleanup())


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": enhanced_service.is_loaded
    }


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "message": "å¢å¼ºç‰ˆCE-CSLæœåŠ¡è¿è¡Œæ­£å¸¸",
        "services": {
            "enhanced_cecsl": "ready" if enhanced_service.is_loaded else "not_ready"
        }
    }


@app.post("/api/enhanced-cecsl/test", response_model=EnhancedCECSLTestResponse)
async def test_enhanced_cecsl_model(request: EnhancedCECSLTestRequest):
    """æµ‹è¯•å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æ¨¡å‹"""
    try:
        if not enhanced_service.is_loaded:
            raise HTTPException(
                status_code=503, 
                detail="å¢å¼ºç‰ˆCE-CSLæœåŠ¡æœªå°±ç»ª"
            )
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæœåŠ¡è¿›è¡Œé¢„æµ‹
        result = await enhanced_service.predict_from_landmarks(request.landmarks)
        
        # è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
        stats = enhanced_service.get_stats()
        
        return EnhancedCECSLTestResponse(
            success=True,
            message="é¢„æµ‹æˆåŠŸ",
            prediction=result,
            stats=stats
        )
        
    except Exception as e:
        logger.error(f"å¢å¼ºç‰ˆCE-CSLé¢„æµ‹å¤±è´¥: {e}")
        return EnhancedCECSLTestResponse(
            success=False,
            message=f"é¢„æµ‹å¤±è´¥: {str(e)}",
            prediction=None,
            stats=None
        )


@app.get("/api/enhanced-cecsl/stats")
async def get_enhanced_cecsl_stats():
    """è·å–å¢å¼ºç‰ˆCE-CSLæœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = enhanced_service.get_stats()
        return {
            "success": True,
            "stats": stats,
            "model_info": {
                "model_path": str(enhanced_service.model_path),
                "vocab_path": str(enhanced_service.vocab_path),
                "vocab_size": len(enhanced_service.vocab) if enhanced_service.vocab else 0,
                "is_loaded": enhanced_service.is_loaded
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–å¢å¼ºç‰ˆCE-CSLç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )


@app.post("/api/enhanced-cecsl/upload-video", response_model=VideoUploadResponse)
async def upload_video(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
):
    """ä¸Šä¼ è§†é¢‘æ–‡ä»¶è¿›è¡Œæ‰‹è¯­è¯†åˆ«"""
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
        
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in ['.mp4', '.avi', '.mov', '.mkv', '.webm']:
            raise HTTPException(
                status_code=400, 
                detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  mp4, avi, mov, mkv æˆ– webm æ ¼å¼çš„è§†é¢‘"
            )
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º100MBï¼‰
        file_size = 0
        temp_content = await file.read()
        file_size = len(temp_content)
        
        # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        await file.seek(0)
        
        if file_size > 100 * 1024 * 1024:  # 100MB
            raise HTTPException(
                status_code=413, 
                detail="æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§100MBï¼‰"
            )
        
        # ä¿å­˜æ–‡ä»¶å¹¶åˆ›å»ºä»»åŠ¡
        task_id, video_path = await video_service.save_uploaded_video(file)
        
        # åœ¨åå°å¤„ç†è§†é¢‘
        background_tasks.add_task(
            video_service.process_video, 
            task_id, 
            enhanced_service
        )
        
        return VideoUploadResponse(
            success=True,
            task_id=task_id,
            message="è§†é¢‘ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨å¤„ç†ä¸­",
            status="uploaded"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}"
        )


@app.get("/api/enhanced-cecsl/video-status/{task_id}", response_model=VideoStatusResponse)
async def get_video_status(task_id: str):
    """è·å–è§†é¢‘å¤„ç†çŠ¶æ€"""
    try:
        task = video_service.get_task_status(task_id)
        
        if not task:
            raise HTTPException(
                status_code=404, 
                detail="ä»»åŠ¡ä¸å­˜åœ¨"
            )
        
        return VideoStatusResponse(
            task_id=task_id,
            status=task["status"],
            progress=task["progress"],
            result=task["result"],
            error=task["error"]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"è·å–è§†é¢‘çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@app.delete("/api/enhanced-cecsl/video-task/{task_id}")
async def delete_video_task(task_id: str):
    """åˆ é™¤è§†é¢‘å¤„ç†ä»»åŠ¡"""
    try:
        task = video_service.get_task_status(task_id)
        
        if not task:
            raise HTTPException(
                status_code=404, 
                detail="ä»»åŠ¡ä¸å­˜åœ¨"
            )
        
        # åˆ é™¤è§†é¢‘æ–‡ä»¶
        try:
            video_path = Path(task["video_path"])
            if video_path.exists():
                video_path.unlink()
        except Exception as e:
            logger.warning(f"åˆ é™¤è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        
        # åˆ é™¤ä»»åŠ¡è®°å½•
        del video_service.video_tasks[task_id]
        
        return {
            "success": True,
            "message": "ä»»åŠ¡åˆ é™¤æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤è§†é¢‘ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"åˆ é™¤è§†é¢‘ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆCE-CSLæ‰‹è¯­è¯†åˆ«æœåŠ¡...")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=False,
        access_log=True
    )
