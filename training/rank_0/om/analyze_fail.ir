# ===============================================================================================
# The following shows the last analyze fail log message.
# ===============================================================================================

----------------------------------------------------
- Caught exception:
----------------------------------------------------
TypeError: The input of max() only support Tensor, List, Tuple, constant Scalar, but got variable Int64

At:
  /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/multitype_ops/_constexpr_utils.py(88): raise_type_error
  /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/primitive.py(822): __infer__


----------------------------------------------------
- The Traceback of Net Construct Code:
----------------------------------------------------
# 0 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                               ^
# 1 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 2 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 3 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 4 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 5 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 6 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 7 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 8 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 9 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 10 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 11 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 12 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 13 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 14 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 15 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 16 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 17 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 18 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 19 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 20 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 21 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 22 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 23 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 24 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 25 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 26 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 27 In file /data/shengteng/training/train_tfnet_gpu.py:629
                        if hasattr(output, 'shape'):
# 28 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 29 In file /data/shengteng/training/train_tfnet_gpu.py:628
                    for i, output in enumerate(model_output):
# 30 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 31 In file /data/shengteng/training/train_tfnet_gpu.py:640
                    for logits_idx, logits in enumerate(logits_list):
                    ^
# 32 In file /data/shengteng/training/train_tfnet_gpu.py:642
                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):
                        ^
# 33 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                                     ^
# 34 In file /data/shengteng/training/train_tfnet_gpu.py:682
                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:
# 35 In file /data/shengteng/training/train_tfnet_gpu.py:685
                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)
                                                ^
# 36 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642
    if len_data <= 0:
# 37 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644
    elif len_data == 1:
# 38 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647
    elif len_data >= 2:
# 39 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650
        if tensor_num == len_data:
# 40 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652
        if tensor_num != 0:
# 41 In file /data/shengteng/training/train_tfnet_gpu.py:685
                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)
                                                ^
# 42 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656
        if exist_tensor(data):
# 43 In file /data/shengteng/training/train_tfnet_gpu.py:685
                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)
                                                ^
# 44 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647
    elif len_data >= 2:
# 45 In file /data/shengteng/training/train_tfnet_gpu.py:685
                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)
                                                ^
# 46 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659
    for input_data in data:
# 47 In file /data/shengteng/training/train_tfnet_gpu.py:685
                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)
                                                ^
# 48 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659
    for input_data in data:
# 49 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2660
        check_isconstant(input_data, "max()")
        ^
# 50 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603
    if not F.isconstant(input_data):
# 51 In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604
        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"
        ^

# ===============================================================================================
# The following shows the IR when the function graphs evaluation fails to help locate the problem.
# You can search the last ------------------------> to the node which is evaluated failure.
# Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
# ===============================================================================================

# IR entry: @after_grad_108
# Total subgraphs: 925

# Total params: 148
# Params:
%para1_args0 : <null>
%para2_args1 : <null>
%para3_args2 : <null>
%para4_args3 : <null>
%para5_conv2d.conv1.weight : <Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:conv2d.conv1.weight>  :  has_default
%para6_conv2d.bn1.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.gamma>  :  has_default
%para7_conv2d.bn1.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.beta>  :  has_default
%para8_conv2d.layer1.0.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.0.weight>  :  has_default
%para9_conv2d.layer1.1.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.gamma>  :  has_default
%para10_conv2d.layer1.1.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.beta>  :  has_default
%para11_conv2d.layer1.3.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.3.weight>  :  has_default
%para12_conv2d.layer1.4.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.gamma>  :  has_default
%para13_conv2d.layer1.4.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.beta>  :  has_default
%para14_conv2d.layer1.6.weight : <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.6.weight>  :  has_default
%para15_conv2d.layer1.7.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.gamma>  :  has_default
%para16_conv2d.layer1.7.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.beta>  :  has_default
%para17_conv2d.layer2.0.weight : <Ref[Tensor[Float32]], (128, 64, 3, 3), ref_key=:conv2d.layer2.0.weight>  :  has_default
%para18_conv2d.layer2.1.gamma : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.gamma>  :  has_default
%para19_conv2d.layer2.1.beta : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.beta>  :  has_default
%para20_conv2d.layer2.3.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.3.weight>  :  has_default
%para21_conv2d.layer2.4.gamma : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.gamma>  :  has_default
%para22_conv2d.layer2.4.beta : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.beta>  :  has_default
%para23_conv2d.layer2.6.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.6.weight>  :  has_default
%para24_conv2d.layer2.7.gamma : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.gamma>  :  has_default
%para25_conv2d.layer2.7.beta : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.beta>  :  has_default
%para26_conv2d.layer2.9.weight : <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.9.weight>  :  has_default
%para27_conv2d.layer2.10.gamma : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.gamma>  :  has_default
%para28_conv2d.layer2.10.beta : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.beta>  :  has_default
%para29_conv2d.layer3.0.weight : <Ref[Tensor[Float32]], (256, 128, 3, 3), ref_key=:conv2d.layer3.0.weight>  :  has_default
%para30_conv2d.layer3.1.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.gamma>  :  has_default
%para31_conv2d.layer3.1.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.beta>  :  has_default
%para32_conv2d.layer3.3.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.3.weight>  :  has_default
%para33_conv2d.layer3.4.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.gamma>  :  has_default
%para34_conv2d.layer3.4.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.beta>  :  has_default
%para35_conv2d.layer3.6.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.6.weight>  :  has_default
%para36_conv2d.layer3.7.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.gamma>  :  has_default
%para37_conv2d.layer3.7.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.beta>  :  has_default
%para38_conv2d.layer3.9.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.9.weight>  :  has_default
%para39_conv2d.layer3.10.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.gamma>  :  has_default
%para40_conv2d.layer3.10.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.beta>  :  has_default
%para41_conv2d.layer3.12.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.12.weight>  :  has_default
%para42_conv2d.layer3.13.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.gamma>  :  has_default
%para43_conv2d.layer3.13.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.beta>  :  has_default
%para44_conv2d.layer3.15.weight : <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.15.weight>  :  has_default
%para45_conv2d.layer3.16.gamma : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.gamma>  :  has_default
%para46_conv2d.layer3.16.beta : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.beta>  :  has_default
%para47_conv2d.layer4.0.weight : <Ref[Tensor[Float32]], (512, 256, 3, 3), ref_key=:conv2d.layer4.0.weight>  :  has_default
%para48_conv2d.layer4.1.gamma : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.gamma>  :  has_default
%para49_conv2d.layer4.1.beta : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.beta>  :  has_default
%para50_conv2d.layer4.3.weight : <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:conv2d.layer4.3.weight>  :  has_default
%para51_conv2d.layer4.4.gamma : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.gamma>  :  has_default
%para52_conv2d.layer4.4.beta : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.beta>  :  has_default
%para53_conv2d.layer4.6.weight : <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:conv2d.layer4.6.weight>  :  has_default
%para54_conv2d.layer4.7.gamma : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.gamma>  :  has_default
%para55_conv2d.layer4.7.beta : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.beta>  :  has_default
%para56_conv1d.temporal_conv.0.weight : <Ref[Tensor[Float32]], (64, 512, 1, 5), ref_key=:conv1d.temporal_conv.0.weight>  :  has_default
%para57_conv1d.temporal_conv.0.bias : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.0.bias>  :  has_default
%para58_conv1d.temporal_conv.1.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.gamma>  :  has_default
%para59_conv1d.temporal_conv.1.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.beta>  :  has_default
%para60_conv1d.temporal_conv.4.weight : <Ref[Tensor[Float32]], (64, 64, 1, 5), ref_key=:conv1d.temporal_conv.4.weight>  :  has_default
%para61_conv1d.temporal_conv.4.bias : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.4.bias>  :  has_default
%para62_conv1d.temporal_conv.5.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.gamma>  :  has_default
%para63_conv1d.temporal_conv.5.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.beta>  :  has_default
%para64_conv1d1.temporal_conv.0.weight : <Ref[Tensor[Float32]], (64, 512, 1, 5), ref_key=:conv1d1.temporal_conv.0.weight>  :  has_default
%para65_conv1d1.temporal_conv.0.bias : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.0.bias>  :  has_default
%para66_conv1d1.temporal_conv.1.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.gamma>  :  has_default
%para67_conv1d1.temporal_conv.1.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.beta>  :  has_default
%para68_conv1d1.temporal_conv.4.weight : <Ref[Tensor[Float32]], (64, 64, 1, 5), ref_key=:conv1d1.temporal_conv.4.weight>  :  has_default
%para69_conv1d1.temporal_conv.4.bias : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.4.bias>  :  has_default
%para70_conv1d1.temporal_conv.5.gamma : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.gamma>  :  has_default
%para71_conv1d1.temporal_conv.5.beta : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.beta>  :  has_default
%para72_temporal_model.rnn.weight_ih_l0 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_ih_l0>  :  has_default
%para73_temporal_model.rnn.weight_ih_l0_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_ih_l0_reverse>  :  has_default
%para74_temporal_model.rnn.weight_ih_l1 : <Ref[Tensor[Float32]], (256, 128), ref_key=:temporal_model.rnn.weight_ih_l1>  :  has_default
%para75_temporal_model.rnn.weight_ih_l1_reverse : <Ref[Tensor[Float32]], (256, 128), ref_key=:temporal_model.rnn.weight_ih_l1_reverse>  :  has_default
%para76_temporal_model.rnn.weight_hh_l0 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_hh_l0>  :  has_default
%para77_temporal_model.rnn.weight_hh_l0_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_hh_l0_reverse>  :  has_default
%para78_temporal_model.rnn.weight_hh_l1 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_hh_l1>  :  has_default
%para79_temporal_model.rnn.weight_hh_l1_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model.rnn.weight_hh_l1_reverse>  :  has_default
%para80_temporal_model.rnn.bias_ih_l0 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_ih_l0>  :  has_default
%para81_temporal_model.rnn.bias_ih_l0_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_ih_l0_reverse>  :  has_default
%para82_temporal_model.rnn.bias_ih_l1 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_ih_l1>  :  has_default
%para83_temporal_model.rnn.bias_ih_l1_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_ih_l1_reverse>  :  has_default
%para84_temporal_model.rnn.bias_hh_l0 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_hh_l0>  :  has_default
%para85_temporal_model.rnn.bias_hh_l0_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_hh_l0_reverse>  :  has_default
%para86_temporal_model.rnn.bias_hh_l1 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_hh_l1>  :  has_default
%para87_temporal_model.rnn.bias_hh_l1_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model.rnn.bias_hh_l1_reverse>  :  has_default
%para88_temporal_model1.rnn.weight_ih_l0 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_ih_l0>  :  has_default
%para89_temporal_model1.rnn.weight_ih_l0_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_ih_l0_reverse>  :  has_default
%para90_temporal_model1.rnn.weight_ih_l1 : <Ref[Tensor[Float32]], (256, 128), ref_key=:temporal_model1.rnn.weight_ih_l1>  :  has_default
%para91_temporal_model1.rnn.weight_ih_l1_reverse : <Ref[Tensor[Float32]], (256, 128), ref_key=:temporal_model1.rnn.weight_ih_l1_reverse>  :  has_default
%para92_temporal_model1.rnn.weight_hh_l0 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_hh_l0>  :  has_default
%para93_temporal_model1.rnn.weight_hh_l0_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_hh_l0_reverse>  :  has_default
%para94_temporal_model1.rnn.weight_hh_l1 : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_hh_l1>  :  has_default
%para95_temporal_model1.rnn.weight_hh_l1_reverse : <Ref[Tensor[Float32]], (256, 64), ref_key=:temporal_model1.rnn.weight_hh_l1_reverse>  :  has_default
%para96_temporal_model1.rnn.bias_ih_l0 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_ih_l0>  :  has_default
%para97_temporal_model1.rnn.bias_ih_l0_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_ih_l0_reverse>  :  has_default
%para98_temporal_model1.rnn.bias_ih_l1 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_ih_l1>  :  has_default
%para99_temporal_model1.rnn.bias_ih_l1_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_ih_l1_reverse>  :  has_default
%para100_temporal_model1.rnn.bias_hh_l0 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_hh_l0>  :  has_default
%para101_temporal_model1.rnn.bias_hh_l0_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_hh_l0_reverse>  :  has_default
%para102_temporal_model1.rnn.bias_hh_l1 : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_hh_l1>  :  has_default
%para103_temporal_model1.rnn.bias_hh_l1_reverse : <Ref[Tensor[Float32]], (256), ref_key=:temporal_model1.rnn.bias_hh_l1_reverse>  :  has_default
%para104_classifier22.weight : <Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier22.weight>  :  has_default
%para105_classifier44.weight : <Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier44.weight>  :  has_default
%para106_classifier55.weight : <Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier55.weight>  :  has_default
%para107_conv2d.bn1.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.moving_mean>  :  has_default
%para108_conv2d.bn1.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.moving_variance>  :  has_default
%para109_conv2d.layer4.1.moving_mean : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.moving_mean>  :  has_default
%para110_conv2d.layer4.1.moving_variance : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.moving_variance>  :  has_default
%para111_conv2d.layer4.4.moving_mean : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.moving_mean>  :  has_default
%para112_conv2d.layer4.4.moving_variance : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.moving_variance>  :  has_default
%para113_conv2d.layer4.7.moving_mean : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.moving_mean>  :  has_default
%para114_conv2d.layer4.7.moving_variance : <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.moving_variance>  :  has_default
%para115_conv1d1.temporal_conv.1.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.moving_mean>  :  has_default
%para116_conv1d1.temporal_conv.1.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.moving_variance>  :  has_default
%para117_conv1d1.temporal_conv.5.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.moving_mean>  :  has_default
%para118_conv1d1.temporal_conv.5.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.moving_variance>  :  has_default
%para119_conv1d.temporal_conv.1.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.moving_mean>  :  has_default
%para120_conv1d.temporal_conv.1.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.moving_variance>  :  has_default
%para121_conv1d.temporal_conv.5.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.moving_mean>  :  has_default
%para122_conv1d.temporal_conv.5.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.moving_variance>  :  has_default
%para123_conv2d.layer3.1.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.moving_mean>  :  has_default
%para124_conv2d.layer3.1.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.moving_variance>  :  has_default
%para125_conv2d.layer3.4.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.moving_mean>  :  has_default
%para126_conv2d.layer3.4.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.moving_variance>  :  has_default
%para127_conv2d.layer3.7.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.moving_mean>  :  has_default
%para128_conv2d.layer3.7.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.moving_variance>  :  has_default
%para129_conv2d.layer3.10.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.moving_mean>  :  has_default
%para130_conv2d.layer3.10.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.moving_variance>  :  has_default
%para131_conv2d.layer3.13.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.moving_mean>  :  has_default
%para132_conv2d.layer3.13.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.moving_variance>  :  has_default
%para133_conv2d.layer3.16.moving_mean : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.moving_mean>  :  has_default
%para134_conv2d.layer3.16.moving_variance : <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.moving_variance>  :  has_default
%para135_conv2d.layer2.1.moving_mean : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.moving_mean>  :  has_default
%para136_conv2d.layer2.1.moving_variance : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.moving_variance>  :  has_default
%para137_conv2d.layer2.4.moving_mean : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.moving_mean>  :  has_default
%para138_conv2d.layer2.4.moving_variance : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.moving_variance>  :  has_default
%para139_conv2d.layer2.7.moving_mean : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.moving_mean>  :  has_default
%para140_conv2d.layer2.7.moving_variance : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.moving_variance>  :  has_default
%para141_conv2d.layer2.10.moving_mean : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.moving_mean>  :  has_default
%para142_conv2d.layer2.10.moving_variance : <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.moving_variance>  :  has_default
%para143_conv2d.layer1.1.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.moving_mean>  :  has_default
%para144_conv2d.layer1.1.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.moving_variance>  :  has_default
%para145_conv2d.layer1.4.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.moving_mean>  :  has_default
%para146_conv2d.layer1.4.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.moving_variance>  :  has_default
%para147_conv2d.layer1.7.moving_mean : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.moving_mean>  :  has_default
%para148_conv2d.layer1.7.moving_variance : <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.moving_variance>  :  has_default

subgraph attr:
subgraph instance: after_grad_108 : 0x37ac28a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
subgraph @after_grad_108(%para1_args0, %para2_args1, %para3_args2, %para4_args3, %para5_conv2d.conv1.weight, %para6_conv2d.bn1.gamma, %para7_conv2d.bn1.beta, %para8_conv2d.layer1.0.weight, %para9_conv2d.layer1.1.gamma, %para10_conv2d.layer1.1.beta, %para11_conv2d.layer1.3.weight, %para12_conv2d.layer1.4.gamma, %para13_conv2d.layer1.4.beta, %para14_conv2d.layer1.6.weight, %para15_conv2d.layer1.7.gamma, %para16_conv2d.layer1.7.beta, %para17_conv2d.layer2.0.weight, %para18_conv2d.layer2.1.gamma, %para19_conv2d.layer2.1.beta, %para20_conv2d.layer2.3.weight, %para21_conv2d.layer2.4.gamma, %para22_conv2d.layer2.4.beta, %para23_conv2d.layer2.6.weight, %para24_conv2d.layer2.7.gamma, %para25_conv2d.layer2.7.beta, %para26_conv2d.layer2.9.weight, %para27_conv2d.layer2.10.gamma, %para28_conv2d.layer2.10.beta, %para29_conv2d.layer3.0.weight, %para30_conv2d.layer3.1.gamma, %para31_conv2d.layer3.1.beta, %para32_conv2d.layer3.3.weight, %para33_conv2d.layer3.4.gamma, %para34_conv2d.layer3.4.beta, %para35_conv2d.layer3.6.weight, %para36_conv2d.layer3.7.gamma, %para37_conv2d.layer3.7.beta, %para38_conv2d.layer3.9.weight, %para39_conv2d.layer3.10.gamma, %para40_conv2d.layer3.10.beta, %para41_conv2d.layer3.12.weight, %para42_conv2d.layer3.13.gamma, %para43_conv2d.layer3.13.beta, %para44_conv2d.layer3.15.weight, %para45_conv2d.layer3.16.gamma, %para46_conv2d.layer3.16.beta, %para47_conv2d.layer4.0.weight, %para48_conv2d.layer4.1.gamma, %para49_conv2d.layer4.1.beta, %para50_conv2d.layer4.3.weight, %para51_conv2d.layer4.4.gamma, %para52_conv2d.layer4.4.beta, %para53_conv2d.layer4.6.weight, %para54_conv2d.layer4.7.gamma, %para55_conv2d.layer4.7.beta, %para56_conv1d.temporal_conv.0.weight, %para57_conv1d.temporal_conv.0.bias, %para58_conv1d.temporal_conv.1.gamma, %para59_conv1d.temporal_conv.1.beta, %para60_conv1d.temporal_conv.4.weight, %para61_conv1d.temporal_conv.4.bias, %para62_conv1d.temporal_conv.5.gamma, %para63_conv1d.temporal_conv.5.beta, %para64_conv1d1.temporal_conv.0.weight, %para65_conv1d1.temporal_conv.0.bias, %para66_conv1d1.temporal_conv.1.gamma, %para67_conv1d1.temporal_conv.1.beta, %para68_conv1d1.temporal_conv.4.weight, %para69_conv1d1.temporal_conv.4.bias, %para70_conv1d1.temporal_conv.5.gamma, %para71_conv1d1.temporal_conv.5.beta, %para72_temporal_model.rnn.weight_ih_l0, %para73_temporal_model.rnn.weight_ih_l0_reverse, %para74_temporal_model.rnn.weight_ih_l1, %para75_temporal_model.rnn.weight_ih_l1_reverse, %para76_temporal_model.rnn.weight_hh_l0, %para77_temporal_model.rnn.weight_hh_l0_reverse, %para78_temporal_model.rnn.weight_hh_l1, %para79_temporal_model.rnn.weight_hh_l1_reverse, %para80_temporal_model.rnn.bias_ih_l0, %para81_temporal_model.rnn.bias_ih_l0_reverse, %para82_temporal_model.rnn.bias_ih_l1, %para83_temporal_model.rnn.bias_ih_l1_reverse, %para84_temporal_model.rnn.bias_hh_l0, %para85_temporal_model.rnn.bias_hh_l0_reverse, %para86_temporal_model.rnn.bias_hh_l1, %para87_temporal_model.rnn.bias_hh_l1_reverse, %para88_temporal_model1.rnn.weight_ih_l0, %para89_temporal_model1.rnn.weight_ih_l0_reverse, %para90_temporal_model1.rnn.weight_ih_l1, %para91_temporal_model1.rnn.weight_ih_l1_reverse, %para92_temporal_model1.rnn.weight_hh_l0, %para93_temporal_model1.rnn.weight_hh_l0_reverse, %para94_temporal_model1.rnn.weight_hh_l1, %para95_temporal_model1.rnn.weight_hh_l1_reverse, %para96_temporal_model1.rnn.bias_ih_l0, %para97_temporal_model1.rnn.bias_ih_l0_reverse, %para98_temporal_model1.rnn.bias_ih_l1, %para99_temporal_model1.rnn.bias_ih_l1_reverse, %para100_temporal_model1.rnn.bias_hh_l0, %para101_temporal_model1.rnn.bias_hh_l0_reverse, %para102_temporal_model1.rnn.bias_hh_l1, %para103_temporal_model1.rnn.bias_hh_l1_reverse, %para104_classifier22.weight, %para105_classifier44.weight, %para106_classifier55.weight, %para107_conv2d.bn1.moving_mean, %para108_conv2d.bn1.moving_variance, %para109_conv2d.layer4.1.moving_mean, %para110_conv2d.layer4.1.moving_variance, %para111_conv2d.layer4.4.moving_mean, %para112_conv2d.layer4.4.moving_variance, %para113_conv2d.layer4.7.moving_mean, %para114_conv2d.layer4.7.moving_variance, %para115_conv1d1.temporal_conv.1.moving_mean, %para116_conv1d1.temporal_conv.1.moving_variance, %para117_conv1d1.temporal_conv.5.moving_mean, %para118_conv1d1.temporal_conv.5.moving_variance, %para119_conv1d.temporal_conv.1.moving_mean, %para120_conv1d.temporal_conv.1.moving_variance, %para121_conv1d.temporal_conv.5.moving_mean, %para122_conv1d.temporal_conv.5.moving_variance, %para123_conv2d.layer3.1.moving_mean, %para124_conv2d.layer3.1.moving_variance, %para125_conv2d.layer3.4.moving_mean, %para126_conv2d.layer3.4.moving_variance, %para127_conv2d.layer3.7.moving_mean, %para128_conv2d.layer3.7.moving_variance, %para129_conv2d.layer3.10.moving_mean, %para130_conv2d.layer3.10.moving_variance, %para131_conv2d.layer3.13.moving_mean, %para132_conv2d.layer3.13.moving_variance, %para133_conv2d.layer3.16.moving_mean, %para134_conv2d.layer3.16.moving_variance, %para135_conv2d.layer2.1.moving_mean, %para136_conv2d.layer2.1.moving_variance, %para137_conv2d.layer2.4.moving_mean, %para138_conv2d.layer2.4.moving_variance, %para139_conv2d.layer2.7.moving_mean, %para140_conv2d.layer2.7.moving_variance, %para141_conv2d.layer2.10.moving_mean, %para142_conv2d.layer2.10.moving_variance, %para143_conv2d.layer1.1.moving_mean, %para144_conv2d.layer1.1.moving_variance, %para145_conv2d.layer1.4.moving_mean, %para146_conv2d.layer1.4.moving_variance, %para147_conv2d.layer1.7.moving_mean, %para148_conv2d.layer1.7.moving_variance) {
  %1(CNode_146) = MakeTuple(%para1_args0, %para2_args1, %para3_args2, %para4_args3)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1, 50)>, <Tensor[Int32], (1)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
  %2(147) = UnpackGraph(@forward_fn_3, %1)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(CNode_148) = MakeTuple(%para5_conv2d.conv1.weight, %para6_conv2d.bn1.gamma, %para7_conv2d.bn1.beta, %para8_conv2d.layer1.0.weight, %para9_conv2d.layer1.1.gamma, %para10_conv2d.layer1.1.beta, %para11_conv2d.layer1.3.weight, %para12_conv2d.layer1.4.gamma, %para13_conv2d.layer1.4.beta, %para14_conv2d.layer1.6.weight, %para15_conv2d.layer1.7.gamma, %para16_conv2d.layer1.7.beta, %para17_conv2d.layer2.0.weight, %para18_conv2d.layer2.1.gamma, %para19_conv2d.layer2.1.beta, %para20_conv2d.layer2.3.weight, %para21_conv2d.layer2.4.gamma, %para22_conv2d.layer2.4.beta, %para23_conv2d.layer2.6.weight, %para24_conv2d.layer2.7.gamma, %para25_conv2d.layer2.7.beta, %para26_conv2d.layer2.9.weight, %para27_conv2d.layer2.10.gamma, %para28_conv2d.layer2.10.beta, %para29_conv2d.layer3.0.weight, %para30_conv2d.layer3.1.gamma, %para31_conv2d.layer3.1.beta, %para32_conv2d.layer3.3.weight, %para33_conv2d.layer3.4.gamma, %para34_conv2d.layer3.4.beta, %para35_conv2d.layer3.6.weight, %para36_conv2d.layer3.7.gamma, %para37_conv2d.layer3.7.beta, %para38_conv2d.layer3.9.weight, %para39_conv2d.layer3.10.gamma, %para40_conv2d.layer3.10.beta, %para41_conv2d.layer3.12.weight, %para42_conv2d.layer3.13.gamma, %para43_conv2d.layer3.13.beta, %para44_conv2d.layer3.15.weight, %para45_conv2d.layer3.16.gamma, %para46_conv2d.layer3.16.beta, %para47_conv2d.layer4.0.weight, %para48_conv2d.layer4.1.gamma, %para49_conv2d.layer4.1.beta, %para50_conv2d.layer4.3.weight, %para51_conv2d.layer4.4.gamma, %para52_conv2d.layer4.4.beta, %para53_conv2d.layer4.6.weight, %para54_conv2d.layer4.7.gamma, %para55_conv2d.layer4.7.beta, %para56_conv1d.temporal_conv.0.weight, %para57_conv1d.temporal_conv.0.bias, %para58_conv1d.temporal_conv.1.gamma, %para59_conv1d.temporal_conv.1.beta, %para60_conv1d.temporal_conv.4.weight, %para61_conv1d.temporal_conv.4.bias, %para62_conv1d.temporal_conv.5.gamma, %para63_conv1d.temporal_conv.5.beta, %para64_conv1d1.temporal_conv.0.weight, %para65_conv1d1.temporal_conv.0.bias, %para66_conv1d1.temporal_conv.1.gamma, %para67_conv1d1.temporal_conv.1.beta, %para68_conv1d1.temporal_conv.4.weight, %para69_conv1d1.temporal_conv.4.bias, %para70_conv1d1.temporal_conv.5.gamma, %para71_conv1d1.temporal_conv.5.beta, %para72_temporal_model.rnn.weight_ih_l0, %para73_temporal_model.rnn.weight_ih_l0_reverse, %para74_temporal_model.rnn.weight_ih_l1, %para75_temporal_model.rnn.weight_ih_l1_reverse, %para76_temporal_model.rnn.weight_hh_l0, %para77_temporal_model.rnn.weight_hh_l0_reverse, %para78_temporal_model.rnn.weight_hh_l1, %para79_temporal_model.rnn.weight_hh_l1_reverse, %para80_temporal_model.rnn.bias_ih_l0, %para81_temporal_model.rnn.bias_ih_l0_reverse, %para82_temporal_model.rnn.bias_ih_l1, %para83_temporal_model.rnn.bias_ih_l1_reverse, %para84_temporal_model.rnn.bias_hh_l0, %para85_temporal_model.rnn.bias_hh_l0_reverse, %para86_temporal_model.rnn.bias_hh_l1, %para87_temporal_model.rnn.bias_hh_l1_reverse, %para88_temporal_model1.rnn.weight_ih_l0, %para89_temporal_model1.rnn.weight_ih_l0_reverse, %para90_temporal_model1.rnn.weight_ih_l1, %para91_temporal_model1.rnn.weight_ih_l1_reverse, %para92_temporal_model1.rnn.weight_hh_l0, %para93_temporal_model1.rnn.weight_hh_l0_reverse, %para94_temporal_model1.rnn.weight_hh_l1, %para95_temporal_model1.rnn.weight_hh_l1_reverse, %para96_temporal_model1.rnn.bias_ih_l0, %para97_temporal_model1.rnn.bias_ih_l0_reverse, %para98_temporal_model1.rnn.bias_ih_l1, %para99_temporal_model1.rnn.bias_ih_l1_reverse, %para100_temporal_model1.rnn.bias_hh_l0, %para101_temporal_model1.rnn.bias_hh_l0_reverse, %para102_temporal_model1.rnn.bias_hh_l1, %para103_temporal_model1.rnn.bias_hh_l1_reverse, %para104_classifier22.weight, %para105_classifier44.weight, %para106_classifier55.weight)
      : (<Ref[Tensor[Float32]], (64, 3, 7, 7)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 64, 3, 3)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 64, 3, 3)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 64, 3, 3)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (128, 64, 3, 3)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128, 128, 3, 3)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128, 128, 3, 3)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128, 128, 3, 3)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (256, 128, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 256, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 256, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 256, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 256, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 256, 3, 3)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (512, 256, 3, 3)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (512, 512, 3, 3)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (512, 512, 3, 3)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (512)>, <Ref[Tensor[Float32]], (64, 512, 1, 5)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 64, 1, 5)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 512, 1, 5)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64, 64, 1, 5)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 128)>, <Ref[Tensor[Float32]], (256, 128)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 128)>, <Ref[Tensor[Float32]], (256, 128)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256, 64)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (256)>, <Ref[Tensor[Float32]], (64, 3512)>, <Ref[Tensor[Float32]], (64, 3512)>, <Ref[Tensor[Float32]], (64, 3512)>) -> (<Tuple[Ref[Tensor[Float32]]*102], TupleShape((64, 3, 7, 7), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (128, 64, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (256, 128, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (512, 256, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (64, 3512), (64, 3512), (64, 3512))>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(147) = S_Prim_grad(%2, %3)
      : (<Func, NoShape>, <Tuple[Ref[Tensor[Float32]]*102], TupleShape((64, 3, 7, 7), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (128, 64, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (256, 128, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (512, 256, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (64, 3512), (64, 3512), (64, 3512))>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 0
  %5(147) = UnpackCall_unpack_call(%4, %1)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @after_grad_108:147{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> forward_fn_3, [2]: CNode_146}
#   2: @after_grad_108:147{[0]: ValueNode<DoSignaturePrimitive> S_Prim_grad, [1]: 147, [2]: CNode_148}
#   3: @after_grad_108:147{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.149, [1]: 147, [2]: CNode_146}
#   4: @after_grad_108:CNode_150{[0]: ValueNode<Primitive> Return, [1]: 147}


subgraph attr:
core : 1
subgraph instance: UnpackCall_109 : 0x39a08e20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
subgraph @UnpackCall_109(%para149_, %para150_) {
  %1(147) = TupleGetItem(%para150_111, I64(0))
      : (<Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>, <Int64, NoShape>) -> (<Tensor[Float32], (1, 50, 3, 160, 160)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %2(147) = TupleGetItem(%para150_111, I64(1))
      : (<Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>, <Int64, NoShape>) -> (<Tensor[Int32], (1, 50)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(147) = TupleGetItem(%para150_111, I64(2))
      : (<Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>, <Int64, NoShape>) -> (<Tensor[Int32], (1)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(147) = TupleGetItem(%para150_111, I64(3))
      : (<Tuple[Tensor[Float32],Tensor[Int32]*3], TupleShape((1, 50, 3, 160, 160), (1, 50), (1), (1))>, <Int64, NoShape>) -> (<Tensor[Int32], (1)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 1
  %5(147) = %para149_110(%1, %2, %3, %4)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1, 50)>, <Tensor[Int32], (1)>, <Tensor[Int32], (1)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @UnpackCall_109:147{[0]: param_110, [1]: 147, [2]: 147, [3]: 147, [4]: 147}
#   2: @UnpackCall_109:147{[0]: ValueNode<Primitive> Return, [1]: 147}


subgraph attr:
k_graph : 1
core : 1
subgraph instance: grad_forward_fn_112 : 0x3994cdb0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @grad_forward_fn_112 parent: [subgraph @grad_forward_fn_151](%para151_, %para152_, %para153_, %para154_) {
  %1(147) = $(grad_forward_fn_151):J[side_effect_propagate: I64(1)](%para-1_152)
      : (<Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 2
  %2(147) = %1(%para151_grad_forward_fn, %para152_grad_forward_fn, %para153_grad_forward_fn, %para154_grad_forward_fn)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1, 50)>, <Tensor[Int32], (1)>, <Tensor[Int32], (1)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(147) = TupleGetItem(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(147) = TupleGetItem(%2, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %5(147) = HyperMapPy_hyper_map[ones_like_leaf]{fn_leaf=MultitypeFuncGraph_ones_like_leaf{(NoneType), (CSRTensor), (COOTensor), (Tensor), (Func), (Number), (TypeType)}}(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %6(147) = %4(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %7(147) = TupleGetItem(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %8(147) = Partial[side_effect_propagate: I64(1)](MultitypeFuncGraph_env_get{(EnvType, MapTensor), (EnvType, Tensor)}, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %9(147) = HyperMap_hyper_map(%8, %para-1_153)
      : (<null>, <Tuple[Ref[Tensor[Float32]]*102], TupleShape((64, 3, 7, 7), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (64, 64, 3, 3), (64), (64), (128, 64, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (128, 128, 3, 3), (128), (128), (256, 128, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (256, 256, 3, 3), (256), (256), (512, 256, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (512, 512, 3, 3), (512), (512), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (64, 512, 1, 5), (64), (64), (64), (64, 64, 1, 5), (64), (64), (64), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (256, 64), (256, 64), (256, 128), (256, 128), (256, 64), (256, 64), (256, 64), (256, 64), (256), (256), (256), (256), (256), (256), (256), (256), (64, 3512), (64, 3512), (64, 3512))>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %10(147) = MakeTuple(%3, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @grad_forward_fn_112:147{[0]: 147, [1]: param_grad_forward_fn, [2]: param_grad_forward_fn, [3]: param_grad_forward_fn, [4]: param_grad_forward_fn}
#   2: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> TupleGetItem, [1]: 147, [2]: ValueNode<Int64Imm> 0}
#   3: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> TupleGetItem, [1]: 147, [2]: ValueNode<Int64Imm> 1}
#   4: @grad_forward_fn_112:147{[0]: ValueNode<HyperMapPy> MetaFuncGraph-hyper_map[ones_like_leaf].154, [1]: 147}
#   5: @grad_forward_fn_112:147{[0]: 147, [1]: 147}
#   6: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> TupleGetItem, [1]: 147, [2]: ValueNode<Int64Imm> 0}
#   7: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> Partial, [1]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-env_get.155, [2]: 147}
#   8: @grad_forward_fn_112:147{[0]: ValueNode<HyperMap> MetaFuncGraph-hyper_map.156, [1]: 147, [2]: param_153}
#   9: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> MakeTuple, [1]: 147, [2]: 147}
#  10: @grad_forward_fn_112:147{[0]: ValueNode<Primitive> Return, [1]: 147}


subgraph attr:
defer_inline : 1
subgraph instance: forward_fn_3 : 0x37a353d0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @forward_fn_3 parent: [subgraph @after_grad_108](%para155_seq_data, %para156_seq_label, %para157_data_len_tensor, %para158_label_len_tensor) {
  %1(CNode_157) = make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[String], TupleShape(NoShape)>) -> (<Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_159) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %4(CNode_160) = getattr(%3, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %5(CNode_161) = JoinedStr("Batch ", I64(0), " - Model output details:")
      : (<String, NoShape>, <Int64, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %6(CNode_162) = %4(%5)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %7(CNode_163) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:627/                    self.logger.info(f"  Number of outputs: {len(model_output)}")/
  %8(CNode_164) = getattr(%7, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:627/                    self.logger.info(f"  Number of outputs: {len(model_output)}")/
  %9(CNode_165) = S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(CNode_166) = S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %11(CNode_167) = S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %12(CNode_168) = S_Prim_make_dict(%10, %11)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %13(model_output) = UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %9, %12)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %14(CNode_170) = S_Prim_inner_len(%13)
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:627/                    self.logger.info(f"  Number of outputs: {len(model_output)}")/
  %15(CNode_171) = JoinedStr("  Number of outputs: ", %14)
      : (<String, NoShape>, <Int64, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:627/                    self.logger.info(f"  Number of outputs: {len(model_output)}")/
  %16(CNode_172) = %8(%15)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:627/                    self.logger.info(f"  Number of outputs: {len(model_output)}")/
  %17(CNode_173) = MakeTuple(%6, %16)
      : (<None, NoShape>, <None, NoShape>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %18(CNode_174) = StopGradient(%17)
      : (<Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/

#------------------------> 3
  %19(CNode_175) = call @↵forward_fn_113(I64(0))
      : (<Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %20(CNode_176) = Depend[side_effect_propagate: I64(1)](%19, %18)
      : (<null>, <Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  Return(%20)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
}
# Order:
#   1: @forward_fn_3:CNode_165{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_seq_data, [2]: param_data_len_tensor}
#   2: @forward_fn_3:CNode_166{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> is_train}
#   3: @forward_fn_3:CNode_167{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<BoolImm> true}
#   4: @forward_fn_3:CNode_168{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_166, [2]: CNode_167}
#   5: @forward_fn_3:model_output{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.177, [1]: ValueNode<FuncGraph> tfnet_model_TFNetModel_construct_169, [2]: CNode_165, [3]: CNode_168}
#   6: @forward_fn_3:CNode_158{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> '__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {}), [3]: CNode_157}
#   7: @forward_fn_3:CNode_159{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   8: @forward_fn_3:CNode_160{[0]: ValueNode<Primitive> getattr, [1]: CNode_159, [2]: ValueNode<StringImm> info}
#   9: @forward_fn_3:CNode_161{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Model output details:}
#  10: @forward_fn_3:CNode_162{[0]: CNode_160, [1]: CNode_161}
#  11: @forward_fn_3:CNode_163{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  12: @forward_fn_3:CNode_164{[0]: ValueNode<Primitive> getattr, [1]: CNode_163, [2]: ValueNode<StringImm> info}
#  13: @forward_fn_3:CNode_170{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: model_output}
#  14: @forward_fn_3:CNode_171{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm>   Number of outputs: , [2]: CNode_170}
#  15: @forward_fn_3:CNode_172{[0]: CNode_164, [1]: CNode_171}
#  16: @forward_fn_3:CNode_178{[0]: ValueNode<FuncGraph> enumerate__179, [1]: model_output}
#  17: @forward_fn_3:CNode_180{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_178}
#  18: @forward_fn_3:CNode_181{[0]: ValueNode<Primitive> Return, [1]: CNode_176}
#  19: @forward_fn_3:CNode_175{[0]: ValueNode<FuncGraph> ↵forward_fn_113, [1]: ValueNode<Int64Imm> 0}
#  20: @forward_fn_3:CNode_182{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  21: @forward_fn_3:CNode_183{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  22: @forward_fn_3:CNode_184{[0]: ValueNode<Primitive> make_dict, [1]: CNode_182, [2]: CNode_183}
#  23: @forward_fn_3:CNode_185{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  24: @forward_fn_3:CNode_186{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_159, [2]: ValueNode<StringImm> info}
#  25: @forward_fn_3:CNode_187{[0]: ValueNode<Primitive> make_dict, [1]: CNode_185, [2]: CNode_186}
#  26: @forward_fn_3:CNode_188{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  27: @forward_fn_3:CNode_189{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  28: @forward_fn_3:CNode_190{[0]: ValueNode<Primitive> make_dict, [1]: CNode_188, [2]: CNode_189}
#  29: @forward_fn_3:CNode_191{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  30: @forward_fn_3:CNode_192{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_163, [2]: ValueNode<StringImm> info}
#  31: @forward_fn_3:CNode_193{[0]: ValueNode<Primitive> make_dict, [1]: CNode_191, [2]: CNode_192}


subgraph attr:
subgraph instance: ↵forward_fn_113 : 0x39740570
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↵forward_fn_113 parent: [subgraph @forward_fn_3](%para159_) {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_178) = $(forward_fn_3):call @enumerate__179(%5)
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %7(CNode_180) = $(forward_fn_3):S_Prim_inner_len(%6)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %8(CNode_194) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para159_@CNode_114, %7)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %9(CNode_195) = Switch(%8, @↻forward_fn_115, @↓forward_fn_119)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/

#------------------------> 40
  %10(CNode_196) = %9()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
}
# Order:
#   1: @↵forward_fn_113:CNode_194{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_114, [2]: CNode_180}
#   2: @↵forward_fn_113:CNode_195{[0]: ValueNode<Primitive> Switch, [1]: CNode_194, [2]: ValueNode<FuncGraph> ↻forward_fn_115, [3]: ValueNode<FuncGraph> ↓forward_fn_119}
#   3: @↵forward_fn_113:CNode_196{[0]: CNode_195}
#   4: @↵forward_fn_113:CNode_197{[0]: ValueNode<Primitive> Return, [1]: CNode_196}


subgraph attr:
subgraph instance: ↻forward_fn_115 : 0x397ebd30
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↻forward_fn_115 parent: [subgraph @↵forward_fn_113]() {
  %1(CNode_114) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para159_@CNode_114, I64(1))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %2(CNode_198) = StopGradient(%1)
      : (<Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %3(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%4, %5)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %3, %6)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_178) = $(forward_fn_3):call @enumerate__179(%7)
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %9(CNode_199) = call @ms_iter_97(%8)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %10(CNode_200) = S_Prim_getitem(%9, %para159_@CNode_114)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>, <Int64, NoShape>) -> (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %11(output) = S_Prim_getitem(%10, I64(1))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %12(CNode_201) = call @hasattr_98(%11, "shape")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/
  %13(CNode_202) = Cond(%12, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/
  %14(CNode_203) = Switch(%13, @✓↻forward_fn_116, @✗↻forward_fn_118)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/

#------------------------> 37
  %15(CNode_204) = %14()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/
  %16(CNode_205) = Depend[side_effect_propagate: I64(1)](%15, %2)
      : (<null>, <Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:629/                        if hasattr(output, 'shape'):/
}
# Order:
#   1: @↻forward_fn_115:CNode_199{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_178}
#   2: @↻forward_fn_115:CNode_200{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_199, [2]: param_@CNode_114}
#   3: @↻forward_fn_115:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_200, [2]: ValueNode<Int64Imm> 0}
#   4: @↻forward_fn_115:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_200, [2]: ValueNode<Int64Imm> 1}
#   5: @↻forward_fn_115:CNode_114{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_114, [2]: ValueNode<Int64Imm> 1}
#   6: @↻forward_fn_115:CNode_201{[0]: ValueNode<FuncGraph> hasattr_98, [1]: output, [2]: ValueNode<StringImm> shape}
#   7: @↻forward_fn_115:CNode_202{[0]: ValueNode<Primitive> Cond, [1]: CNode_201, [2]: ValueNode<BoolImm> false}
#   8: @↻forward_fn_115:CNode_203{[0]: ValueNode<Primitive> Switch, [1]: CNode_202, [2]: ValueNode<FuncGraph> ✓↻forward_fn_116, [3]: ValueNode<FuncGraph> ✗↻forward_fn_118}
#   9: @↻forward_fn_115:CNode_204{[0]: CNode_203}
#  10: @↻forward_fn_115:CNode_206{[0]: ValueNode<Primitive> Return, [1]: CNode_205}


subgraph attr:
subgraph instance: ✓↻forward_fn_116 : 0x39801bb0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓↻forward_fn_116 parent: [subgraph @↻forward_fn_115]() {
  %1(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[String], TupleShape(NoShape)>) -> (<Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_207) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  %4(CNode_208) = getattr(%3, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  %5(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%6, %7)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %9(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %5, %8)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(CNode_178) = $(forward_fn_3):call @enumerate__179(%9)
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %11(CNode_199) = $(↻forward_fn_115):call @ms_iter_97(%10)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %12(CNode_200) = $(↻forward_fn_115):S_Prim_getitem(%11, %para159_@CNode_114)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>, <Int64, NoShape>) -> (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %13(i) = $(↻forward_fn_115):S_Prim_getitem(%12, I64(0))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %14(output) = $(↻forward_fn_115):S_Prim_getitem(%12, I64(1))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %15(CNode_209) = getattr(%14, "shape")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  %16(CNode_210) = JoinedStr("  Output ", %13, " shape: ", %15)
      : (<String, NoShape>, <Int64, NoShape>, <String, NoShape>, <Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  %17(CNode_211) = %4(%16)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  %18(CNode_212) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:631/                            self.logger.info(f"  Output {i} dtype: {output.dtype}")/
  %19(CNode_213) = getattr(%18, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:631/                            self.logger.info(f"  Output {i} dtype: {output.dtype}")/
  %20(CNode_214) = getattr(%14, "dtype")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:631/                            self.logger.info(f"  Output {i} dtype: {output.dtype}")/
  %21(CNode_215) = JoinedStr("  Output ", %13, " dtype: ", %20)
      : (<String, NoShape>, <Int64, NoShape>, <String, NoShape>, <TypeType, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:631/                            self.logger.info(f"  Output {i} dtype: {output.dtype}")/
  %22(CNode_216) = %19(%21)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:631/                            self.logger.info(f"  Output {i} dtype: {output.dtype}")/
  %23(CNode_217) = MakeTuple(%17, %22)
      : (<None, NoShape>, <None, NoShape>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %24(CNode_218) = StopGradient(%23)
      : (<Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/

#------------------------> 26
  %25(CNode_219) = call @↓↻forward_fn_117()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %26(CNode_220) = Depend[side_effect_propagate: I64(1)](%25, %24)
      : (<null>, <Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
  Return(%26)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:630/                            self.logger.info(f"  Output {i} shape: {output.shape}")/
}
# Order:
#   1: @✓↻forward_fn_116:CNode_207{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✓↻forward_fn_116:CNode_208{[0]: ValueNode<Primitive> getattr, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#   3: @✓↻forward_fn_116:CNode_209{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> shape}
#   4: @✓↻forward_fn_116:CNode_210{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm>   Output , [2]: i, [3]: ValueNode<StringImm>  shape: , [4]: CNode_209}
#   5: @✓↻forward_fn_116:CNode_211{[0]: CNode_208, [1]: CNode_210}
#   6: @✓↻forward_fn_116:CNode_212{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   7: @✓↻forward_fn_116:CNode_213{[0]: ValueNode<Primitive> getattr, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#   8: @✓↻forward_fn_116:CNode_214{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> dtype}
#   9: @✓↻forward_fn_116:CNode_215{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm>   Output , [2]: i, [3]: ValueNode<StringImm>  dtype: , [4]: CNode_214}
#  10: @✓↻forward_fn_116:CNode_216{[0]: CNode_213, [1]: CNode_215}
#  11: @✓↻forward_fn_116:CNode_221{[0]: ValueNode<Primitive> Return, [1]: CNode_220}
#  12: @✓↻forward_fn_116:CNode_219{[0]: ValueNode<FuncGraph> ↓↻forward_fn_117}
#  13: @✓↻forward_fn_116:CNode_222{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  14: @✓↻forward_fn_116:CNode_223{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  15: @✓↻forward_fn_116:CNode_224{[0]: ValueNode<Primitive> make_dict, [1]: CNode_222, [2]: CNode_223}
#  16: @✓↻forward_fn_116:CNode_225{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  17: @✓↻forward_fn_116:CNode_226{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  18: @✓↻forward_fn_116:CNode_227{[0]: ValueNode<Primitive> make_dict, [1]: CNode_225, [2]: CNode_226}
#  19: @✓↻forward_fn_116:CNode_228{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  20: @✓↻forward_fn_116:CNode_229{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  21: @✓↻forward_fn_116:CNode_230{[0]: ValueNode<Primitive> make_dict, [1]: CNode_228, [2]: CNode_229}
#  22: @✓↻forward_fn_116:CNode_231{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  23: @✓↻forward_fn_116:CNode_232{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  24: @✓↻forward_fn_116:CNode_233{[0]: ValueNode<Primitive> make_dict, [1]: CNode_231, [2]: CNode_232}
#  25: @✓↻forward_fn_116:CNode_234{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  26: @✓↻forward_fn_116:CNode_235{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  27: @✓↻forward_fn_116:CNode_236{[0]: ValueNode<Primitive> make_dict, [1]: CNode_234, [2]: CNode_235}
#  28: @✓↻forward_fn_116:CNode_237{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  29: @✓↻forward_fn_116:CNode_238{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  30: @✓↻forward_fn_116:CNode_239{[0]: ValueNode<Primitive> make_dict, [1]: CNode_237, [2]: CNode_238}
#  31: @✓↻forward_fn_116:CNode_240{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  32: @✓↻forward_fn_116:CNode_241{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  33: @✓↻forward_fn_116:CNode_242{[0]: ValueNode<Primitive> make_dict, [1]: CNode_240, [2]: CNode_241}
#  34: @✓↻forward_fn_116:CNode_243{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  35: @✓↻forward_fn_116:CNode_244{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  36: @✓↻forward_fn_116:CNode_245{[0]: ValueNode<Primitive> make_dict, [1]: CNode_243, [2]: CNode_244}
#  37: @✓↻forward_fn_116:CNode_246{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  38: @✓↻forward_fn_116:CNode_247{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  39: @✓↻forward_fn_116:CNode_248{[0]: ValueNode<Primitive> make_dict, [1]: CNode_246, [2]: CNode_247}
#  40: @✓↻forward_fn_116:CNode_249{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  41: @✓↻forward_fn_116:CNode_250{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  42: @✓↻forward_fn_116:CNode_251{[0]: ValueNode<Primitive> make_dict, [1]: CNode_249, [2]: CNode_250}
#  43: @✓↻forward_fn_116:CNode_252{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  44: @✓↻forward_fn_116:CNode_253{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  45: @✓↻forward_fn_116:CNode_254{[0]: ValueNode<Primitive> make_dict, [1]: CNode_252, [2]: CNode_253}
#  46: @✓↻forward_fn_116:CNode_255{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  47: @✓↻forward_fn_116:CNode_256{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  48: @✓↻forward_fn_116:CNode_257{[0]: ValueNode<Primitive> make_dict, [1]: CNode_255, [2]: CNode_256}
#  49: @✓↻forward_fn_116:CNode_258{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  50: @✓↻forward_fn_116:CNode_259{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  51: @✓↻forward_fn_116:CNode_260{[0]: ValueNode<Primitive> make_dict, [1]: CNode_258, [2]: CNode_259}
#  52: @✓↻forward_fn_116:CNode_261{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  53: @✓↻forward_fn_116:CNode_262{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  54: @✓↻forward_fn_116:CNode_263{[0]: ValueNode<Primitive> make_dict, [1]: CNode_261, [2]: CNode_262}
#  55: @✓↻forward_fn_116:CNode_264{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  56: @✓↻forward_fn_116:CNode_265{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  57: @✓↻forward_fn_116:CNode_266{[0]: ValueNode<Primitive> make_dict, [1]: CNode_264, [2]: CNode_265}
#  58: @✓↻forward_fn_116:CNode_267{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  59: @✓↻forward_fn_116:CNode_268{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  60: @✓↻forward_fn_116:CNode_269{[0]: ValueNode<Primitive> make_dict, [1]: CNode_267, [2]: CNode_268}
#  61: @✓↻forward_fn_116:CNode_270{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  62: @✓↻forward_fn_116:CNode_271{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  63: @✓↻forward_fn_116:CNode_272{[0]: ValueNode<Primitive> make_dict, [1]: CNode_270, [2]: CNode_271}
#  64: @✓↻forward_fn_116:CNode_273{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  65: @✓↻forward_fn_116:CNode_274{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  66: @✓↻forward_fn_116:CNode_275{[0]: ValueNode<Primitive> make_dict, [1]: CNode_273, [2]: CNode_274}
#  67: @✓↻forward_fn_116:CNode_276{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  68: @✓↻forward_fn_116:CNode_277{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  69: @✓↻forward_fn_116:CNode_278{[0]: ValueNode<Primitive> make_dict, [1]: CNode_276, [2]: CNode_277}
#  70: @✓↻forward_fn_116:CNode_279{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  71: @✓↻forward_fn_116:CNode_280{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  72: @✓↻forward_fn_116:CNode_281{[0]: ValueNode<Primitive> make_dict, [1]: CNode_279, [2]: CNode_280}
#  73: @✓↻forward_fn_116:CNode_282{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  74: @✓↻forward_fn_116:CNode_283{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  75: @✓↻forward_fn_116:CNode_284{[0]: ValueNode<Primitive> make_dict, [1]: CNode_282, [2]: CNode_283}
#  76: @✓↻forward_fn_116:CNode_285{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  77: @✓↻forward_fn_116:CNode_286{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_207, [2]: ValueNode<StringImm> info}
#  78: @✓↻forward_fn_116:CNode_287{[0]: ValueNode<Primitive> make_dict, [1]: CNode_285, [2]: CNode_286}
#  79: @✓↻forward_fn_116:CNode_288{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  80: @✓↻forward_fn_116:CNode_289{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  81: @✓↻forward_fn_116:CNode_290{[0]: ValueNode<Primitive> make_dict, [1]: CNode_288, [2]: CNode_289}
#  82: @✓↻forward_fn_116:CNode_291{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  83: @✓↻forward_fn_116:CNode_292{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_212, [2]: ValueNode<StringImm> info}
#  84: @✓↻forward_fn_116:CNode_293{[0]: ValueNode<Primitive> make_dict, [1]: CNode_291, [2]: CNode_292}


subgraph attr:
after_block : 1
subgraph instance: ↓↻forward_fn_117 : 0x397faa20
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↓↻forward_fn_117 parent: [subgraph @↻forward_fn_115]() {
  %1(CNode_114) = $(↻forward_fn_115):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para159_@CNode_114, I64(1))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/

#------------------------> 39
  %2(CNode_294) = call @↵forward_fn_113(%1)
      : (<Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
}
# Order:
#   1: @↓↻forward_fn_117:CNode_295{[0]: ValueNode<Primitive> Return, [1]: CNode_294}
#   2: @↓↻forward_fn_117:CNode_294{[0]: ValueNode<FuncGraph> ↵forward_fn_113, [1]: CNode_114}


subgraph attr:
subgraph instance: ✗↻forward_fn_118 : 0x397f1ba0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗↻forward_fn_118 parent: [subgraph @↻forward_fn_115]() {
  %1(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[String], TupleShape(NoShape)>) -> (<Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_296) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %4(CNode_297) = getattr(%3, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %5(CNode_298) = S_Prim_MakeTuple("output", "i")
      : (<String, NoShape>, <String, NoShape>) -> (<Tuple[String*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %6(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %9(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%7, %8)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %6, %9)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %11(CNode_178) = $(forward_fn_3):call @enumerate__179(%10)
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %12(CNode_199) = $(↻forward_fn_115):call @ms_iter_97(%11)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %13(CNode_200) = $(↻forward_fn_115):S_Prim_getitem(%12, %para159_@CNode_114)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]*5,Tuple[Int64,Tensor[Int32]],Tuple[Int64,None]*3], TupleShape(TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (12, 1, 3512)), TupleShape(NoShape, (1)), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape), TupleShape(NoShape, NoShape))>, <Int64, NoShape>) -> (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %14(output) = $(↻forward_fn_115):S_Prim_getitem(%13, I64(1))
      : (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>, <Int64, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %15(i) = $(↻forward_fn_115):S_Prim_getitem(%13, I64(0))
      : (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %16(CNode_299) = S_Prim_MakeTuple(%14, %15)
      : (<None, NoShape>, <Int64, NoShape>) -> (<Tuple[None,Int64], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %17(CNode_300) = S_Prim_make_dict(%5, %16)
      : (<Tuple[String*2], TupleShape(NoShape, NoShape)>, <Tuple[None,Int64], TupleShape(NoShape, NoShape)>) -> (<Dictionary[[output,i,],[None,Int64]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %18(CNode_301) = PyInterpret[side_effect_io: Bool(1)](Script['f"  Output {i} type: {type(output)}"'], InterpretedObject, %17)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[output,i,],[None,Int64]], NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %19(CNode_302) = %4(%18)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  %20(CNode_303) = StopGradient(%19)
      : (<None, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/

#------------------------> 38
  %21(CNode_304) = call @↓↻forward_fn_117()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %22(CNode_305) = Depend[side_effect_propagate: I64(1)](%21, %20)
      : (<null>, <None, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
  Return(%22)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:633/                            self.logger.info(f"  Output {i} type: {type(output)}")/
}
# Order:
#   1: @✗↻forward_fn_118:CNode_296{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✗↻forward_fn_118:CNode_297{[0]: ValueNode<Primitive> getattr, [1]: CNode_296, [2]: ValueNode<StringImm> info}
#   3: @✗↻forward_fn_118:CNode_298{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> output, [2]: ValueNode<StringImm> i}
#   4: @✗↻forward_fn_118:CNode_299{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: output, [2]: i}
#   5: @✗↻forward_fn_118:CNode_300{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_298, [2]: CNode_299}
#   6: @✗↻forward_fn_118:CNode_301{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"  Output {i} type: {type(output)}"', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'len': <built-in function len>, 'enumerate': <class 'enumerate'>, 'hasattr': <built-in function hasattr>, 'type': <class 'type'>}), [3]: CNode_300}
#   7: @✗↻forward_fn_118:CNode_302{[0]: CNode_297, [1]: CNode_301}
#   8: @✗↻forward_fn_118:CNode_306{[0]: ValueNode<Primitive> Return, [1]: CNode_305}
#   9: @✗↻forward_fn_118:CNode_304{[0]: ValueNode<FuncGraph> ↓↻forward_fn_117}
#  10: @✗↻forward_fn_118:CNode_307{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  11: @✗↻forward_fn_118:CNode_308{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  12: @✗↻forward_fn_118:CNode_309{[0]: ValueNode<Primitive> make_dict, [1]: CNode_307, [2]: CNode_308}
#  13: @✗↻forward_fn_118:CNode_310{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  14: @✗↻forward_fn_118:CNode_311{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_296, [2]: ValueNode<StringImm> info}
#  15: @✗↻forward_fn_118:CNode_312{[0]: ValueNode<Primitive> make_dict, [1]: CNode_310, [2]: CNode_311}
#  16: @✗↻forward_fn_118:CNode_313{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  17: @✗↻forward_fn_118:CNode_314{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  18: @✗↻forward_fn_118:CNode_315{[0]: ValueNode<Primitive> make_dict, [1]: CNode_313, [2]: CNode_314}
#  19: @✗↻forward_fn_118:CNode_316{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  20: @✗↻forward_fn_118:CNode_317{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_296, [2]: ValueNode<StringImm> info}
#  21: @✗↻forward_fn_118:CNode_318{[0]: ValueNode<Primitive> make_dict, [1]: CNode_316, [2]: CNode_317}
#  22: @✗↻forward_fn_118:CNode_319{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  23: @✗↻forward_fn_118:CNode_320{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  24: @✗↻forward_fn_118:CNode_321{[0]: ValueNode<Primitive> make_dict, [1]: CNode_319, [2]: CNode_320}
#  25: @✗↻forward_fn_118:CNode_322{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  26: @✗↻forward_fn_118:CNode_323{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_296, [2]: ValueNode<StringImm> info}
#  27: @✗↻forward_fn_118:CNode_324{[0]: ValueNode<Primitive> make_dict, [1]: CNode_322, [2]: CNode_323}


subgraph attr:
subgraph instance: ↓forward_fn_119 : 0x39744900
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↓forward_fn_119 parent: [subgraph @forward_fn_3]() {

#------------------------> 41
  %1(CNode_325) = call @↵↓forward_fn_120(I64(0), F32(0))
      : (<Int64, NoShape>, <Float32, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
}
# Order:
#   1: @↓forward_fn_119:CNode_326{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: model_output, [2]: ValueNode<Int64Imm> 0}
#   2: @↓forward_fn_119:CNode_327{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: CNode_326, [2]: ValueNode<ClassType> class 'list'}
#   3: @↓forward_fn_119:CNode_328{[0]: ValueNode<Primitive> Cond, [1]: CNode_327, [2]: ValueNode<BoolImm> false}
#   4: @↓forward_fn_119:CNode_329{[0]: ValueNode<Primitive> Switch, [1]: CNode_328, [2]: ValueNode<FuncGraph> ↰↓forward_fn_330, [3]: ValueNode<FuncGraph> ↱↓forward_fn_331}
#   5: @↓forward_fn_119:logits_list{[0]: CNode_329}
#   6: @↓forward_fn_119:CNode_332{[0]: ValueNode<FuncGraph> enumerate__179, [1]: logits_list}
#   7: @↓forward_fn_119:CNode_333{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_332}
#   8: @↓forward_fn_119:CNode_334{[0]: ValueNode<Primitive> Return, [1]: CNode_325}
#   9: @↓forward_fn_119:CNode_325{[0]: ValueNode<FuncGraph> ↵↓forward_fn_120, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<FP32Imm> 0}


subgraph attr:
subgraph instance: ↵↓forward_fn_120 : 0x3974d080
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↵↓forward_fn_120 parent: [subgraph @↓forward_fn_119](%para160_, %para161_) {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%5, I64(0))
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %7(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%6, ClassType)
      : (<Tensor[Float32], (12, 1, 3512)>, <TypeType, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %8(CNode_328) = $(↓forward_fn_119):Cond(%7, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %9(CNode_329) = $(↓forward_fn_119):Switch(%8, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %10(logits_list) = $(↓forward_fn_119):%9()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%10)
      : (<List[Tensor[Float32]], ListShape[(12, 1, 3512)]>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %12(CNode_333) = $(↓forward_fn_119):S_Prim_inner_len(%11)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %13(CNode_335) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para160_@CNode_121, %12)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %14(CNode_336) = Switch(%13, @↻↓forward_fn_122, @2↓forward_fn_337)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/

#------------------------> 42
  %15(CNode_338) = %14()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
}
# Order:
#   1: @↵↓forward_fn_120:CNode_335{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_121, [2]: CNode_333}
#   2: @↵↓forward_fn_120:CNode_336{[0]: ValueNode<Primitive> Switch, [1]: CNode_335, [2]: ValueNode<FuncGraph> ↻↓forward_fn_122, [3]: ValueNode<FuncGraph> 2↓forward_fn_337}
#   3: @↵↓forward_fn_120:CNode_338{[0]: CNode_336}
#   4: @↵↓forward_fn_120:CNode_339{[0]: ValueNode<Primitive> Return, [1]: CNode_338}


subgraph attr:
subgraph instance: ↻↓forward_fn_122 : 0x39757730
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↻↓forward_fn_122 parent: [subgraph @↵↓forward_fn_120]() {
  %1(CNode_121) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para160_@CNode_121, I64(1))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %2(CNode_340) = StopGradient(%1)
      : (<Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %3(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%4, %5)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %3, %6)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%7, I64(0))
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %9(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%8, ClassType)
      : (<Tensor[Float32], (12, 1, 3512)>, <TypeType, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %10(CNode_328) = $(↓forward_fn_119):Cond(%9, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_329) = $(↓forward_fn_119):Switch(%10, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %12(logits_list) = $(↓forward_fn_119):%11()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %13(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%12)
      : (<List[Tensor[Float32]], ListShape[(12, 1, 3512)]>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %14(CNode_341) = call @ms_iter_97(%13)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %15(CNode_342) = S_Prim_getitem(%14, %para160_@CNode_121)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>, <Int64, NoShape>) -> (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %16(logits) = S_Prim_getitem(%15, I64(1))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %17(CNode_343) = call @hasattr_98(%16, "shape")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %18(CNode_344) = S_Prim_logical_not(%17)
      : (<Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %19(CNode_345) = Cond(%18, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %20(CNode_346) = Switch(%19, @↰↻↓forward_fn_347, @↱↻↓forward_fn_348)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %21(CNode_349) = %20()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %22(CNode_350) = Cond(%21, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %23(CNode_351) = Switch(%22, @✓↻↓forward_fn_352, @✗↻↓forward_fn_123)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/

#------------------------> 43
  %24(CNode_353) = %23()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %25(CNode_354) = Depend[side_effect_propagate: I64(1)](%24, %2)
      : (<null>, <Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  Return(%25)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
}
# Order:
#   1: @↻↓forward_fn_122:CNode_341{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_332}
#   2: @↻↓forward_fn_122:CNode_342{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_341, [2]: param_@CNode_121}
#   3: @↻↓forward_fn_122:logits_idx{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_342, [2]: ValueNode<Int64Imm> 0}
#   4: @↻↓forward_fn_122:logits{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_342, [2]: ValueNode<Int64Imm> 1}
#   5: @↻↓forward_fn_122:CNode_121{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_121, [2]: ValueNode<Int64Imm> 1}
#   6: @↻↓forward_fn_122:CNode_343{[0]: ValueNode<FuncGraph> hasattr_98, [1]: logits, [2]: ValueNode<StringImm> shape}
#   7: @↻↓forward_fn_122:CNode_344{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_343}
#   8: @↻↓forward_fn_122:CNode_345{[0]: ValueNode<Primitive> Cond, [1]: CNode_344, [2]: ValueNode<BoolImm> false}
#   9: @↻↓forward_fn_122:CNode_346{[0]: ValueNode<Primitive> Switch, [1]: CNode_345, [2]: ValueNode<FuncGraph> ↰↻↓forward_fn_347, [3]: ValueNode<FuncGraph> ↱↻↓forward_fn_348}
#  10: @↻↓forward_fn_122:CNode_349{[0]: CNode_346}
#  11: @↻↓forward_fn_122:CNode_350{[0]: ValueNode<Primitive> Cond, [1]: CNode_349, [2]: ValueNode<BoolImm> false}
#  12: @↻↓forward_fn_122:CNode_351{[0]: ValueNode<Primitive> Switch, [1]: CNode_350, [2]: ValueNode<FuncGraph> ✓↻↓forward_fn_352, [3]: ValueNode<FuncGraph> ✗↻↓forward_fn_123}
#  13: @↻↓forward_fn_122:CNode_353{[0]: CNode_351}
#  14: @↻↓forward_fn_122:CNode_355{[0]: ValueNode<Primitive> Return, [1]: CNode_354}


subgraph attr:
subgraph instance: ✗↻↓forward_fn_123 : 0x39764430
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗↻↓forward_fn_123 parent: [subgraph @↻↓forward_fn_122]() {

#------------------------> 44
  %1(CNode_356) = call @↓↻↓forward_fn_124()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
}
# Order:
#   1: @✗↻↓forward_fn_123:CNode_356{[0]: ValueNode<FuncGraph> ↓↻↓forward_fn_124}
#   2: @✗↻↓forward_fn_123:CNode_357{[0]: ValueNode<Primitive> Return, [1]: CNode_356}


subgraph attr:
after_block : 1
subgraph instance: ↓↻↓forward_fn_124 : 0x39769c20
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↓↻↓forward_fn_124 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[String], TupleShape(NoShape)>) -> (<Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_358) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:647/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} shape: {logits.shape}")/
  %4(CNode_359) = getattr(%3, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:647/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} shape: {logits.shape}")/
  %5(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<Tensor[Float32], (1, 50, 3, 160, 160)>, <Tensor[Int32], (1)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<Bool, NoShape>) -> (<Tuple[Bool], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%6, %7)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Bool], TupleShape(NoShape)>) -> (<Dictionary[[is_train,],[Bool]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %9(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %5, %8)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((1, 50, 3, 160, 160), (1))>, <Dictionary[[is_train,],[Bool]], NoShape>) -> (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%9, I64(0))
      : (<Tuple[Tensor[Float32]*5,Tensor[Int32],None*3], TupleShape((12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (12, 1, 3512), (1), NoShape, NoShape, NoShape)>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%10, ClassType)
      : (<Tensor[Float32], (12, 1, 3512)>, <TypeType, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %12(CNode_328) = $(↓forward_fn_119):Cond(%11, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %13(CNode_329) = $(↓forward_fn_119):Switch(%12, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %14(logits_list) = $(↓forward_fn_119):%13()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %15(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%14)
      : (<List[Tensor[Float32]], ListShape[(12, 1, 3512)]>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %16(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%15)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>) -> (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %17(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%16, %para160_@CNode_121)
      : (<Tuple[Tuple[Int64,Tensor[Float32]]], TupleShape(TupleShape(NoShape, (12, 1, 3512)))>, <Int64, NoShape>) -> (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %18(logits_idx) = $(↻↓forward_fn_122):S_Prim_getitem(%17, I64(0))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %19(logits) = $(↻↓forward_fn_122):S_Prim_getitem(%17, I64(1))
      : (<Tuple[Int64,Tensor[Float32]], TupleShape(NoShape, (12, 1, 3512))>, <Int64, NoShape>) -> (<Tensor[Float32], (12, 1, 3512)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %20(CNode_360) = getattr(%19, "shape")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:647/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} shape: {logits.shape}")/
  %21(CNode_361) = JoinedStr("Batch ", I64(0), " - Logits ", %18, " shape: ", %20)
      : (<String, NoShape>, <Int64, NoShape>, <String, NoShape>, <Int64, NoShape>, <String, NoShape>, <Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:647/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} shape: {logits.shape}")/
  %22(CNode_362) = %4(%21)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:647/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} shape: {logits.shape}")/
  %23(CNode_363) = getattr(%2, "logger")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:648/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} dtype: {logits.dtype}")/
  %24(CNode_364) = getattr(%23, "info")
      : (<External, NoShape>, <String, NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:648/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} dtype: {logits.dtype}")/
  %25(CNode_365) = getattr(%19, "dtype")
      : (<Tensor[Float32], (12, 1, 3512)>, <String, NoShape>) -> (<TypeType, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:648/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} dtype: {logits.dtype}")/
  %26(CNode_366) = JoinedStr("Batch ", I64(0), " - Logits ", %18, " dtype: ", %25)
      : (<String, NoShape>, <Int64, NoShape>, <String, NoShape>, <Int64, NoShape>, <String, NoShape>, <TypeType, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:648/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} dtype: {logits.dtype}")/
  %27(CNode_367) = %24(%26)
      : (<String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:648/                        self.logger.info(f"Batch {batch_idx} - Logits {logits_idx} dtype: {logits.dtype}")/
  %28(CNode_368) = MakeTuple(%22, %27)
      : (<None, NoShape>, <None, NoShape>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %29(CNode_369) = StopGradient(%28)
      : (<Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<Tuple[None*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %30(CNode_370) = S_Prim_MakeTuple("logits")
      : (<String, NoShape>) -> (<Tuple[String], TupleShape(NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
  %31(CNode_371) = S_Prim_MakeTuple(%19)
      : (<Tensor[Float32], (12, 1, 3512)>) -> (<Tuple[Tensor[Float32]], TupleShape((12, 1, 3512))>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
  %32(CNode_372) = S_Prim_make_dict(%30, %31)
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[Tensor[Float32]], TupleShape((12, 1, 3512))>) -> (<Dictionary[[logits,],[Tensor[Float32]]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
  %33(CNode_373) = PyInterpret[side_effect_io: Bool(1)](Script['bool(any(dim <= 0 for dim in logits.shape))'], InterpretedObject, %32)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[logits,],[Tensor[Float32]]], NoShape>) -> (<Any(Tensor)[Float32], (-2)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
  %34(CNode_374) = Switch(%33, @✓↓↻↓forward_fn_99, @✗↓↻↓forward_fn_100)
      : (<Any(Tensor)[Float32], (-2)>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
  %35(CNode_375) = %34()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/

#------------------------> 45
  %36(CNode_376) = call @2↓↻↓forward_fn_125(%35)
      : (<Tensor[Float32], (-1, 1, 3512)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %37(CNode_377) = Depend[side_effect_propagate: I64(1)](%36, %29)
      : (<null>, <Tuple[None*2], TupleShape(NoShape, NoShape)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%37)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
}
# Order:
#   1: @↓↻↓forward_fn_124:CNode_358{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @↓↻↓forward_fn_124:CNode_359{[0]: ValueNode<Primitive> getattr, [1]: CNode_358, [2]: ValueNode<StringImm> info}
#   3: @↓↻↓forward_fn_124:CNode_360{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#   4: @↓↻↓forward_fn_124:CNode_361{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Logits , [4]: logits_idx, [5]: ValueNode<StringImm>  shape: , [6]: CNode_360}
#   5: @↓↻↓forward_fn_124:CNode_362{[0]: CNode_359, [1]: CNode_361}
#   6: @↓↻↓forward_fn_124:CNode_363{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   7: @↓↻↓forward_fn_124:CNode_364{[0]: ValueNode<Primitive> getattr, [1]: CNode_363, [2]: ValueNode<StringImm> info}
#   8: @↓↻↓forward_fn_124:CNode_365{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> dtype}
#   9: @↓↻↓forward_fn_124:CNode_366{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Logits , [4]: logits_idx, [5]: ValueNode<StringImm>  dtype: , [6]: CNode_365}
#  10: @↓↻↓forward_fn_124:CNode_367{[0]: CNode_364, [1]: CNode_366}
#  11: @↓↻↓forward_fn_124:CNode_370{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> logits}
#  12: @↓↻↓forward_fn_124:CNode_371{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: logits}
#  13: @↓↻↓forward_fn_124:CNode_372{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_370, [2]: CNode_371}
#  14: @↓↻↓forward_fn_124:CNode_373{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'bool(any(dim <= 0 for dim in logits.shape))', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'len': <built-in function len>, 'enumerate': <class 'enumerate'>, 'hasattr': <built-in function hasattr>, 'type': <class 'type'>, 'isinstance': <built-in function isinstance>, 'list': <class 'list'>, 'any': <built-in function any>}), [3]: CNode_372}
#  15: @↓↻↓forward_fn_124:CNode_374{[0]: ValueNode<Primitive> Switch, [1]: CNode_373, [2]: ValueNode<FuncGraph> ✓↓↻↓forward_fn_99, [3]: ValueNode<FuncGraph> ✗↓↻↓forward_fn_100}
#  16: @↓↻↓forward_fn_124:CNode_375{[0]: CNode_374}
#  17: @↓↻↓forward_fn_124:CNode_376{[0]: ValueNode<FuncGraph> 2↓↻↓forward_fn_125, [1]: CNode_375}
#  18: @↓↻↓forward_fn_124:CNode_377{[0]: ValueNode<Primitive> Depend, [1]: CNode_376, [2]: CNode_369}
#  19: @↓↻↓forward_fn_124:CNode_378{[0]: ValueNode<Primitive> Return, [1]: CNode_377}
#  20: @↓↻↓forward_fn_124:CNode_379{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  21: @↓↻↓forward_fn_124:CNode_380{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  22: @↓↻↓forward_fn_124:CNode_381{[0]: ValueNode<Primitive> make_dict, [1]: CNode_379, [2]: CNode_380}
#  23: @↓↻↓forward_fn_124:CNode_382{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  24: @↓↻↓forward_fn_124:CNode_383{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_358, [2]: ValueNode<StringImm> info}
#  25: @↓↻↓forward_fn_124:CNode_384{[0]: ValueNode<Primitive> make_dict, [1]: CNode_382, [2]: CNode_383}
#  26: @↓↻↓forward_fn_124:CNode_385{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  27: @↓↻↓forward_fn_124:CNode_386{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  28: @↓↻↓forward_fn_124:CNode_387{[0]: ValueNode<Primitive> make_dict, [1]: CNode_385, [2]: CNode_386}
#  29: @↓↻↓forward_fn_124:CNode_388{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  30: @↓↻↓forward_fn_124:CNode_389{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_363, [2]: ValueNode<StringImm> info}
#  31: @↓↻↓forward_fn_124:CNode_390{[0]: ValueNode<Primitive> make_dict, [1]: CNode_388, [2]: CNode_389}


subgraph attr:
after_block : 1
subgraph instance: 2↓↻↓forward_fn_125 : 0x39778d70
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @2↓↻↓forward_fn_125 parent: [subgraph @↻↓forward_fn_122](%para162_) {
  %1(CNode_391) = getattr(%para162_фlogits, "ndim")
      : (<Tensor[Float32], (-1, 1, 3512)>, <String, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %2(CNode_392) = S_Prim_equal(%1, I64(3))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %3(CNode_393) = Cond(%2, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %4(CNode_394) = Switch(%3, @↰2↓↻↓forward_fn_395, @↱2↓↻↓forward_fn_396)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %5(CNode_397) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %6(CNode_398) = Cond(%5, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %7(CNode_399) = Switch(%6, @✓2↓↻↓forward_fn_101, @✗2↓↻↓forward_fn_102)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %8(CNode_400) = %7()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/

#------------------------> 46
  %9(CNode_401) = call @3↓↻↓forward_fn_126(%8)
      : (<Tensor[Float32], (-1, -1, 3512)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
}
# Order:
#   1: @2↓↻↓forward_fn_125:CNode_391{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> ndim}
#   2: @2↓↻↓forward_fn_125:CNode_392{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_391, [2]: ValueNode<Int64Imm> 3}
#   3: @2↓↻↓forward_fn_125:CNode_393{[0]: ValueNode<Primitive> Cond, [1]: CNode_392, [2]: ValueNode<BoolImm> false}
#   4: @2↓↻↓forward_fn_125:CNode_394{[0]: ValueNode<Primitive> Switch, [1]: CNode_393, [2]: ValueNode<FuncGraph> ↰2↓↻↓forward_fn_395, [3]: ValueNode<FuncGraph> ↱2↓↻↓forward_fn_396}
#   5: @2↓↻↓forward_fn_125:CNode_397{[0]: CNode_394}
#   6: @2↓↻↓forward_fn_125:CNode_398{[0]: ValueNode<Primitive> Cond, [1]: CNode_397, [2]: ValueNode<BoolImm> false}
#   7: @2↓↻↓forward_fn_125:CNode_399{[0]: ValueNode<Primitive> Switch, [1]: CNode_398, [2]: ValueNode<FuncGraph> ✓2↓↻↓forward_fn_101, [3]: ValueNode<FuncGraph> ✗2↓↻↓forward_fn_102}
#   8: @2↓↻↓forward_fn_125:CNode_400{[0]: CNode_399}
#   9: @2↓↻↓forward_fn_125:CNode_401{[0]: ValueNode<FuncGraph> 3↓↻↓forward_fn_126, [1]: CNode_400}
#  10: @2↓↻↓forward_fn_125:CNode_402{[0]: ValueNode<Primitive> Return, [1]: CNode_401}


subgraph attr:
after_block : 1
subgraph instance: 3↓↻↓forward_fn_126 : 0x39787b10
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @3↓↻↓forward_fn_126 parent: [subgraph @↻↓forward_fn_122](%para163_) {
  %1(CNode_403) = getattr(%para163_фlogits, "ndim")
      : (<Tensor[Float32], (-1, -1, 3512)>, <String, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
  %2(CNode_404) = S_Prim_not_equal(%1, I64(3))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
  %3(CNode_405) = Cond(%2, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
  %4(CNode_406) = Switch(%3, @✓3↓↻↓forward_fn_407, @✗3↓↻↓forward_fn_408)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
  %5(CNode_409) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/

#------------------------> 47
  %6(CNode_410) = call @4↓↻↓forward_fn_127(%5)
      : (<Tensor[Float32], (-1, -1, 3512)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
}
# Order:
#   1: @3↓↻↓forward_fn_126:CNode_403{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> ndim}
#   2: @3↓↻↓forward_fn_126:CNode_404{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_403, [2]: ValueNode<Int64Imm> 3}
#   3: @3↓↻↓forward_fn_126:CNode_405{[0]: ValueNode<Primitive> Cond, [1]: CNode_404, [2]: ValueNode<BoolImm> false}
#   4: @3↓↻↓forward_fn_126:CNode_406{[0]: ValueNode<Primitive> Switch, [1]: CNode_405, [2]: ValueNode<FuncGraph> ✓3↓↻↓forward_fn_407, [3]: ValueNode<FuncGraph> ✗3↓↻↓forward_fn_408}
#   5: @3↓↻↓forward_fn_126:CNode_409{[0]: CNode_406}
#   6: @3↓↻↓forward_fn_126:CNode_410{[0]: ValueNode<FuncGraph> 4↓↻↓forward_fn_127, [1]: CNode_409}
#   7: @3↓↻↓forward_fn_126:CNode_411{[0]: ValueNode<Primitive> Return, [1]: CNode_410}


subgraph attr:
after_block : 1
subgraph instance: 4↓↻↓forward_fn_127 : 0x39794250
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @4↓↻↓forward_fn_127 parent: [subgraph @↻↓forward_fn_122](%para164_) {
  %1(CNode_412) = getattr(%para164_фlogits, "shape")
      : (<Tensor[Float32], (-1, -1, 3512)>, <String, NoShape>) -> (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %2(CNode_413) = S_Prim_getitem(%1, I64(1))
      : (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %3(CNode_414) = S_Prim_less_equal(%2, I64(0))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %4(CNode_415) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %5(CNode_416) = Switch(%4, @↰4↓↻↓forward_fn_103, @↱4↓↻↓forward_fn_104)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %6(CNode_417) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %7(CNode_418) = Cond(%6, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %8(CNode_419) = Switch(%7, @✓4↓↻↓forward_fn_105, @✗4↓↻↓forward_fn_420)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/

#------------------------> 48
  %9(CNode_421) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %10(CNode_423) = call @5↓↻↓forward_fn_422(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
}
# Order:
#   1: @4↓↻↓forward_fn_127:CNode_424{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   2: @4↓↻↓forward_fn_127:actual_time_steps{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_424, [2]: ValueNode<Int64Imm> 0}
#   3: @4↓↻↓forward_fn_127:CNode_425{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> actual_time_steps}
#   4: @4↓↻↓forward_fn_127:CNode_426{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: actual_time_steps}
#   5: @4↓↻↓forward_fn_127:CNode_427{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_425, [2]: CNode_426}
#   6: @4↓↻↓forward_fn_127:ts_tensor{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(actual_time_steps, ms.int32)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'len': <built-in function len>, 'enumerate': <class 'enumerate'>, 'hasattr': <built-in function hasattr>, 'type': <class 'type'>, 'isinstance': <built-in function isinstance>, 'list': <class 'list'>, 'any': <built-in function any>, 'ops': <module 'mindspore.ops' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/__init__.py'>, 'ms': <module 'mindspore' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/__init__.py'>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>}), [3]: CNode_427}
#   7: @4↓↻↓forward_fn_127:CNode_428{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   8: @4↓↻↓forward_fn_127:CNode_429{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   9: @4↓↻↓forward_fn_127:CNode_430{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_428, [2]: CNode_429}
#  10: @4↓↻↓forward_fn_127:one_tensor{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(1, ms.int32)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'len': <built-in function len>, 'enumerate': <class 'enumerate'>, 'hasattr': <built-in function hasattr>, 'type': <class 'type'>, 'isinstance': <built-in function isinstance>, 'list': <class 'list'>, 'any': <built-in function any>, 'ops': <module 'mindspore.ops' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/__init__.py'>, 'ms': <module 'mindspore' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/__init__.py'>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>}), [3]: CNode_430}
#  11: @4↓↻↓forward_fn_127:current_data_len{[0]: ValueNode<FuncGraph> minimum_431, [1]: param_data_len_tensor, [2]: ts_tensor}
#  12: @4↓↻↓forward_fn_127:current_data_len{[0]: ValueNode<FuncGraph> maximum_432, [1]: current_data_len, [2]: one_tensor}
#  13: @4↓↻↓forward_fn_127:current_data_len{[0]: ValueNode<FuncGraph> maximum_432, [1]: current_data_len, [2]: param_label_len_tensor}
#  14: @4↓↻↓forward_fn_127:CNode_412{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#  15: @4↓↻↓forward_fn_127:CNode_413{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_412, [2]: ValueNode<Int64Imm> 1}
#  16: @4↓↻↓forward_fn_127:CNode_414{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: CNode_413, [2]: ValueNode<Int64Imm> 0}
#  17: @4↓↻↓forward_fn_127:CNode_415{[0]: ValueNode<Primitive> Cond, [1]: CNode_414, [2]: ValueNode<BoolImm> false}
#  18: @4↓↻↓forward_fn_127:CNode_416{[0]: ValueNode<Primitive> Switch, [1]: CNode_415, [2]: ValueNode<FuncGraph> ↰4↓↻↓forward_fn_103, [3]: ValueNode<FuncGraph> ↱4↓↻↓forward_fn_104}
#  19: @4↓↻↓forward_fn_127:CNode_417{[0]: CNode_416}
#  20: @4↓↻↓forward_fn_127:CNode_418{[0]: ValueNode<Primitive> Cond, [1]: CNode_417, [2]: ValueNode<BoolImm> false}
#  21: @4↓↻↓forward_fn_127:CNode_419{[0]: ValueNode<Primitive> Switch, [1]: CNode_418, [2]: ValueNode<FuncGraph> ✓4↓↻↓forward_fn_105, [3]: ValueNode<FuncGraph> ✗4↓↻↓forward_fn_420}
#  22: @4↓↻↓forward_fn_127:CNode_421{[0]: CNode_419}
#  23: @4↓↻↓forward_fn_127:CNode_423{[0]: ValueNode<FuncGraph> 5↓↻↓forward_fn_422, [1]: CNode_421}
#  24: @4↓↻↓forward_fn_127:CNode_433{[0]: ValueNode<Primitive> Return, [1]: CNode_423}


subgraph attr:
subgraph instance: ✓4↓↻↓forward_fn_105 : 0x397a2e00
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓4↓↻↓forward_fn_105 parent: [subgraph @4↓↻↓forward_fn_127]() {
  %1(CNode_434) = getattr(%para164_фlogits, "shape")
      : (<Tensor[Float32], (-1, -1, 3512)>, <String, NoShape>) -> (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %2(CNode_435) = S_Prim_getitem(%1, I64(0))
      : (<Tuple[Int64*3], TupleShape(NoShape, NoShape, NoShape)>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/

#------------------------> 49
  %3(CNode_437) = call @ms_max_436(I64(1), %2)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %4(CNode_438) = getattr(%para164_фlogits, "shape")
      : (<Tensor[Float32], (-1, -1, 3512)>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %5(CNode_439) = S_Prim_getitem(%4, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %6(CNode_440) = call @ms_max_436(I64(1), %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %7(CNode_441) = S_Prim_MakeTuple(%3, %6, I64(3512))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %8(logits) = call @zeros_442(%7, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %9(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<Tuple[String], TupleShape(NoShape)>, <Tuple[String], TupleShape(NoShape)>) -> (<Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %10(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %9)
      : (<String, NoShape>, <External, NoShape>, <Dictionary[[__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__,],[String]], NoShape>) -> (<External, NoShape>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %11(CNode_443) = getattr(%10, "logger")
      : (<External, NoShape>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %12(CNode_444) = getattr(%11, "warning")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %13(CNode_445) = getattr(%para164_фlogits, "shape")
      : (<Tensor[Float32], (-1, -1, 3512)>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %14(CNode_446) = JoinedStr("Batch ", I64(0), " - Invalid logits shape dimensions: ", %13)
      : (<null>, <Int64, NoShape>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %15(CNode_447) = %12(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %16(CNode_448) = getattr(%10, "logger")
      : (<External, NoShape>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:686/                            self.logger.info(f"Batch {batch_idx} - Fixed logits shape: {logits.shape}")/
  %17(CNode_449) = getattr(%16, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:686/                            self.logger.info(f"Batch {batch_idx} - Fixed logits shape: {logits.shape}")/
  %18(CNode_450) = getattr(%8, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:686/                            self.logger.info(f"Batch {batch_idx} - Fixed logits shape: {logits.shape}")/
  %19(CNode_451) = JoinedStr("Batch ", I64(0), " - Fixed logits shape: ", %18)
      : (<null>, <Int64, NoShape>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:686/                            self.logger.info(f"Batch {batch_idx} - Fixed logits shape: {logits.shape}")/
  %20(CNode_452) = %17(%19)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:686/                            self.logger.info(f"Batch {batch_idx} - Fixed logits shape: {logits.shape}")/
  %21(CNode_453) = MakeTuple(%15, %20)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %22(CNode_454) = StopGradient(%21)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %23(CNode_455) = Depend[side_effect_propagate: I64(1)](%8, %22)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%23)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:683/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
}
# Order:
#   1: @✓4↓↻↓forward_fn_105:CNode_443{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✓4↓↻↓forward_fn_105:CNode_444{[0]: ValueNode<Primitive> getattr, [1]: CNode_443, [2]: ValueNode<StringImm> warning}
#   3: @✓4↓↻↓forward_fn_105:CNode_445{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   4: @✓4↓↻↓forward_fn_105:CNode_446{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Invalid logits shape dimensions: , [4]: CNode_445}
#   5: @✓4↓↻↓forward_fn_105:CNode_447{[0]: CNode_444, [1]: CNode_446}
#   6: @✓4↓↻↓forward_fn_105:CNode_434{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   7: @✓4↓↻↓forward_fn_105:CNode_435{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_434, [2]: ValueNode<Int64Imm> 0}
#   8: @✓4↓↻↓forward_fn_105:CNode_437{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_435}
#   9: @✓4↓↻↓forward_fn_105:CNode_438{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#  10: @✓4↓↻↓forward_fn_105:CNode_439{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_438, [2]: ValueNode<Int64Imm> 1}
#  11: @✓4↓↻↓forward_fn_105:CNode_440{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_439}
#  12: @✓4↓↻↓forward_fn_105:CNode_441{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_437, [2]: CNode_440, [3]: ValueNode<Int64Imm> 3512}
#  13: @✓4↓↻↓forward_fn_105:logits{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_441, [2]: ValueNode<Float> Float32}
#  14: @✓4↓↻↓forward_fn_105:CNode_448{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  15: @✓4↓↻↓forward_fn_105:CNode_449{[0]: ValueNode<Primitive> getattr, [1]: CNode_448, [2]: ValueNode<StringImm> info}
#  16: @✓4↓↻↓forward_fn_105:CNode_450{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#  17: @✓4↓↻↓forward_fn_105:CNode_451{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Fixed logits shape: , [4]: CNode_450}
#  18: @✓4↓↻↓forward_fn_105:CNode_452{[0]: CNode_449, [1]: CNode_451}
#  19: @✓4↓↻↓forward_fn_105:CNode_456{[0]: ValueNode<Primitive> Return, [1]: CNode_455}


subgraph attr:
subgraph instance: ms_max_128 : 0x7f91205e65d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @ms_max_128(%para165_data0, %para166_data1) {
  %1(CNode_457) = MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(len_data) = call @get_max_min_data_len_458(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %3(CNode_459) = S_Prim_less_equal(%2, I64(0))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  %4(CNode_460) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  %5(CNode_461) = Switch(%4, @✓ms_max_462, @✗ms_max_129)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/

#------------------------> 50
  %6(CNode_463) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
}
# Order:
#   1: @ms_max_128:len_data{[0]: ValueNode<FuncGraph> get_max_min_data_len_458, [1]: CNode_457}
#   2: @ms_max_128:CNode_459{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 0}
#   3: @ms_max_128:CNode_460{[0]: ValueNode<Primitive> Cond, [1]: CNode_459, [2]: ValueNode<BoolImm> false}
#   4: @ms_max_128:CNode_461{[0]: ValueNode<Primitive> Switch, [1]: CNode_460, [2]: ValueNode<FuncGraph> ✓ms_max_462, [3]: ValueNode<FuncGraph> ✗ms_max_129}
#   5: @ms_max_128:CNode_463{[0]: CNode_461}
#   6: @ms_max_128:CNode_464{[0]: ValueNode<Primitive> Return, [1]: CNode_463}


subgraph attr:
subgraph instance: ✗ms_max_129 : 0x7f91205f0b10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗ms_max_129 parent: [subgraph @ms_max_128]() {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(len_data) = $(ms_max_128):call @get_max_min_data_len_458(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %3(CNode_465) = S_Prim_equal(%2, I64(1))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  %4(CNode_466) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  %5(CNode_467) = Switch(%4, @✓✗ms_max_468, @2✗ms_max_130)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/

#------------------------> 51
  %6(CNode_469) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
}
# Order:
#   1: @✗ms_max_129:CNode_465{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 1}
#   2: @✗ms_max_129:CNode_466{[0]: ValueNode<Primitive> Cond, [1]: CNode_465, [2]: ValueNode<BoolImm> false}
#   3: @✗ms_max_129:CNode_467{[0]: ValueNode<Primitive> Switch, [1]: CNode_466, [2]: ValueNode<FuncGraph> ✓✗ms_max_468, [3]: ValueNode<FuncGraph> 2✗ms_max_130}
#   4: @✗ms_max_129:CNode_469{[0]: CNode_467}
#   5: @✗ms_max_129:CNode_470{[0]: ValueNode<Primitive> Return, [1]: CNode_469}


subgraph attr:
subgraph instance: 2✗ms_max_130 : 0x7f9120602870
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2✗ms_max_130 parent: [subgraph @ms_max_128]() {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(len_data) = $(ms_max_128):call @get_max_min_data_len_458(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %3(CNode_471) = S_Prim_greater_equal(%2, I64(2))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  %4(CNode_472) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  %5(CNode_473) = Switch(%4, @✓2✗ms_max_131, @3✗ms_max_474)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/

#------------------------> 52
  %6(CNode_475) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
}
# Order:
#   1: @2✗ms_max_130:CNode_471{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 2}
#   2: @2✗ms_max_130:CNode_472{[0]: ValueNode<Primitive> Cond, [1]: CNode_471, [2]: ValueNode<BoolImm> false}
#   3: @2✗ms_max_130:CNode_473{[0]: ValueNode<Primitive> Switch, [1]: CNode_472, [2]: ValueNode<FuncGraph> ✓2✗ms_max_131, [3]: ValueNode<FuncGraph> 3✗ms_max_474}
#   4: @2✗ms_max_130:CNode_475{[0]: CNode_473}
#   5: @2✗ms_max_130:CNode_476{[0]: ValueNode<Primitive> Return, [1]: CNode_475}


subgraph attr:
subgraph instance: ✓2✗ms_max_131 : 0x7f9120629710
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓2✗ms_max_131 parent: [subgraph @ms_max_128]() {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(tensor_num) = call @get_tensor_num_477(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %3(len_data) = $(ms_max_128):call @get_max_min_data_len_458(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %4(CNode_478) = S_Prim_equal(%2, %3)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  %5(CNode_479) = Cond(%4, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  %6(CNode_480) = Switch(%5, @2✓2✗ms_max_481, @✗✓2✗ms_max_132)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/

#------------------------> 53
  %7(CNode_482) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
}
# Order:
#   1: @✓2✗ms_max_131:tensor_num{[0]: ValueNode<FuncGraph> get_tensor_num_477, [1]: CNode_457}
#   2: @✓2✗ms_max_131:CNode_478{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_num, [2]: len_data}
#   3: @✓2✗ms_max_131:CNode_479{[0]: ValueNode<Primitive> Cond, [1]: CNode_478, [2]: ValueNode<BoolImm> false}
#   4: @✓2✗ms_max_131:CNode_480{[0]: ValueNode<Primitive> Switch, [1]: CNode_479, [2]: ValueNode<FuncGraph> 2✓2✗ms_max_481, [3]: ValueNode<FuncGraph> ✗✓2✗ms_max_132}
#   5: @✓2✗ms_max_131:CNode_482{[0]: CNode_480}
#   6: @✓2✗ms_max_131:CNode_483{[0]: ValueNode<Primitive> Return, [1]: CNode_482}


subgraph attr:
subgraph instance: ✗✓2✗ms_max_132 : 0x7f912062dba0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗✓2✗ms_max_132 parent: [subgraph @✓2✗ms_max_131]() {

#------------------------> 54
  %1(CNode_484) = call @↓✓2✗ms_max_133()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
}
# Order:
#   1: @✗✓2✗ms_max_132:CNode_484{[0]: ValueNode<FuncGraph> ↓✓2✗ms_max_133}
#   2: @✗✓2✗ms_max_132:CNode_485{[0]: ValueNode<Primitive> Return, [1]: CNode_484}


subgraph attr:
after_block : 1
subgraph instance: ↓✓2✗ms_max_133 : 0x7f912062fa80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓✓2✗ms_max_133 parent: [subgraph @✓2✗ms_max_131]() {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(tensor_num) = $(✓2✗ms_max_131):call @get_tensor_num_477(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %3(CNode_486) = S_Prim_not_equal(%2, I64(0))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  %4(CNode_487) = Cond(%3, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  %5(CNode_488) = Switch(%4, @✓↓✓2✗ms_max_489, @✗↓✓2✗ms_max_134)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/

#------------------------> 55
  %6(CNode_490) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
}
# Order:
#   1: @↓✓2✗ms_max_133:CNode_486{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_num, [2]: ValueNode<Int64Imm> 0}
#   2: @↓✓2✗ms_max_133:CNode_487{[0]: ValueNode<Primitive> Cond, [1]: CNode_486, [2]: ValueNode<BoolImm> false}
#   3: @↓✓2✗ms_max_133:CNode_488{[0]: ValueNode<Primitive> Switch, [1]: CNode_487, [2]: ValueNode<FuncGraph> ✓↓✓2✗ms_max_489, [3]: ValueNode<FuncGraph> ✗↓✓2✗ms_max_134}
#   4: @↓✓2✗ms_max_133:CNode_490{[0]: CNode_488}
#   5: @↓✓2✗ms_max_133:CNode_491{[0]: ValueNode<Primitive> Return, [1]: CNode_490}


subgraph attr:
subgraph instance: ✗↓✓2✗ms_max_134 : 0x7f9120632480
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗↓✓2✗ms_max_134 parent: [subgraph @ms_max_128]() {

#------------------------> 56
  %1(CNode_492) = call @2↓✓2✗ms_max_135()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
}
# Order:
#   1: @✗↓✓2✗ms_max_134:CNode_493{[0]: ValueNode<Primitive> Return, [1]: CNode_492}
#   2: @✗↓✓2✗ms_max_134:CNode_492{[0]: ValueNode<FuncGraph> 2↓✓2✗ms_max_135}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓2✗ms_max_135 : 0x7f91206343c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2↓✓2✗ms_max_135 parent: [subgraph @ms_max_128]() {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(CNode_495) = call @exist_tensor_494(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  %3(CNode_496) = Cond(%2, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  %4(CNode_497) = Switch(%3, @✓2↓✓2✗ms_max_498, @✗2↓✓2✗ms_max_136)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/

#------------------------> 57
  %5(CNode_499) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
}
# Order:
#   1: @2↓✓2✗ms_max_135:CNode_495{[0]: ValueNode<FuncGraph> exist_tensor_494, [1]: CNode_457}
#   2: @2↓✓2✗ms_max_135:CNode_496{[0]: ValueNode<Primitive> Cond, [1]: CNode_495, [2]: ValueNode<BoolImm> false}
#   3: @2↓✓2✗ms_max_135:CNode_497{[0]: ValueNode<Primitive> Switch, [1]: CNode_496, [2]: ValueNode<FuncGraph> ✓2↓✓2✗ms_max_498, [3]: ValueNode<FuncGraph> ✗2↓✓2✗ms_max_136}
#   4: @2↓✓2✗ms_max_135:CNode_499{[0]: CNode_497}
#   5: @2↓✓2✗ms_max_135:CNode_500{[0]: ValueNode<Primitive> Return, [1]: CNode_499}


subgraph attr:
subgraph instance: ✗2↓✓2✗ms_max_136 : 0x7f9120651a60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗2↓✓2✗ms_max_136 parent: [subgraph @ms_max_128]() {

#------------------------> 58
  %1(CNode_501) = call @3↓✓2✗ms_max_137()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
}
# Order:
#   1: @✗2↓✓2✗ms_max_136:CNode_502{[0]: ValueNode<Primitive> Return, [1]: CNode_501}
#   2: @✗2↓✓2✗ms_max_136:CNode_501{[0]: ValueNode<FuncGraph> 3↓✓2✗ms_max_137}


subgraph attr:
after_block : 1
subgraph instance: 3↓✓2✗ms_max_137 : 0x7f9120653410
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @3↓✓2✗ms_max_137 parent: [subgraph @ms_max_128]() {

#------------------------> 59
  %1(CNode_503) = call @↓2✗ms_max_138()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
}
# Order:
#   1: @3↓✓2✗ms_max_137:CNode_504{[0]: ValueNode<Primitive> Return, [1]: CNode_503}
#   2: @3↓✓2✗ms_max_137:CNode_503{[0]: ValueNode<FuncGraph> ↓2✗ms_max_138}


subgraph attr:
after_block : 1
subgraph instance: ↓2✗ms_max_138 : 0x7f9120609a30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓2✗ms_max_138 parent: [subgraph @ms_max_128]() {

#------------------------> 60
  %1(CNode_505) = call @↓✗ms_max_139()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
}
# Order:
#   1: @↓2✗ms_max_138:CNode_505{[0]: ValueNode<FuncGraph> ↓✗ms_max_139}
#   2: @↓2✗ms_max_138:CNode_506{[0]: ValueNode<Primitive> Return, [1]: CNode_505}


subgraph attr:
after_block : 1
subgraph instance: ↓✗ms_max_139 : 0x7f912060b380
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓✗ms_max_139 parent: [subgraph @ms_max_128]() {

#------------------------> 61
  %1(CNode_507) = call @↓ms_max_140()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
}
# Order:
#   1: @↓✗ms_max_139:CNode_508{[0]: ValueNode<Primitive> Return, [1]: CNode_507}
#   2: @↓✗ms_max_139:CNode_507{[0]: ValueNode<FuncGraph> ↓ms_max_140}


subgraph attr:
after_block : 1
subgraph instance: ↓ms_max_140 : 0x7f912060cce0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓ms_max_140 parent: [subgraph @ms_max_128]() {

#------------------------> 62
  %1(CNode_509) = call @↵↓ms_max_141(I64(0))
      : (<Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↓ms_max_140:CNode_510{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_457}
#   2: @↓ms_max_140:CNode_511{[0]: ValueNode<Primitive> Return, [1]: CNode_509}
#   3: @↓ms_max_140:CNode_509{[0]: ValueNode<FuncGraph> ↵↓ms_max_141, [1]: ValueNode<Int64Imm> 0}


subgraph attr:
subgraph instance: ↵↓ms_max_141 : 0x7f912060ed80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↵↓ms_max_141 parent: [subgraph @↓ms_max_140](%para167_) {
  %1(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %2(CNode_510) = $(↓ms_max_140):S_Prim_inner_len(%1)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %3(CNode_512) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para167_@CNode_142, %2)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %4(CNode_513) = Switch(%3, @↻↓ms_max_143, @2↓ms_max_514)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/

#------------------------> 65
  %5(CNode_515) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↵↓ms_max_141:CNode_512{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_142, [2]: CNode_510}
#   2: @↵↓ms_max_141:CNode_513{[0]: ValueNode<Primitive> Switch, [1]: CNode_512, [2]: ValueNode<FuncGraph> ↻↓ms_max_143, [3]: ValueNode<FuncGraph> 2↓ms_max_514}
#   3: @↵↓ms_max_141:CNode_515{[0]: CNode_513}
#   4: @↵↓ms_max_141:CNode_516{[0]: ValueNode<Primitive> Return, [1]: CNode_515}


subgraph attr:
subgraph instance: ↻↓ms_max_143 : 0x7f91206055f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↻↓ms_max_143 parent: [subgraph @↵↓ms_max_141]() {
  %1(CNode_142) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para167_@CNode_142, I64(1))
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %2(CNode_457) = $(ms_max_128):MakeTuple(%para165_data0, %para166_data1)
      : (<Int64, NoShape>, <Int64, NoShape>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %3(CNode_517) = call @ms_iter_106(%2)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>) -> (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %4(input_data) = S_Prim_getitem(%3, %para167_@CNode_142)
      : (<Tuple[Int64*2], TupleShape(NoShape, NoShape)>, <Int64, NoShape>) -> (<Int64, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/

#------------------------> 66
  %5(CNode_518) = call @check_isconstant_144(%4, "max()")
      : (<Int64, NoShape>, <String, NoShape>) -> (<None, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2660/        check_isconstant(input_data, "max()")/
  %6(CNode_519) = MakeTuple(%1, %5)
      : (<Int64, NoShape>, <None, NoShape>) -> (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %7(CNode_520) = StopGradient(%6)
      : (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>) -> (<Tuple[Int64,None], TupleShape(NoShape, NoShape)>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/

#------------------------> 64
  %8(CNode_521) = call @↵↓ms_max_141(%1)
      : (<Int64, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %9(CNode_522) = Depend[side_effect_propagate: I64(1)](%8, %7)
      : (<null>, <Tuple[Int64,None], TupleShape(NoShape, NoShape)>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↻↓ms_max_143:CNode_517{[0]: ValueNode<FuncGraph> ms_iter_106, [1]: CNode_457}
#   2: @↻↓ms_max_143:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_517, [2]: param_@CNode_142}
#   3: @↻↓ms_max_143:CNode_142{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_142, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓ms_max_143:CNode_518{[0]: ValueNode<FuncGraph> check_isconstant_144, [1]: input_data, [2]: ValueNode<StringImm> max()}
#   5: @↻↓ms_max_143:CNode_523{[0]: ValueNode<Primitive> Return, [1]: CNode_522}
#   6: @↻↓ms_max_143:CNode_521{[0]: ValueNode<FuncGraph> ↵↓ms_max_141, [1]: CNode_142}


subgraph attr:
subgraph instance: check_isconstant_144 : 0x7f9120619090
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @check_isconstant_144(%para168_input_data, %para169_func_name) {
  %1(CNode_524) = S_Prim_IsConstant(%para168_input_data)
      : (<Int64, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %2(CNode_525) = S_Prim_logical_not(%1)
      : (<Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %3(CNode_526) = Cond(%2, Bool(0))
      : (<Bool, NoShape>, <Bool, NoShape>) -> (<Bool, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %4(CNode_527) = Switch(%3, @✓check_isconstant_145, @✗check_isconstant_528)
      : (<Bool, NoShape>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/

#------------------------> 67
  %5(CNode_529) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
}
# Order:
#   1: @check_isconstant_144:CNode_524{[0]: ValueNode<DoSignaturePrimitive> S_Prim_IsConstant, [1]: param_input_data}
#   2: @check_isconstant_144:CNode_525{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_524}
#   3: @check_isconstant_144:CNode_526{[0]: ValueNode<Primitive> Cond, [1]: CNode_525, [2]: ValueNode<BoolImm> false}
#   4: @check_isconstant_144:CNode_527{[0]: ValueNode<Primitive> Switch, [1]: CNode_526, [2]: ValueNode<FuncGraph> ✓check_isconstant_145, [3]: ValueNode<FuncGraph> ✗check_isconstant_528}
#   5: @check_isconstant_144:CNode_529{[0]: CNode_527}
#   6: @check_isconstant_144:CNode_530{[0]: ValueNode<Primitive> Return, [1]: CNode_529}


subgraph attr:
subgraph instance: ✓check_isconstant_145 : 0x7f91206209a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @✓check_isconstant_145 parent: [subgraph @check_isconstant_144]() {
  %1(CNode_531) = S_Prim_add("The input of ", %para169_func_name)
      : (<String, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %2(CNode_532) = S_Prim_add(%1, " only support Tensor, List, Tuple, constant Scalar, but got ")
      : (<String, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %3(CNode_534) = call @get_data_type_str_533(%para168_input_data)
      : (<Int64, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2605/                                                                   " but got " + get_data_type_str(input_data))/
  %4(CNode_535) = S_Prim_add(%2, %3)
      : (<String, NoShape>, <String, NoShape>) -> (<String, NoShape>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/

#------------------------> 68
  %5(CNode_536) = S_Prim_raise_type_error[constexpr_prim: Bool(1)](%4)
      : (<String, NoShape>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %6(CNode_537) = StopGradient(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
  %7(CNode_539) = call @↓check_isconstant_538()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %8(CNode_540) = Depend[side_effect_propagate: I64(1)](%7, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
}
# Order:
#   1: @✓check_isconstant_145:CNode_531{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: ValueNode<StringImm> The input of , [2]: param_func_name}
#   2: @✓check_isconstant_145:CNode_532{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_531, [2]: ValueNode<StringImm>  only support Tensor, List, Tuple, constant Scalar, but got }
#   3: @✓check_isconstant_145:CNode_534{[0]: ValueNode<FuncGraph> get_data_type_str_533, [1]: param_input_data}
#   4: @✓check_isconstant_145:CNode_535{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_532, [2]: CNode_534}
#   5: @✓check_isconstant_145:CNode_536{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: CNode_535}
#   6: @✓check_isconstant_145:CNode_539{[0]: ValueNode<FuncGraph> ↓check_isconstant_538}
#   7: @✓check_isconstant_145:CNode_541{[0]: ValueNode<Primitive> Return, [1]: CNode_540}


# ===============================================================================================
# The total of function graphs in evaluation stack: 35/70 (Ignored 35 internal frames).
# ===============================================================================================


# ===============================================================================================
# The rest function graphs are the following:
# ===============================================================================================
subgraph attr:
training : 1
subgraph instance: tfnet_model_TFNetModel_construct_169 : 0x305e1980
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @tfnet_model_TFNetModel_construct_169 parent: [subgraph @after_grad_108](%para170_seq_data, %para171_data_len, %para172_is_train) {
  %1(CNode_542) = getattr(%para170_seq_data, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
  %2(CNode_543) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
  %3(CNode_544) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
  %4(CNode_545) = Switch(%3, @✓tfnet_model_TFNetModel_construct_546, @✗tfnet_model_TFNetModel_construct_547)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
  %5(CNode_548) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
  %6(CNode_550) = call @↓tfnet_model_TFNetModel_construct_549(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
}
# Order:
#   1: @tfnet_model_TFNetModel_construct_169:CNode_542{[0]: ValueNode<Primitive> getattr, [1]: param_seq_data, [2]: ValueNode<StringImm> dtype}
#   2: @tfnet_model_TFNetModel_construct_169:CNode_543{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_542, [2]: ValueNode<Float> Float32}
#   3: @tfnet_model_TFNetModel_construct_169:CNode_544{[0]: ValueNode<Primitive> Cond, [1]: CNode_543, [2]: ValueNode<BoolImm> false}
#   4: @tfnet_model_TFNetModel_construct_169:CNode_545{[0]: ValueNode<Primitive> Switch, [1]: CNode_544, [2]: ValueNode<FuncGraph> ✓tfnet_model_TFNetModel_construct_546, [3]: ValueNode<FuncGraph> ✗tfnet_model_TFNetModel_construct_547}
#   5: @tfnet_model_TFNetModel_construct_169:CNode_548{[0]: CNode_545}
#   6: @tfnet_model_TFNetModel_construct_169:CNode_550{[0]: ValueNode<FuncGraph> ↓tfnet_model_TFNetModel_construct_549, [1]: CNode_548}
#   7: @tfnet_model_TFNetModel_construct_169:CNode_551{[0]: ValueNode<Primitive> Return, [1]: CNode_550}


subgraph attr:
subgraph instance: enumerate__179 : 0x37a105e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @enumerate__179(%para173_x, %para174_start) {
  %1(CNode_552) = S_Prim_MakeTuple(ClassType, ClassType, ClassType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  %2(CNode_553) = S_Prim_isinstance(%para173_x, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  %3(CNode_554) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  %4(CNode_555) = Switch(%3, @✓enumerate__556, @✗enumerate__557)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  %5(CNode_558) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
}
# Order:
#   1: @enumerate__179:x_type{[0]: ValueNode<DoSignaturePrimitive> S_Prim_typeof, [1]: param_x}
#   2: @enumerate__179:CNode_552{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: ValueNode<ClassType> class 'float', [3]: ValueNode<ClassType> class 'bool'}
#   3: @enumerate__179:CNode_553{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: CNode_552}
#   4: @enumerate__179:CNode_554{[0]: ValueNode<Primitive> Cond, [1]: CNode_553, [2]: ValueNode<BoolImm> false}
#   5: @enumerate__179:CNode_555{[0]: ValueNode<Primitive> Switch, [1]: CNode_554, [2]: ValueNode<FuncGraph> ✓enumerate__556, [3]: ValueNode<FuncGraph> ✗enumerate__557}
#   6: @enumerate__179:CNode_558{[0]: CNode_555}
#   7: @enumerate__179:CNode_559{[0]: ValueNode<Primitive> Return, [1]: CNode_558}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓tfnet_model_TFNetModel_construct_549 : 0x3764dbe0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓tfnet_model_TFNetModel_construct_549 parent: [subgraph @tfnet_model_TFNetModel_construct_169](%para175_) {
  %1(CNode_560) = getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(batch) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_561) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %4(CNode_562) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %5(CNode_563) = Switch(%4, @↰↓tfnet_model_TFNetModel_construct_564, @↱↓tfnet_model_TFNetModel_construct_565)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %6(CNode_566) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %7(CNode_567) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %8(CNode_568) = Switch(%7, @✓↓tfnet_model_TFNetModel_construct_569, @✗↓tfnet_model_TFNetModel_construct_570)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %9(CNode_571) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %10(CNode_572) = TupleGetItem(%9, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %11(CNode_573) = TupleGetItem(%9, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %12(CNode_574) = TupleGetItem(%9, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %13(CNode_575) = TupleGetItem(%9, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %14(CNode_576) = TupleGetItem(%9, I64(4))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %15(CNode_577) = TupleGetItem(%9, I64(5))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %16(CNode_579) = call @2↓tfnet_model_TFNetModel_construct_578(%10, %11, %12, %13, %14, %15)
      : (<null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↓tfnet_model_TFNetModel_construct_549:CNode_560{[0]: ValueNode<Primitive> getattr, [1]: param_фseq_data, [2]: ValueNode<StringImm> shape}
#   2: @↓tfnet_model_TFNetModel_construct_549:batch{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_560, [2]: ValueNode<Int64Imm> 0}
#   3: @↓tfnet_model_TFNetModel_construct_549:temp{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_560, [2]: ValueNode<Int64Imm> 1}
#   4: @↓tfnet_model_TFNetModel_construct_549:channel{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_560, [2]: ValueNode<Int64Imm> 2}
#   5: @↓tfnet_model_TFNetModel_construct_549:height{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_560, [2]: ValueNode<Int64Imm> 3}
#   6: @↓tfnet_model_TFNetModel_construct_549:width{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_560, [2]: ValueNode<Int64Imm> 4}
#   7: @↓tfnet_model_TFNetModel_construct_549:CNode_561{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: batch, [2]: ValueNode<Int64Imm> 0}
#   8: @↓tfnet_model_TFNetModel_construct_549:CNode_562{[0]: ValueNode<Primitive> Cond, [1]: CNode_561, [2]: ValueNode<BoolImm> false}
#   9: @↓tfnet_model_TFNetModel_construct_549:CNode_563{[0]: ValueNode<Primitive> Switch, [1]: CNode_562, [2]: ValueNode<FuncGraph> ↰↓tfnet_model_TFNetModel_construct_564, [3]: ValueNode<FuncGraph> ↱↓tfnet_model_TFNetModel_construct_565}
#  10: @↓tfnet_model_TFNetModel_construct_549:CNode_566{[0]: CNode_563}
#  11: @↓tfnet_model_TFNetModel_construct_549:CNode_567{[0]: ValueNode<Primitive> Cond, [1]: CNode_566, [2]: ValueNode<BoolImm> false}
#  12: @↓tfnet_model_TFNetModel_construct_549:CNode_568{[0]: ValueNode<Primitive> Switch, [1]: CNode_567, [2]: ValueNode<FuncGraph> ✓↓tfnet_model_TFNetModel_construct_569, [3]: ValueNode<FuncGraph> ✗↓tfnet_model_TFNetModel_construct_570}
#  13: @↓tfnet_model_TFNetModel_construct_549:CNode_571{[0]: CNode_568}
#  14: @↓tfnet_model_TFNetModel_construct_549:CNode_579{[0]: ValueNode<FuncGraph> 2↓tfnet_model_TFNetModel_construct_578, [1]: CNode_572, [2]: CNode_573, [3]: CNode_574, [4]: CNode_575, [5]: CNode_576, [6]: CNode_577}
#  15: @↓tfnet_model_TFNetModel_construct_549:CNode_580{[0]: ValueNode<Primitive> Return, [1]: CNode_579}
#  16: @↓tfnet_model_TFNetModel_construct_549:CNode_572{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 0}
#  17: @↓tfnet_model_TFNetModel_construct_549:CNode_573{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 1}
#  18: @↓tfnet_model_TFNetModel_construct_549:CNode_574{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 2}
#  19: @↓tfnet_model_TFNetModel_construct_549:CNode_575{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 3}
#  20: @↓tfnet_model_TFNetModel_construct_549:CNode_576{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 4}
#  21: @↓tfnet_model_TFNetModel_construct_549:CNode_577{[0]: ValueNode<Primitive> TupleGetItem, [1]: CNode_571, [2]: ValueNode<Int64Imm> 5}


subgraph attr:
training : 1
subgraph instance: ✓tfnet_model_TFNetModel_construct_546 : 0x3793ae00
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓tfnet_model_TFNetModel_construct_546 parent: [subgraph @tfnet_model_TFNetModel_construct_169]() {
  %1(seq_data) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para170_seq_data, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:80/            seq_data = ops.cast(seq_data, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:80/            seq_data = ops.cast(seq_data, ms.float32)/
}
# Order:
#   1: @✓tfnet_model_TFNetModel_construct_546:seq_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_seq_data, [2]: ValueNode<Float> Float32}
#   2: @✓tfnet_model_TFNetModel_construct_546:CNode_581{[0]: ValueNode<Primitive> Return, [1]: seq_data}


subgraph attr:
training : 1
subgraph instance: ✗tfnet_model_TFNetModel_construct_547 : 0x37a51640
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗tfnet_model_TFNetModel_construct_547 parent: [subgraph @tfnet_model_TFNetModel_construct_169]() {
  Return(%para170_seq_data)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:79/        if seq_data.dtype != ms.float32:/
}
# Order:
#   1: @✗tfnet_model_TFNetModel_construct_547:CNode_582{[0]: ValueNode<Primitive> Return, [1]: param_seq_data}


subgraph attr:
subgraph instance: ✓enumerate__556 : 0x372c3010
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @✓enumerate__556 parent: [subgraph @enumerate__179]() {
  %1(CNode_583) = S_Prim_MakeTuple("x")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
  %2(CNode_584) = S_Prim_MakeTuple(%para173_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
  %3(CNode_585) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
  %4(CNode_586) = PyInterpret[side_effect_io: Bool(1)](Script['f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}."'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
  %5(CNode_587) = raise[side_effect_io: Bool(1)]("TypeError", %4, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2833/        raise TypeError(f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}.")/
}
# Order:
#   1: @✓enumerate__556:CNode_583{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> x}
#   2: @✓enumerate__556:CNode_584{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_x}
#   3: @✓enumerate__556:CNode_585{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_583, [2]: CNode_584}
#   4: @✓enumerate__556:CNode_586{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'f"For 'enumerate', the 'first input' should be tuple or list or tensor, but got {type(x)}."', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'F': <module 'mindspore.ops.functional' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/functional.py'>, 'isinstance': <built-in function isinstance>, 'int': <class 'int'>, 'float': <class 'float'>, 'bool': <class 'bool'>, 'type': <class 'type'>}), [3]: CNode_585}
#   5: @✓enumerate__556:CNode_587{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: CNode_586, [3]: ValueNode<StringImm> None}
#   6: @✓enumerate__556:CNode_588{[0]: ValueNode<Primitive> Return, [1]: CNode_587}


subgraph attr:
subgraph instance: ✗enumerate__557 : 0x37342c80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @✗enumerate__557 parent: [subgraph @enumerate__179]() {
  %1(CNode_590) = call @↓enumerate__589()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2832/    if isinstance(x, (int, float, bool)):/
}
# Order:
#   1: @✗enumerate__557:CNode_590{[0]: ValueNode<FuncGraph> ↓enumerate__589}
#   2: @✗enumerate__557:CNode_591{[0]: ValueNode<Primitive> Return, [1]: CNode_590}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓tfnet_model_TFNetModel_construct_578 : 0x305f2720
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @2↓tfnet_model_TFNetModel_construct_578 parent: [subgraph @tfnet_model_TFNetModel_construct_169](%para176_, %para177_, %para178_, %para179_, %para180_, %para181_) {
  %1(CNode_592) = S_Prim_is_(%para171_len_x, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:95/        if len_x is None:/
  %2(CNode_593) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:95/        if len_x is None:/
  %3(CNode_594) = Switch(%2, @✓2↓tfnet_model_TFNetModel_construct_595, @✗2↓tfnet_model_TFNetModel_construct_596)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:95/        if len_x is None:/
  %4(CNode_597) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:95/        if len_x is None:/
  %5(CNode_599) = call @3↓tfnet_model_TFNetModel_construct_598(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:95/        if len_x is None:/
}
# Order:
#   1: @2↓tfnet_model_TFNetModel_construct_578:CNode_592{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_len_x, [2]: ValueNode<None> None}
#   2: @2↓tfnet_model_TFNetModel_construct_578:CNode_593{[0]: ValueNode<Primitive> Cond, [1]: CNode_592, [2]: ValueNode<BoolImm> false}
#   3: @2↓tfnet_model_TFNetModel_construct_578:CNode_594{[0]: ValueNode<Primitive> Switch, [1]: CNode_593, [2]: ValueNode<FuncGraph> ✓2↓tfnet_model_TFNetModel_construct_595, [3]: ValueNode<FuncGraph> ✗2↓tfnet_model_TFNetModel_construct_596}
#   4: @2↓tfnet_model_TFNetModel_construct_578:CNode_597{[0]: CNode_594}
#   5: @2↓tfnet_model_TFNetModel_construct_578:CNode_599{[0]: ValueNode<FuncGraph> 3↓tfnet_model_TFNetModel_construct_598, [1]: CNode_597}
#   6: @2↓tfnet_model_TFNetModel_construct_578:CNode_600{[0]: ValueNode<Primitive> Return, [1]: CNode_599}


subgraph attr:
training : 1
subgraph instance: ✓↓tfnet_model_TFNetModel_construct_569 : 0x37bd51f0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↓tfnet_model_TFNetModel_construct_569 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(temp) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_601) = ClassType(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:89/            temp = max(1, int(temp))/
  %4(temp) = call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:89/            temp = max(1, int(temp))/
  %5(batch) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %6(CNode_602) = ClassType(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:88/            batch = max(1, int(batch))/
  %7(batch) = call @ms_max_436(I64(1), %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:88/            batch = max(1, int(batch))/
  %8(channel) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %9(CNode_603) = ClassType(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:90/            channel = max(1, int(channel))/
  %10(channel) = call @ms_max_436(I64(1), %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:90/            channel = max(1, int(channel))/
  %11(height) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %12(CNode_604) = ClassType(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:91/            height = max(1, int(height))/
  %13(height) = call @ms_max_436(I64(1), %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:91/            height = max(1, int(height))/
  %14(width) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(4))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %15(CNode_605) = ClassType(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:92/            width = max(1, int(width))/
  %16(width) = call @ms_max_436(I64(1), %15)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:92/            width = max(1, int(width))/
  %17(CNode_606) = S_Prim_MakeTuple(%7, %4, %10, %13, %16)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:93/            seq_data = ops.zeros((batch, temp, channel, height, width), ms.float32)/
  %18(seq_data) = call @zeros_442(%17, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:93/            seq_data = ops.zeros((batch, temp, channel, height, width), ms.float32)/
  %19(CNode_607) = MakeTuple(%4, %7, %18, %10, %13, %16)
      : (<null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%19)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:88/            batch = max(1, int(batch))/
}
# Order:
#   1: @✓↓tfnet_model_TFNetModel_construct_569:CNode_602{[0]: ValueNode<ClassType> class 'int', [1]: batch}
#   2: @✓↓tfnet_model_TFNetModel_construct_569:batch{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_602}
#   3: @✓↓tfnet_model_TFNetModel_construct_569:CNode_601{[0]: ValueNode<ClassType> class 'int', [1]: temp}
#   4: @✓↓tfnet_model_TFNetModel_construct_569:temp{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_601}
#   5: @✓↓tfnet_model_TFNetModel_construct_569:CNode_603{[0]: ValueNode<ClassType> class 'int', [1]: channel}
#   6: @✓↓tfnet_model_TFNetModel_construct_569:channel{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_603}
#   7: @✓↓tfnet_model_TFNetModel_construct_569:CNode_604{[0]: ValueNode<ClassType> class 'int', [1]: height}
#   8: @✓↓tfnet_model_TFNetModel_construct_569:height{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_604}
#   9: @✓↓tfnet_model_TFNetModel_construct_569:CNode_605{[0]: ValueNode<ClassType> class 'int', [1]: width}
#  10: @✓↓tfnet_model_TFNetModel_construct_569:width{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_605}
#  11: @✓↓tfnet_model_TFNetModel_construct_569:CNode_606{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: batch, [2]: temp, [3]: channel, [4]: height, [5]: width}
#  12: @✓↓tfnet_model_TFNetModel_construct_569:seq_data{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_606, [2]: ValueNode<Float> Float32}
#  13: @✓↓tfnet_model_TFNetModel_construct_569:CNode_608{[0]: ValueNode<Primitive> Return, [1]: CNode_607}
#  14: @✓↓tfnet_model_TFNetModel_construct_569:CNode_607{[0]: ValueNode<Primitive> MakeTuple, [1]: temp, [2]: batch, [3]: seq_data, [4]: channel, [5]: height, [6]: width}


subgraph attr:
training : 1
subgraph instance: ✗↓tfnet_model_TFNetModel_construct_570 : 0x37c64730
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↓tfnet_model_TFNetModel_construct_570 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(temp) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(batch) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %4(channel) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %5(height) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %6(width) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(4))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %7(CNode_609) = MakeTuple(%2, %3, %para175_фseq_data, %4, %5, %6)
      : (<null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @✗↓tfnet_model_TFNetModel_construct_570:CNode_610{[0]: ValueNode<Primitive> Return, [1]: CNode_609}
#   2: @✗↓tfnet_model_TFNetModel_construct_570:CNode_609{[0]: ValueNode<Primitive> MakeTuple, [1]: temp, [2]: batch, [3]: param_фseq_data, [4]: channel, [5]: height, [6]: width}


subgraph attr:
training : 1
subgraph instance: ↰↓tfnet_model_TFNetModel_construct_564 : 0x37f0ad60
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰↓tfnet_model_TFNetModel_construct_564 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(batch) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_561) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↰↓tfnet_model_TFNetModel_construct_564:CNode_611{[0]: ValueNode<Primitive> Return, [1]: CNode_561}


subgraph attr:
training : 1
subgraph instance: ↱↓tfnet_model_TFNetModel_construct_565 : 0x37aeccb0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↱↓tfnet_model_TFNetModel_construct_565 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(temp) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_612) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %4(CNode_613) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %5(CNode_614) = Switch(%4, @↰↱↓tfnet_model_TFNetModel_construct_615, @2↱↓tfnet_model_TFNetModel_construct_616)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %6(CNode_617) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↱↓tfnet_model_TFNetModel_construct_565:CNode_612{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: temp, [2]: ValueNode<Int64Imm> 0}
#   2: @↱↓tfnet_model_TFNetModel_construct_565:CNode_613{[0]: ValueNode<Primitive> Cond, [1]: CNode_612, [2]: ValueNode<BoolImm> false}
#   3: @↱↓tfnet_model_TFNetModel_construct_565:CNode_614{[0]: ValueNode<Primitive> Switch, [1]: CNode_613, [2]: ValueNode<FuncGraph> ↰↱↓tfnet_model_TFNetModel_construct_615, [3]: ValueNode<FuncGraph> 2↱↓tfnet_model_TFNetModel_construct_616}
#   4: @↱↓tfnet_model_TFNetModel_construct_565:CNode_617{[0]: CNode_614}
#   5: @↱↓tfnet_model_TFNetModel_construct_565:CNode_618{[0]: ValueNode<Primitive> Return, [1]: CNode_617}


subgraph attr:
after_block : 1
subgraph instance: ↓enumerate__589 : 0x37949d00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @↓enumerate__589 parent: [subgraph @enumerate__179]() {
  %1(CNode_620) = call @check_is_const_int_619(%para174_start, "enumerate", "start")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
  %2(CNode_621) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
  %3(CNode_622) = Switch(%2, @✓↓enumerate__623, @✗↓enumerate__624)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
  %4(CNode_625) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
  %5(CNode_627) = call @2↓enumerate__626(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
}
# Order:
#   1: @↓enumerate__589:CNode_620{[0]: ValueNode<FuncGraph> check_is_const_int_619, [1]: param_start, [2]: ValueNode<StringImm> enumerate, [3]: ValueNode<StringImm> start}
#   2: @↓enumerate__589:CNode_621{[0]: ValueNode<Primitive> Cond, [1]: CNode_620, [2]: ValueNode<BoolImm> false}
#   3: @↓enumerate__589:CNode_622{[0]: ValueNode<Primitive> Switch, [1]: CNode_621, [2]: ValueNode<FuncGraph> ✓↓enumerate__623, [3]: ValueNode<FuncGraph> ✗↓enumerate__624}
#   4: @↓enumerate__589:CNode_625{[0]: CNode_622}
#   5: @↓enumerate__589:CNode_627{[0]: ValueNode<FuncGraph> 2↓enumerate__626, [1]: CNode_625}
#   6: @↓enumerate__589:CNode_628{[0]: ValueNode<Primitive> Return, [1]: CNode_627}


subgraph attr:
subgraph instance: ms_iter_97 : 0x375c9410
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2345/def ms_iter(xs):/
subgraph @ms_iter_97(%para182_xs) {
  %1(CNode_629) = getattr(%para182_xs, "__ms_iter__")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2347/    return xs.__ms_iter__/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2347/    return xs.__ms_iter__/
}
# Order:
#   1: @ms_iter_97:CNode_629{[0]: ValueNode<Primitive> getattr, [1]: param_xs, [2]: ValueNode<StringImm> __ms_iter__}
#   2: @ms_iter_97:CNode_630{[0]: ValueNode<Primitive> Return, [1]: CNode_629}


subgraph attr:
subgraph instance: hasattr_98 : 0x3975ff70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:370/def hasattr(x, attr):  # pylint: disable=redefined-builtin/
subgraph @hasattr_98(%para183_x, %para184_attr) {
  %1(out) = S_Prim_getattr(%para183_x, %para184_attr, NullType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:381/    out = getattr(x, attr, mstype._null)/
  %2(CNode_631) = S_Prim_isinstance(%1, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:382/    return not isinstance(out, mstype._NullType)/
  %3(CNode_632) = S_Prim_logical_not(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:382/    return not isinstance(out, mstype._NullType)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:382/    return not isinstance(out, mstype._NullType)/
}
# Order:
#   1: @hasattr_98:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getattr, [1]: param_x, [2]: param_attr, [3]: ValueNode<TypeNull> Null}
#   2: @hasattr_98:CNode_631{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: out, [2]: ValueNode<ClassType> class 'mindspore._c_expression.typing.TypeNull'}
#   3: @hasattr_98:CNode_632{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_631}
#   4: @hasattr_98:CNode_633{[0]: ValueNode<Primitive> Return, [1]: CNode_632}


subgraph attr:
subgraph instance: ↰↓forward_fn_330 : 0x397eaaf0
# In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
subgraph @↰↓forward_fn_330 parent: [subgraph @forward_fn_3]() {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_634) = S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
}
# Order:
#   1: @↰↓forward_fn_330:CNode_634{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: model_output, [2]: ValueNode<Int64Imm> 0}
#   2: @↰↓forward_fn_330:CNode_635{[0]: ValueNode<Primitive> Return, [1]: CNode_634}


subgraph attr:
subgraph instance: ↱↓forward_fn_331 : 0x397e96b0
# In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
subgraph @↱↓forward_fn_331 parent: [subgraph @forward_fn_3]() {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_636) = S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %7(CNode_637) = S_Prim_make_list(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
}
# Order:
#   1: @↱↓forward_fn_331:CNode_636{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: model_output, [2]: ValueNode<Int64Imm> 0}
#   2: @↱↓forward_fn_331:CNode_637{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_636}
#   3: @↱↓forward_fn_331:CNode_638{[0]: ValueNode<Primitive> Return, [1]: CNode_637}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓tfnet_model_TFNetModel_construct_598 : 0x37384c20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @3↓tfnet_model_TFNetModel_construct_598 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578](%para185_) {
  %1(CNode_639) = S_Prim_inner_len(%para185_фlen_x_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %2(CNode_640) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %3(CNode_641) = S_Prim_less(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %4(CNode_642) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %5(CNode_643) = Switch(%4, @✓3↓tfnet_model_TFNetModel_construct_644, @✗3↓tfnet_model_TFNetModel_construct_645)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %6(CNode_646) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
  %7(CNode_648) = call @4↓tfnet_model_TFNetModel_construct_647(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:105/        if len(len_x_list) < int(batch):/
}
# Order:
#   1: @3↓tfnet_model_TFNetModel_construct_598:CNode_639{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фlen_x_list}
#   2: @3↓tfnet_model_TFNetModel_construct_598:CNode_640{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   3: @3↓tfnet_model_TFNetModel_construct_598:CNode_641{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less, [1]: CNode_639, [2]: CNode_640}
#   4: @3↓tfnet_model_TFNetModel_construct_598:CNode_642{[0]: ValueNode<Primitive> Cond, [1]: CNode_641, [2]: ValueNode<BoolImm> false}
#   5: @3↓tfnet_model_TFNetModel_construct_598:CNode_643{[0]: ValueNode<Primitive> Switch, [1]: CNode_642, [2]: ValueNode<FuncGraph> ✓3↓tfnet_model_TFNetModel_construct_644, [3]: ValueNode<FuncGraph> ✗3↓tfnet_model_TFNetModel_construct_645}
#   6: @3↓tfnet_model_TFNetModel_construct_598:CNode_646{[0]: CNode_643}
#   7: @3↓tfnet_model_TFNetModel_construct_598:CNode_648{[0]: ValueNode<FuncGraph> 4↓tfnet_model_TFNetModel_construct_647, [1]: CNode_646}
#   8: @3↓tfnet_model_TFNetModel_construct_598:CNode_649{[0]: ValueNode<Primitive> Return, [1]: CNode_648}


subgraph attr:
training : 1
subgraph instance: ✓2↓tfnet_model_TFNetModel_construct_595 : 0x3738d0a0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓2↓tfnet_model_TFNetModel_construct_595 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_650) = ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:96/            len_x_list = [int(temp)] * int(batch)/
  %2(CNode_651) = S_Prim_make_list(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:96/            len_x_list = [int(temp)] * int(batch)/
  %3(CNode_652) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:96/            len_x_list = [int(temp)] * int(batch)/
  %4(len_x_list) = S_Prim_mul(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:96/            len_x_list = [int(temp)] * int(batch)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:96/            len_x_list = [int(temp)] * int(batch)/
}
# Order:
#   1: @✓2↓tfnet_model_TFNetModel_construct_595:CNode_650{[0]: ValueNode<ClassType> class 'int', [1]: param_фtemp}
#   2: @✓2↓tfnet_model_TFNetModel_construct_595:CNode_651{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_650}
#   3: @✓2↓tfnet_model_TFNetModel_construct_595:CNode_652{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   4: @✓2↓tfnet_model_TFNetModel_construct_595:len_x_list{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_651, [2]: CNode_652}
#   5: @✓2↓tfnet_model_TFNetModel_construct_595:CNode_653{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: ✗2↓tfnet_model_TFNetModel_construct_596 : 0x37c814d0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗2↓tfnet_model_TFNetModel_construct_596 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_654) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
  %2(CNode_655) = S_Prim_isinstance(%para171_len_x, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
  %3(CNode_656) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
  %4(CNode_657) = Switch(%3, @✓✗2↓tfnet_model_TFNetModel_construct_658, @2✗2↓tfnet_model_TFNetModel_construct_659)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
  %5(CNode_660) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
  %6(CNode_662) = call @↓✗2↓tfnet_model_TFNetModel_construct_661(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
}
# Order:
#   1: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_654{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'list', [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_655{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_len_x, [2]: CNode_654}
#   3: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_656{[0]: ValueNode<Primitive> Cond, [1]: CNode_655, [2]: ValueNode<BoolImm> false}
#   4: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_657{[0]: ValueNode<Primitive> Switch, [1]: CNode_656, [2]: ValueNode<FuncGraph> ✓✗2↓tfnet_model_TFNetModel_construct_658, [3]: ValueNode<FuncGraph> 2✗2↓tfnet_model_TFNetModel_construct_659}
#   5: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_660{[0]: CNode_657}
#   6: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_662{[0]: ValueNode<FuncGraph> ↓✗2↓tfnet_model_TFNetModel_construct_661, [1]: CNode_660}
#   7: @✗2↓tfnet_model_TFNetModel_construct_596:CNode_663{[0]: ValueNode<Primitive> Return, [1]: CNode_662}


subgraph attr:
subgraph instance: ms_max_436 : 0x37589190
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @ms_max_436(%para186_data) {
  %1(len_data) = call @get_max_min_data_len_664(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %2(CNode_459) = S_Prim_less_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  %3(CNode_460) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  %4(CNode_461) = Switch(%3, @✓ms_max_665, @✗ms_max_666)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  %5(CNode_463) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2642/    if len_data <= 0:/
}
# Order:
#   1: @ms_max_436:len_data{[0]: ValueNode<FuncGraph> get_max_min_data_len_664, [1]: param_data}
#   2: @ms_max_436:CNode_459{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 0}
#   3: @ms_max_436:CNode_460{[0]: ValueNode<Primitive> Cond, [1]: CNode_459, [2]: ValueNode<BoolImm> false}
#   4: @ms_max_436:CNode_461{[0]: ValueNode<Primitive> Switch, [1]: CNode_460, [2]: ValueNode<FuncGraph> ✓ms_max_665, [3]: ValueNode<FuncGraph> ✗ms_max_666}
#   5: @ms_max_436:CNode_463{[0]: CNode_461}
#   6: @ms_max_436:CNode_464{[0]: ValueNode<Primitive> Return, [1]: CNode_463}


subgraph attr:
subgraph instance: zeros_442 : 0x37a394d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @zeros_442(%para187_size, %para188_dtype) {
  %1(CNode_667) = S_Prim_isinstance(%para187_size, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1034/    if isinstance(size, int):/
  %2(CNode_668) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1034/    if isinstance(size, int):/
  %3(CNode_669) = Switch(%2, @✓zeros_670, @✗zeros_671)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1034/    if isinstance(size, int):/
  %4(CNode_672) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1034/    if isinstance(size, int):/
  %5(CNode_674) = call @↓zeros_673(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1034/    if isinstance(size, int):/
}
# Order:
#   1: @zeros_442:CNode_675{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.FillV2'}
#   2: @zeros_442:zero_op{[0]: CNode_675}
#   3: @zeros_442:CNode_677{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_dtype, [2]: ValueNode<None> None}
#   4: @zeros_442:CNode_678{[0]: ValueNode<Primitive> Cond, [1]: CNode_677, [2]: ValueNode<BoolImm> false}
#   5: @zeros_442:CNode_679{[0]: ValueNode<Primitive> Switch, [1]: CNode_678, [2]: ValueNode<FuncGraph> ↰zeros_680, [3]: ValueNode<FuncGraph> ↱zeros_681}
#   6: @zeros_442:_dtype{[0]: CNode_679}
#   7: @zeros_442:CNode_682{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> _dtype}
#   8: @zeros_442:CNode_683{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: _dtype}
#   9: @zeros_442:CNode_684{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_682, [2]: CNode_683}
#  10: @zeros_442:value{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(0, _dtype)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'_get_cache_prim': <function _get_cache_prim at 0x7f9335990a60>, 'P': <module 'mindspore.ops.operations' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/operations/__init__.py'>, 'mstype': <module 'mindspore.common.dtype' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/common/dtype.py'>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>}), [3]: CNode_684}
#  11: @zeros_442:CNode_667{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_size, [2]: ValueNode<ClassType> class 'int'}
#  12: @zeros_442:CNode_668{[0]: ValueNode<Primitive> Cond, [1]: CNode_667, [2]: ValueNode<BoolImm> false}
#  13: @zeros_442:CNode_669{[0]: ValueNode<Primitive> Switch, [1]: CNode_668, [2]: ValueNode<FuncGraph> ✓zeros_670, [3]: ValueNode<FuncGraph> ✗zeros_671}
#  14: @zeros_442:CNode_672{[0]: CNode_669}
#  15: @zeros_442:CNode_674{[0]: ValueNode<FuncGraph> ↓zeros_673, [1]: CNode_672}
#  16: @zeros_442:CNode_685{[0]: ValueNode<Primitive> Return, [1]: CNode_674}


subgraph attr:
training : 1
subgraph instance: ↰↱↓tfnet_model_TFNetModel_construct_615 : 0x33380e40
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰↱↓tfnet_model_TFNetModel_construct_615 parent: [subgraph @↱↓tfnet_model_TFNetModel_construct_565]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(temp) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_612) = $(↱↓tfnet_model_TFNetModel_construct_565):S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↰↱↓tfnet_model_TFNetModel_construct_615:CNode_686{[0]: ValueNode<Primitive> Return, [1]: CNode_612}


subgraph attr:
training : 1
subgraph instance: 2↱↓tfnet_model_TFNetModel_construct_616 : 0x37ae9920
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @2↱↓tfnet_model_TFNetModel_construct_616 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(channel) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_687) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %4(CNode_688) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %5(CNode_689) = Switch(%4, @↰2↱↓tfnet_model_TFNetModel_construct_690, @3↱↓tfnet_model_TFNetModel_construct_691)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %6(CNode_692) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @2↱↓tfnet_model_TFNetModel_construct_616:CNode_687{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: channel, [2]: ValueNode<Int64Imm> 0}
#   2: @2↱↓tfnet_model_TFNetModel_construct_616:CNode_688{[0]: ValueNode<Primitive> Cond, [1]: CNode_687, [2]: ValueNode<BoolImm> false}
#   3: @2↱↓tfnet_model_TFNetModel_construct_616:CNode_689{[0]: ValueNode<Primitive> Switch, [1]: CNode_688, [2]: ValueNode<FuncGraph> ↰2↱↓tfnet_model_TFNetModel_construct_690, [3]: ValueNode<FuncGraph> 3↱↓tfnet_model_TFNetModel_construct_691}
#   4: @2↱↓tfnet_model_TFNetModel_construct_616:CNode_692{[0]: CNode_689}
#   5: @2↱↓tfnet_model_TFNetModel_construct_616:CNode_693{[0]: ValueNode<Primitive> Return, [1]: CNode_692}


subgraph attr:
after_block : 1
subgraph instance: 2↓enumerate__626 : 0x37a292a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @2↓enumerate__626(%para189_) {
  Return(%para189_фret)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2840/    return ret/
}
# Order:
#   1: @2↓enumerate__626:CNode_694{[0]: ValueNode<Primitive> Return, [1]: param_фret}


subgraph attr:
subgraph instance: ✓↓enumerate__623 : 0x3765cb90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @✓↓enumerate__623 parent: [subgraph @enumerate__179]() {
  %1(x_type) = $(enumerate__179):S_Prim_typeof(%para173_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2829/    x_type = F.typeof(x)/
  %2(CNode_695) = S_Prim_check_is_tensor[constexpr_prim: Bool(1)](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
  %3(CNode_696) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
  %4(CNode_697) = Switch(%3, @2✓↓enumerate__698, @✗✓↓enumerate__699)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
  %5(CNode_700) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
  %6(CNode_702) = call @↓✓↓enumerate__701(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
}
# Order:
#   1: @✓↓enumerate__623:CNode_695{[0]: ValueNode<DoSignaturePrimitive> S_Prim_check_is_tensor, [1]: x_type}
#   2: @✓↓enumerate__623:CNode_696{[0]: ValueNode<Primitive> Cond, [1]: CNode_695, [2]: ValueNode<BoolImm> false}
#   3: @✓↓enumerate__623:CNode_697{[0]: ValueNode<Primitive> Switch, [1]: CNode_696, [2]: ValueNode<FuncGraph> 2✓↓enumerate__698, [3]: ValueNode<FuncGraph> ✗✓↓enumerate__699}
#   4: @✓↓enumerate__623:CNode_700{[0]: CNode_697}
#   5: @✓↓enumerate__623:CNode_702{[0]: ValueNode<FuncGraph> ↓✓↓enumerate__701, [1]: CNode_700}
#   6: @✓↓enumerate__623:CNode_703{[0]: ValueNode<Primitive> Return, [1]: CNode_702}


subgraph attr:
subgraph instance: ✗↓enumerate__624 : 0x372cf210
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @✗↓enumerate__624() {
  Return(())
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2834/    if check_is_const_int(start, op_name, "start"):/
}
# Order:
#   1: @✗↓enumerate__624:CNode_704{[0]: ValueNode<Primitive> Return, [1]: ValueNode<ValueTuple> ()}


subgraph attr:
subgraph instance: check_is_const_int_619 : 0x37946970
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @check_is_const_int_619(%para190_x, %para191_op_name, %para192_arg_name) {
  %1(CNode_705) = S_Prim_is_(%para190_x, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
  %2(CNode_706) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
  %3(CNode_707) = Switch(%2, @✓check_is_const_int_708, @✗check_is_const_int_709)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
  %4(CNode_710) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
}
# Order:
#   1: @check_is_const_int_619:CNode_705{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_x, [2]: ValueNode<None> None}
#   2: @check_is_const_int_619:CNode_706{[0]: ValueNode<Primitive> Cond, [1]: CNode_705, [2]: ValueNode<BoolImm> false}
#   3: @check_is_const_int_619:CNode_707{[0]: ValueNode<Primitive> Switch, [1]: CNode_706, [2]: ValueNode<FuncGraph> ✓check_is_const_int_708, [3]: ValueNode<FuncGraph> ✗check_is_const_int_709}
#   4: @check_is_const_int_619:CNode_710{[0]: CNode_707}
#   5: @check_is_const_int_619:CNode_711{[0]: ValueNode<Primitive> Return, [1]: CNode_710}


subgraph attr:
subgraph instance: 2↓forward_fn_337 : 0x397568b0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @2↓forward_fn_337 parent: [subgraph @↵↓forward_fn_120]() {
  Return(%para161_фtotal_loss)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:696/                    return total_loss/
}
# Order:
#   1: @2↓forward_fn_337:CNode_712{[0]: ValueNode<Primitive> Return, [1]: param_фtotal_loss}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 4↓tfnet_model_TFNetModel_construct_647 : 0x38f231c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @4↓tfnet_model_TFNetModel_construct_647 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578](%para193_) {
  %1(CNode_714) = call @↵4↓tfnet_model_TFNetModel_construct_713(I64(0), I64(0), [])
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
}
# Order:
#   1: @4↓tfnet_model_TFNetModel_construct_647:len_x_list{[0]: ValueNode<FuncGraph> G_4↓tfnet_model_TFNetModel_construct_715}
#   2: @4↓tfnet_model_TFNetModel_construct_647:CNode_716{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: param_фbatch, [2]: param_фtemp}
#   3: @4↓tfnet_model_TFNetModel_construct_647:CNode_717{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_716, [2]: param_фchannel, [3]: param_фheight, [4]: param_фwidth}
#   4: @4↓tfnet_model_TFNetModel_construct_647:inputs{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_фseq_data, [2]: CNode_717}
#   5: @4↓tfnet_model_TFNetModel_construct_647:CNode_718{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   6: @4↓tfnet_model_TFNetModel_construct_647:CNode_719{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_range, [1]: CNode_718}
#   7: @4↓tfnet_model_TFNetModel_construct_647:CNode_720{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_719}
#   8: @4↓tfnet_model_TFNetModel_construct_647:CNode_721{[0]: ValueNode<Primitive> Return, [1]: CNode_714}
#   9: @4↓tfnet_model_TFNetModel_construct_647:CNode_714{[0]: ValueNode<FuncGraph> ↵4↓tfnet_model_TFNetModel_construct_713, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<ValueList> []}


subgraph attr:
training : 1
subgraph instance: ✓3↓tfnet_model_TFNetModel_construct_644 : 0x37496d20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓3↓tfnet_model_TFNetModel_construct_644 parent: [subgraph @3↓tfnet_model_TFNetModel_construct_598]() {
  %1(CNode_722) = ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %2(CNode_723) = S_Prim_make_list(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %3(CNode_724) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %4(CNode_725) = S_Prim_inner_len(%para185_фlen_x_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %5(CNode_726) = S_Prim_sub(%3, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %6(CNode_727) = S_Prim_mul(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  %7(len_x_list) = S_Prim_add(%para185_фlen_x_list, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:106/            len_x_list = len_x_list + [int(temp)] * (int(batch) - len(len_x_list))/
}
# Order:
#   1: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_722{[0]: ValueNode<ClassType> class 'int', [1]: param_фtemp}
#   2: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_723{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_722}
#   3: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_724{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   4: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_725{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фlen_x_list}
#   5: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_726{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: CNode_724, [2]: CNode_725}
#   6: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_727{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_723, [2]: CNode_726}
#   7: @✓3↓tfnet_model_TFNetModel_construct_644:len_x_list{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фlen_x_list, [2]: CNode_727}
#   8: @✓3↓tfnet_model_TFNetModel_construct_644:CNode_728{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: ✗3↓tfnet_model_TFNetModel_construct_645 : 0x37b96740
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗3↓tfnet_model_TFNetModel_construct_645 parent: [subgraph @3↓tfnet_model_TFNetModel_construct_598]() {
  %1(CNode_729) = S_Prim_inner_len(%para185_фlen_x_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %2(CNode_730) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %3(CNode_731) = S_Prim_greater(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %4(CNode_732) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %5(CNode_733) = Switch(%4, @✓✗3↓tfnet_model_TFNetModel_construct_734, @2✗3↓tfnet_model_TFNetModel_construct_735)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %6(CNode_736) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
  %7(CNode_738) = call @↓✗3↓tfnet_model_TFNetModel_construct_737(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
}
# Order:
#   1: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_729{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фlen_x_list}
#   2: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_730{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   3: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_731{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_729, [2]: CNode_730}
#   4: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_732{[0]: ValueNode<Primitive> Cond, [1]: CNode_731, [2]: ValueNode<BoolImm> false}
#   5: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_733{[0]: ValueNode<Primitive> Switch, [1]: CNode_732, [2]: ValueNode<FuncGraph> ✓✗3↓tfnet_model_TFNetModel_construct_734, [3]: ValueNode<FuncGraph> 2✗3↓tfnet_model_TFNetModel_construct_735}
#   6: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_736{[0]: CNode_733}
#   7: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_738{[0]: ValueNode<FuncGraph> ↓✗3↓tfnet_model_TFNetModel_construct_737, [1]: CNode_736}
#   8: @✗3↓tfnet_model_TFNetModel_construct_645:CNode_739{[0]: ValueNode<Primitive> Return, [1]: CNode_738}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✗2↓tfnet_model_TFNetModel_construct_661 : 0x37c86f40
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✗2↓tfnet_model_TFNetModel_construct_661(%para194_) {
  Return(%para194_фlen_x_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:97/        elif isinstance(len_x, (list, tuple)):/
}
# Order:
#   1: @↓✗2↓tfnet_model_TFNetModel_construct_661:CNode_740{[0]: ValueNode<Primitive> Return, [1]: param_фlen_x_list}


subgraph attr:
training : 1
subgraph instance: ✓✗2↓tfnet_model_TFNetModel_construct_658 : 0x37c89050
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓✗2↓tfnet_model_TFNetModel_construct_658 parent: [subgraph @tfnet_model_TFNetModel_construct_169]() {
  %1(len_x_list) = call @G_✓✗2↓tfnet_model_TFNetModel_construct_741()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @✓✗2↓tfnet_model_TFNetModel_construct_658:len_x_list{[0]: ValueNode<FuncGraph> G_✓✗2↓tfnet_model_TFNetModel_construct_741}
#   2: @✓✗2↓tfnet_model_TFNetModel_construct_658:CNode_742{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: 2✗2↓tfnet_model_TFNetModel_construct_659 : 0x37c75950
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @2✗2↓tfnet_model_TFNetModel_construct_659 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_743) = S_Prim_MakeTuple()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %2(CNode_744) = S_Prim_MakeTuple()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %3(CNode_745) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %4(CNode_746) = PyInterpret[side_effect_io: Bool(1)](Script['np.integer'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %5(CNode_747) = S_Prim_MakeTuple(ClassType, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %6(CNode_748) = S_Prim_isinstance(%para171_len_x, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %7(CNode_749) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %8(CNode_750) = Switch(%7, @✓2✗2↓tfnet_model_TFNetModel_construct_751, @3✗2↓tfnet_model_TFNetModel_construct_752)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %9(CNode_753) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
  %10(CNode_755) = call @↓2✗2↓tfnet_model_TFNetModel_construct_754(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
}
# Order:
#   1: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_743{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   2: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_744{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   3: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_745{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_743, [2]: CNode_744}
#   4: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_746{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'np.integer', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'ms': <module 'mindspore' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/__init__.py'>, 'ops': <module 'mindspore.ops' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/__init__.py'>, 'max': <built-in function max>, 'int': <class 'int'>, 'isinstance': <built-in function isinstance>, 'list': <class 'list'>, 'tuple': <class 'tuple'>, 'np': <module 'numpy' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/numpy/__init__.py'>}), [3]: CNode_745}
#   5: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_747{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: CNode_746}
#   6: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_748{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_len_x, [2]: CNode_747}
#   7: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_749{[0]: ValueNode<Primitive> Cond, [1]: CNode_748, [2]: ValueNode<BoolImm> false}
#   8: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_750{[0]: ValueNode<Primitive> Switch, [1]: CNode_749, [2]: ValueNode<FuncGraph> ✓2✗2↓tfnet_model_TFNetModel_construct_751, [3]: ValueNode<FuncGraph> 3✗2↓tfnet_model_TFNetModel_construct_752}
#   9: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_753{[0]: CNode_750}
#  10: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_755{[0]: ValueNode<FuncGraph> ↓2✗2↓tfnet_model_TFNetModel_construct_754, [1]: CNode_753}
#  11: @2✗2↓tfnet_model_TFNetModel_construct_659:CNode_756{[0]: ValueNode<Primitive> Return, [1]: CNode_755}


subgraph attr:
subgraph instance: ✓ms_max_665 : 0x310c9300
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓ms_max_665 parent: [subgraph @ms_max_436]() {
  %1(CNode_757) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("max() requires 1 argument at least.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2643/        const_utils.raise_type_error("max() requires 1 argument at least.")/
  %2(CNode_758) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %3(CNode_760) = call @↓ms_max_759()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %4(CNode_761) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2643/        const_utils.raise_type_error("max() requires 1 argument at least.")/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2643/        const_utils.raise_type_error("max() requires 1 argument at least.")/
}
# Order:
#   1: @✓ms_max_665:CNode_757{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> max() requires 1 argument at least.}
#   2: @✓ms_max_665:CNode_762{[0]: ValueNode<Primitive> Return, [1]: CNode_761}
#   3: @✓ms_max_665:CNode_760{[0]: ValueNode<FuncGraph> ↓ms_max_759}


subgraph attr:
subgraph instance: get_max_min_data_len_664 : 0x37a0f530
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @get_max_min_data_len_664(%para195_data) {
  %1(CNode_763) = S_Prim_isinstance(%para195_data, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %2(CNode_764) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %3(CNode_765) = Switch(%2, @↰get_max_min_data_len_766, @↱get_max_min_data_len_767)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %4(CNode_768) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %5(CNode_769) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %6(CNode_770) = Switch(%5, @✓get_max_min_data_len_771, @✗get_max_min_data_len_772)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %7(CNode_773) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %8(CNode_775) = call @↓get_max_min_data_len_774(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @get_max_min_data_len_664:CNode_763{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_data, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @get_max_min_data_len_664:CNode_764{[0]: ValueNode<Primitive> Cond, [1]: CNode_763, [2]: ValueNode<BoolImm> false}
#   3: @get_max_min_data_len_664:CNode_765{[0]: ValueNode<Primitive> Switch, [1]: CNode_764, [2]: ValueNode<FuncGraph> ↰get_max_min_data_len_766, [3]: ValueNode<FuncGraph> ↱get_max_min_data_len_767}
#   4: @get_max_min_data_len_664:CNode_768{[0]: CNode_765}
#   5: @get_max_min_data_len_664:CNode_769{[0]: ValueNode<Primitive> Cond, [1]: CNode_768, [2]: ValueNode<BoolImm> false}
#   6: @get_max_min_data_len_664:CNode_770{[0]: ValueNode<Primitive> Switch, [1]: CNode_769, [2]: ValueNode<FuncGraph> ✓get_max_min_data_len_771, [3]: ValueNode<FuncGraph> ✗get_max_min_data_len_772}
#   7: @get_max_min_data_len_664:CNode_773{[0]: CNode_770}
#   8: @get_max_min_data_len_664:CNode_775{[0]: ValueNode<FuncGraph> ↓get_max_min_data_len_774, [1]: CNode_773}
#   9: @get_max_min_data_len_664:CNode_776{[0]: ValueNode<Primitive> Return, [1]: CNode_775}


subgraph attr:
subgraph instance: ✗ms_max_666 : 0x3791eb70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗ms_max_666 parent: [subgraph @ms_max_436]() {
  %1(len_data) = $(ms_max_436):call @get_max_min_data_len_664(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %2(CNode_465) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  %3(CNode_466) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  %4(CNode_467) = Switch(%3, @✓✗ms_max_777, @2✗ms_max_778)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  %5(CNode_469) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
}
# Order:
#   1: @✗ms_max_666:CNode_465{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 1}
#   2: @✗ms_max_666:CNode_466{[0]: ValueNode<Primitive> Cond, [1]: CNode_465, [2]: ValueNode<BoolImm> false}
#   3: @✗ms_max_666:CNode_467{[0]: ValueNode<Primitive> Switch, [1]: CNode_466, [2]: ValueNode<FuncGraph> ✓✗ms_max_777, [3]: ValueNode<FuncGraph> 2✗ms_max_778}
#   4: @✗ms_max_666:CNode_469{[0]: CNode_467}
#   5: @✗ms_max_666:CNode_470{[0]: ValueNode<Primitive> Return, [1]: CNode_469}


subgraph attr:
subgraph instance: ↰zeros_680 : 0x33d01b00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
subgraph @↰zeros_680() {
  Return(F32)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
}
# Order:
#   1: @↰zeros_680:CNode_779{[0]: ValueNode<Primitive> Return, [1]: ValueNode<Float> Float32}


subgraph attr:
subgraph instance: ↱zeros_681 : 0x33d0ef50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
subgraph @↱zeros_681 parent: [subgraph @zeros_442]() {
  Return(%para188_dtype)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
}
# Order:
#   1: @↱zeros_681:CNode_780{[0]: ValueNode<Primitive> Return, [1]: param_dtype}


subgraph attr:
subgraph instance: _get_cache_prim_676 : 0x37635450
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:35/def _get_cache_prim(cls: Primitive) -> Primitive:/
subgraph @_get_cache_prim_676(%para196_cls) {
  %1(CNode_782) = call @✓_get_cache_prim_781()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:88/    if _is_need_compile(_temp_func): # @jit.cond: True/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:88/    if _is_need_compile(_temp_func): # @jit.cond: True/
}
# Order:
#   1: @_get_cache_prim_676:CNode_782{[0]: ValueNode<FuncGraph> ✓_get_cache_prim_781}
#   2: @_get_cache_prim_676:CNode_783{[0]: ValueNode<Primitive> Return, [1]: CNode_782}


subgraph attr:
after_block : 1
subgraph instance: ↓zeros_673 : 0x33cf0d40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↓zeros_673 parent: [subgraph @zeros_442](%para197_) {
  %1(CNode_675) = $(zeros_442):call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1031/    zero_op = _get_cache_prim(P.FillV2)()/
  %2(zero_op) = $(zeros_442):%1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1031/    zero_op = _get_cache_prim(P.FillV2)()/
  %3(CNode_682) = $(zeros_442):S_Prim_MakeTuple("_dtype")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1033/    value = Tensor(0, _dtype)/
  %4(CNode_677) = $(zeros_442):S_Prim_is_(%para188_dtype, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
  %5(CNode_678) = $(zeros_442):Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
  %6(CNode_679) = $(zeros_442):Switch(%5, @↰zeros_680, @↱zeros_681)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
  %7(_dtype) = $(zeros_442):%6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1032/    _dtype = mstype.float32 if dtype is None else dtype/
  %8(CNode_683) = $(zeros_442):S_Prim_MakeTuple(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1033/    value = Tensor(0, _dtype)/
  %9(CNode_684) = $(zeros_442):S_Prim_make_dict(%3, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1033/    value = Tensor(0, _dtype)/
  %10(value) = $(zeros_442):PyInterpret[side_effect_io: Bool(1)](Script['Tensor(0, _dtype)'], InterpretedObject, %9)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1033/    value = Tensor(0, _dtype)/
  %11(output) = %2(%para197_фsize, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1040/    output = zero_op(size, value)/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1041/    return output/
}
# Order:
#   1: @↓zeros_673:output{[0]: zero_op, [1]: param_фsize, [2]: value}
#   2: @↓zeros_673:CNode_784{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
subgraph instance: ✓zeros_670 : 0x37c6e290
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @✓zeros_670 parent: [subgraph @zeros_442]() {
  %1(CNode_785) = S_Prim_make_list(%para187_size)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1035/        size = tuple([size])/
  %2(size) = ClassType(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1035/        size = tuple([size])/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1035/        size = tuple([size])/
}
# Order:
#   1: @✓zeros_670:CNode_785{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: param_size}
#   2: @✓zeros_670:size{[0]: ValueNode<ClassType> class 'tuple', [1]: CNode_785}
#   3: @✓zeros_670:CNode_786{[0]: ValueNode<Primitive> Return, [1]: size}


subgraph attr:
subgraph instance: ✗zeros_671 : 0x37b24020
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @✗zeros_671 parent: [subgraph @zeros_442]() {
  %1(CNode_787) = S_Prim_isinstance(%para187_size, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
  %2(CNode_788) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
  %3(CNode_789) = Switch(%2, @✓✗zeros_790, @2✗zeros_791)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
  %4(CNode_792) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
}
# Order:
#   1: @✗zeros_671:CNode_787{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_size, [2]: ValueNode<ClassType> class 'list'}
#   2: @✗zeros_671:CNode_788{[0]: ValueNode<Primitive> Cond, [1]: CNode_787, [2]: ValueNode<BoolImm> false}
#   3: @✗zeros_671:CNode_789{[0]: ValueNode<Primitive> Switch, [1]: CNode_788, [2]: ValueNode<FuncGraph> ✓✗zeros_790, [3]: ValueNode<FuncGraph> 2✗zeros_791}
#   4: @✗zeros_671:CNode_792{[0]: CNode_789}
#   5: @✗zeros_671:CNode_793{[0]: ValueNode<Primitive> Return, [1]: CNode_792}


subgraph attr:
training : 1
subgraph instance: ↰2↱↓tfnet_model_TFNetModel_construct_690 : 0x373627e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰2↱↓tfnet_model_TFNetModel_construct_690 parent: [subgraph @2↱↓tfnet_model_TFNetModel_construct_616]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(channel) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_687) = $(2↱↓tfnet_model_TFNetModel_construct_616):S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↰2↱↓tfnet_model_TFNetModel_construct_690:CNode_794{[0]: ValueNode<Primitive> Return, [1]: CNode_687}


subgraph attr:
training : 1
subgraph instance: 3↱↓tfnet_model_TFNetModel_construct_691 : 0x37addc00
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @3↱↓tfnet_model_TFNetModel_construct_691 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(height) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_795) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %4(CNode_796) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %5(CNode_797) = Switch(%4, @↰3↱↓tfnet_model_TFNetModel_construct_798, @4↱↓tfnet_model_TFNetModel_construct_799)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  %6(CNode_800) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @3↱↓tfnet_model_TFNetModel_construct_691:CNode_795{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: height, [2]: ValueNode<Int64Imm> 0}
#   2: @3↱↓tfnet_model_TFNetModel_construct_691:CNode_796{[0]: ValueNode<Primitive> Cond, [1]: CNode_795, [2]: ValueNode<BoolImm> false}
#   3: @3↱↓tfnet_model_TFNetModel_construct_691:CNode_797{[0]: ValueNode<Primitive> Switch, [1]: CNode_796, [2]: ValueNode<FuncGraph> ↰3↱↓tfnet_model_TFNetModel_construct_798, [3]: ValueNode<FuncGraph> 4↱↓tfnet_model_TFNetModel_construct_799}
#   4: @3↱↓tfnet_model_TFNetModel_construct_691:CNode_800{[0]: CNode_797}
#   5: @3↱↓tfnet_model_TFNetModel_construct_691:CNode_801{[0]: ValueNode<Primitive> Return, [1]: CNode_800}


subgraph attr:
after_block : 1
subgraph instance: ↓✓↓enumerate__701 : 0x376082f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @↓✓↓enumerate__701(%para198_) {
  Return(%para198_фret)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2835/        if check_is_tensor(x_type):/
}
# Order:
#   1: @↓✓↓enumerate__701:CNode_802{[0]: ValueNode<Primitive> Return, [1]: param_фret}


subgraph attr:
subgraph instance: 2✓↓enumerate__698 : 0x376346e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @2✓↓enumerate__698 parent: [subgraph @enumerate__179]() {
  %1(CNode_804) = call @↵2✓↓enumerate__803(I64(0), ())
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
}
# Order:
#   1: @2✓↓enumerate__698:CNode_805{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @2✓↓enumerate__698:CNode_806{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_805, [2]: ValueNode<Int64Imm> 0}
#   3: @2✓↓enumerate__698:CNode_807{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_range, [1]: CNode_806}
#   4: @2✓↓enumerate__698:CNode_808{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_807}
#   5: @2✓↓enumerate__698:CNode_809{[0]: ValueNode<Primitive> Return, [1]: CNode_804}
#   6: @2✓↓enumerate__698:CNode_804{[0]: ValueNode<FuncGraph> ↵2✓↓enumerate__803, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<ValueTuple> ()}


subgraph attr:
subgraph instance: ✗✓↓enumerate__699 : 0x37659800
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @✗✓↓enumerate__699 parent: [subgraph @enumerate__179]() {
  %1(CNode_810) = S_Prim_inner_len(%para173_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2839/            ret = zip(range(start, start + len(x)), x)/
  %2(CNode_811) = S_Prim_add(%para174_start, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2839/            ret = zip(range(start, start + len(x)), x)/
  %3(CNode_812) = S_Prim_make_range(%para174_start, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2839/            ret = zip(range(start, start + len(x)), x)/
  %4(ret) = S_Prim_zip_operation(%3, %para173_x)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2839/            ret = zip(range(start, start + len(x)), x)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2839/            ret = zip(range(start, start + len(x)), x)/
}
# Order:
#   1: @✗✓↓enumerate__699:CNode_810{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   2: @✗✓↓enumerate__699:CNode_811{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_start, [2]: CNode_810}
#   3: @✗✓↓enumerate__699:CNode_812{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_range, [1]: param_start, [2]: CNode_811}
#   4: @✗✓↓enumerate__699:ret{[0]: ValueNode<DoSignaturePrimitive> S_Prim_zip_operation, [1]: CNode_812, [2]: param_x}
#   5: @✗✓↓enumerate__699:CNode_813{[0]: ValueNode<Primitive> Return, [1]: ret}


subgraph attr:
subgraph instance: ✓check_is_const_int_708 : 0x378a6550
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @✓check_is_const_int_708 parent: [subgraph @check_is_const_int_619]() {
  %1(CNode_814) = JoinedStr("For '", %para191_op_name, "', the '", %para192_arg_name, "' should be a const int number, but got not const.")
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3273/            f"For '{op_name}', the '{arg_name}' should be a const int number, but got not const.")/
  %2(CNode_815) = raise[side_effect_io: Bool(1)]("TypeError", %1, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3272/        raise TypeError(/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3272/        raise TypeError(/
}
# Order:
#   1: @✓check_is_const_int_708:CNode_814{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For ', [2]: param_op_name, [3]: ValueNode<StringImm> ', the ', [4]: param_arg_name, [5]: ValueNode<StringImm> ' should be a const int number, but got not const.}
#   2: @✓check_is_const_int_708:CNode_815{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: CNode_814, [3]: ValueNode<StringImm> None}
#   3: @✓check_is_const_int_708:CNode_816{[0]: ValueNode<Primitive> Return, [1]: CNode_815}


subgraph attr:
subgraph instance: ✗check_is_const_int_709 : 0x37921f00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @✗check_is_const_int_709 parent: [subgraph @check_is_const_int_619]() {
  %1(CNode_818) = call @↓check_is_const_int_817()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3271/    if x is None:/
}
# Order:
#   1: @✗check_is_const_int_709:CNode_818{[0]: ValueNode<FuncGraph> ↓check_is_const_int_817}
#   2: @✗check_is_const_int_709:CNode_819{[0]: ValueNode<Primitive> Return, [1]: CNode_818}


subgraph attr:
subgraph instance: ✓↻↓forward_fn_352 : 0x397e2d70
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓↻↓forward_fn_352 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_820) = getattr(%2, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:643/                            self.logger.warning(f"Batch {batch_idx} - Logits {logits_idx} is not a valid tensor")/
  %4(CNode_821) = getattr(%3, "warning")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:643/                            self.logger.warning(f"Batch {batch_idx} - Logits {logits_idx} is not a valid tensor")/
  %5(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %7(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %9(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %5, %8)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%9, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%10, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %12(CNode_328) = $(↓forward_fn_119):Cond(%11, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %13(CNode_329) = $(↓forward_fn_119):Switch(%12, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %14(logits_list) = $(↓forward_fn_119):%13()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %15(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %16(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%15)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %17(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%16, %para160_@CNode_121)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %18(logits_idx) = $(↻↓forward_fn_122):S_Prim_getitem(%17, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %19(CNode_822) = JoinedStr("Batch ", I64(0), " - Logits ", %18, " is not a valid tensor")
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:643/                            self.logger.warning(f"Batch {batch_idx} - Logits {logits_idx} is not a valid tensor")/
  %20(CNode_823) = %4(%19)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:643/                            self.logger.warning(f"Batch {batch_idx} - Logits {logits_idx} is not a valid tensor")/
  %21(CNode_824) = StopGradient(%20)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %22(CNode_121) = $(↻↓forward_fn_122):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para160_@CNode_121, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %23(CNode_825) = call @↵↓forward_fn_120(%22, %para161_фtotal_loss)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %24(CNode_826) = Depend[side_effect_propagate: I64(1)](%23, %21)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:644/                            continue/
  Return(%24)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:644/                            continue/
}
# Order:
#   1: @✓↻↓forward_fn_352:CNode_820{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✓↻↓forward_fn_352:CNode_821{[0]: ValueNode<Primitive> getattr, [1]: CNode_820, [2]: ValueNode<StringImm> warning}
#   3: @✓↻↓forward_fn_352:CNode_822{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Logits , [4]: logits_idx, [5]: ValueNode<StringImm>  is not a valid tensor}
#   4: @✓↻↓forward_fn_352:CNode_823{[0]: CNode_821, [1]: CNode_822}
#   5: @✓↻↓forward_fn_352:CNode_827{[0]: ValueNode<Primitive> Return, [1]: CNode_826}
#   6: @✓↻↓forward_fn_352:CNode_825{[0]: ValueNode<FuncGraph> ↵↓forward_fn_120, [1]: CNode_121, [2]: param_фtotal_loss}


subgraph attr:
subgraph instance: ↰↻↓forward_fn_347 : 0x39763280
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↰↻↓forward_fn_347 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %7(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%6, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %8(CNode_328) = $(↓forward_fn_119):Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %9(CNode_329) = $(↓forward_fn_119):Switch(%8, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %10(logits_list) = $(↓forward_fn_119):%9()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %12(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %13(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%12, %para160_@CNode_121)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %14(logits) = $(↻↓forward_fn_122):S_Prim_getitem(%13, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %15(CNode_343) = $(↻↓forward_fn_122):call @hasattr_98(%14, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %16(CNode_344) = $(↻↓forward_fn_122):S_Prim_logical_not(%15)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
}
# Order:
#   1: @↰↻↓forward_fn_347:CNode_828{[0]: ValueNode<Primitive> Return, [1]: CNode_344}


subgraph attr:
subgraph instance: ↱↻↓forward_fn_348 : 0x397619d0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↱↻↓forward_fn_348 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %7(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%6, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %8(CNode_328) = $(↓forward_fn_119):Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %9(CNode_329) = $(↓forward_fn_119):Switch(%8, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %10(logits_list) = $(↓forward_fn_119):%9()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %12(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %13(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%12, %para160_@CNode_121)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %14(logits) = $(↻↓forward_fn_122):S_Prim_getitem(%13, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %15(CNode_829) = call @hasattr_98(%14, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  %16(CNode_830) = S_Prim_logical_not(%15)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:642/                        if not hasattr(logits, 'shape') or not hasattr(logits, 'dtype'):/
}
# Order:
#   1: @↱↻↓forward_fn_348:CNode_829{[0]: ValueNode<FuncGraph> hasattr_98, [1]: logits, [2]: ValueNode<StringImm> dtype}
#   2: @↱↻↓forward_fn_348:CNode_830{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_829}
#   3: @↱↻↓forward_fn_348:CNode_831{[0]: ValueNode<Primitive> Return, [1]: CNode_830}


subgraph attr:
training : 1
subgraph instance: G_4↓tfnet_model_TFNetModel_construct_715 : 0x3971ee70
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_4↓tfnet_model_TFNetModel_construct_715 parent: [subgraph @4↓tfnet_model_TFNetModel_construct_647]() {
  %1(CNode_833) = call @↵4↓tfnet_model_TFNetModel_construct_832(%para193_фlen_x_list, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @G_4↓tfnet_model_TFNetModel_construct_715:CNode_834{[0]: ValueNode<Primitive> Return, [1]: CNode_833}
#   2: @G_4↓tfnet_model_TFNetModel_construct_715:CNode_833{[0]: ValueNode<FuncGraph> ↵4↓tfnet_model_TFNetModel_construct_832, [1]: param_фlen_x_list, [2]: ValueNode<ValueList> []}


subgraph attr:
training : 1
subgraph instance: ↵4↓tfnet_model_TFNetModel_construct_713 : 0x37b1d980
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵4↓tfnet_model_TFNetModel_construct_713 parent: [subgraph @4↓tfnet_model_TFNetModel_construct_647](%para199_, %para200_, %para201_) {
  %1(CNode_718) = $(4↓tfnet_model_TFNetModel_construct_647):ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %2(CNode_719) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_make_range(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %3(CNode_720) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_inner_len(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %4(CNode_835) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para199_@CNode_836, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %5(CNode_837) = Switch(%4, @↻4↓tfnet_model_TFNetModel_construct_838, @5↓tfnet_model_TFNetModel_construct_839)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %6(CNode_840) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
}
# Order:
#   1: @↵4↓tfnet_model_TFNetModel_construct_713:CNode_835{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_836, [2]: CNode_720}
#   2: @↵4↓tfnet_model_TFNetModel_construct_713:CNode_837{[0]: ValueNode<Primitive> Switch, [1]: CNode_835, [2]: ValueNode<FuncGraph> ↻4↓tfnet_model_TFNetModel_construct_838, [3]: ValueNode<FuncGraph> 5↓tfnet_model_TFNetModel_construct_839}
#   3: @↵4↓tfnet_model_TFNetModel_construct_713:CNode_840{[0]: CNode_837}
#   4: @↵4↓tfnet_model_TFNetModel_construct_713:CNode_841{[0]: ValueNode<Primitive> Return, [1]: CNode_840}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✗3↓tfnet_model_TFNetModel_construct_737 : 0x373aa6c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✗3↓tfnet_model_TFNetModel_construct_737(%para202_) {
  Return(%para202_фlen_x_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
}
# Order:
#   1: @↓✗3↓tfnet_model_TFNetModel_construct_737:CNode_842{[0]: ValueNode<Primitive> Return, [1]: param_фlen_x_list}


subgraph attr:
training : 1
subgraph instance: ✓✗3↓tfnet_model_TFNetModel_construct_734 : 0x3725ecb0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓✗3↓tfnet_model_TFNetModel_construct_734 parent: [subgraph @3↓tfnet_model_TFNetModel_construct_598]() {
  %1(CNode_843) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:108/            len_x_list = len_x_list[:int(batch)]/
  %2(CNode_844) = S_Prim_make_slice(None, %1, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:108/            len_x_list = len_x_list[:int(batch)]/
  %3(len_x_list) = S_Prim_getitem(%para185_фlen_x_list, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:108/            len_x_list = len_x_list[:int(batch)]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:108/            len_x_list = len_x_list[:int(batch)]/
}
# Order:
#   1: @✓✗3↓tfnet_model_TFNetModel_construct_734:CNode_843{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   2: @✓✗3↓tfnet_model_TFNetModel_construct_734:CNode_844{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: CNode_843, [3]: ValueNode<None> None}
#   3: @✓✗3↓tfnet_model_TFNetModel_construct_734:len_x_list{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фlen_x_list, [2]: CNode_844}
#   4: @✓✗3↓tfnet_model_TFNetModel_construct_734:CNode_845{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: 2✗3↓tfnet_model_TFNetModel_construct_735 : 0x30629850
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @2✗3↓tfnet_model_TFNetModel_construct_735 parent: [subgraph @3↓tfnet_model_TFNetModel_construct_598]() {
  Return(%para185_фlen_x_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:107/        elif len(len_x_list) > int(batch):/
}
# Order:
#   1: @2✗3↓tfnet_model_TFNetModel_construct_735:CNode_846{[0]: ValueNode<Primitive> Return, [1]: param_фlen_x_list}


subgraph attr:
training : 1
subgraph instance: G_✓✗2↓tfnet_model_TFNetModel_construct_741 : 0x376cd1c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_✓✗2↓tfnet_model_TFNetModel_construct_741 parent: [subgraph @tfnet_model_TFNetModel_construct_169]() {
  %1(CNode_848) = call @↵✓✗2↓tfnet_model_TFNetModel_construct_847(%para171_len_x, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @G_✓✗2↓tfnet_model_TFNetModel_construct_741:CNode_849{[0]: ValueNode<Primitive> Return, [1]: CNode_848}
#   2: @G_✓✗2↓tfnet_model_TFNetModel_construct_741:CNode_848{[0]: ValueNode<FuncGraph> ↵✓✗2↓tfnet_model_TFNetModel_construct_847, [1]: param_len_x, [2]: ValueNode<ValueList> []}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓2✗2↓tfnet_model_TFNetModel_construct_754 : 0x374db8d0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓2✗2↓tfnet_model_TFNetModel_construct_754(%para203_) {
  Return(%para203_фlen_x_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:99/        elif isinstance(len_x, (int, np.integer)):/
}
# Order:
#   1: @↓2✗2↓tfnet_model_TFNetModel_construct_754:CNode_850{[0]: ValueNode<Primitive> Return, [1]: param_фlen_x_list}


subgraph attr:
training : 1
subgraph instance: ✓2✗2↓tfnet_model_TFNetModel_construct_751 : 0x37a97550
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓2✗2↓tfnet_model_TFNetModel_construct_751 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_851) = ClassType(%para171_len_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:100/            len_x_list = [int(len_x)] * int(batch)/
  %2(CNode_852) = S_Prim_make_list(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:100/            len_x_list = [int(len_x)] * int(batch)/
  %3(CNode_853) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:100/            len_x_list = [int(len_x)] * int(batch)/
  %4(len_x_list) = S_Prim_mul(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:100/            len_x_list = [int(len_x)] * int(batch)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:100/            len_x_list = [int(len_x)] * int(batch)/
}
# Order:
#   1: @✓2✗2↓tfnet_model_TFNetModel_construct_751:CNode_851{[0]: ValueNode<ClassType> class 'int', [1]: param_len_x}
#   2: @✓2✗2↓tfnet_model_TFNetModel_construct_751:CNode_852{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_851}
#   3: @✓2✗2↓tfnet_model_TFNetModel_construct_751:CNode_853{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   4: @✓2✗2↓tfnet_model_TFNetModel_construct_751:len_x_list{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_852, [2]: CNode_853}
#   5: @✓2✗2↓tfnet_model_TFNetModel_construct_751:CNode_854{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: 3✗2↓tfnet_model_TFNetModel_construct_752 : 0x37adccc0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @3✗2↓tfnet_model_TFNetModel_construct_752 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_855) = ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:103/            len_x_list = [int(temp)] * int(batch)/
  %2(CNode_856) = S_Prim_make_list(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:103/            len_x_list = [int(temp)] * int(batch)/
  %3(CNode_857) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:103/            len_x_list = [int(temp)] * int(batch)/
  %4(len_x_list) = S_Prim_mul(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:103/            len_x_list = [int(temp)] * int(batch)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:103/            len_x_list = [int(temp)] * int(batch)/
}
# Order:
#   1: @3✗2↓tfnet_model_TFNetModel_construct_752:CNode_855{[0]: ValueNode<ClassType> class 'int', [1]: param_фtemp}
#   2: @3✗2↓tfnet_model_TFNetModel_construct_752:CNode_856{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_855}
#   3: @3✗2↓tfnet_model_TFNetModel_construct_752:CNode_857{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   4: @3✗2↓tfnet_model_TFNetModel_construct_752:len_x_list{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_856, [2]: CNode_857}
#   5: @3✗2↓tfnet_model_TFNetModel_construct_752:CNode_858{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
after_block : 1
subgraph instance: ↓ms_max_759 : 0x378c27f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓ms_max_759 parent: [subgraph @ms_max_436]() {
  %1(CNode_509) = call @↵↓ms_max_859(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↓ms_max_759:CNode_510{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @↓ms_max_759:CNode_511{[0]: ValueNode<Primitive> Return, [1]: CNode_509}
#   3: @↓ms_max_759:CNode_509{[0]: ValueNode<FuncGraph> ↵↓ms_max_859, [1]: ValueNode<Int64Imm> 0}


subgraph attr:
after_block : 1
subgraph instance: ↓get_max_min_data_len_774 : 0x37a36500
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @↓get_max_min_data_len_774(%para204_) {
  %1(CNode_860) = S_Prim_MakeTuple(ClassType, ClassType, ClassType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
  %2(CNode_861) = S_Prim_isinstance(%para204_фdata, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
  %3(CNode_862) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
  %4(CNode_863) = Switch(%3, @✓↓get_max_min_data_len_864, @✗↓get_max_min_data_len_865)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
  %5(CNode_866) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
  %6(CNode_868) = call @2↓get_max_min_data_len_867(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2543/    if isinstance(data, (dict, list, tuple)):/
}
# Order:
#   1: @↓get_max_min_data_len_774:CNode_860{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'dict', [2]: ValueNode<ClassType> class 'list', [3]: ValueNode<ClassType> class 'tuple'}
#   2: @↓get_max_min_data_len_774:CNode_861{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_фdata, [2]: CNode_860}
#   3: @↓get_max_min_data_len_774:CNode_862{[0]: ValueNode<Primitive> Cond, [1]: CNode_861, [2]: ValueNode<BoolImm> false}
#   4: @↓get_max_min_data_len_774:CNode_863{[0]: ValueNode<Primitive> Switch, [1]: CNode_862, [2]: ValueNode<FuncGraph> ✓↓get_max_min_data_len_864, [3]: ValueNode<FuncGraph> ✗↓get_max_min_data_len_865}
#   5: @↓get_max_min_data_len_774:CNode_866{[0]: CNode_863}
#   6: @↓get_max_min_data_len_774:CNode_868{[0]: ValueNode<FuncGraph> 2↓get_max_min_data_len_867, [1]: CNode_866}
#   7: @↓get_max_min_data_len_774:CNode_869{[0]: ValueNode<Primitive> Return, [1]: CNode_868}


subgraph attr:
subgraph instance: ✓get_max_min_data_len_771 : 0x37ab51f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @✓get_max_min_data_len_771 parent: [subgraph @get_max_min_data_len_664]() {
  %1(data) = S_Prim_getitem(%para195_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2540/        data = data[0]/
  %2(CNode_870) = S_Prim_isinstance(%1, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
  %3(CNode_871) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
  %4(CNode_872) = Switch(%3, @2✓get_max_min_data_len_873, @✗✓get_max_min_data_len_874)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
  %5(CNode_875) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
  %6(CNode_877) = call @↓✓get_max_min_data_len_876(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
}
# Order:
#   1: @✓get_max_min_data_len_771:data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @✓get_max_min_data_len_771:CNode_870{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: data, [2]: ValueNode<ClassType> class 'dict'}
#   3: @✓get_max_min_data_len_771:CNode_871{[0]: ValueNode<Primitive> Cond, [1]: CNode_870, [2]: ValueNode<BoolImm> false}
#   4: @✓get_max_min_data_len_771:CNode_872{[0]: ValueNode<Primitive> Switch, [1]: CNode_871, [2]: ValueNode<FuncGraph> 2✓get_max_min_data_len_873, [3]: ValueNode<FuncGraph> ✗✓get_max_min_data_len_874}
#   5: @✓get_max_min_data_len_771:CNode_875{[0]: CNode_872}
#   6: @✓get_max_min_data_len_771:CNode_877{[0]: ValueNode<FuncGraph> ↓✓get_max_min_data_len_876, [1]: CNode_875}
#   7: @✓get_max_min_data_len_771:CNode_878{[0]: ValueNode<Primitive> Return, [1]: CNode_877}


subgraph attr:
subgraph instance: ✗get_max_min_data_len_772 : 0x3764e850
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @✗get_max_min_data_len_772 parent: [subgraph @get_max_min_data_len_664]() {
  Return(%para195_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @✗get_max_min_data_len_772:CNode_879{[0]: ValueNode<Primitive> Return, [1]: param_data}


subgraph attr:
subgraph instance: ↰get_max_min_data_len_766 : 0x37913a50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @↰get_max_min_data_len_766 parent: [subgraph @get_max_min_data_len_664]() {
  %1(CNode_880) = S_Prim_inner_len(%para195_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %2(CNode_881) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %3(CNode_882) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %4(CNode_883) = Switch(%3, @2↰get_max_min_data_len_884, @↱↰get_max_min_data_len_885)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %5(CNode_886) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @↰get_max_min_data_len_766:CNode_880{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @↰get_max_min_data_len_766:CNode_881{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_880, [2]: ValueNode<Int64Imm> 1}
#   3: @↰get_max_min_data_len_766:CNode_882{[0]: ValueNode<Primitive> Cond, [1]: CNode_881, [2]: ValueNode<BoolImm> false}
#   4: @↰get_max_min_data_len_766:CNode_883{[0]: ValueNode<Primitive> Switch, [1]: CNode_882, [2]: ValueNode<FuncGraph> 2↰get_max_min_data_len_884, [3]: ValueNode<FuncGraph> ↱↰get_max_min_data_len_885}
#   5: @↰get_max_min_data_len_766:CNode_886{[0]: CNode_883}
#   6: @↰get_max_min_data_len_766:CNode_887{[0]: ValueNode<Primitive> Return, [1]: CNode_886}


subgraph attr:
subgraph instance: ↱get_max_min_data_len_767 : 0x37a523c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @↱get_max_min_data_len_767 parent: [subgraph @get_max_min_data_len_664]() {
  %1(CNode_763) = $(get_max_min_data_len_664):S_Prim_isinstance(%para195_data, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @↱get_max_min_data_len_767:CNode_888{[0]: ValueNode<Primitive> Return, [1]: CNode_763}


subgraph attr:
subgraph instance: ✓✗ms_max_777 : 0x33cde4b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓✗ms_max_777 parent: [subgraph @ms_max_436]() {
  %1(x) = S_Prim_getitem(%para186_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2645/        x = data[0]/
  %2(CNode_890) = call @ms_max_one_element_889(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
}
# Order:
#   1: @✓✗ms_max_777:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @✓✗ms_max_777:CNode_890{[0]: ValueNode<FuncGraph> ms_max_one_element_889, [1]: x}
#   3: @✓✗ms_max_777:CNode_891{[0]: ValueNode<Primitive> Return, [1]: CNode_890}


subgraph attr:
subgraph instance: 2✗ms_max_778 : 0x3791fca0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2✗ms_max_778 parent: [subgraph @ms_max_436]() {
  %1(len_data) = $(ms_max_436):call @get_max_min_data_len_664(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %2(CNode_471) = S_Prim_greater_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  %3(CNode_472) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  %4(CNode_473) = Switch(%3, @✓2✗ms_max_892, @3✗ms_max_893)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  %5(CNode_475) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
}
# Order:
#   1: @2✗ms_max_778:CNode_471{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 2}
#   2: @2✗ms_max_778:CNode_472{[0]: ValueNode<Primitive> Cond, [1]: CNode_471, [2]: ValueNode<BoolImm> false}
#   3: @2✗ms_max_778:CNode_473{[0]: ValueNode<Primitive> Switch, [1]: CNode_472, [2]: ValueNode<FuncGraph> ✓2✗ms_max_892, [3]: ValueNode<FuncGraph> 3✗ms_max_893}
#   4: @2✗ms_max_778:CNode_475{[0]: CNode_473}
#   5: @2✗ms_max_778:CNode_476{[0]: ValueNode<Primitive> Return, [1]: CNode_475}


subgraph attr:
subgraph instance: ✓_get_cache_prim_781 : 0x37a9beb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:35/def _get_cache_prim(cls: Primitive) -> Primitive:/
subgraph @✓_get_cache_prim_781 parent: [subgraph @_get_cache_prim_676]() {
  Return(@_new_prim_for_graph_894)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:89/        return _new_prim_for_graph/
}
# Order:
#   1: @✓_get_cache_prim_781:CNode_895{[0]: ValueNode<Primitive> Return, [1]: ValueNode<FuncGraph> _new_prim_for_graph_894}


subgraph attr:
subgraph instance: ✓✗zeros_790 : 0x375805d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @✓✗zeros_790 parent: [subgraph @zeros_442]() {
  %1(CNode_896) = S_Prim_MakeTuple("size")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1037/        size = Tensor(size, dtype=mstype.int64)/
  %2(CNode_897) = S_Prim_MakeTuple(%para187_size)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1037/        size = Tensor(size, dtype=mstype.int64)/
  %3(CNode_898) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1037/        size = Tensor(size, dtype=mstype.int64)/
  %4(size) = PyInterpret[side_effect_io: Bool(1)](Script['Tensor(size, dtype=mstype.int64)'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1037/        size = Tensor(size, dtype=mstype.int64)/
  %5(CNode_900) = call @↓✗zeros_899(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1037/        size = Tensor(size, dtype=mstype.int64)/
}
# Order:
#   1: @✓✗zeros_790:CNode_896{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> size}
#   2: @✓✗zeros_790:CNode_897{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_size}
#   3: @✓✗zeros_790:CNode_898{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_896, [2]: CNode_897}
#   4: @✓✗zeros_790:size{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(size, dtype=mstype.int64)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'_get_cache_prim': <function _get_cache_prim at 0x7f9335990a60>, 'P': <module 'mindspore.ops.operations' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/operations/__init__.py'>, 'mstype': <module 'mindspore.common.dtype' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/common/dtype.py'>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'isinstance': <built-in function isinstance>, 'int': <class 'int'>, 'tuple': <class 'tuple'>, 'list': <class 'list'>}), [3]: CNode_898}
#   5: @✓✗zeros_790:CNode_901{[0]: ValueNode<Primitive> Return, [1]: CNode_900}
#   6: @✓✗zeros_790:CNode_900{[0]: ValueNode<FuncGraph> ↓✗zeros_899, [1]: size}


subgraph attr:
subgraph instance: 2✗zeros_791 : 0x3738bea0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @2✗zeros_791 parent: [subgraph @zeros_442]() {
  %1(CNode_902) = S_Prim_isinstance(%para187_size, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %2(CNode_903) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %3(CNode_904) = Switch(%2, @↰2✗zeros_905, @↱2✗zeros_906)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %4(CNode_907) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %5(CNode_908) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %6(CNode_909) = Switch(%5, @✓2✗zeros_910, @3✗zeros_911)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %7(CNode_912) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %8(CNode_914) = call @↓2✗zeros_913(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @2✗zeros_791:CNode_902{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_size, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @2✗zeros_791:CNode_903{[0]: ValueNode<Primitive> Cond, [1]: CNode_902, [2]: ValueNode<BoolImm> false}
#   3: @2✗zeros_791:CNode_904{[0]: ValueNode<Primitive> Switch, [1]: CNode_903, [2]: ValueNode<FuncGraph> ↰2✗zeros_905, [3]: ValueNode<FuncGraph> ↱2✗zeros_906}
#   4: @2✗zeros_791:CNode_907{[0]: CNode_904}
#   5: @2✗zeros_791:CNode_908{[0]: ValueNode<Primitive> Cond, [1]: CNode_907, [2]: ValueNode<BoolImm> false}
#   6: @2✗zeros_791:CNode_909{[0]: ValueNode<Primitive> Switch, [1]: CNode_908, [2]: ValueNode<FuncGraph> ✓2✗zeros_910, [3]: ValueNode<FuncGraph> 3✗zeros_911}
#   7: @2✗zeros_791:CNode_912{[0]: CNode_909}
#   8: @2✗zeros_791:CNode_914{[0]: ValueNode<FuncGraph> ↓2✗zeros_913, [1]: CNode_912}
#   9: @2✗zeros_791:CNode_915{[0]: ValueNode<Primitive> Return, [1]: CNode_914}


subgraph attr:
training : 1
subgraph instance: ↰3↱↓tfnet_model_TFNetModel_construct_798 : 0x305df040
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰3↱↓tfnet_model_TFNetModel_construct_798 parent: [subgraph @3↱↓tfnet_model_TFNetModel_construct_691]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(height) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_795) = $(3↱↓tfnet_model_TFNetModel_construct_691):S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @↰3↱↓tfnet_model_TFNetModel_construct_798:CNode_916{[0]: ValueNode<Primitive> Return, [1]: CNode_795}


subgraph attr:
training : 1
subgraph instance: 4↱↓tfnet_model_TFNetModel_construct_799 : 0x37b7b8b0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @4↱↓tfnet_model_TFNetModel_construct_799 parent: [subgraph @↓tfnet_model_TFNetModel_construct_549]() {
  %1(CNode_560) = $(↓tfnet_model_TFNetModel_construct_549):getattr(%para175_фseq_data, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %2(width) = $(↓tfnet_model_TFNetModel_construct_549):S_Prim_getitem(%1, I64(4))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:83/        batch, temp, channel, height, width = seq_data.shape/
  %3(CNode_917) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:86/        if batch <= 0 or temp <= 0 or channel <= 0 or height <= 0 or width <= 0:/
}
# Order:
#   1: @4↱↓tfnet_model_TFNetModel_construct_799:CNode_917{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: width, [2]: ValueNode<Int64Imm> 0}
#   2: @4↱↓tfnet_model_TFNetModel_construct_799:CNode_918{[0]: ValueNode<Primitive> Return, [1]: CNode_917}


subgraph attr:
subgraph instance: ↵2✓↓enumerate__803 : 0x37631350
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @↵2✓↓enumerate__803 parent: [subgraph @2✓↓enumerate__698](%para205_, %para206_) {
  %1(CNode_805) = $(2✓↓enumerate__698):getattr(%para173_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %2(CNode_806) = $(2✓↓enumerate__698):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %3(CNode_807) = $(2✓↓enumerate__698):S_Prim_make_range(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %4(CNode_808) = $(2✓↓enumerate__698):S_Prim_inner_len(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %5(CNode_919) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para205_@CNode_920, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %6(CNode_921) = Switch(%5, @↻2✓↓enumerate__922, @↓2✓↓enumerate__923)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %7(CNode_924) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
}
# Order:
#   1: @↵2✓↓enumerate__803:CNode_919{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_920, [2]: CNode_808}
#   2: @↵2✓↓enumerate__803:CNode_921{[0]: ValueNode<Primitive> Switch, [1]: CNode_919, [2]: ValueNode<FuncGraph> ↻2✓↓enumerate__922, [3]: ValueNode<FuncGraph> ↓2✓↓enumerate__923}
#   3: @↵2✓↓enumerate__803:CNode_924{[0]: CNode_921}
#   4: @↵2✓↓enumerate__803:CNode_925{[0]: ValueNode<Primitive> Return, [1]: CNode_924}


subgraph attr:
after_block : 1
subgraph instance: ↓check_is_const_int_817 : 0x378f9b90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @↓check_is_const_int_817 parent: [subgraph @check_is_const_int_619]() {
  %1(CNode_926) = S_Prim_isinstance(%para190_x, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  %2(CNode_927) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  %3(CNode_928) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  %4(CNode_929) = Switch(%3, @✓↓check_is_const_int_930, @✗↓check_is_const_int_931)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  %5(CNode_932) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
}
# Order:
#   1: @↓check_is_const_int_817:CNode_926{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: ValueNode<ClassType> class 'int'}
#   2: @↓check_is_const_int_817:CNode_927{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_926}
#   3: @↓check_is_const_int_817:CNode_928{[0]: ValueNode<Primitive> Cond, [1]: CNode_927, [2]: ValueNode<BoolImm> false}
#   4: @↓check_is_const_int_817:CNode_929{[0]: ValueNode<Primitive> Switch, [1]: CNode_928, [2]: ValueNode<FuncGraph> ✓↓check_is_const_int_930, [3]: ValueNode<FuncGraph> ✗↓check_is_const_int_931}
#   5: @↓check_is_const_int_817:CNode_932{[0]: CNode_929}
#   6: @↓check_is_const_int_817:CNode_933{[0]: ValueNode<Primitive> Return, [1]: CNode_932}


subgraph attr:
training : 1
subgraph instance: ↵4↓tfnet_model_TFNetModel_construct_832 : 0x3972f410
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵4↓tfnet_model_TFNetModel_construct_832(%para207_iter, %para208_list) {
  %1(CNode_935) = call @hasnext_934(%para207_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_936) = Switch(%1, @↻4↓tfnet_model_TFNetModel_construct_937, @5↓tfnet_model_TFNetModel_construct_938)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %3(CNode_939) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @↵4↓tfnet_model_TFNetModel_construct_832:CNode_935{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵4↓tfnet_model_TFNetModel_construct_832:CNode_936{[0]: ValueNode<Primitive> Switch, [1]: CNode_935, [2]: ValueNode<FuncGraph> ↻4↓tfnet_model_TFNetModel_construct_937, [3]: ValueNode<FuncGraph> 5↓tfnet_model_TFNetModel_construct_938}
#   3: @↵4↓tfnet_model_TFNetModel_construct_832:CNode_939{[0]: CNode_936}
#   4: @↵4↓tfnet_model_TFNetModel_construct_832:CNode_940{[0]: ValueNode<Primitive> Return, [1]: CNode_939}


subgraph attr:
training : 1
subgraph instance: ↻4↓tfnet_model_TFNetModel_construct_838 : 0x394f3720
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻4↓tfnet_model_TFNetModel_construct_838 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  %1(CNode_836) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para199_@CNode_836, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %2(CNode_941) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
  %3(CNode_716) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_mul(%para177_фbatch, %para176_фtemp)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %4(CNode_717) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_MakeTuple(%3, %para179_фchannel, %para180_фheight, %para181_фwidth)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %5(inputs) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para178_фseq_data, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %6(CNode_942) = getattr(%5, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %7(CNode_943) = S_Prim_getitem(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %8(CNode_944) = S_Prim_less(%para200_фstart_idx, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %9(CNode_945) = Cond(%8, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %10(CNode_946) = Switch(%9, @↰↻4↓tfnet_model_TFNetModel_construct_947, @↱↻4↓tfnet_model_TFNetModel_construct_948)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %11(CNode_949) = %10()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %12(CNode_950) = Cond(%11, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %13(CNode_951) = Switch(%12, @✓↻4↓tfnet_model_TFNetModel_construct_952, @✗↻4↓tfnet_model_TFNetModel_construct_953)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %14(CNode_954) = %13()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %15(CNode_956) = call @↓↻4↓tfnet_model_TFNetModel_construct_955(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %16(CNode_957) = Depend[side_effect_propagate: I64(1)](%15, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%16)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
}
# Order:
#   1: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_958{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_719}
#   2: @↻4↓tfnet_model_TFNetModel_construct_838:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_958, [2]: param_@CNode_836}
#   3: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_836{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_836, [2]: ValueNode<Int64Imm> 1}
#   4: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_959{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: len_x_list, [2]: i}
#   5: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_960{[0]: ValueNode<ClassType> class 'int', [1]: CNode_959}
#   6: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_961{[0]: ValueNode<ClassType> class 'int', [1]: param_фtemp}
#   7: @↻4↓tfnet_model_TFNetModel_construct_838:lgt_i{[0]: ValueNode<FuncGraph> ms_min_962, [1]: CNode_960, [2]: CNode_961}
#   8: @↻4↓tfnet_model_TFNetModel_construct_838:end_idx{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фstart_idx, [2]: lgt_i}
#   9: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_963{[0]: ValueNode<Primitive> getattr, [1]: inputs, [2]: ValueNode<StringImm> shape}
#  10: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_964{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_963, [2]: ValueNode<Int64Imm> 0}
#  11: @↻4↓tfnet_model_TFNetModel_construct_838:end_idx{[0]: ValueNode<FuncGraph> ms_min_962, [1]: end_idx, [2]: CNode_964}
#  12: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_942{[0]: ValueNode<Primitive> getattr, [1]: inputs, [2]: ValueNode<StringImm> shape}
#  13: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_943{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_942, [2]: ValueNode<Int64Imm> 0}
#  14: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_944{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less, [1]: param_фstart_idx, [2]: CNode_943}
#  15: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_945{[0]: ValueNode<Primitive> Cond, [1]: CNode_944, [2]: ValueNode<BoolImm> false}
#  16: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_946{[0]: ValueNode<Primitive> Switch, [1]: CNode_945, [2]: ValueNode<FuncGraph> ↰↻4↓tfnet_model_TFNetModel_construct_947, [3]: ValueNode<FuncGraph> ↱↻4↓tfnet_model_TFNetModel_construct_948}
#  17: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_949{[0]: CNode_946}
#  18: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_950{[0]: ValueNode<Primitive> Cond, [1]: CNode_949, [2]: ValueNode<BoolImm> false}
#  19: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_951{[0]: ValueNode<Primitive> Switch, [1]: CNode_950, [2]: ValueNode<FuncGraph> ✓↻4↓tfnet_model_TFNetModel_construct_952, [3]: ValueNode<FuncGraph> ✗↻4↓tfnet_model_TFNetModel_construct_953}
#  20: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_954{[0]: CNode_951}
#  21: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_956{[0]: ValueNode<FuncGraph> ↓↻4↓tfnet_model_TFNetModel_construct_955, [1]: CNode_954}
#  22: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_957{[0]: ValueNode<Primitive> Depend, [1]: CNode_956, [2]: CNode_941}
#  23: @↻4↓tfnet_model_TFNetModel_construct_838:CNode_965{[0]: ValueNode<Primitive> Return, [1]: CNode_957}


subgraph attr:
training : 1
subgraph instance: 5↓tfnet_model_TFNetModel_construct_839 : 0x37fc9600
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @5↓tfnet_model_TFNetModel_construct_839 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  %1(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_966) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %3(CNode_967) = Switch(%2, @↰5↓tfnet_model_TFNetModel_construct_968, @↱5↓tfnet_model_TFNetModel_construct_969)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %4(CNode_970) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %5(CNode_971) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %6(CNode_972) = Switch(%5, @✓5↓tfnet_model_TFNetModel_construct_973, @✗5↓tfnet_model_TFNetModel_construct_974)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %7(CNode_975) = %6()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
  %8(CNode_977) = call @6↓tfnet_model_TFNetModel_construct_976(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
}
# Order:
#   1: @5↓tfnet_model_TFNetModel_construct_839:CNode_966{[0]: ValueNode<Primitive> Cond, [1]: len_x_list, [2]: ValueNode<BoolImm> false}
#   2: @5↓tfnet_model_TFNetModel_construct_839:CNode_967{[0]: ValueNode<Primitive> Switch, [1]: CNode_966, [2]: ValueNode<FuncGraph> ↰5↓tfnet_model_TFNetModel_construct_968, [3]: ValueNode<FuncGraph> ↱5↓tfnet_model_TFNetModel_construct_969}
#   3: @5↓tfnet_model_TFNetModel_construct_839:CNode_970{[0]: CNode_967}
#   4: @5↓tfnet_model_TFNetModel_construct_839:CNode_971{[0]: ValueNode<Primitive> Cond, [1]: CNode_970, [2]: ValueNode<BoolImm> false}
#   5: @5↓tfnet_model_TFNetModel_construct_839:CNode_972{[0]: ValueNode<Primitive> Switch, [1]: CNode_971, [2]: ValueNode<FuncGraph> ✓5↓tfnet_model_TFNetModel_construct_973, [3]: ValueNode<FuncGraph> ✗5↓tfnet_model_TFNetModel_construct_974}
#   6: @5↓tfnet_model_TFNetModel_construct_839:CNode_975{[0]: CNode_972}
#   7: @5↓tfnet_model_TFNetModel_construct_839:CNode_977{[0]: ValueNode<FuncGraph> 6↓tfnet_model_TFNetModel_construct_976, [1]: CNode_975}
#   8: @5↓tfnet_model_TFNetModel_construct_839:CNode_978{[0]: ValueNode<Primitive> Return, [1]: CNode_977}


subgraph attr:
training : 1
subgraph instance: ↵✓✗2↓tfnet_model_TFNetModel_construct_847 : 0x378114c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵✓✗2↓tfnet_model_TFNetModel_construct_847(%para209_iter, %para210_list) {
  %1(CNode_979) = call @hasnext_934(%para209_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %2(CNode_980) = Switch(%1, @↻✓✗2↓tfnet_model_TFNetModel_construct_981, @↓✓✗2↓tfnet_model_TFNetModel_construct_982)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %3(CNode_983) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @↵✓✗2↓tfnet_model_TFNetModel_construct_847:CNode_979{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵✓✗2↓tfnet_model_TFNetModel_construct_847:CNode_980{[0]: ValueNode<Primitive> Switch, [1]: CNode_979, [2]: ValueNode<FuncGraph> ↻✓✗2↓tfnet_model_TFNetModel_construct_981, [3]: ValueNode<FuncGraph> ↓✓✗2↓tfnet_model_TFNetModel_construct_982}
#   3: @↵✓✗2↓tfnet_model_TFNetModel_construct_847:CNode_983{[0]: CNode_980}
#   4: @↵✓✗2↓tfnet_model_TFNetModel_construct_847:CNode_984{[0]: ValueNode<Primitive> Return, [1]: CNode_983}


subgraph attr:
subgraph instance: ↵↓ms_max_859 : 0x377872d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↵↓ms_max_859 parent: [subgraph @↓ms_max_759](%para211_) {
  %1(CNode_510) = $(↓ms_max_759):S_Prim_inner_len(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %2(CNode_512) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para211_@CNode_142, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %3(CNode_513) = Switch(%2, @↻↓ms_max_985, @2↓ms_max_986)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %4(CNode_515) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↵↓ms_max_859:CNode_512{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_142, [2]: CNode_510}
#   2: @↵↓ms_max_859:CNode_513{[0]: ValueNode<Primitive> Switch, [1]: CNode_512, [2]: ValueNode<FuncGraph> ↻↓ms_max_985, [3]: ValueNode<FuncGraph> 2↓ms_max_986}
#   3: @↵↓ms_max_859:CNode_515{[0]: CNode_513}
#   4: @↵↓ms_max_859:CNode_516{[0]: ValueNode<Primitive> Return, [1]: CNode_515}


subgraph attr:
after_block : 1
subgraph instance: 2↓get_max_min_data_len_867 : 0x37340a20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @2↓get_max_min_data_len_867(%para212_) {
  Return(%para212_фlen_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2548/    return len_data/
}
# Order:
#   1: @2↓get_max_min_data_len_867:CNode_987{[0]: ValueNode<Primitive> Return, [1]: param_фlen_data}


subgraph attr:
subgraph instance: ✓↓get_max_min_data_len_864 : 0x373680b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @✓↓get_max_min_data_len_864 parent: [subgraph @↓get_max_min_data_len_774]() {
  %1(len_data) = S_Prim_inner_len(%para204_фdata)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2544/        len_data = len(data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2544/        len_data = len(data)/
}
# Order:
#   1: @✓↓get_max_min_data_len_864:len_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фdata}
#   2: @✓↓get_max_min_data_len_864:CNode_988{[0]: ValueNode<Primitive> Return, [1]: len_data}


subgraph attr:
subgraph instance: ✗↓get_max_min_data_len_865 : 0x373691e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @✗↓get_max_min_data_len_865() {
  %1(CNode_989) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("max() or min() does not support the data type.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2546/        const_utils.raise_type_error(/
  %2(CNode_990) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
  %3(CNode_991) = Depend[side_effect_propagate: I64(1)](I64(0), %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2546/        const_utils.raise_type_error(/
}
# Order:
#   1: @✗↓get_max_min_data_len_865:CNode_989{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> max() or min() does not support the data type.}
#   2: @✗↓get_max_min_data_len_865:CNode_992{[0]: ValueNode<Primitive> Return, [1]: CNode_991}


subgraph attr:
after_block : 1
subgraph instance: ↓✓get_max_min_data_len_876 : 0x37a5e640
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @↓✓get_max_min_data_len_876(%para213_) {
  Return(%para213_фdata)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2540/        data = data[0]/
}
# Order:
#   1: @↓✓get_max_min_data_len_876:CNode_993{[0]: ValueNode<Primitive> Return, [1]: param_фdata}


subgraph attr:
subgraph instance: 2✓get_max_min_data_len_873 : 0x37f3ea10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @2✓get_max_min_data_len_873 parent: [subgraph @✓get_max_min_data_len_771]() {
  %1(data) = $(✓get_max_min_data_len_771):S_Prim_getitem(%para195_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2540/        data = data[0]/
  %2(data) = call @ms_iter_97(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2542/            data = iter(data)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2542/            data = iter(data)/
}
# Order:
#   1: @2✓get_max_min_data_len_873:data{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: data}
#   2: @2✓get_max_min_data_len_873:CNode_994{[0]: ValueNode<Primitive> Return, [1]: data}


subgraph attr:
subgraph instance: ✗✓get_max_min_data_len_874 : 0x37f58a80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @✗✓get_max_min_data_len_874 parent: [subgraph @✓get_max_min_data_len_771]() {
  %1(data) = $(✓get_max_min_data_len_771):S_Prim_getitem(%para195_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2540/        data = data[0]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2541/        if isinstance(data, dict):/
}
# Order:
#   1: @✗✓get_max_min_data_len_874:CNode_995{[0]: ValueNode<Primitive> Return, [1]: data}


subgraph attr:
subgraph instance: 2↰get_max_min_data_len_884 : 0x3789b080
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @2↰get_max_min_data_len_884 parent: [subgraph @get_max_min_data_len_664]() {
  %1(CNode_996) = S_Prim_getitem(%para195_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %2(CNode_997) = S_Prim_MakeTuple(ClassType, ClassType, ClassType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %3(CNode_998) = S_Prim_isinstance(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @2↰get_max_min_data_len_884:CNode_996{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @2↰get_max_min_data_len_884:CNode_997{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'dict', [2]: ValueNode<ClassType> class 'list', [3]: ValueNode<ClassType> class 'tuple'}
#   3: @2↰get_max_min_data_len_884:CNode_998{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: CNode_996, [2]: CNode_997}
#   4: @2↰get_max_min_data_len_884:CNode_999{[0]: ValueNode<Primitive> Return, [1]: CNode_998}


subgraph attr:
subgraph instance: ↱↰get_max_min_data_len_885 : 0x378c35c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2536/def get_max_min_data_len(*data):/
subgraph @↱↰get_max_min_data_len_885 parent: [subgraph @↰get_max_min_data_len_766]() {
  %1(CNode_880) = $(↰get_max_min_data_len_766):S_Prim_inner_len(%para195_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  %2(CNode_881) = $(↰get_max_min_data_len_766):S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2539/    if isinstance(data, tuple) and len(data) == 1 and isinstance(data[0], (dict, list, tuple)):/
}
# Order:
#   1: @↱↰get_max_min_data_len_885:CNode_1000{[0]: ValueNode<Primitive> Return, [1]: CNode_881}


subgraph attr:
subgraph instance: ms_max_one_element_889 : 0x376c7060
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @ms_max_one_element_889(%para214_x) {
  %1(CNode_1001) = S_Prim_isinstance(%para214_x, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
  %2(CNode_1002) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
  %3(CNode_1003) = Switch(%2, @✓ms_max_one_element_1004, @✗ms_max_one_element_1005)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
  %4(CNode_1006) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
}
# Order:
#   1: @ms_max_one_element_889:CNode_1001{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @ms_max_one_element_889:CNode_1002{[0]: ValueNode<Primitive> Cond, [1]: CNode_1001, [2]: ValueNode<BoolImm> false}
#   3: @ms_max_one_element_889:CNode_1003{[0]: ValueNode<Primitive> Switch, [1]: CNode_1002, [2]: ValueNode<FuncGraph> ✓ms_max_one_element_1004, [3]: ValueNode<FuncGraph> ✗ms_max_one_element_1005}
#   4: @ms_max_one_element_889:CNode_1006{[0]: CNode_1003}
#   5: @ms_max_one_element_889:CNode_1007{[0]: ValueNode<Primitive> Return, [1]: CNode_1006}


subgraph attr:
subgraph instance: ✓2✗ms_max_892 : 0x30602820
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓2✗ms_max_892 parent: [subgraph @ms_max_436]() {
  %1(tensor_num) = call @get_tensor_num_1008(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %2(len_data) = $(ms_max_436):call @get_max_min_data_len_664(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2641/    len_data = get_max_min_data_len(data)/
  %3(CNode_478) = S_Prim_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  %4(CNode_479) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  %5(CNode_480) = Switch(%4, @2✓2✗ms_max_1009, @✗✓2✗ms_max_1010)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  %6(CNode_482) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
}
# Order:
#   1: @✓2✗ms_max_892:tensor_num{[0]: ValueNode<FuncGraph> get_tensor_num_1008, [1]: param_data}
#   2: @✓2✗ms_max_892:CNode_478{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_num, [2]: len_data}
#   3: @✓2✗ms_max_892:CNode_479{[0]: ValueNode<Primitive> Cond, [1]: CNode_478, [2]: ValueNode<BoolImm> false}
#   4: @✓2✗ms_max_892:CNode_480{[0]: ValueNode<Primitive> Switch, [1]: CNode_479, [2]: ValueNode<FuncGraph> 2✓2✗ms_max_1009, [3]: ValueNode<FuncGraph> ✗✓2✗ms_max_1010}
#   5: @✓2✗ms_max_892:CNode_482{[0]: CNode_480}
#   6: @✓2✗ms_max_892:CNode_483{[0]: ValueNode<Primitive> Return, [1]: CNode_482}


subgraph attr:
subgraph instance: 3✗ms_max_893 : 0x378f7930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @3✗ms_max_893 parent: [subgraph @ms_max_436]() {
  %1(CNode_1012) = call @↓2✗ms_max_1011()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
}
# Order:
#   1: @3✗ms_max_893:CNode_1013{[0]: ValueNode<Primitive> Return, [1]: CNode_1012}
#   2: @3✗ms_max_893:CNode_1012{[0]: ValueNode<FuncGraph> ↓2✗ms_max_1011}


subgraph attr:
subgraph instance: _new_prim_for_graph_894 : 0x38f72c00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:67/    def _new_prim_for_graph(*args, **kwargs) -> Primitive:/
subgraph @_new_prim_for_graph_894 parent: [subgraph @_get_cache_prim_676](%para215_args, %para216_kwargs) {
  %1(CNode_1014) = UnpackCall_unpack_call(%para196_cls, %para215_args, %para216_kwargs)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:68/        return cls(*args, **kwargs)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/_primitive_cache.py:68/        return cls(*args, **kwargs)/
}
# Order:
#   1: @_new_prim_for_graph_894:CNode_1014{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.87, [1]: param_cls, [2]: param_args, [3]: param_kwargs}
#   2: @_new_prim_for_graph_894:CNode_1015{[0]: ValueNode<Primitive> Return, [1]: CNode_1014}


subgraph attr:
after_block : 1
subgraph instance: ↓✗zeros_899 : 0x37b41180
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↓✗zeros_899(%para217_) {
  Return(%para217_фsize)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1036/    elif isinstance(size, list):/
}
# Order:
#   1: @↓✗zeros_899:CNode_1016{[0]: ValueNode<Primitive> Return, [1]: param_фsize}


subgraph attr:
after_block : 1
subgraph instance: ↓2✗zeros_913 : 0x3764d460
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↓2✗zeros_913(%para218_) {
  %1(CNode_1017) = call @↓✗zeros_899(%para218_фsize)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @↓2✗zeros_913:CNode_1018{[0]: ValueNode<Primitive> Return, [1]: CNode_1017}
#   2: @↓2✗zeros_913:CNode_1017{[0]: ValueNode<FuncGraph> ↓✗zeros_899, [1]: param_фsize}


subgraph attr:
subgraph instance: ✓2✗zeros_910 : 0x37a29870
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @✓2✗zeros_910 parent: [subgraph @zeros_442]() {
  %1(CNode_1019) = getattr(%para187_size, "reshape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1039/        size = size.reshape(1)/
  %2(size) = %1(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1039/        size = size.reshape(1)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1039/        size = size.reshape(1)/
}
# Order:
#   1: @✓2✗zeros_910:CNode_1019{[0]: ValueNode<Primitive> getattr, [1]: param_size, [2]: ValueNode<StringImm> reshape}
#   2: @✓2✗zeros_910:size{[0]: CNode_1019, [1]: ValueNode<Int64Imm> 1}
#   3: @✓2✗zeros_910:CNode_1020{[0]: ValueNode<Primitive> Return, [1]: size}


subgraph attr:
subgraph instance: 3✗zeros_911 : 0x333825f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @3✗zeros_911 parent: [subgraph @zeros_442]() {
  Return(%para187_size)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @3✗zeros_911:CNode_1021{[0]: ValueNode<Primitive> Return, [1]: param_size}


subgraph attr:
subgraph instance: ↰2✗zeros_905 : 0x37f7ea30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↰2✗zeros_905 parent: [subgraph @zeros_442]() {
  %1(CNode_1022) = getattr(%para187_size, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %2(CNode_1023) = S_Prim_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %3(CNode_1024) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %4(CNode_1025) = Switch(%3, @2↰2✗zeros_1026, @↱↰2✗zeros_1027)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %5(CNode_1028) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @↰2✗zeros_905:CNode_1022{[0]: ValueNode<Primitive> getattr, [1]: param_size, [2]: ValueNode<StringImm> ndim}
#   2: @↰2✗zeros_905:CNode_1023{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1022, [2]: ValueNode<Int64Imm> 0}
#   3: @↰2✗zeros_905:CNode_1024{[0]: ValueNode<Primitive> Cond, [1]: CNode_1023, [2]: ValueNode<BoolImm> false}
#   4: @↰2✗zeros_905:CNode_1025{[0]: ValueNode<Primitive> Switch, [1]: CNode_1024, [2]: ValueNode<FuncGraph> 2↰2✗zeros_1026, [3]: ValueNode<FuncGraph> ↱↰2✗zeros_1027}
#   5: @↰2✗zeros_905:CNode_1028{[0]: CNode_1025}
#   6: @↰2✗zeros_905:CNode_1029{[0]: ValueNode<Primitive> Return, [1]: CNode_1028}


subgraph attr:
subgraph instance: ↱2✗zeros_906 : 0x37b37b30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↱2✗zeros_906 parent: [subgraph @2✗zeros_791]() {
  %1(CNode_902) = $(2✗zeros_791):S_Prim_isinstance(%para187_size, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @↱2✗zeros_906:CNode_1030{[0]: ValueNode<Primitive> Return, [1]: CNode_902}


subgraph attr:
subgraph instance: ↻2✓↓enumerate__922 : 0x37608880
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @↻2✓↓enumerate__922 parent: [subgraph @↵2✓↓enumerate__803]() {
  %1(CNode_920) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para205_@CNode_920, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %2(CNode_1031) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
  %3(CNode_805) = $(2✓↓enumerate__698):getattr(%para173_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %4(CNode_806) = $(2✓↓enumerate__698):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %5(CNode_807) = $(2✓↓enumerate__698):S_Prim_make_range(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %6(CNode_1032) = call @ms_iter_97(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %7(i) = S_Prim_getitem(%6, %para205_@CNode_920)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  %8(CNode_1033) = S_Prim_add(%para174_start, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2837/                ret += ((start + i, x[i]),)/
  %9(CNode_1034) = S_Prim_getitem(%para173_x, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2837/                ret += ((start + i, x[i]),)/
  %10(CNode_1035) = S_Prim_MakeTuple(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2837/                ret += ((start + i, x[i]),)/
  %11(CNode_1036) = S_Prim_MakeTuple(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2837/                ret += ((start + i, x[i]),)/
  %12(ret) = S_Prim_add(%para206_фret, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2837/                ret += ((start + i, x[i]),)/
  %13(CNode_1037) = call @↵2✓↓enumerate__803(%1, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:628/                    for i, output in enumerate(model_output):/
  %14(CNode_1038) = Depend[side_effect_propagate: I64(1)](%13, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
  Return(%14)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
}
# Order:
#   1: @↻2✓↓enumerate__922:CNode_1032{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_807}
#   2: @↻2✓↓enumerate__922:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1032, [2]: param_@CNode_920}
#   3: @↻2✓↓enumerate__922:CNode_920{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_920, [2]: ValueNode<Int64Imm> 1}
#   4: @↻2✓↓enumerate__922:CNode_1033{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_start, [2]: i}
#   5: @↻2✓↓enumerate__922:CNode_1034{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_x, [2]: i}
#   6: @↻2✓↓enumerate__922:CNode_1035{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_1033, [2]: CNode_1034}
#   7: @↻2✓↓enumerate__922:CNode_1036{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_1035}
#   8: @↻2✓↓enumerate__922:ret{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фret, [2]: CNode_1036}
#   9: @↻2✓↓enumerate__922:CNode_1039{[0]: ValueNode<Primitive> Return, [1]: CNode_1038}
#  10: @↻2✓↓enumerate__922:CNode_1037{[0]: ValueNode<FuncGraph> ↵2✓↓enumerate__803, [1]: CNode_920, [2]: ret}


subgraph attr:
subgraph instance: ↓2✓↓enumerate__923 : 0x3760ba90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2827/def enumerate_(x, start=0):/
subgraph @↓2✓↓enumerate__923 parent: [subgraph @↵2✓↓enumerate__803]() {
  Return(%para206_фret)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2836/            for i in range(x.shape[0]):/
}
# Order:
#   1: @↓2✓↓enumerate__923:CNode_1040{[0]: ValueNode<Primitive> Return, [1]: param_фret}


subgraph attr:
subgraph instance: ✓↓check_is_const_int_930 : 0x378a98e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @✓↓check_is_const_int_930 parent: [subgraph @check_is_const_int_619]() {
  %1(CNode_1041) = JoinedStr("For '", %para191_op_name, "', the '", %para192_arg_name, "' should be a const int number, but got ", %para190_x, ".")
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3276/            f"For '{op_name}', the '{arg_name}' should be a const int number, but got {x}.")/
  %2(CNode_1042) = raise[side_effect_io: Bool(1)]("TypeError", %1, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3275/        raise TypeError(/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3275/        raise TypeError(/
}
# Order:
#   1: @✓↓check_is_const_int_930:CNode_1041{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For ', [2]: param_op_name, [3]: ValueNode<StringImm> ', the ', [4]: param_arg_name, [5]: ValueNode<StringImm> ' should be a const int number, but got , [6]: param_x, [7]: ValueNode<StringImm> .}
#   2: @✓↓check_is_const_int_930:CNode_1042{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: CNode_1041, [3]: ValueNode<StringImm> None}
#   3: @✓↓check_is_const_int_930:CNode_1043{[0]: ValueNode<Primitive> Return, [1]: CNode_1042}


subgraph attr:
subgraph instance: ✗↓check_is_const_int_931 : 0x378f6800
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @✗↓check_is_const_int_931() {
  %1(CNode_1045) = call @2↓check_is_const_int_1044()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3274/    if not isinstance(x, int):/
}
# Order:
#   1: @✗↓check_is_const_int_931:CNode_1045{[0]: ValueNode<FuncGraph> 2↓check_is_const_int_1044}
#   2: @✗↓check_is_const_int_931:CNode_1046{[0]: ValueNode<Primitive> Return, [1]: CNode_1045}


subgraph attr:
subgraph instance: ✓↓↻↓forward_fn_99 : 0x39774230
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓↓↻↓forward_fn_99 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_1047) = S_Prim_MakeTuple(I64(1), I64(1), I64(3512))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:654/                            logits = ops.zeros((1, 1, 3512), ms.float32)/
  %2(logits) = call @zeros_442(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:654/                            logits = ops.zeros((1, 1, 3512), ms.float32)/
  %3(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %4(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %5(CNode_1048) = getattr(%4, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %6(CNode_1049) = getattr(%5, "warning")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %7(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %8(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %9(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %10(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %11(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %7, %10)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %12(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%11, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %13(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%12, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %14(CNode_328) = $(↓forward_fn_119):Cond(%13, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %15(CNode_329) = $(↓forward_fn_119):Switch(%14, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %16(logits_list) = $(↓forward_fn_119):%15()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %17(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%16)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %18(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%17)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %19(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%18, %para160_@CNode_121)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %20(logits) = $(↻↓forward_fn_122):S_Prim_getitem(%19, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %21(CNode_1050) = getattr(%20, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %22(CNode_1051) = JoinedStr("Batch ", I64(0), " - Invalid logits shape dimensions: ", %21)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %23(CNode_1052) = %6(%22)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
  %24(CNode_1053) = getattr(%4, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:655/                            self.logger.info(f"Batch {batch_idx} - Replaced with placeholder: {logits.shape}")/
  %25(CNode_1054) = getattr(%24, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:655/                            self.logger.info(f"Batch {batch_idx} - Replaced with placeholder: {logits.shape}")/
  %26(CNode_1055) = getattr(%2, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:655/                            self.logger.info(f"Batch {batch_idx} - Replaced with placeholder: {logits.shape}")/
  %27(CNode_1056) = JoinedStr("Batch ", I64(0), " - Replaced with placeholder: ", %26)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:655/                            self.logger.info(f"Batch {batch_idx} - Replaced with placeholder: {logits.shape}")/
  %28(CNode_1057) = %25(%27)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:655/                            self.logger.info(f"Batch {batch_idx} - Replaced with placeholder: {logits.shape}")/
  %29(CNode_1058) = MakeTuple(%23, %28)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %30(CNode_1059) = StopGradient(%29)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %31(CNode_1060) = Depend[side_effect_propagate: I64(1)](%2, %30)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%31)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:652/                            self.logger.warning(f"Batch {batch_idx} - Invalid logits shape dimensions: {logits.shape}")/
}
# Order:
#   1: @✓↓↻↓forward_fn_99:CNode_1048{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✓↓↻↓forward_fn_99:CNode_1049{[0]: ValueNode<Primitive> getattr, [1]: CNode_1048, [2]: ValueNode<StringImm> warning}
#   3: @✓↓↻↓forward_fn_99:CNode_1050{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#   4: @✓↓↻↓forward_fn_99:CNode_1051{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Invalid logits shape dimensions: , [4]: CNode_1050}
#   5: @✓↓↻↓forward_fn_99:CNode_1052{[0]: CNode_1049, [1]: CNode_1051}
#   6: @✓↓↻↓forward_fn_99:CNode_1047{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 3512}
#   7: @✓↓↻↓forward_fn_99:logits{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_1047, [2]: ValueNode<Float> Float32}
#   8: @✓↓↻↓forward_fn_99:CNode_1053{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   9: @✓↓↻↓forward_fn_99:CNode_1054{[0]: ValueNode<Primitive> getattr, [1]: CNode_1053, [2]: ValueNode<StringImm> info}
#  10: @✓↓↻↓forward_fn_99:CNode_1055{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#  11: @✓↓↻↓forward_fn_99:CNode_1056{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Replaced with placeholder: , [4]: CNode_1055}
#  12: @✓↓↻↓forward_fn_99:CNode_1057{[0]: CNode_1054, [1]: CNode_1056}
#  13: @✓↓↻↓forward_fn_99:CNode_1061{[0]: ValueNode<Primitive> Return, [1]: CNode_1060}
#  14: @✓↓↻↓forward_fn_99:CNode_1062{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  15: @✓↓↻↓forward_fn_99:CNode_1063{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  16: @✓↓↻↓forward_fn_99:CNode_1064{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1062, [2]: CNode_1063}
#  17: @✓↓↻↓forward_fn_99:CNode_1065{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  18: @✓↓↻↓forward_fn_99:CNode_1066{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_1048, [2]: ValueNode<StringImm> warning}
#  19: @✓↓↻↓forward_fn_99:CNode_1067{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1065, [2]: CNode_1066}
#  20: @✓↓↻↓forward_fn_99:CNode_1068{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  21: @✓↓↻↓forward_fn_99:CNode_1069{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  22: @✓↓↻↓forward_fn_99:CNode_1070{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1068, [2]: CNode_1069}
#  23: @✓↓↻↓forward_fn_99:CNode_1071{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  24: @✓↓↻↓forward_fn_99:CNode_1072{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_1053, [2]: ValueNode<StringImm> info}
#  25: @✓↓↻↓forward_fn_99:CNode_1073{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1071, [2]: CNode_1072}


subgraph attr:
subgraph instance: ✗↓↻↓forward_fn_100 : 0x39773410
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗↓↻↓forward_fn_100 parent: [subgraph @↻↓forward_fn_122]() {
  %1(CNode_165) = $(forward_fn_3):S_Prim_MakeTuple(%para155_seq_data, %para157_data_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %2(CNode_166) = $(forward_fn_3):S_Prim_MakeTuple("is_train")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %3(CNode_167) = $(forward_fn_3):S_Prim_MakeTuple(Bool(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %4(CNode_168) = $(forward_fn_3):S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %5(model_output) = $(forward_fn_3):UnpackCall_unpack_call(@tfnet_model_TFNetModel_construct_169, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %6(CNode_326) = $(↓forward_fn_119):S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %7(CNode_327) = $(↓forward_fn_119):S_Prim_isinstance(%6, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %8(CNode_328) = $(↓forward_fn_119):Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %9(CNode_329) = $(↓forward_fn_119):Switch(%8, @↰↓forward_fn_330, @↱↓forward_fn_331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %10(logits_list) = $(↓forward_fn_119):%9()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:638/                    logits_list = model_output[0] if isinstance(model_output[0], list) else [model_output[0]]/
  %11(CNode_332) = $(↓forward_fn_119):call @enumerate__179(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %12(CNode_341) = $(↻↓forward_fn_122):call @ms_iter_97(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %13(CNode_342) = $(↻↓forward_fn_122):S_Prim_getitem(%12, %para160_@CNode_121)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %14(logits) = $(↻↓forward_fn_122):S_Prim_getitem(%13, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  Return(%14)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:651/                        if any(dim <= 0 for dim in logits.shape):/
}
# Order:
#   1: @✗↓↻↓forward_fn_100:CNode_1074{[0]: ValueNode<Primitive> Return, [1]: logits}


subgraph attr:
training : 1
subgraph instance: ↻4↓tfnet_model_TFNetModel_construct_937 : 0x39734f50
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻4↓tfnet_model_TFNetModel_construct_937 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_832]() {
  %1(CNode_1076) = call @ms_next_1075(%para207_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_1077) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %3(CNode_1078) = Switch(Bool(1), @✓↻4↓tfnet_model_TFNetModel_construct_1079, @✗↻4↓tfnet_model_TFNetModel_construct_1080)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %4(CNode_1081) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %5(CNode_1082) = call @↵4↓tfnet_model_TFNetModel_construct_832(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1076{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻4↓tfnet_model_TFNetModel_construct_937:l{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1076, [2]: ValueNode<Int64Imm> 0}
#   3: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1077{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1076, [2]: ValueNode<Int64Imm> 1}
#   4: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1083{[0]: ValueNode<ClassType> class 'int', [1]: l}
#   5: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1084{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_1083}
#   6: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1085{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_1084}
#   7: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1086{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_1085}
#   8: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1078{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> ✓↻4↓tfnet_model_TFNetModel_construct_1079, [3]: ValueNode<FuncGraph> ✗↻4↓tfnet_model_TFNetModel_construct_1080}
#   9: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1081{[0]: CNode_1078}
#  10: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1087{[0]: ValueNode<Primitive> Return, [1]: CNode_1082}
#  11: @↻4↓tfnet_model_TFNetModel_construct_937:CNode_1082{[0]: ValueNode<FuncGraph> ↵4↓tfnet_model_TFNetModel_construct_832, [1]: CNode_1077, [2]: CNode_1081}


subgraph attr:
training : 1
subgraph instance: 5↓tfnet_model_TFNetModel_construct_938 : 0x397375f0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @5↓tfnet_model_TFNetModel_construct_938 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_832]() {
  Return(%para208_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @5↓tfnet_model_TFNetModel_construct_938:CNode_1088{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: hasnext_934 : 0x3722f400
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2355/def hasnext(it):/
subgraph @hasnext_934(%para219_it) {
  %1(CNode_1089) = getattr(%para219_it, "__ms_hasnext__")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2357/    return it.__ms_hasnext__/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2357/    return it.__ms_hasnext__/
}
# Order:
#   1: @hasnext_934:CNode_1089{[0]: ValueNode<Primitive> getattr, [1]: param_it, [2]: ValueNode<StringImm> __ms_hasnext__}
#   2: @hasnext_934:CNode_1090{[0]: ValueNode<Primitive> Return, [1]: CNode_1089}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓↻4↓tfnet_model_TFNetModel_construct_955 : 0x3971c1c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓↻4↓tfnet_model_TFNetModel_construct_955 parent: [subgraph @↻4↓tfnet_model_TFNetModel_construct_838](%para220_) {
  %1(CNode_836) = $(↻4↓tfnet_model_TFNetModel_construct_838):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para199_@CNode_836, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %2(CNode_1091) = ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:135/            start_idx += int(temp)  # 移动到下一个序列（固定步长）/
  %3(start_idx) = S_Prim_add(%para200_фstart_idx, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:135/            start_idx += int(temp)  # 移动到下一个序列（固定步长）/
  %4(CNode_1092) = call @↵4↓tfnet_model_TFNetModel_construct_713(%1, %3, %para220_фfeature_list)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
}
# Order:
#   1: @↓↻4↓tfnet_model_TFNetModel_construct_955:CNode_1091{[0]: ValueNode<ClassType> class 'int', [1]: param_фtemp}
#   2: @↓↻4↓tfnet_model_TFNetModel_construct_955:start_idx{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фstart_idx, [2]: CNode_1091}
#   3: @↓↻4↓tfnet_model_TFNetModel_construct_955:CNode_1093{[0]: ValueNode<Primitive> Return, [1]: CNode_1092}
#   4: @↓↻4↓tfnet_model_TFNetModel_construct_955:CNode_1092{[0]: ValueNode<FuncGraph> ↵4↓tfnet_model_TFNetModel_construct_713, [1]: CNode_836, [2]: start_idx, [3]: param_фfeature_list}


subgraph attr:
subgraph instance: ms_min_962 : 0x39501030
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @ms_min_962(%para221_data) {
  %1(len_data) = call @get_max_min_data_len_664(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2724/    len_data = get_max_min_data_len(data)/
  %2(CNode_1094) = S_Prim_less_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2725/    if len_data <= 0:/
  %3(CNode_1095) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2725/    if len_data <= 0:/
  %4(CNode_1096) = Switch(%3, @✓ms_min_1097, @✗ms_min_1098)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2725/    if len_data <= 0:/
  %5(CNode_1099) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2725/    if len_data <= 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2725/    if len_data <= 0:/
}
# Order:
#   1: @ms_min_962:len_data{[0]: ValueNode<FuncGraph> get_max_min_data_len_664, [1]: param_data}
#   2: @ms_min_962:CNode_1094{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 0}
#   3: @ms_min_962:CNode_1095{[0]: ValueNode<Primitive> Cond, [1]: CNode_1094, [2]: ValueNode<BoolImm> false}
#   4: @ms_min_962:CNode_1096{[0]: ValueNode<Primitive> Switch, [1]: CNode_1095, [2]: ValueNode<FuncGraph> ✓ms_min_1097, [3]: ValueNode<FuncGraph> ✗ms_min_1098}
#   5: @ms_min_962:CNode_1099{[0]: CNode_1096}
#   6: @ms_min_962:CNode_1100{[0]: ValueNode<Primitive> Return, [1]: CNode_1099}


subgraph attr:
training : 1
subgraph instance: ✓↻4↓tfnet_model_TFNetModel_construct_952 : 0x39715df0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻4↓tfnet_model_TFNetModel_construct_952 parent: [subgraph @↻4↓tfnet_model_TFNetModel_construct_838]() {
  %1(CNode_1101) = getattr(%para201_фfeature_list, "append")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:127/                feature_list.append(seq_features)/
  %2(CNode_716) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_mul(%para177_фbatch, %para176_фtemp)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %3(CNode_717) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_MakeTuple(%2, %para179_фchannel, %para180_фheight, %para181_фwidth)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %4(inputs) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para178_фseq_data, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %5(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %6(CNode_718) = $(4↓tfnet_model_TFNetModel_construct_647):ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %7(CNode_719) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_make_range(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %8(CNode_958) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_iter_97(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %9(i) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%8, %para199_@CNode_836)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %10(CNode_959) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%5, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %11(CNode_960) = $(↻4↓tfnet_model_TFNetModel_construct_838):ClassType(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %12(CNode_961) = $(↻4↓tfnet_model_TFNetModel_construct_838):ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %13(lgt_i) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_min_962(%11, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %14(end_idx) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_add(%para200_фstart_idx, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:122/            end_idx = start_idx + lgt_i/
  %15(CNode_963) = $(↻4↓tfnet_model_TFNetModel_construct_838):getattr(%4, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %16(CNode_964) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%15, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %17(end_idx) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_min_962(%14, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %18(CNode_1102) = S_Prim_make_slice(%para200_фstart_idx, %17, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:126/                seq_features = self.conv2d(inputs[start_idx:end_idx])/
  %19(CNode_1103) = S_Prim_getitem(%4, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:126/                seq_features = self.conv2d(inputs[start_idx:end_idx])/
  %20(seq_features) = call @modules_ResNet34Backbone_construct_1104(%19)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:126/                seq_features = self.conv2d(inputs[start_idx:end_idx])/
  %21(feature_list) = %1(%20)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:127/                feature_list.append(seq_features)/
  Return(%21)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:126/                seq_features = self.conv2d(inputs[start_idx:end_idx])/
}
# Order:
#   1: @✓↻4↓tfnet_model_TFNetModel_construct_952:CNode_1102{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: param_фstart_idx, [2]: end_idx, [3]: ValueNode<None> None}
#   2: @✓↻4↓tfnet_model_TFNetModel_construct_952:CNode_1103{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: inputs, [2]: CNode_1102}
#   3: @✓↻4↓tfnet_model_TFNetModel_construct_952:seq_features{[0]: ValueNode<FuncGraph> modules_ResNet34Backbone_construct_1104, [1]: CNode_1103}
#   4: @✓↻4↓tfnet_model_TFNetModel_construct_952:CNode_1101{[0]: ValueNode<Primitive> getattr, [1]: param_фfeature_list, [2]: ValueNode<StringImm> append}
#   5: @✓↻4↓tfnet_model_TFNetModel_construct_952:feature_list{[0]: CNode_1101, [1]: seq_features}
#   6: @✓↻4↓tfnet_model_TFNetModel_construct_952:CNode_1105{[0]: ValueNode<Primitive> Return, [1]: feature_list}


subgraph attr:
training : 1
subgraph instance: ✗↻4↓tfnet_model_TFNetModel_construct_953 : 0x39594de0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻4↓tfnet_model_TFNetModel_construct_953 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  %1(CNode_1106) = getattr(%para201_фfeature_list, "append")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:134/                feature_list.append(zero_features)/
  %2(CNode_716) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_mul(%para177_фbatch, %para176_фtemp)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %3(CNode_717) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_MakeTuple(%2, %para179_фchannel, %para180_фheight, %para181_фwidth)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %4(inputs) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para178_фseq_data, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %5(CNode_1107) = S_Prim_make_slice(I64(0), I64(1), None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:130/                dummy_input = inputs[0:1]  # 取第一个样本作为模板/
  %6(dummy_input) = S_Prim_getitem(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:130/                dummy_input = inputs[0:1]  # 取第一个样本作为模板/
  %7(dummy_features) = call @modules_ResNet34Backbone_construct_1104(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:131/                dummy_features = self.conv2d(dummy_input)/
  %8(zero_features) = call @zeros_like_1108(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:133/                zero_features = ops.zeros_like(dummy_features)/
  %9(feature_list) = %1(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:134/                feature_list.append(zero_features)/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:130/                dummy_input = inputs[0:1]  # 取第一个样本作为模板/
}
# Order:
#   1: @✗↻4↓tfnet_model_TFNetModel_construct_953:CNode_1107{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<None> None}
#   2: @✗↻4↓tfnet_model_TFNetModel_construct_953:dummy_input{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: inputs, [2]: CNode_1107}
#   3: @✗↻4↓tfnet_model_TFNetModel_construct_953:dummy_features{[0]: ValueNode<FuncGraph> modules_ResNet34Backbone_construct_1104, [1]: dummy_input}
#   4: @✗↻4↓tfnet_model_TFNetModel_construct_953:zero_features{[0]: ValueNode<FuncGraph> zeros_like_1108, [1]: dummy_features}
#   5: @✗↻4↓tfnet_model_TFNetModel_construct_953:CNode_1106{[0]: ValueNode<Primitive> getattr, [1]: param_фfeature_list, [2]: ValueNode<StringImm> append}
#   6: @✗↻4↓tfnet_model_TFNetModel_construct_953:feature_list{[0]: CNode_1106, [1]: zero_features}
#   7: @✗↻4↓tfnet_model_TFNetModel_construct_953:CNode_1109{[0]: ValueNode<Primitive> Return, [1]: feature_list}


subgraph attr:
training : 1
subgraph instance: ↰↻4↓tfnet_model_TFNetModel_construct_947 : 0x39593b20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰↻4↓tfnet_model_TFNetModel_construct_947 parent: [subgraph @↻4↓tfnet_model_TFNetModel_construct_838]() {
  %1(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_718) = $(4↓tfnet_model_TFNetModel_construct_647):ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %3(CNode_719) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_make_range(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %4(CNode_958) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %5(i) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%4, %para199_@CNode_836)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:119/        for i in range(int(batch)):/
  %6(CNode_959) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%1, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %7(CNode_960) = $(↻4↓tfnet_model_TFNetModel_construct_838):ClassType(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %8(CNode_961) = $(↻4↓tfnet_model_TFNetModel_construct_838):ClassType(%para176_фtemp)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %9(lgt_i) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_min_962(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %10(end_idx) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_add(%para200_фstart_idx, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:122/            end_idx = start_idx + lgt_i/
  %11(CNode_716) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_mul(%para177_фbatch, %para176_фtemp)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %12(CNode_717) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_MakeTuple(%11, %para179_фchannel, %para180_фheight, %para181_фwidth)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %13(inputs) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para178_фseq_data, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %14(CNode_963) = $(↻4↓tfnet_model_TFNetModel_construct_838):getattr(%13, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %15(CNode_964) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%14, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %16(end_idx) = $(↻4↓tfnet_model_TFNetModel_construct_838):call @ms_min_962(%10, %15)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:124/            end_idx = min(end_idx, inputs.shape[0])/
  %17(CNode_1110) = S_Prim_less(%para200_фstart_idx, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  Return(%17)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
}
# Order:
#   1: @↰↻4↓tfnet_model_TFNetModel_construct_947:CNode_1110{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less, [1]: param_фstart_idx, [2]: end_idx}
#   2: @↰↻4↓tfnet_model_TFNetModel_construct_947:CNode_1111{[0]: ValueNode<Primitive> Return, [1]: CNode_1110}


subgraph attr:
training : 1
subgraph instance: ↱↻4↓tfnet_model_TFNetModel_construct_948 : 0x39592d10
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↱↻4↓tfnet_model_TFNetModel_construct_948 parent: [subgraph @↻4↓tfnet_model_TFNetModel_construct_838]() {
  %1(CNode_716) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_mul(%para177_фbatch, %para176_фtemp)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %2(CNode_717) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_MakeTuple(%1, %para179_фchannel, %para180_фheight, %para181_фwidth)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %3(inputs) = $(4↓tfnet_model_TFNetModel_construct_647):S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para178_фseq_data, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:114/        inputs = self.reshape(seq_data, (batch * temp, channel, height, width))/
  %4(CNode_942) = $(↻4↓tfnet_model_TFNetModel_construct_838):getattr(%3, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %5(CNode_943) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  %6(CNode_944) = $(↻4↓tfnet_model_TFNetModel_construct_838):S_Prim_less(%para200_фstart_idx, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:125/            if start_idx < inputs.shape[0] and start_idx < end_idx:/
}
# Order:
#   1: @↱↻4↓tfnet_model_TFNetModel_construct_948:CNode_1112{[0]: ValueNode<Primitive> Return, [1]: CNode_944}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 6↓tfnet_model_TFNetModel_construct_976 : 0x37c3ff10
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @6↓tfnet_model_TFNetModel_construct_976 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713](%para222_) {
  %1(CNode_1114) = call @↵6↓tfnet_model_TFNetModel_construct_1113(I64(0), [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
}
# Order:
#   1: @6↓tfnet_model_TFNetModel_construct_976:CNode_1115{[0]: ValueNode<ClassType> class 'int', [1]: param_фmax_len}
#   2: @6↓tfnet_model_TFNetModel_construct_976:max_len{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_1115}
#   3: @6↓tfnet_model_TFNetModel_construct_976:CNode_1116{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фfeature_list}
#   4: @6↓tfnet_model_TFNetModel_construct_976:CNode_1117{[0]: ValueNode<Primitive> Return, [1]: CNode_1114}
#   5: @6↓tfnet_model_TFNetModel_construct_976:CNode_1114{[0]: ValueNode<FuncGraph> ↵6↓tfnet_model_TFNetModel_construct_1113, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<ValueList> []}


subgraph attr:
training : 1
subgraph instance: ✓5↓tfnet_model_TFNetModel_construct_973 : 0x372aaa50
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓5↓tfnet_model_TFNetModel_construct_973 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  %1(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_1118) = call @ms_max_436(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %3(CNode_1120) = call @G_✓5↓tfnet_model_TFNetModel_construct_1119()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %4(CNode_1121) = call @ms_max_436(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %5(max_len) = call @ms_max_436(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @✓5↓tfnet_model_TFNetModel_construct_973:CNode_1118{[0]: ValueNode<FuncGraph> ms_max_436, [1]: len_x_list}
#   2: @✓5↓tfnet_model_TFNetModel_construct_973:CNode_1120{[0]: ValueNode<FuncGraph> G_✓5↓tfnet_model_TFNetModel_construct_1119}
#   3: @✓5↓tfnet_model_TFNetModel_construct_973:CNode_1121{[0]: ValueNode<FuncGraph> ms_max_436, [1]: CNode_1120}
#   4: @✓5↓tfnet_model_TFNetModel_construct_973:max_len{[0]: ValueNode<FuncGraph> ms_max_436, [1]: CNode_1118, [2]: CNode_1121}
#   5: @✓5↓tfnet_model_TFNetModel_construct_973:CNode_1122{[0]: ValueNode<Primitive> Return, [1]: max_len}


subgraph attr:
training : 1
subgraph instance: ✗5↓tfnet_model_TFNetModel_construct_974 : 0x372eca80
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗5↓tfnet_model_TFNetModel_construct_974() {
  Return(I64(1))
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:141/            max_len = 1  # 默认最小长度/
}
# Order:
#   1: @✗5↓tfnet_model_TFNetModel_construct_974:CNode_1123{[0]: ValueNode<Primitive> Return, [1]: ValueNode<Int64Imm> 1}


subgraph attr:
training : 1
subgraph instance: ↰5↓tfnet_model_TFNetModel_construct_968 : 0x38f25cd0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰5↓tfnet_model_TFNetModel_construct_968 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  Return(%para201_фfeature_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
}
# Order:
#   1: @↰5↓tfnet_model_TFNetModel_construct_968:CNode_1124{[0]: ValueNode<Primitive> Return, [1]: param_фfeature_list}


subgraph attr:
training : 1
subgraph instance: ↱5↓tfnet_model_TFNetModel_construct_969 : 0x37b27890
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↱5↓tfnet_model_TFNetModel_construct_969 parent: [subgraph @4↓tfnet_model_TFNetModel_construct_647]() {
  %1(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:138/        if len_x_list and feature_list:/
}
# Order:
#   1: @↱5↓tfnet_model_TFNetModel_construct_969:CNode_1125{[0]: ValueNode<Primitive> Return, [1]: len_x_list}


subgraph attr:
training : 1
subgraph instance: ↻✓✗2↓tfnet_model_TFNetModel_construct_981 : 0x377a2180
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻✓✗2↓tfnet_model_TFNetModel_construct_981 parent: [subgraph @↵✓✗2↓tfnet_model_TFNetModel_construct_847]() {
  %1(CNode_1126) = call @ms_next_1075(%para209_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %2(CNode_1127) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %3(CNode_1128) = Switch(Bool(1), @✓↻✓✗2↓tfnet_model_TFNetModel_construct_1129, @✗↻✓✗2↓tfnet_model_TFNetModel_construct_1130)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %4(CNode_1131) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %5(CNode_1132) = call @↵✓✗2↓tfnet_model_TFNetModel_construct_847(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1126{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:v{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1126, [2]: ValueNode<Int64Imm> 0}
#   3: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1127{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1126, [2]: ValueNode<Int64Imm> 1}
#   4: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1133{[0]: ValueNode<ClassType> class 'int', [1]: v}
#   5: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1134{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_1133}
#   6: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1135{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_1134}
#   7: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1128{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> ✓↻✓✗2↓tfnet_model_TFNetModel_construct_1129, [3]: ValueNode<FuncGraph> ✗↻✓✗2↓tfnet_model_TFNetModel_construct_1130}
#   8: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1131{[0]: CNode_1128}
#   9: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1136{[0]: ValueNode<Primitive> Return, [1]: CNode_1132}
#  10: @↻✓✗2↓tfnet_model_TFNetModel_construct_981:CNode_1132{[0]: ValueNode<FuncGraph> ↵✓✗2↓tfnet_model_TFNetModel_construct_847, [1]: CNode_1127, [2]: CNode_1131}


subgraph attr:
training : 1
subgraph instance: ↓✓✗2↓tfnet_model_TFNetModel_construct_982 : 0x37c88380
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✓✗2↓tfnet_model_TFNetModel_construct_982 parent: [subgraph @↵✓✗2↓tfnet_model_TFNetModel_construct_847]() {
  Return(%para210_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @↓✓✗2↓tfnet_model_TFNetModel_construct_982:CNode_1137{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: ↻↓ms_max_985 : 0x37764f80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↻↓ms_max_985 parent: [subgraph @↵↓ms_max_859]() {
  %1(CNode_142) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para211_@CNode_142, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %2(CNode_517) = call @ms_iter_97(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %3(input_data) = S_Prim_getitem(%2, %para211_@CNode_142)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  %4(CNode_518) = call @check_isconstant_1138(%3, "max()")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2660/        check_isconstant(input_data, "max()")/
  %5(CNode_519) = MakeTuple(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %6(CNode_520) = StopGradient(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %7(CNode_521) = call @↵↓ms_max_859(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %8(CNode_522) = Depend[side_effect_propagate: I64(1)](%7, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2659/    for input_data in data:/
}
# Order:
#   1: @↻↓ms_max_985:CNode_517{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_data}
#   2: @↻↓ms_max_985:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_517, [2]: param_@CNode_142}
#   3: @↻↓ms_max_985:CNode_142{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_142, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓ms_max_985:CNode_518{[0]: ValueNode<FuncGraph> check_isconstant_1138, [1]: input_data, [2]: ValueNode<StringImm> max()}
#   5: @↻↓ms_max_985:CNode_523{[0]: ValueNode<Primitive> Return, [1]: CNode_522}
#   6: @↻↓ms_max_985:CNode_521{[0]: ValueNode<FuncGraph> ↵↓ms_max_859, [1]: CNode_142}


subgraph attr:
subgraph instance: 2↓ms_max_986 : 0x3770a810
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2↓ms_max_986 parent: [subgraph @ms_max_436]() {
  %1(CNode_1139) = UnpackCall_unpack_call(S_Prim_max_[constexpr_prim: Bool(1)], %para186_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2661/    return max_(*data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2661/    return max_(*data)/
}
# Order:
#   1: @2↓ms_max_986:CNode_1139{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1140, [1]: ValueNode<DoSignaturePrimitive> S_Prim_max_, [2]: param_data}
#   2: @2↓ms_max_986:CNode_1141{[0]: ValueNode<Primitive> Return, [1]: CNode_1139}


subgraph attr:
subgraph instance: ✓ms_max_one_element_1004 : 0x37e8ca20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓ms_max_one_element_1004 parent: [subgraph @ms_max_one_element_889]() {
  %1(tensor_shape) = call @shape_1142(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2611/        tensor_shape = F.shape(x)/
  %2(tensor_shape_len) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2612/        tensor_shape_len = len(tensor_shape)/
  %3(CNode_1143) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
  %4(CNode_1144) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
  %5(CNode_1145) = Switch(%4, @2✓ms_max_one_element_1146, @✗✓ms_max_one_element_1147)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
  %6(CNode_1148) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
}
# Order:
#   1: @✓ms_max_one_element_1004:tensor_shape{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_x}
#   2: @✓ms_max_one_element_1004:tensor_shape_len{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: tensor_shape}
#   3: @✓ms_max_one_element_1004:CNode_1143{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 0}
#   4: @✓ms_max_one_element_1004:CNode_1144{[0]: ValueNode<Primitive> Cond, [1]: CNode_1143, [2]: ValueNode<BoolImm> false}
#   5: @✓ms_max_one_element_1004:CNode_1145{[0]: ValueNode<Primitive> Switch, [1]: CNode_1144, [2]: ValueNode<FuncGraph> 2✓ms_max_one_element_1146, [3]: ValueNode<FuncGraph> ✗✓ms_max_one_element_1147}
#   6: @✓ms_max_one_element_1004:CNode_1148{[0]: CNode_1145}
#   7: @✓ms_max_one_element_1004:CNode_1149{[0]: ValueNode<Primitive> Return, [1]: CNode_1148}


subgraph attr:
subgraph instance: ✗ms_max_one_element_1005 : 0x37f6a940
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗ms_max_one_element_1005 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1151) = call @↓ms_max_one_element_1150()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2610/    if isinstance(x, Tensor):/
}
# Order:
#   1: @✗ms_max_one_element_1005:CNode_1151{[0]: ValueNode<FuncGraph> ↓ms_max_one_element_1150}
#   2: @✗ms_max_one_element_1005:CNode_1152{[0]: ValueNode<Primitive> Return, [1]: CNode_1151}


subgraph attr:
subgraph instance: 2✓2✗ms_max_1009 : 0x37f40fd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2✓2✗ms_max_1009 parent: [subgraph @ms_max_436]() {
  %1(CNode_1153) = UnpackCall_unpack_call(@max_tensor_1154, %para186_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2651/            return max_tensor(*data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2651/            return max_tensor(*data)/
}
# Order:
#   1: @2✓2✗ms_max_1009:CNode_1153{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1155, [1]: ValueNode<FuncGraph> max_tensor_1154, [2]: param_data}
#   2: @2✓2✗ms_max_1009:CNode_1156{[0]: ValueNode<Primitive> Return, [1]: CNode_1153}


subgraph attr:
subgraph instance: get_tensor_num_1008 : 0x305f88d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @get_tensor_num_1008(%para223_data) {
  %1(CNode_1158) = call @↵get_tensor_num_1157(I64(0), I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
}
# Order:
#   1: @get_tensor_num_1008:CNode_1159{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @get_tensor_num_1008:CNode_1160{[0]: ValueNode<Primitive> Return, [1]: CNode_1158}
#   3: @get_tensor_num_1008:CNode_1158{[0]: ValueNode<FuncGraph> ↵get_tensor_num_1157, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 0}


subgraph attr:
subgraph instance: ✗✓2✗ms_max_1010 : 0x373be5e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗✓2✗ms_max_1010 parent: [subgraph @✓2✗ms_max_892]() {
  %1(CNode_484) = call @↓✓2✗ms_max_1161()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2650/        if tensor_num == len_data:/
}
# Order:
#   1: @✗✓2✗ms_max_1010:CNode_484{[0]: ValueNode<FuncGraph> ↓✓2✗ms_max_1161}
#   2: @✗✓2✗ms_max_1010:CNode_485{[0]: ValueNode<Primitive> Return, [1]: CNode_484}


subgraph attr:
after_block : 1
subgraph instance: ↓2✗ms_max_1011 : 0x378a7680
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓2✗ms_max_1011 parent: [subgraph @ms_max_436]() {
  %1(CNode_505) = call @↓✗ms_max_1162()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2647/    elif len_data >= 2:/
}
# Order:
#   1: @↓2✗ms_max_1011:CNode_505{[0]: ValueNode<FuncGraph> ↓✗ms_max_1162}
#   2: @↓2✗ms_max_1011:CNode_506{[0]: ValueNode<Primitive> Return, [1]: CNode_505}


subgraph attr:
subgraph instance: 2↰2✗zeros_1026 : 0x38fd4d40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @2↰2✗zeros_1026 parent: [subgraph @zeros_442]() {
  %1(CNode_1163) = getattr(%para187_size, "size")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %2(CNode_1164) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @2↰2✗zeros_1026:CNode_1163{[0]: ValueNode<Primitive> getattr, [1]: param_size, [2]: ValueNode<StringImm> size}
#   2: @2↰2✗zeros_1026:CNode_1164{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1163, [2]: ValueNode<Int64Imm> 1}
#   3: @2↰2✗zeros_1026:CNode_1165{[0]: ValueNode<Primitive> Return, [1]: CNode_1164}


subgraph attr:
subgraph instance: ↱↰2✗zeros_1027 : 0x33d68640
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1003/def zeros(size, dtype=None):  # pylint: disable=redefined-outer-name/
subgraph @↱↰2✗zeros_1027 parent: [subgraph @↰2✗zeros_905]() {
  %1(CNode_1022) = $(↰2✗zeros_905):getattr(%para187_size, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  %2(CNode_1023) = $(↰2✗zeros_905):S_Prim_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1038/    elif isinstance(size, Tensor) and size.ndim == 0 and size.size == 1:/
}
# Order:
#   1: @↱↰2✗zeros_1027:CNode_1166{[0]: ValueNode<Primitive> Return, [1]: CNode_1023}


subgraph attr:
after_block : 1
subgraph instance: 2↓check_is_const_int_1044 : 0x378d19b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3269/def check_is_const_int(x, op_name, arg_name):/
subgraph @2↓check_is_const_int_1044() {
  Return(Bool(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:3277/    return True/
}
# Order:
#   1: @2↓check_is_const_int_1044:CNode_1167{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✓2↓↻↓forward_fn_101 : 0x39783850
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓2↓↻↓forward_fn_101 parent: [subgraph @2↓↻↓forward_fn_125]() {
  %1(CNode_1168) = S_Prim_MakeTuple(I64(1), I64(0), I64(2))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:661/                            logits = ops.transpose(logits, (1, 0, 2))/
  %2(logits) = call @transpose_1169(%para162_фlogits, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:661/                            logits = ops.transpose(logits, (1, 0, 2))/
  %3(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %4(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %5(CNode_1170) = getattr(%4, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:662/                            self.logger.info(f"Batch {batch_idx} - Transposed logits shape: {logits.shape}")/
  %6(CNode_1171) = getattr(%5, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:662/                            self.logger.info(f"Batch {batch_idx} - Transposed logits shape: {logits.shape}")/
  %7(CNode_1172) = getattr(%2, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:662/                            self.logger.info(f"Batch {batch_idx} - Transposed logits shape: {logits.shape}")/
  %8(CNode_1173) = JoinedStr("Batch ", I64(0), " - Transposed logits shape: ", %7)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:662/                            self.logger.info(f"Batch {batch_idx} - Transposed logits shape: {logits.shape}")/
  %9(CNode_1174) = %6(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:662/                            self.logger.info(f"Batch {batch_idx} - Transposed logits shape: {logits.shape}")/
  %10(CNode_1175) = StopGradient(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %11(CNode_1176) = Depend[side_effect_propagate: I64(1)](%2, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:661/                            logits = ops.transpose(logits, (1, 0, 2))/
}
# Order:
#   1: @✓2↓↻↓forward_fn_101:CNode_1168{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<Int64Imm> 2}
#   2: @✓2↓↻↓forward_fn_101:logits{[0]: ValueNode<FuncGraph> transpose_1169, [1]: param_фlogits, [2]: CNode_1168}
#   3: @✓2↓↻↓forward_fn_101:CNode_1170{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   4: @✓2↓↻↓forward_fn_101:CNode_1171{[0]: ValueNode<Primitive> getattr, [1]: CNode_1170, [2]: ValueNode<StringImm> info}
#   5: @✓2↓↻↓forward_fn_101:CNode_1172{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#   6: @✓2↓↻↓forward_fn_101:CNode_1173{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Transposed logits shape: , [4]: CNode_1172}
#   7: @✓2↓↻↓forward_fn_101:CNode_1174{[0]: CNode_1171, [1]: CNode_1173}
#   8: @✓2↓↻↓forward_fn_101:CNode_1177{[0]: ValueNode<Primitive> Return, [1]: CNode_1176}
#   9: @✓2↓↻↓forward_fn_101:CNode_1178{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  10: @✓2↓↻↓forward_fn_101:CNode_1179{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  11: @✓2↓↻↓forward_fn_101:CNode_1180{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1178, [2]: CNode_1179}
#  12: @✓2↓↻↓forward_fn_101:CNode_1181{[0]: ValueNode<Primitive> MakeTuple, [1]: ValueNode<StringImm> __py_exec_index1_getattr__, [2]: ValueNode<StringImm> __py_exec_index2_getattr__}
#  13: @✓2↓↻↓forward_fn_101:CNode_1182{[0]: ValueNode<Primitive> MakeTuple, [1]: CNode_1170, [2]: ValueNode<StringImm> info}
#  14: @✓2↓↻↓forward_fn_101:CNode_1183{[0]: ValueNode<Primitive> make_dict, [1]: CNode_1181, [2]: CNode_1182}


subgraph attr:
subgraph instance: ✗2↓↻↓forward_fn_102 : 0x39782b60
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗2↓↻↓forward_fn_102 parent: [subgraph @2↓↻↓forward_fn_125]() {
  Return(%para162_фlogits)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
}
# Order:
#   1: @✗2↓↻↓forward_fn_102:CNode_1184{[0]: ValueNode<Primitive> Return, [1]: param_фlogits}


subgraph attr:
subgraph instance: ↰2↓↻↓forward_fn_395 : 0x39780a10
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↰2↓↻↓forward_fn_395 parent: [subgraph @2↓↻↓forward_fn_125]() {
  %1(CNode_1185) = getattr(%para162_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %2(CNode_1186) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %3(CNode_1187) = getattr(%para157_data_len_tensor, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %4(CNode_1188) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %5(CNode_1189) = S_Prim_equal(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
}
# Order:
#   1: @↰2↓↻↓forward_fn_395:CNode_1185{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   2: @↰2↓↻↓forward_fn_395:CNode_1186{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1185, [2]: ValueNode<Int64Imm> 0}
#   3: @↰2↓↻↓forward_fn_395:CNode_1187{[0]: ValueNode<Primitive> getattr, [1]: param_data_len_tensor, [2]: ValueNode<StringImm> shape}
#   4: @↰2↓↻↓forward_fn_395:CNode_1188{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1187, [2]: ValueNode<Int64Imm> 0}
#   5: @↰2↓↻↓forward_fn_395:CNode_1189{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1186, [2]: CNode_1188}
#   6: @↰2↓↻↓forward_fn_395:CNode_1190{[0]: ValueNode<Primitive> Return, [1]: CNode_1189}


subgraph attr:
subgraph instance: ↱2↓↻↓forward_fn_396 : 0x3977fd30
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↱2↓↻↓forward_fn_396 parent: [subgraph @2↓↻↓forward_fn_125]() {
  %1(CNode_391) = $(2↓↻↓forward_fn_125):getattr(%para162_фlogits, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  %2(CNode_392) = $(2↓↻↓forward_fn_125):S_Prim_equal(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:659/                        if logits.ndim == 3 and logits.shape[0] == data_len_tensor.shape[0]:/
}
# Order:
#   1: @↱2↓↻↓forward_fn_396:CNode_1191{[0]: ValueNode<Primitive> Return, [1]: CNode_392}


subgraph attr:
subgraph instance: ms_next_1075 : 0x37725d90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2350/def ms_next(it):/
subgraph @ms_next_1075(%para224_it) {
  %1(CNode_1192) = getattr(%para224_it, "__ms_next__")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2352/    return it.__ms_next__/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2352/    return it.__ms_next__/
}
# Order:
#   1: @ms_next_1075:CNode_1192{[0]: ValueNode<Primitive> getattr, [1]: param_it, [2]: ValueNode<StringImm> __ms_next__}
#   2: @ms_next_1075:CNode_1193{[0]: ValueNode<Primitive> Return, [1]: CNode_1192}


subgraph attr:
training : 1
subgraph instance: ✓↻4↓tfnet_model_TFNetModel_construct_1079 : 0x3973eda0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻4↓tfnet_model_TFNetModel_construct_1079 parent: [subgraph @↻4↓tfnet_model_TFNetModel_construct_937]() {
  %1(CNode_1076) = $(↻4↓tfnet_model_TFNetModel_construct_937):call @ms_next_1075(%para207_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(l) = $(↻4↓tfnet_model_TFNetModel_construct_937):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %3(CNode_1083) = $(↻4↓tfnet_model_TFNetModel_construct_937):ClassType(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %4(CNode_1084) = $(↻4↓tfnet_model_TFNetModel_construct_937):call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %5(CNode_1085) = $(↻4↓tfnet_model_TFNetModel_construct_937):S_Prim_make_list(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %6(CNode_1086) = $(↻4↓tfnet_model_TFNetModel_construct_937):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para208_list, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @✓↻4↓tfnet_model_TFNetModel_construct_1079:CNode_1194{[0]: ValueNode<Primitive> Return, [1]: CNode_1086}


subgraph attr:
training : 1
subgraph instance: ✗↻4↓tfnet_model_TFNetModel_construct_1080 : 0x3973f670
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻4↓tfnet_model_TFNetModel_construct_1080 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_832]() {
  Return(%para208_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
}
# Order:
#   1: @✗↻4↓tfnet_model_TFNetModel_construct_1080:CNode_1195{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: ✓ms_min_1097 : 0x395909b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✓ms_min_1097 parent: [subgraph @ms_min_962]() {
  %1(CNode_1196) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("min() requires 1 argument at least.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2726/        const_utils.raise_type_error("min() requires 1 argument at least.")/
  %2(CNode_1197) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
  %3(CNode_1199) = call @↓ms_min_1198()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %4(CNode_1200) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2726/        const_utils.raise_type_error("min() requires 1 argument at least.")/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2726/        const_utils.raise_type_error("min() requires 1 argument at least.")/
}
# Order:
#   1: @✓ms_min_1097:CNode_1196{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> min() requires 1 argument at least.}
#   2: @✓ms_min_1097:CNode_1201{[0]: ValueNode<Primitive> Return, [1]: CNode_1200}
#   3: @✓ms_min_1097:CNode_1199{[0]: ValueNode<FuncGraph> ↓ms_min_1198}


subgraph attr:
subgraph instance: ✗ms_min_1098 : 0x39513b50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✗ms_min_1098 parent: [subgraph @ms_min_962]() {
  %1(len_data) = $(ms_min_962):call @get_max_min_data_len_664(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2724/    len_data = get_max_min_data_len(data)/
  %2(CNode_1202) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
  %3(CNode_1203) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
  %4(CNode_1204) = Switch(%3, @✓✗ms_min_1205, @2✗ms_min_1206)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
  %5(CNode_1207) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
}
# Order:
#   1: @✗ms_min_1098:CNode_1202{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 1}
#   2: @✗ms_min_1098:CNode_1203{[0]: ValueNode<Primitive> Cond, [1]: CNode_1202, [2]: ValueNode<BoolImm> false}
#   3: @✗ms_min_1098:CNode_1204{[0]: ValueNode<Primitive> Switch, [1]: CNode_1203, [2]: ValueNode<FuncGraph> ✓✗ms_min_1205, [3]: ValueNode<FuncGraph> 2✗ms_min_1206}
#   4: @✗ms_min_1098:CNode_1207{[0]: CNode_1204}
#   5: @✗ms_min_1098:CNode_1208{[0]: ValueNode<Primitive> Return, [1]: CNode_1207}


subgraph attr:
training : 1
subgraph instance: modules_ResNet34Backbone_construct_1104 : 0x395994d0
# In file /data/shengteng/training/modules.py:220/    def construct(self, x):/
subgraph @modules_ResNet34Backbone_construct_1104 parent: [subgraph @after_grad_108](%para225_x) {
  %1(x) = call @mindspore_nn_layer_conv_Conv2d_construct_1209(%para225_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:221/        x = self.conv1(x)/
  %2(x) = call @mindspore_nn_layer_normalization_BatchNorm2d_construct_1210(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:222/        x = self.bn1(x)/
  %3(x) = call @mindspore_nn_layer_activation_ReLU_construct_1211(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:223/        x = self.relu(x)/
  %4(x) = call @mindspore_nn_layer_pooling_MaxPool2d_construct_1212(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  %5(x) = call @mindspore_nn_layer_container_SequentialCell_construct_1213(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:226/        x = self.layer1(x)/
  %6(x) = call @mindspore_nn_layer_container_SequentialCell_construct_1214(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:227/        x = self.layer2(x)/
  %7(x) = call @mindspore_nn_layer_container_SequentialCell_construct_1215(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:228/        x = self.layer3(x)/
  %8(x) = call @mindspore_nn_layer_container_SequentialCell_construct_1216(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:229/        x = self.layer4(x)/
  %9(x) = call @mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:231/        x = self.avgpool(x)/
  %10(x) = call @mindspore_nn_layer_basic_Flatten_construct_1218(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:232/        x = self.flatten(x)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:233/        return x/
}
# Order:
#   1: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_conv_Conv2d_construct_1209, [1]: param_x}
#   2: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_normalization_BatchNorm2d_construct_1210, [1]: x}
#   3: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_1211, [1]: x}
#   4: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_pooling_MaxPool2d_construct_1212, [1]: x}
#   5: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_1213, [1]: x}
#   6: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_1214, [1]: x}
#   7: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_1215, [1]: x}
#   8: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_1216, [1]: x}
#   9: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217, [1]: x}
#  10: @modules_ResNet34Backbone_construct_1104:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Flatten_construct_1218, [1]: x}
#  11: @modules_ResNet34Backbone_construct_1104:CNode_1219{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
subgraph instance: zeros_like_1108 : 0x391ab310
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1044/def zeros_like(input, *, dtype=None):/
subgraph @zeros_like_1108(%para226_input, %para227_dtype) {
  %1(CNode_1220) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1078/    _cast = _get_cache_prim(P.Cast)()/
  %2(_cast) = %1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1078/    _cast = _get_cache_prim(P.Cast)()/
  %3(CNode_1221) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1077/    _zeros_like = _get_cache_prim(P.ZerosLike)()/
  %4(_zeros_like) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1077/    _zeros_like = _get_cache_prim(P.ZerosLike)()/
  %5(output) = %4(%para226_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1079/    output = _zeros_like(input)/
  %6(CNode_1222) = S_Prim_is_(%para227_dtype, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
  %7(CNode_1223) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
  %8(CNode_1224) = Switch(%7, @↰zeros_like_1225, @↱zeros_like_1226)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
  %9(_dtype) = %8()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
  %10(output) = %2(%5, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1080/    output = _cast(output, _dtype)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1081/    return output/
}
# Order:
#   1: @zeros_like_1108:CNode_1222{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: param_dtype, [2]: ValueNode<None> None}
#   2: @zeros_like_1108:CNode_1223{[0]: ValueNode<Primitive> Cond, [1]: CNode_1222, [2]: ValueNode<BoolImm> false}
#   3: @zeros_like_1108:CNode_1224{[0]: ValueNode<Primitive> Switch, [1]: CNode_1223, [2]: ValueNode<FuncGraph> ↰zeros_like_1225, [3]: ValueNode<FuncGraph> ↱zeros_like_1226}
#   4: @zeros_like_1108:_dtype{[0]: CNode_1224}
#   5: @zeros_like_1108:CNode_1221{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.ZerosLike'}
#   6: @zeros_like_1108:_zeros_like{[0]: CNode_1221}
#   7: @zeros_like_1108:CNode_1220{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Cast'}
#   8: @zeros_like_1108:_cast{[0]: CNode_1220}
#   9: @zeros_like_1108:output{[0]: _zeros_like, [1]: param_input}
#  10: @zeros_like_1108:output{[0]: _cast, [1]: output, [2]: _dtype}
#  11: @zeros_like_1108:CNode_1227{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ↵6↓tfnet_model_TFNetModel_construct_1113 : 0x37f24a30
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵6↓tfnet_model_TFNetModel_construct_1113 parent: [subgraph @6↓tfnet_model_TFNetModel_construct_976](%para228_, %para229_) {
  %1(CNode_1116) = $(6↓tfnet_model_TFNetModel_construct_976):S_Prim_inner_len(%para201_фfeature_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %2(CNode_1228) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para228_@CNode_1229, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %3(CNode_1230) = Switch(%2, @↻6↓tfnet_model_TFNetModel_construct_1231, @7↓tfnet_model_TFNetModel_construct_1232)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %4(CNode_1233) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
}
# Order:
#   1: @↵6↓tfnet_model_TFNetModel_construct_1113:CNode_1228{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1229, [2]: CNode_1116}
#   2: @↵6↓tfnet_model_TFNetModel_construct_1113:CNode_1230{[0]: ValueNode<Primitive> Switch, [1]: CNode_1228, [2]: ValueNode<FuncGraph> ↻6↓tfnet_model_TFNetModel_construct_1231, [3]: ValueNode<FuncGraph> 7↓tfnet_model_TFNetModel_construct_1232}
#   3: @↵6↓tfnet_model_TFNetModel_construct_1113:CNode_1233{[0]: CNode_1230}
#   4: @↵6↓tfnet_model_TFNetModel_construct_1113:CNode_1234{[0]: ValueNode<Primitive> Return, [1]: CNode_1233}


subgraph attr:
training : 1
subgraph instance: G_✓5↓tfnet_model_TFNetModel_construct_1119 : 0x376f3430
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_✓5↓tfnet_model_TFNetModel_construct_1119 parent: [subgraph @↵4↓tfnet_model_TFNetModel_construct_713]() {
  %1(CNode_1236) = call @↵✓5↓tfnet_model_TFNetModel_construct_1235(%para201_фfeature_list, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @G_✓5↓tfnet_model_TFNetModel_construct_1119:CNode_1236{[0]: ValueNode<FuncGraph> ↵✓5↓tfnet_model_TFNetModel_construct_1235, [1]: param_фfeature_list, [2]: ValueNode<ValueList> []}
#   2: @G_✓5↓tfnet_model_TFNetModel_construct_1119:CNode_1237{[0]: ValueNode<Primitive> Return, [1]: CNode_1236}


subgraph attr:
training : 1
subgraph instance: ✓↻✓✗2↓tfnet_model_TFNetModel_construct_1129 : 0x374981c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻✓✗2↓tfnet_model_TFNetModel_construct_1129 parent: [subgraph @↻✓✗2↓tfnet_model_TFNetModel_construct_981]() {
  %1(CNode_1126) = $(↻✓✗2↓tfnet_model_TFNetModel_construct_981):call @ms_next_1075(%para209_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %2(v) = $(↻✓✗2↓tfnet_model_TFNetModel_construct_981):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %3(CNode_1133) = $(↻✓✗2↓tfnet_model_TFNetModel_construct_981):ClassType(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %4(CNode_1134) = $(↻✓✗2↓tfnet_model_TFNetModel_construct_981):S_Prim_make_list(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  %5(CNode_1135) = $(↻✓✗2↓tfnet_model_TFNetModel_construct_981):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para210_list, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @✓↻✓✗2↓tfnet_model_TFNetModel_construct_1129:CNode_1238{[0]: ValueNode<Primitive> Return, [1]: CNode_1135}


subgraph attr:
training : 1
subgraph instance: ✗↻✓✗2↓tfnet_model_TFNetModel_construct_1130 : 0x373bd8a0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻✓✗2↓tfnet_model_TFNetModel_construct_1130 parent: [subgraph @↵✓✗2↓tfnet_model_TFNetModel_construct_847]() {
  Return(%para210_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:98/            len_x_list = [int(v) for v in len_x]/
}
# Order:
#   1: @✗↻✓✗2↓tfnet_model_TFNetModel_construct_1130:CNode_1239{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: check_isconstant_1138 : 0x376a4150
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @check_isconstant_1138(%para230_input_data, %para231_func_name) {
  %1(CNode_524) = S_Prim_IsConstant(%para230_input_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %2(CNode_525) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %3(CNode_526) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %4(CNode_527) = Switch(%3, @✓check_isconstant_1240, @✗check_isconstant_1241)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  %5(CNode_529) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
}
# Order:
#   1: @check_isconstant_1138:CNode_524{[0]: ValueNode<DoSignaturePrimitive> S_Prim_IsConstant, [1]: param_input_data}
#   2: @check_isconstant_1138:CNode_525{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_524}
#   3: @check_isconstant_1138:CNode_526{[0]: ValueNode<Primitive> Cond, [1]: CNode_525, [2]: ValueNode<BoolImm> false}
#   4: @check_isconstant_1138:CNode_527{[0]: ValueNode<Primitive> Switch, [1]: CNode_526, [2]: ValueNode<FuncGraph> ✓check_isconstant_1240, [3]: ValueNode<FuncGraph> ✗check_isconstant_1241}
#   5: @check_isconstant_1138:CNode_529{[0]: CNode_527}
#   6: @check_isconstant_1138:CNode_530{[0]: ValueNode<Primitive> Return, [1]: CNode_529}


subgraph attr:
subgraph instance: shape_1142 : 0x3738dde0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1484/def shape(input_x):/
subgraph @shape_1142(%para232_input_x) {
  %1(CNode_1242) = S_Prim_Shape(%para232_input_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
}
# Order:
#   1: @shape_1142:CNode_1242{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_input_x}
#   2: @shape_1142:CNode_1243{[0]: ValueNode<Primitive> Return, [1]: CNode_1242}


subgraph attr:
subgraph instance: 2✓ms_max_one_element_1146 : 0x374a4210
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @2✓ms_max_one_element_1146 parent: [subgraph @✓ms_max_one_element_1004]() {
  %1(CNode_1244) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("Cannot iterate over a scalar tensor.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2614/            const_utils.raise_type_error(/
  %2(CNode_1245) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_1247) = call @↓✓ms_max_one_element_1246()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  %4(CNode_1248) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2614/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2614/            const_utils.raise_type_error(/
}
# Order:
#   1: @2✓ms_max_one_element_1146:CNode_1244{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> Cannot iterate over a scalar tensor.}
#   2: @2✓ms_max_one_element_1146:CNode_1249{[0]: ValueNode<Primitive> Return, [1]: CNode_1248}
#   3: @2✓ms_max_one_element_1146:CNode_1247{[0]: ValueNode<FuncGraph> ↓✓ms_max_one_element_1246}


subgraph attr:
subgraph instance: ✗✓ms_max_one_element_1147 : 0x37d2bb80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗✓ms_max_one_element_1147 parent: [subgraph @✓ms_max_one_element_1004]() {
  %1(CNode_1250) = call @↓✓ms_max_one_element_1246()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2613/        if tensor_shape_len == 0:/
}
# Order:
#   1: @✗✓ms_max_one_element_1147:CNode_1251{[0]: ValueNode<Primitive> Return, [1]: CNode_1250}
#   2: @✗✓ms_max_one_element_1147:CNode_1250{[0]: ValueNode<FuncGraph> ↓✓ms_max_one_element_1246}


subgraph attr:
after_block : 1
subgraph instance: ↓ms_max_one_element_1150 : 0x37f6f660
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @↓ms_max_one_element_1150 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1252) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
  %2(CNode_1253) = S_Prim_isinstance(%para214_x, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
  %3(CNode_1254) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
  %4(CNode_1255) = Switch(%3, @✓↓ms_max_one_element_1256, @✗↓ms_max_one_element_1257)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
  %5(CNode_1258) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
}
# Order:
#   1: @↓ms_max_one_element_1150:CNode_1252{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'list', [2]: ValueNode<ClassType> class 'tuple'}
#   2: @↓ms_max_one_element_1150:CNode_1253{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: CNode_1252}
#   3: @↓ms_max_one_element_1150:CNode_1254{[0]: ValueNode<Primitive> Cond, [1]: CNode_1253, [2]: ValueNode<BoolImm> false}
#   4: @↓ms_max_one_element_1150:CNode_1255{[0]: ValueNode<Primitive> Switch, [1]: CNode_1254, [2]: ValueNode<FuncGraph> ✓↓ms_max_one_element_1256, [3]: ValueNode<FuncGraph> ✗↓ms_max_one_element_1257}
#   5: @↓ms_max_one_element_1150:CNode_1258{[0]: CNode_1255}
#   6: @↓ms_max_one_element_1150:CNode_1259{[0]: ValueNode<Primitive> Return, [1]: CNode_1258}


subgraph attr:
subgraph instance: max_tensor_1154 : 0x37e00400
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @max_tensor_1154(%para233_data) {
  %1(CNode_1260) = S_Prim_inner_len(%para233_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
  %2(CNode_1261) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
  %3(CNode_1262) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
  %4(CNode_1263) = Switch(%3, @✓max_tensor_1264, @✗max_tensor_1265)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
  %5(CNode_1266) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
  %6(CNode_1268) = call @↓max_tensor_1267(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2651/            return max_tensor(*data)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
}
# Order:
#   1: @max_tensor_1154:CNode_1260{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @max_tensor_1154:CNode_1261{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1260, [2]: ValueNode<Int64Imm> 1}
#   3: @max_tensor_1154:CNode_1262{[0]: ValueNode<Primitive> Cond, [1]: CNode_1261, [2]: ValueNode<BoolImm> false}
#   4: @max_tensor_1154:CNode_1263{[0]: ValueNode<Primitive> Switch, [1]: CNode_1262, [2]: ValueNode<FuncGraph> ✓max_tensor_1264, [3]: ValueNode<FuncGraph> ✗max_tensor_1265}
#   5: @max_tensor_1154:CNode_1266{[0]: CNode_1263}
#   6: @max_tensor_1154:CNode_1268{[0]: ValueNode<FuncGraph> ↓max_tensor_1267, [1]: CNode_1266}
#   7: @max_tensor_1154:CNode_1269{[0]: ValueNode<Primitive> Return, [1]: CNode_1268}


subgraph attr:
subgraph instance: ↵get_tensor_num_1157 : 0x30603100
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↵get_tensor_num_1157 parent: [subgraph @get_tensor_num_1008](%para234_, %para235_) {
  %1(CNode_1159) = $(get_tensor_num_1008):S_Prim_inner_len(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(CNode_1270) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para234_@CNode_1271, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(CNode_1272) = Switch(%2, @↻get_tensor_num_1273, @↓get_tensor_num_1274)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %4(CNode_1275) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
}
# Order:
#   1: @↵get_tensor_num_1157:CNode_1270{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1271, [2]: CNode_1159}
#   2: @↵get_tensor_num_1157:CNode_1272{[0]: ValueNode<Primitive> Switch, [1]: CNode_1270, [2]: ValueNode<FuncGraph> ↻get_tensor_num_1273, [3]: ValueNode<FuncGraph> ↓get_tensor_num_1274}
#   3: @↵get_tensor_num_1157:CNode_1275{[0]: CNode_1272}
#   4: @↵get_tensor_num_1157:CNode_1276{[0]: ValueNode<Primitive> Return, [1]: CNode_1275}


subgraph attr:
after_block : 1
subgraph instance: ↓✓2✗ms_max_1161 : 0x37b82150
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓✓2✗ms_max_1161 parent: [subgraph @✓2✗ms_max_892]() {
  %1(tensor_num) = $(✓2✗ms_max_892):call @get_tensor_num_1008(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %2(CNode_486) = S_Prim_not_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  %3(CNode_487) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  %4(CNode_488) = Switch(%3, @✓↓✓2✗ms_max_1277, @✗↓✓2✗ms_max_1278)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  %5(CNode_490) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
}
# Order:
#   1: @↓✓2✗ms_max_1161:CNode_486{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_num, [2]: ValueNode<Int64Imm> 0}
#   2: @↓✓2✗ms_max_1161:CNode_487{[0]: ValueNode<Primitive> Cond, [1]: CNode_486, [2]: ValueNode<BoolImm> false}
#   3: @↓✓2✗ms_max_1161:CNode_488{[0]: ValueNode<Primitive> Switch, [1]: CNode_487, [2]: ValueNode<FuncGraph> ✓↓✓2✗ms_max_1277, [3]: ValueNode<FuncGraph> ✗↓✓2✗ms_max_1278}
#   4: @↓✓2✗ms_max_1161:CNode_490{[0]: CNode_488}
#   5: @↓✓2✗ms_max_1161:CNode_491{[0]: ValueNode<Primitive> Return, [1]: CNode_490}


subgraph attr:
after_block : 1
subgraph instance: ↓✗ms_max_1162 : 0x378eaae0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @↓✗ms_max_1162 parent: [subgraph @ms_max_436]() {
  %1(CNode_507) = call @↓ms_max_759()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2644/    elif len_data == 1:/
}
# Order:
#   1: @↓✗ms_max_1162:CNode_508{[0]: ValueNode<Primitive> Return, [1]: CNode_507}
#   2: @↓✗ms_max_1162:CNode_507{[0]: ValueNode<FuncGraph> ↓ms_max_759}


subgraph attr:
subgraph instance: ✓3↓↻↓forward_fn_407 : 0x3978f390
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✓3↓↻↓forward_fn_407 parent: [subgraph @3↓↻↓forward_fn_126]() {
  %1(CNode_1279) = S_Prim_MakeTuple(I64(1), I64(1), I64(3512))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:668/                            logits = ops.zeros((1, 1, 3512), ms.float32)/
  %2(logits) = call @zeros_442(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:668/                            logits = ops.zeros((1, 1, 3512), ms.float32)/
  %3(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %4(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %3)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %5(CNode_1280) = getattr(%4, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
  %6(CNode_1281) = getattr(%5, "warning")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
  %7(CNode_1282) = getattr(%para163_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
  %8(CNode_1283) = JoinedStr("Batch ", I64(0), " - Unexpected logits shape: ", %7, ", expected 3D tensor")
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
  %9(CNode_1284) = %6(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
  %10(CNode_1285) = getattr(%4, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:669/                            self.logger.info(f"Batch {batch_idx} - Replaced with 3D placeholder: {logits.shape}")/
  %11(CNode_1286) = getattr(%10, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:669/                            self.logger.info(f"Batch {batch_idx} - Replaced with 3D placeholder: {logits.shape}")/
  %12(CNode_1287) = getattr(%2, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:669/                            self.logger.info(f"Batch {batch_idx} - Replaced with 3D placeholder: {logits.shape}")/
  %13(CNode_1288) = JoinedStr("Batch ", I64(0), " - Replaced with 3D placeholder: ", %12)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:669/                            self.logger.info(f"Batch {batch_idx} - Replaced with 3D placeholder: {logits.shape}")/
  %14(CNode_1289) = %11(%13)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:669/                            self.logger.info(f"Batch {batch_idx} - Replaced with 3D placeholder: {logits.shape}")/
  %15(CNode_1290) = MakeTuple(%9, %14)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %16(CNode_1291) = StopGradient(%15)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %17(CNode_1292) = Depend[side_effect_propagate: I64(1)](%2, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%17)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:666/                            self.logger.warning(f"Batch {batch_idx} - Unexpected logits shape: {logits.shape}, expected 3D tensor")/
}
# Order:
#   1: @✓3↓↻↓forward_fn_407:CNode_1280{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @✓3↓↻↓forward_fn_407:CNode_1281{[0]: ValueNode<Primitive> getattr, [1]: CNode_1280, [2]: ValueNode<StringImm> warning}
#   3: @✓3↓↻↓forward_fn_407:CNode_1282{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   4: @✓3↓↻↓forward_fn_407:CNode_1283{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Unexpected logits shape: , [4]: CNode_1282, [5]: ValueNode<StringImm> , expected 3D tensor}
#   5: @✓3↓↻↓forward_fn_407:CNode_1284{[0]: CNode_1281, [1]: CNode_1283}
#   6: @✓3↓↻↓forward_fn_407:CNode_1279{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> 1, [3]: ValueNode<Int64Imm> 3512}
#   7: @✓3↓↻↓forward_fn_407:logits{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_1279, [2]: ValueNode<Float> Float32}
#   8: @✓3↓↻↓forward_fn_407:CNode_1285{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   9: @✓3↓↻↓forward_fn_407:CNode_1286{[0]: ValueNode<Primitive> getattr, [1]: CNode_1285, [2]: ValueNode<StringImm> info}
#  10: @✓3↓↻↓forward_fn_407:CNode_1287{[0]: ValueNode<Primitive> getattr, [1]: logits, [2]: ValueNode<StringImm> shape}
#  11: @✓3↓↻↓forward_fn_407:CNode_1288{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Replaced with 3D placeholder: , [4]: CNode_1287}
#  12: @✓3↓↻↓forward_fn_407:CNode_1289{[0]: CNode_1286, [1]: CNode_1288}
#  13: @✓3↓↻↓forward_fn_407:CNode_1293{[0]: ValueNode<Primitive> Return, [1]: CNode_1292}


subgraph attr:
subgraph instance: ✗3↓↻↓forward_fn_408 : 0x3978e6b0
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗3↓↻↓forward_fn_408 parent: [subgraph @3↓↻↓forward_fn_126]() {
  Return(%para163_фlogits)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:665/                        if logits.ndim != 3:/
}
# Order:
#   1: @✗3↓↻↓forward_fn_408:CNode_1294{[0]: ValueNode<Primitive> Return, [1]: param_фlogits}


subgraph attr:
subgraph instance: transpose_1169 : 0x397865c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2414/def transpose(input, input_perm):/
subgraph @transpose_1169(%para236_input, %para237_input_perm) {
  %1(CNode_1295) = S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para236_input, %para237_input_perm)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2462/    return transpose_(input, input_perm)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2462/    return transpose_(input, input_perm)/
}
# Order:
#   1: @transpose_1169:CNode_1295{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: param_input, [2]: param_input_perm}
#   2: @transpose_1169:CNode_1296{[0]: ValueNode<Primitive> Return, [1]: CNode_1295}


subgraph attr:
after_block : 1
subgraph instance: ↓ms_min_1198 : 0x39521440
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↓ms_min_1198 parent: [subgraph @ms_min_962]() {
  %1(CNode_1298) = call @↵↓ms_min_1297(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
}
# Order:
#   1: @↓ms_min_1198:CNode_1299{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @↓ms_min_1198:CNode_1300{[0]: ValueNode<Primitive> Return, [1]: CNode_1298}
#   3: @↓ms_min_1198:CNode_1298{[0]: ValueNode<FuncGraph> ↵↓ms_min_1297, [1]: ValueNode<Int64Imm> 0}


subgraph attr:
subgraph instance: ✓✗ms_min_1205 : 0x3954b280
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✓✗ms_min_1205 parent: [subgraph @ms_min_962]() {
  %1(x) = S_Prim_getitem(%para221_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2728/        x = data[0]/
  %2(CNode_1302) = call @ms_min_one_element_1301(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
}
# Order:
#   1: @✓✗ms_min_1205:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @✓✗ms_min_1205:CNode_1302{[0]: ValueNode<FuncGraph> ms_min_one_element_1301, [1]: x}
#   3: @✓✗ms_min_1205:CNode_1303{[0]: ValueNode<Primitive> Return, [1]: CNode_1302}


subgraph attr:
subgraph instance: 2✗ms_min_1206 : 0x39516e60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @2✗ms_min_1206 parent: [subgraph @ms_min_962]() {
  %1(len_data) = $(ms_min_962):call @get_max_min_data_len_664(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2724/    len_data = get_max_min_data_len(data)/
  %2(CNode_1304) = S_Prim_greater_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
  %3(CNode_1305) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
  %4(CNode_1306) = Switch(%3, @✓2✗ms_min_1307, @3✗ms_min_1308)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
  %5(CNode_1309) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
}
# Order:
#   1: @2✗ms_min_1206:CNode_1304{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: len_data, [2]: ValueNode<Int64Imm> 2}
#   2: @2✗ms_min_1206:CNode_1305{[0]: ValueNode<Primitive> Cond, [1]: CNode_1304, [2]: ValueNode<BoolImm> false}
#   3: @2✗ms_min_1206:CNode_1306{[0]: ValueNode<Primitive> Switch, [1]: CNode_1305, [2]: ValueNode<FuncGraph> ✓2✗ms_min_1307, [3]: ValueNode<FuncGraph> 3✗ms_min_1308}
#   4: @2✗ms_min_1206:CNode_1309{[0]: CNode_1306}
#   5: @2✗ms_min_1206:CNode_1310{[0]: ValueNode<Primitive> Return, [1]: CNode_1309}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_basic_Flatten_construct_1218 : 0x3967a5e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:461/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Flatten_construct_1218(%para238_x) {
  %1(x_rank) = call @rank_1311(%para238_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:462/        x_rank = F.rank(x)/
  %2(CNode_1312) = S_Prim_not_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
  %3(CNode_1313) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
  %4(CNode_1314) = Switch(%3, @↰mindspore_nn_layer_basic_Flatten_construct_1315, @↱mindspore_nn_layer_basic_Flatten_construct_1316)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
  %5(ndim) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
  %6(CNode_1318) = call @check_axis_valid_1317(I64(1), %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:464/        self.check_axis_valid(self.start_dim, ndim)/
  %7(CNode_1319) = call @check_axis_valid_1317(I64(-1), %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:465/        self.check_axis_valid(self.end_dim, ndim)/
  %8(CNode_1320) = MakeTuple(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:461/    def construct(self, x):/
  %9(CNode_1321) = StopGradient(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:461/    def construct(self, x):/
  %10(CNode_1322) = S_Prim_MakeTuple(%para238_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  %11(CNode_1323) = S_Prim_MakeTuple("start_dim", "end_dim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  %12(CNode_1324) = S_Prim_MakeTuple(I64(1), I64(-1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  %13(CNode_1325) = S_Prim_make_dict(%11, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  %14(CNode_1326) = UnpackCall_unpack_call(@flatten_1327, %10, %13)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  %15(CNode_1328) = Depend[side_effect_propagate: I64(1)](%14, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
}
# Order:
#   1: @mindspore_nn_layer_basic_Flatten_construct_1218:x_rank{[0]: ValueNode<FuncGraph> rank_1311, [1]: param_x}
#   2: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1312{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: x_rank, [2]: ValueNode<Int64Imm> 0}
#   3: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1313{[0]: ValueNode<Primitive> Cond, [1]: CNode_1312, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1314{[0]: ValueNode<Primitive> Switch, [1]: CNode_1313, [2]: ValueNode<FuncGraph> ↰mindspore_nn_layer_basic_Flatten_construct_1315, [3]: ValueNode<FuncGraph> ↱mindspore_nn_layer_basic_Flatten_construct_1316}
#   5: @mindspore_nn_layer_basic_Flatten_construct_1218:ndim{[0]: CNode_1314}
#   6: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1318{[0]: ValueNode<FuncGraph> check_axis_valid_1317, [1]: ValueNode<Int64Imm> 1, [2]: ndim}
#   7: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1319{[0]: ValueNode<FuncGraph> check_axis_valid_1317, [1]: ValueNode<Int64Imm> -1, [2]: ndim}
#   8: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1322{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_x}
#   9: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1323{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> start_dim, [2]: ValueNode<StringImm> end_dim}
#  10: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1324{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<Int64Imm> -1}
#  11: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1325{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_1323, [2]: CNode_1324}
#  12: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1326{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1329, [1]: ValueNode<FuncGraph> flatten_1327, [2]: CNode_1322, [3]: CNode_1325}
#  13: @mindspore_nn_layer_basic_Flatten_construct_1218:CNode_1330{[0]: ValueNode<Primitive> Return, [1]: CNode_1328}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217 : 0x39679180
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:1356/    def construct(self, input):/
subgraph @mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217(%para239_input) {
  %1(CNode_1331) = S_Prim_AdaptiveAvgPool2D[output_names: ["y"], output_size: (I64(1), I64(1)), input_names: ["x"]](%para239_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:1357/        return self.adaptive_avgpool2d(input)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:1357/        return self.adaptive_avgpool2d(input)/
}
# Order:
#   1: @mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217:CNode_1331{[0]: ValueNode<DoSignaturePrimitive> S_Prim_AdaptiveAvgPool2D, [1]: param_input}
#   2: @mindspore_nn_layer_pooling_AdaptiveAvgPool2d_construct_1217:CNode_1332{[0]: ValueNode<Primitive> Return, [1]: CNode_1331}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_1216 : 0x39650750
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_1216 parent: [subgraph @after_grad_108](%para240_input_data) {
  %1(CNode_1334) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1333(I64(0), %para240_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_1216:CNode_1335{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1336}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_1216:CNode_1334{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1333, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_1216:CNode_1337{[0]: ValueNode<Primitive> Return, [1]: CNode_1334}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_1215 : 0x3961ab10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_1215 parent: [subgraph @after_grad_108](%para241_input_data) {
  %1(CNode_1339) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1338(I64(0), %para241_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_1215:CNode_1340{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1341}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_1215:CNode_1339{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1338, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_1215:CNode_1342{[0]: ValueNode<Primitive> Return, [1]: CNode_1339}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_1214 : 0x395edab0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_1214 parent: [subgraph @after_grad_108](%para242_input_data) {
  %1(CNode_1344) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1343(I64(0), %para242_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_1214:CNode_1345{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1346}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_1214:CNode_1344{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1343, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_1214:CNode_1347{[0]: ValueNode<Primitive> Return, [1]: CNode_1344}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_1213 : 0x395d54d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_1213 parent: [subgraph @after_grad_108](%para243_input_data) {
  %1(CNode_1349) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1348(I64(0), %para243_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_1213:CNode_1350{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1351}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_1213:CNode_1349{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1348, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_1213:CNode_1352{[0]: ValueNode<Primitive> Return, [1]: CNode_1349}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_MaxPool2d_construct_1212 : 0x395b83b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_1212(%para244_x) {
  %1(CNode_1353) = getattr(%para244_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %2(CNode_1354) = S_Prim_equal(%1, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %3(CNode_1355) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %4(CNode_1356) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357, @✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  %5(CNode_1359) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1353{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1354{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1353, [2]: ValueNode<Int64Imm> 3}
#   3: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1355{[0]: ValueNode<Primitive> Cond, [1]: CNode_1354, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1356{[0]: ValueNode<Primitive> Switch, [1]: CNode_1355, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358}
#   5: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1359{[0]: CNode_1356}
#   6: @mindspore_nn_layer_pooling_MaxPool2d_construct_1212:CNode_1360{[0]: ValueNode<Primitive> Return, [1]: CNode_1359}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1211 : 0x395b6fa0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1211(%para245_x) {
  %1(CNode_1361) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para245_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1211:CNode_1361{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1211:CNode_1362{[0]: ValueNode<Primitive> Return, [1]: CNode_1361}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1210 : 0x395a7f10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1210 parent: [subgraph @after_grad_108](%para246_x) {
  %1(CNode_1364) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363(%para246_x, %para6_conv2d.bn1.gamma, %para7_conv2d.bn1.beta, %para107_conv2d.bn1.moving_mean, %para108_conv2d.bn1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.bn1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1210:CNode_1364{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363, [1]: param_x, [2]: param_conv2d.bn1.gamma, [3]: param_conv2d.bn1.beta, [4]: param_conv2d.bn1.moving_mean, [5]: param_conv2d.bn1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1210:CNode_1365{[0]: ValueNode<Primitive> Return, [1]: CNode_1364}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1209 : 0x395a4270
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1209 parent: [subgraph @after_grad_108](%para247_x) {
  %1(CNode_1367) = call @✗mindspore_nn_layer_conv_Conv2d_construct_1366()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1209:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_conv2d.conv1.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1209:CNode_1367{[0]: ValueNode<FuncGraph> ✗mindspore_nn_layer_conv_Conv2d_construct_1366}
#   3: @mindspore_nn_layer_conv_Conv2d_construct_1209:CNode_1368{[0]: ValueNode<Primitive> Return, [1]: CNode_1367}


subgraph attr:
subgraph instance: ↰zeros_like_1225 : 0x391afd30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
subgraph @↰zeros_like_1225 parent: [subgraph @zeros_like_1108]() {
  %1(CNode_1369) = getattr(%para226_input, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
}
# Order:
#   1: @↰zeros_like_1225:CNode_1369{[0]: ValueNode<Primitive> getattr, [1]: param_input, [2]: ValueNode<StringImm> dtype}
#   2: @↰zeros_like_1225:CNode_1370{[0]: ValueNode<Primitive> Return, [1]: CNode_1369}


subgraph attr:
subgraph instance: ↱zeros_like_1226 : 0x391aef20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
subgraph @↱zeros_like_1226 parent: [subgraph @zeros_like_1108]() {
  Return(%para227_dtype)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1076/    _dtype = input.dtype if dtype is None else dtype/
}
# Order:
#   1: @↱zeros_like_1226:CNode_1371{[0]: ValueNode<Primitive> Return, [1]: param_dtype}


subgraph attr:
training : 1
subgraph instance: ↻6↓tfnet_model_TFNetModel_construct_1231 : 0x394b9ea0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻6↓tfnet_model_TFNetModel_construct_1231 parent: [subgraph @↵6↓tfnet_model_TFNetModel_construct_1113]() {
  %1(CNode_1229) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para228_@CNode_1229, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %2(CNode_1372) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
  %3(CNode_1373) = call @ms_iter_97(%para201_фfeature_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %4(features) = S_Prim_getitem(%3, %para228_@CNode_1229)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %5(CNode_1374) = getattr(%4, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %6(CNode_1375) = S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %7(CNode_1376) = S_Prim_greater(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %8(CNode_1377) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %9(CNode_1378) = Switch(%8, @✓↻6↓tfnet_model_TFNetModel_construct_1379, @✗↻6↓tfnet_model_TFNetModel_construct_1380)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %10(CNode_1381) = %9()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
  %11(CNode_1383) = call @↓↻6↓tfnet_model_TFNetModel_construct_1382(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %12(CNode_1384) = Depend[side_effect_propagate: I64(1)](%11, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%12)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:148/            if features.shape[0] > 0:/
}
# Order:
#   1: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1373{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_фfeature_list}
#   2: @↻6↓tfnet_model_TFNetModel_construct_1231:features{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1373, [2]: param_@CNode_1229}
#   3: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1229{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1229, [2]: ValueNode<Int64Imm> 1}
#   4: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1374{[0]: ValueNode<Primitive> getattr, [1]: features, [2]: ValueNode<StringImm> shape}
#   5: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1375{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1374, [2]: ValueNode<Int64Imm> 0}
#   6: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1376{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_1375, [2]: ValueNode<Int64Imm> 0}
#   7: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1377{[0]: ValueNode<Primitive> Cond, [1]: CNode_1376, [2]: ValueNode<BoolImm> false}
#   8: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1378{[0]: ValueNode<Primitive> Switch, [1]: CNode_1377, [2]: ValueNode<FuncGraph> ✓↻6↓tfnet_model_TFNetModel_construct_1379, [3]: ValueNode<FuncGraph> ✗↻6↓tfnet_model_TFNetModel_construct_1380}
#   9: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1381{[0]: CNode_1378}
#  10: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1383{[0]: ValueNode<FuncGraph> ↓↻6↓tfnet_model_TFNetModel_construct_1382, [1]: CNode_1381}
#  11: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1384{[0]: ValueNode<Primitive> Depend, [1]: CNode_1383, [2]: CNode_1372}
#  12: @↻6↓tfnet_model_TFNetModel_construct_1231:CNode_1385{[0]: ValueNode<Primitive> Return, [1]: CNode_1384}


subgraph attr:
training : 1
subgraph instance: 7↓tfnet_model_TFNetModel_construct_1232 : 0x38f610a0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @7↓tfnet_model_TFNetModel_construct_1232 parent: [subgraph @↵6↓tfnet_model_TFNetModel_construct_1113]() {
  %1(CNode_1386) = S_Prim_logical_not(%para229_фpadded_features)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:157/        if not padded_features:/
  %2(CNode_1387) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:157/        if not padded_features:/
  %3(CNode_1388) = Switch(%2, @✓7↓tfnet_model_TFNetModel_construct_1389, @✗7↓tfnet_model_TFNetModel_construct_1390)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:157/        if not padded_features:/
  %4(CNode_1391) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:157/        if not padded_features:/
  %5(CNode_1393) = call @8↓tfnet_model_TFNetModel_construct_1392(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:157/        if not padded_features:/
}
# Order:
#   1: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1386{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: param_фpadded_features}
#   2: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1387{[0]: ValueNode<Primitive> Cond, [1]: CNode_1386, [2]: ValueNode<BoolImm> false}
#   3: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1388{[0]: ValueNode<Primitive> Switch, [1]: CNode_1387, [2]: ValueNode<FuncGraph> ✓7↓tfnet_model_TFNetModel_construct_1389, [3]: ValueNode<FuncGraph> ✗7↓tfnet_model_TFNetModel_construct_1390}
#   4: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1391{[0]: CNode_1388}
#   5: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1393{[0]: ValueNode<FuncGraph> 8↓tfnet_model_TFNetModel_construct_1392, [1]: CNode_1391}
#   6: @7↓tfnet_model_TFNetModel_construct_1232:CNode_1394{[0]: ValueNode<Primitive> Return, [1]: CNode_1393}


subgraph attr:
training : 1
subgraph instance: ↵✓5↓tfnet_model_TFNetModel_construct_1235 : 0x37fe1de0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵✓5↓tfnet_model_TFNetModel_construct_1235(%para248_iter, %para249_list) {
  %1(CNode_1395) = call @hasnext_934(%para248_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %2(CNode_1396) = Switch(%1, @↻✓5↓tfnet_model_TFNetModel_construct_1397, @↓✓5↓tfnet_model_TFNetModel_construct_1398)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %3(CNode_1399) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @↵✓5↓tfnet_model_TFNetModel_construct_1235:CNode_1395{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵✓5↓tfnet_model_TFNetModel_construct_1235:CNode_1396{[0]: ValueNode<Primitive> Switch, [1]: CNode_1395, [2]: ValueNode<FuncGraph> ↻✓5↓tfnet_model_TFNetModel_construct_1397, [3]: ValueNode<FuncGraph> ↓✓5↓tfnet_model_TFNetModel_construct_1398}
#   3: @↵✓5↓tfnet_model_TFNetModel_construct_1235:CNode_1399{[0]: CNode_1396}
#   4: @↵✓5↓tfnet_model_TFNetModel_construct_1235:CNode_1400{[0]: ValueNode<Primitive> Return, [1]: CNode_1399}


subgraph attr:
subgraph instance: ✓check_isconstant_1240 : 0x376252e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @✓check_isconstant_1240 parent: [subgraph @check_isconstant_1138]() {
  %1(CNode_531) = S_Prim_add("The input of ", %para231_func_name)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %2(CNode_532) = S_Prim_add(%1, " only support Tensor, List, Tuple, constant Scalar, but got ")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %3(CNode_534) = call @get_data_type_str_1401(%para230_input_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2605/                                                                   " but got " + get_data_type_str(input_data))/
  %4(CNode_535) = S_Prim_add(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %5(CNode_536) = S_Prim_raise_type_error[constexpr_prim: Bool(1)](%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %6(CNode_537) = StopGradient(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
  %7(CNode_539) = call @↓check_isconstant_1402()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  %8(CNode_540) = Depend[side_effect_propagate: I64(1)](%7, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2604/        const_utils.raise_type_error("The input of " + func_name + " only support Tensor, List, Tuple, constant Scalar,"/
}
# Order:
#   1: @✓check_isconstant_1240:CNode_531{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: ValueNode<StringImm> The input of , [2]: param_func_name}
#   2: @✓check_isconstant_1240:CNode_532{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_531, [2]: ValueNode<StringImm>  only support Tensor, List, Tuple, constant Scalar, but got }
#   3: @✓check_isconstant_1240:CNode_534{[0]: ValueNode<FuncGraph> get_data_type_str_1401, [1]: param_input_data}
#   4: @✓check_isconstant_1240:CNode_535{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_532, [2]: CNode_534}
#   5: @✓check_isconstant_1240:CNode_536{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: CNode_535}
#   6: @✓check_isconstant_1240:CNode_539{[0]: ValueNode<FuncGraph> ↓check_isconstant_1402}
#   7: @✓check_isconstant_1240:CNode_541{[0]: ValueNode<Primitive> Return, [1]: CNode_540}


subgraph attr:
subgraph instance: ✗check_isconstant_1241 : 0x3776cd60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @✗check_isconstant_1241() {
  %1(CNode_1403) = call @↓check_isconstant_1402()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2603/    if not F.isconstant(input_data):/
}
# Order:
#   1: @✗check_isconstant_1241:CNode_1403{[0]: ValueNode<FuncGraph> ↓check_isconstant_1402}
#   2: @✗check_isconstant_1241:CNode_1404{[0]: ValueNode<Primitive> Return, [1]: CNode_1403}


subgraph attr:
after_block : 1
subgraph instance: ↓✓ms_max_one_element_1246 : 0x33d06b30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @↓✓ms_max_one_element_1246 parent: [subgraph @✓ms_max_one_element_1004]() {
  %1(tensor_shape) = $(✓ms_max_one_element_1004):call @shape_1142(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2611/        tensor_shape = F.shape(x)/
  %2(tensor_shape_len) = $(✓ms_max_one_element_1004):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2612/        tensor_shape_len = len(tensor_shape)/
  %3(CNode_1405) = S_Prim_greater_equal(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
  %4(CNode_1406) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
  %5(CNode_1407) = Switch(%4, @✓↓✓ms_max_one_element_1408, @✗↓✓ms_max_one_element_1409)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
  %6(CNode_1410) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
}
# Order:
#   1: @↓✓ms_max_one_element_1246:CNode_1405{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 2}
#   2: @↓✓ms_max_one_element_1246:CNode_1406{[0]: ValueNode<Primitive> Cond, [1]: CNode_1405, [2]: ValueNode<BoolImm> false}
#   3: @↓✓ms_max_one_element_1246:CNode_1407{[0]: ValueNode<Primitive> Switch, [1]: CNode_1406, [2]: ValueNode<FuncGraph> ✓↓✓ms_max_one_element_1408, [3]: ValueNode<FuncGraph> ✗↓✓ms_max_one_element_1409}
#   4: @↓✓ms_max_one_element_1246:CNode_1410{[0]: CNode_1407}
#   5: @↓✓ms_max_one_element_1246:CNode_1411{[0]: ValueNode<Primitive> Return, [1]: CNode_1410}


subgraph attr:
subgraph instance: ✓↓ms_max_one_element_1256 : 0x37313d80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓↓ms_max_one_element_1256 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1413) = call @check_sequence_all_variable_scalar_1412(%para214_x, "max")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  %2(CNode_1414) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  %3(CNode_1415) = Switch(%2, @2✓↓ms_max_one_element_1416, @✗✓↓ms_max_one_element_1417)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  %4(CNode_1418) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
}
# Order:
#   1: @✓↓ms_max_one_element_1256:CNode_1413{[0]: ValueNode<FuncGraph> check_sequence_all_variable_scalar_1412, [1]: param_x, [2]: ValueNode<StringImm> max}
#   2: @✓↓ms_max_one_element_1256:CNode_1414{[0]: ValueNode<Primitive> Cond, [1]: CNode_1413, [2]: ValueNode<BoolImm> false}
#   3: @✓↓ms_max_one_element_1256:CNode_1415{[0]: ValueNode<Primitive> Switch, [1]: CNode_1414, [2]: ValueNode<FuncGraph> 2✓↓ms_max_one_element_1416, [3]: ValueNode<FuncGraph> ✗✓↓ms_max_one_element_1417}
#   4: @✓↓ms_max_one_element_1256:CNode_1418{[0]: CNode_1415}
#   5: @✓↓ms_max_one_element_1256:CNode_1419{[0]: ValueNode<Primitive> Return, [1]: CNode_1418}


subgraph attr:
subgraph instance: ✗↓ms_max_one_element_1257 : 0x310cdca0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗↓ms_max_one_element_1257 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1421) = call @2↓ms_max_one_element_1420()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2621/    if isinstance(x, (list, tuple)):/
}
# Order:
#   1: @✗↓ms_max_one_element_1257:CNode_1422{[0]: ValueNode<Primitive> Return, [1]: CNode_1421}
#   2: @✗↓ms_max_one_element_1257:CNode_1421{[0]: ValueNode<FuncGraph> 2↓ms_max_one_element_1420}


subgraph attr:
after_block : 1
subgraph instance: ↓max_tensor_1267 : 0x37495f00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @↓max_tensor_1267(%para250_) {
  %1(max_tensor_data) = S_Prim_getitem(%para250_фdata, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2530/    max_tensor_data = data[0]/
  %2(CNode_1424) = call @↵↓max_tensor_1423(I64(0), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2651/            return max_tensor(*data)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
}
# Order:
#   1: @↓max_tensor_1267:max_tensor_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фdata, [2]: ValueNode<Int64Imm> 0}
#   2: @↓max_tensor_1267:CNode_1425{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фdata}
#   3: @↓max_tensor_1267:CNode_1426{[0]: ValueNode<Primitive> Return, [1]: CNode_1424}
#   4: @↓max_tensor_1267:CNode_1424{[0]: ValueNode<FuncGraph> ↵↓max_tensor_1423, [1]: ValueNode<Int64Imm> 0, [2]: max_tensor_data}


subgraph attr:
subgraph instance: ✓max_tensor_1264 : 0x37c7b270
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @✓max_tensor_1264 parent: [subgraph @max_tensor_1154]() {
  %1(data) = S_Prim_getitem(%para233_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2529/        data = data[0]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2529/        data = data[0]/
}
# Order:
#   1: @✓max_tensor_1264:data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @✓max_tensor_1264:CNode_1427{[0]: ValueNode<Primitive> Return, [1]: data}


subgraph attr:
subgraph instance: ✗max_tensor_1265 : 0x37e50b00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @✗max_tensor_1265 parent: [subgraph @max_tensor_1154]() {
  Return(%para233_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2528/    if len(data) == 1:/
}
# Order:
#   1: @✗max_tensor_1265:CNode_1428{[0]: ValueNode<Primitive> Return, [1]: param_data}


subgraph attr:
subgraph instance: ↻get_tensor_num_1273 : 0x3725e4b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↻get_tensor_num_1273 parent: [subgraph @↵get_tensor_num_1157]() {
  %1(CNode_1271) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para234_@CNode_1271, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(CNode_1429) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
  %3(CNode_1430) = call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %4(input_data) = S_Prim_getitem(%3, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %5(CNode_1431) = S_Prim_isinstance(%4, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
  %6(CNode_1432) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
  %7(CNode_1433) = Switch(%6, @✓↻get_tensor_num_1434, @✗↻get_tensor_num_1435)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
  %8(CNode_1436) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
  %9(CNode_1438) = call @↓↻get_tensor_num_1437(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %10(CNode_1439) = Depend[side_effect_propagate: I64(1)](%9, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
}
# Order:
#   1: @↻get_tensor_num_1273:CNode_1430{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_data}
#   2: @↻get_tensor_num_1273:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1430, [2]: param_@CNode_1271}
#   3: @↻get_tensor_num_1273:CNode_1271{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1271, [2]: ValueNode<Int64Imm> 1}
#   4: @↻get_tensor_num_1273:CNode_1431{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: input_data, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   5: @↻get_tensor_num_1273:CNode_1432{[0]: ValueNode<Primitive> Cond, [1]: CNode_1431, [2]: ValueNode<BoolImm> false}
#   6: @↻get_tensor_num_1273:CNode_1433{[0]: ValueNode<Primitive> Switch, [1]: CNode_1432, [2]: ValueNode<FuncGraph> ✓↻get_tensor_num_1434, [3]: ValueNode<FuncGraph> ✗↻get_tensor_num_1435}
#   7: @↻get_tensor_num_1273:CNode_1436{[0]: CNode_1433}
#   8: @↻get_tensor_num_1273:CNode_1438{[0]: ValueNode<FuncGraph> ↓↻get_tensor_num_1437, [1]: CNode_1436}
#   9: @↻get_tensor_num_1273:CNode_1439{[0]: ValueNode<Primitive> Depend, [1]: CNode_1438, [2]: CNode_1429}
#  10: @↻get_tensor_num_1273:CNode_1440{[0]: ValueNode<Primitive> Return, [1]: CNode_1439}


subgraph attr:
subgraph instance: ↓get_tensor_num_1274 : 0x310f5740
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↓get_tensor_num_1274 parent: [subgraph @↵get_tensor_num_1157]() {
  Return(%para235_фtensor_num)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2562/    return tensor_num/
}
# Order:
#   1: @↓get_tensor_num_1274:CNode_1441{[0]: ValueNode<Primitive> Return, [1]: param_фtensor_num}


subgraph attr:
subgraph instance: ✓↓✓2✗ms_max_1277 : 0x377eae60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓↓✓2✗ms_max_1277 parent: [subgraph @ms_max_436]() {
  %1(CNode_1442) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("max() cannot contain both tensor and non-tensor type.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2653/            const_utils.raise_type_error(/
  %2(CNode_1443) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %3(CNode_1445) = call @2↓✓2✗ms_max_1444()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %4(CNode_1446) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2653/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2653/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓↓✓2✗ms_max_1277:CNode_1442{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> max() cannot contain both tensor and non-tensor type.}
#   2: @✓↓✓2✗ms_max_1277:CNode_1447{[0]: ValueNode<Primitive> Return, [1]: CNode_1446}
#   3: @✓↓✓2✗ms_max_1277:CNode_1445{[0]: ValueNode<FuncGraph> 2↓✓2✗ms_max_1444}


subgraph attr:
subgraph instance: ✗↓✓2✗ms_max_1278 : 0x37c617f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗↓✓2✗ms_max_1278 parent: [subgraph @ms_max_436]() {
  %1(CNode_492) = call @2↓✓2✗ms_max_1444()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2652/        if tensor_num != 0:/
}
# Order:
#   1: @✗↓✓2✗ms_max_1278:CNode_493{[0]: ValueNode<Primitive> Return, [1]: CNode_492}
#   2: @✗↓✓2✗ms_max_1278:CNode_492{[0]: ValueNode<FuncGraph> 2↓✓2✗ms_max_1444}


subgraph attr:
subgraph instance: maximum_432 : 0x391a98b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:4949/def maximum(input, other):/
subgraph @maximum_432(%para251_input, %para252_other) {
  %1(CNode_1448) = S_Prim_Maximum[output_names: ["output"], input_names: ["x", "y"]](%para251_input, %para252_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5001/    return maximum_(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5001/    return maximum_(input, other)/
}
# Order:
#   1: @maximum_432:CNode_1448{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Maximum, [1]: param_input, [2]: param_other}
#   2: @maximum_432:CNode_1449{[0]: ValueNode<Primitive> Return, [1]: CNode_1448}


subgraph attr:
subgraph instance: minimum_431 : 0x3979e0b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5047/def minimum(input, other):/
subgraph @minimum_431(%para253_input, %para254_other) {
  %1(CNode_1450) = S_Prim_Minimum[output_names: ["output"], input_names: ["x", "y"]](%para253_input, %para254_other)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5097/    return minimum_(input, other)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5097/    return minimum_(input, other)/
}
# Order:
#   1: @minimum_431:CNode_1450{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Minimum, [1]: param_input, [2]: param_other}
#   2: @minimum_431:CNode_1451{[0]: ValueNode<Primitive> Return, [1]: CNode_1450}


subgraph attr:
after_block : 1
subgraph instance: 5↓↻↓forward_fn_422 : 0x397ac170
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @5↓↻↓forward_fn_422 parent: [subgraph @4↓↻↓forward_fn_127](%para255_) {
  %1(CNode_157) = $(forward_fn_3):make_dict(("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"), ("__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__"))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %2(CNode_158) = $(forward_fn_3):PyInterpret[side_effect_io: Bool(1)](Script['__import__('mindspore').common._jit_fallback_utils.get_local_variable(__py_exec_index0_PythonObject_0x28_type_0x3a_0x20_0x3c_class_0x20_0x27_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x27_0x3e_0x2c_0x20_value_0x3a_0x20_0x3c_0x5f_0x5f_main_0x5f_0x5f_0x2e_GPUTFNetTrainer_0x20_object_0x20_at_0x20_0x7f92902b12e0_0x3e_0x29__)'], InterpretedObject, %1)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:626/                    self.logger.info(f"Batch {batch_idx} - Model output details:")/
  %3(CNode_1452) = getattr(%2, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:689/                        self.logger.info(f"Batch {batch_idx} - Final logits shape: {logits.shape}")/
  %4(CNode_1453) = getattr(%3, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:689/                        self.logger.info(f"Batch {batch_idx} - Final logits shape: {logits.shape}")/
  %5(CNode_1454) = getattr(%para255_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:689/                        self.logger.info(f"Batch {batch_idx} - Final logits shape: {logits.shape}")/
  %6(CNode_1455) = JoinedStr("Batch ", I64(0), " - Final logits shape: ", %5)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:689/                        self.logger.info(f"Batch {batch_idx} - Final logits shape: {logits.shape}")/
  %7(CNode_1456) = %4(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:689/                        self.logger.info(f"Batch {batch_idx} - Final logits shape: {logits.shape}")/
  %8(CNode_1457) = getattr(%2, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:690/                        self.logger.info(f"Batch {batch_idx} - data_len_tensor: {data_len_tensor}")/
  %9(CNode_1458) = getattr(%8, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:690/                        self.logger.info(f"Batch {batch_idx} - data_len_tensor: {data_len_tensor}")/
  %10(CNode_1459) = JoinedStr("Batch ", I64(0), " - data_len_tensor: ", %para157_data_len_tensor)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:690/                        self.logger.info(f"Batch {batch_idx} - data_len_tensor: {data_len_tensor}")/
  %11(CNode_1460) = %9(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:690/                        self.logger.info(f"Batch {batch_idx} - data_len_tensor: {data_len_tensor}")/
  %12(CNode_1461) = getattr(%2, "logger")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:691/                        self.logger.info(f"Batch {batch_idx} - label_len_tensor: {label_len_tensor}")/
  %13(CNode_1462) = getattr(%12, "info")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:691/                        self.logger.info(f"Batch {batch_idx} - label_len_tensor: {label_len_tensor}")/
  %14(CNode_1463) = JoinedStr("Batch ", I64(0), " - label_len_tensor: ", %para158_label_len_tensor)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:691/                        self.logger.info(f"Batch {batch_idx} - label_len_tensor: {label_len_tensor}")/
  %15(CNode_1464) = %13(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:691/                        self.logger.info(f"Batch {batch_idx} - label_len_tensor: {label_len_tensor}")/
  %16(CNode_1465) = MakeTuple(%7, %11, %15)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %17(CNode_1466) = StopGradient(%16)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
  %18(CNode_121) = $(↻↓forward_fn_122):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para160_@CNode_121, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  %19(CNode_425) = $(4↓↻↓forward_fn_127):S_Prim_MakeTuple("actual_time_steps")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:672/                        ts_tensor = Tensor(actual_time_steps, ms.int32)/
  %20(CNode_424) = $(4↓↻↓forward_fn_127):getattr(%para164_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:671/                        actual_time_steps = logits.shape[0]/
  %21(actual_time_steps) = $(4↓↻↓forward_fn_127):S_Prim_getitem(%20, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:671/                        actual_time_steps = logits.shape[0]/
  %22(CNode_426) = $(4↓↻↓forward_fn_127):S_Prim_MakeTuple(%21)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:672/                        ts_tensor = Tensor(actual_time_steps, ms.int32)/
  %23(CNode_427) = $(4↓↻↓forward_fn_127):S_Prim_make_dict(%19, %22)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:672/                        ts_tensor = Tensor(actual_time_steps, ms.int32)/
  %24(ts_tensor) = $(4↓↻↓forward_fn_127):PyInterpret[side_effect_io: Bool(1)](Script['Tensor(actual_time_steps, ms.int32)'], InterpretedObject, %23)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:672/                        ts_tensor = Tensor(actual_time_steps, ms.int32)/
  %25(current_data_len) = $(4↓↻↓forward_fn_127):call @minimum_431(%para157_data_len_tensor, %24)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:675/                        current_data_len = ops.minimum(data_len_tensor, ts_tensor)/
  %26(CNode_428) = $(4↓↻↓forward_fn_127):S_Prim_MakeTuple()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:673/                        one_tensor = Tensor(1, ms.int32)/
  %27(CNode_429) = $(4↓↻↓forward_fn_127):S_Prim_MakeTuple()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:673/                        one_tensor = Tensor(1, ms.int32)/
  %28(CNode_430) = $(4↓↻↓forward_fn_127):S_Prim_make_dict(%26, %27)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:673/                        one_tensor = Tensor(1, ms.int32)/
  %29(one_tensor) = $(4↓↻↓forward_fn_127):PyInterpret[side_effect_io: Bool(1)](Script['Tensor(1, ms.int32)'], InterpretedObject, %28)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:673/                        one_tensor = Tensor(1, ms.int32)/
  %30(current_data_len) = $(4↓↻↓forward_fn_127):call @maximum_432(%25, %29)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:676/                        current_data_len = ops.maximum(current_data_len, one_tensor)/
  %31(current_data_len) = $(4↓↻↓forward_fn_127):call @maximum_432(%30, %para158_label_len_tensor)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:679/                        current_data_len = ops.maximum(current_data_len, label_len_tensor)/
  %32(loss) = call @mindspore_nn_loss_loss_CTCLoss_construct_1467(%para255_фlogits, %para156_seq_label, %31, %para158_label_len_tensor)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:693/                        loss = loss_fn(logits, seq_label, current_data_len, label_len_tensor)/
  %33(total_loss) = S_Prim_add(%para161_фtotal_loss, %32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:694/                        total_loss += loss/
  %34(CNode_1468) = call @↵↓forward_fn_120(%18, %33)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %35(CNode_1469) = Depend[side_effect_propagate: I64(1)](%34, %17)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
  Return(%35)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:640/                    for logits_idx, logits in enumerate(logits_list):/
}
# Order:
#   1: @5↓↻↓forward_fn_422:CNode_1452{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   2: @5↓↻↓forward_fn_422:CNode_1453{[0]: ValueNode<Primitive> getattr, [1]: CNode_1452, [2]: ValueNode<StringImm> info}
#   3: @5↓↻↓forward_fn_422:CNode_1454{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   4: @5↓↻↓forward_fn_422:CNode_1455{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - Final logits shape: , [4]: CNode_1454}
#   5: @5↓↻↓forward_fn_422:CNode_1456{[0]: CNode_1453, [1]: CNode_1455}
#   6: @5↓↻↓forward_fn_422:CNode_1457{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#   7: @5↓↻↓forward_fn_422:CNode_1458{[0]: ValueNode<Primitive> getattr, [1]: CNode_1457, [2]: ValueNode<StringImm> info}
#   8: @5↓↻↓forward_fn_422:CNode_1459{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - data_len_tensor: , [4]: param_data_len_tensor}
#   9: @5↓↻↓forward_fn_422:CNode_1460{[0]: CNode_1458, [1]: CNode_1459}
#  10: @5↓↻↓forward_fn_422:CNode_1461{[0]: ValueNode<Primitive> getattr, [1]: CNode_158, [2]: ValueNode<StringImm> logger}
#  11: @5↓↻↓forward_fn_422:CNode_1462{[0]: ValueNode<Primitive> getattr, [1]: CNode_1461, [2]: ValueNode<StringImm> info}
#  12: @5↓↻↓forward_fn_422:CNode_1463{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Batch , [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<StringImm>  - label_len_tensor: , [4]: param_label_len_tensor}
#  13: @5↓↻↓forward_fn_422:CNode_1464{[0]: CNode_1462, [1]: CNode_1463}
#  14: @5↓↻↓forward_fn_422:loss{[0]: ValueNode<FuncGraph> mindspore_nn_loss_loss_CTCLoss_construct_1467, [1]: param_фlogits, [2]: param_seq_label, [3]: current_data_len, [4]: param_label_len_tensor}
#  15: @5↓↻↓forward_fn_422:total_loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фtotal_loss, [2]: loss}
#  16: @5↓↻↓forward_fn_422:CNode_1470{[0]: ValueNode<Primitive> Return, [1]: CNode_1469}
#  17: @5↓↻↓forward_fn_422:CNode_1468{[0]: ValueNode<FuncGraph> ↵↓forward_fn_120, [1]: CNode_121, [2]: total_loss}


subgraph attr:
subgraph instance: ✗4↓↻↓forward_fn_420 : 0x397a1c80
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @✗4↓↻↓forward_fn_420 parent: [subgraph @4↓↻↓forward_fn_127]() {
  Return(%para164_фlogits)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
}
# Order:
#   1: @✗4↓↻↓forward_fn_420:CNode_1471{[0]: ValueNode<Primitive> Return, [1]: param_фlogits}


subgraph attr:
subgraph instance: ↰4↓↻↓forward_fn_103 : 0x397a0e80
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↰4↓↻↓forward_fn_103 parent: [subgraph @4↓↻↓forward_fn_127]() {
  %1(CNode_412) = $(4↓↻↓forward_fn_127):getattr(%para164_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %2(CNode_413) = $(4↓↻↓forward_fn_127):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %3(CNode_414) = $(4↓↻↓forward_fn_127):S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
}
# Order:
#   1: @↰4↓↻↓forward_fn_103:CNode_1472{[0]: ValueNode<Primitive> Return, [1]: CNode_414}


subgraph attr:
subgraph instance: ↱4↓↻↓forward_fn_104 : 0x3979f480
# In file /data/shengteng/training/train_tfnet_gpu.py:622/                def forward_fn(seq_data, seq_label, data_len_tensor, label_len_tensor):/
subgraph @↱4↓↻↓forward_fn_104 parent: [subgraph @4↓↻↓forward_fn_127]() {
  %1(CNode_1473) = getattr(%para164_фlogits, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %2(CNode_1474) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  %3(CNode_1475) = S_Prim_less_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:682/                        if logits.shape[1] <= 0 or logits.shape[2] <= 0:/
}
# Order:
#   1: @↱4↓↻↓forward_fn_104:CNode_1473{[0]: ValueNode<Primitive> getattr, [1]: param_фlogits, [2]: ValueNode<StringImm> shape}
#   2: @↱4↓↻↓forward_fn_104:CNode_1474{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1473, [2]: ValueNode<Int64Imm> 2}
#   3: @↱4↓↻↓forward_fn_104:CNode_1475{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less_equal, [1]: CNode_1474, [2]: ValueNode<Int64Imm> 0}
#   4: @↱4↓↻↓forward_fn_104:CNode_1476{[0]: ValueNode<Primitive> Return, [1]: CNode_1475}


subgraph attr:
subgraph instance: ↵↓ms_min_1297 : 0x395230c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↵↓ms_min_1297 parent: [subgraph @↓ms_min_1198](%para256_) {
  %1(CNode_1299) = $(↓ms_min_1198):S_Prim_inner_len(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %2(CNode_1477) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para256_@CNode_1478, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %3(CNode_1479) = Switch(%2, @↻↓ms_min_1480, @2↓ms_min_1481)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %4(CNode_1482) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
}
# Order:
#   1: @↵↓ms_min_1297:CNode_1477{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1478, [2]: CNode_1299}
#   2: @↵↓ms_min_1297:CNode_1479{[0]: ValueNode<Primitive> Switch, [1]: CNode_1477, [2]: ValueNode<FuncGraph> ↻↓ms_min_1480, [3]: ValueNode<FuncGraph> 2↓ms_min_1481}
#   3: @↵↓ms_min_1297:CNode_1482{[0]: CNode_1479}
#   4: @↵↓ms_min_1297:CNode_1483{[0]: ValueNode<Primitive> Return, [1]: CNode_1482}


subgraph attr:
subgraph instance: ms_min_one_element_1301 : 0x3954f660
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @ms_min_one_element_1301(%para257_x) {
  %1(CNode_1484) = S_Prim_isinstance(%para257_x, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
  %2(CNode_1485) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
  %3(CNode_1486) = Switch(%2, @✓ms_min_one_element_1487, @✗ms_min_one_element_1488)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
  %4(CNode_1489) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
}
# Order:
#   1: @ms_min_one_element_1301:CNode_1484{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @ms_min_one_element_1301:CNode_1485{[0]: ValueNode<Primitive> Cond, [1]: CNode_1484, [2]: ValueNode<BoolImm> false}
#   3: @ms_min_one_element_1301:CNode_1486{[0]: ValueNode<Primitive> Switch, [1]: CNode_1485, [2]: ValueNode<FuncGraph> ✓ms_min_one_element_1487, [3]: ValueNode<FuncGraph> ✗ms_min_one_element_1488}
#   4: @ms_min_one_element_1301:CNode_1489{[0]: CNode_1486}
#   5: @ms_min_one_element_1301:CNode_1490{[0]: ValueNode<Primitive> Return, [1]: CNode_1489}


subgraph attr:
subgraph instance: ✓2✗ms_min_1307 : 0x39529010
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✓2✗ms_min_1307 parent: [subgraph @ms_min_962]() {
  %1(tensor_num) = call @get_tensor_num_1008(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2731/        tensor_num = get_tensor_num(data)/
  %2(len_data) = $(ms_min_962):call @get_max_min_data_len_664(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2724/    len_data = get_max_min_data_len(data)/
  %3(CNode_1491) = S_Prim_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
  %4(CNode_1492) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
  %5(CNode_1493) = Switch(%4, @2✓2✗ms_min_1494, @✗✓2✗ms_min_1495)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
  %6(CNode_1496) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
}
# Order:
#   1: @✓2✗ms_min_1307:tensor_num{[0]: ValueNode<FuncGraph> get_tensor_num_1008, [1]: param_data}
#   2: @✓2✗ms_min_1307:CNode_1491{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_num, [2]: len_data}
#   3: @✓2✗ms_min_1307:CNode_1492{[0]: ValueNode<Primitive> Cond, [1]: CNode_1491, [2]: ValueNode<BoolImm> false}
#   4: @✓2✗ms_min_1307:CNode_1493{[0]: ValueNode<Primitive> Switch, [1]: CNode_1492, [2]: ValueNode<FuncGraph> 2✓2✗ms_min_1494, [3]: ValueNode<FuncGraph> ✗✓2✗ms_min_1495}
#   5: @✓2✗ms_min_1307:CNode_1496{[0]: CNode_1493}
#   6: @✓2✗ms_min_1307:CNode_1497{[0]: ValueNode<Primitive> Return, [1]: CNode_1496}


subgraph attr:
subgraph instance: 3✗ms_min_1308 : 0x3951ba50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @3✗ms_min_1308 parent: [subgraph @ms_min_962]() {
  %1(CNode_1499) = call @↓2✗ms_min_1498()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
}
# Order:
#   1: @3✗ms_min_1308:CNode_1500{[0]: ValueNode<Primitive> Return, [1]: CNode_1499}
#   2: @3✗ms_min_1308:CNode_1499{[0]: ValueNode<FuncGraph> ↓2✗ms_min_1498}


subgraph attr:
training : 1
subgraph instance: check_axis_valid_1317 : 0x39680bd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @check_axis_valid_1317(%para258_axis, %para259_ndim) {
  %1(CNode_1501) = S_Prim_negative(%para259_ndim)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %2(CNode_1502) = S_Prim_less(%para258_axis, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %3(CNode_1503) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %4(CNode_1504) = Switch(%3, @↰check_axis_valid_1505, @↱check_axis_valid_1506)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %5(CNode_1507) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %6(CNode_1508) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %7(CNode_1509) = Switch(%6, @✓check_axis_valid_1510, @✗check_axis_valid_1511)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %8(CNode_1512) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @check_axis_valid_1317:CNode_1501{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: param_ndim}
#   2: @check_axis_valid_1317:CNode_1502{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less, [1]: param_axis, [2]: CNode_1501}
#   3: @check_axis_valid_1317:CNode_1503{[0]: ValueNode<Primitive> Cond, [1]: CNode_1502, [2]: ValueNode<BoolImm> false}
#   4: @check_axis_valid_1317:CNode_1504{[0]: ValueNode<Primitive> Switch, [1]: CNode_1503, [2]: ValueNode<FuncGraph> ↰check_axis_valid_1505, [3]: ValueNode<FuncGraph> ↱check_axis_valid_1506}
#   5: @check_axis_valid_1317:CNode_1507{[0]: CNode_1504}
#   6: @check_axis_valid_1317:CNode_1508{[0]: ValueNode<Primitive> Cond, [1]: CNode_1507, [2]: ValueNode<BoolImm> false}
#   7: @check_axis_valid_1317:CNode_1509{[0]: ValueNode<Primitive> Switch, [1]: CNode_1508, [2]: ValueNode<FuncGraph> ✓check_axis_valid_1510, [3]: ValueNode<FuncGraph> ✗check_axis_valid_1511}
#   8: @check_axis_valid_1317:CNode_1512{[0]: CNode_1509}
#   9: @check_axis_valid_1317:CNode_1513{[0]: ValueNode<Primitive> Return, [1]: CNode_1512}


subgraph attr:
subgraph instance: rank_1311 : 0x39712b70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1541/def rank(input_x):/
subgraph @rank_1311(%para260_input_x) {
  %1(CNode_1514) = S_Prim_Rank(%para260_input_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1571/    return rank_(input_x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1571/    return rank_(input_x)/
}
# Order:
#   1: @rank_1311:CNode_1514{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Rank, [1]: param_input_x}
#   2: @rank_1311:CNode_1515{[0]: ValueNode<Primitive> Return, [1]: CNode_1514}


subgraph attr:
training : 1
subgraph instance: ↰mindspore_nn_layer_basic_Flatten_construct_1315 : 0x39714e60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
subgraph @↰mindspore_nn_layer_basic_Flatten_construct_1315 parent: [subgraph @mindspore_nn_layer_basic_Flatten_construct_1218]() {
  %1(x_rank) = $(mindspore_nn_layer_basic_Flatten_construct_1218):call @rank_1311(%para238_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:462/        x_rank = F.rank(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
}
# Order:
#   1: @↰mindspore_nn_layer_basic_Flatten_construct_1315:CNode_1516{[0]: ValueNode<Primitive> Return, [1]: x_rank}


subgraph attr:
training : 1
subgraph instance: ↱mindspore_nn_layer_basic_Flatten_construct_1316 : 0x39713ed0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
subgraph @↱mindspore_nn_layer_basic_Flatten_construct_1316() {
  Return(I64(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:463/        ndim = x_rank if x_rank != 0 else 1/
}
# Order:
#   1: @↱mindspore_nn_layer_basic_Flatten_construct_1316:CNode_1517{[0]: ValueNode<Primitive> Return, [1]: ValueNode<Int64Imm> 1}


subgraph attr:
subgraph instance: flatten_1327 : 0x39688dc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @flatten_1327(%para261_input, %para262_order, %para263_start_dim, %para264_end_dim) {
  %1(CNode_1518) = S_Prim_isinstance(%para261_input, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  %2(CNode_1519) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  %3(CNode_1520) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  %4(CNode_1521) = Switch(%3, @✓flatten_1522, @✗flatten_1523)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  %5(CNode_1524) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
}
# Order:
#   1: @flatten_1327:CNode_1518{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_input, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   2: @flatten_1327:CNode_1519{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_1518}
#   3: @flatten_1327:CNode_1520{[0]: ValueNode<Primitive> Cond, [1]: CNode_1519, [2]: ValueNode<BoolImm> false}
#   4: @flatten_1327:CNode_1521{[0]: ValueNode<Primitive> Switch, [1]: CNode_1520, [2]: ValueNode<FuncGraph> ✓flatten_1522, [3]: ValueNode<FuncGraph> ✗flatten_1523}
#   5: @flatten_1327:CNode_1524{[0]: CNode_1521}
#   6: @flatten_1327:CNode_1525{[0]: ValueNode<Primitive> Return, [1]: CNode_1524}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1526 : 0x3966fb30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1526 parent: [subgraph @after_grad_108](%para265_x) {
  %1(CNode_1528) = call @✗mindspore_nn_layer_conv_Conv2d_construct_1527()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1526:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_conv2d.layer4.0.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1526:CNode_1528{[0]: ValueNode<FuncGraph> ✗mindspore_nn_layer_conv_Conv2d_construct_1527}
#   3: @mindspore_nn_layer_conv_Conv2d_construct_1526:CNode_1529{[0]: ValueNode<Primitive> Return, [1]: CNode_1528}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1530 : 0x3966e290
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1530 parent: [subgraph @after_grad_108](%para266_x) {
  %1(CNode_1532) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531(%para266_x, %para48_conv2d.layer4.1.gamma, %para49_conv2d.layer4.1.beta, %para109_conv2d.layer4.1.moving_mean, %para110_conv2d.layer4.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.gamma>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.beta>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.moving_mean>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1530:CNode_1532{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531, [1]: param_x, [2]: param_conv2d.layer4.1.gamma, [3]: param_conv2d.layer4.1.beta, [4]: param_conv2d.layer4.1.moving_mean, [5]: param_conv2d.layer4.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1530:CNode_1533{[0]: ValueNode<Primitive> Return, [1]: CNode_1532}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1534 : 0x3966ce30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1534(%para267_x) {
  %1(CNode_1535) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para267_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1534:CNode_1535{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1534:CNode_1536{[0]: ValueNode<Primitive> Return, [1]: CNode_1535}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1537 : 0x3966b8c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1537 parent: [subgraph @after_grad_108](%para268_x) {
  %1(CNode_1539) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1538(%para268_x, %para50_conv2d.layer4.3.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:conv2d.layer4.3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1537:CNode_1539{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1538, [1]: param_x, [2]: param_conv2d.layer4.3.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1537:CNode_1540{[0]: ValueNode<Primitive> Return, [1]: CNode_1539}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1541 : 0x39669e30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1541 parent: [subgraph @after_grad_108](%para269_x) {
  %1(CNode_1542) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531(%para269_x, %para51_conv2d.layer4.4.gamma, %para52_conv2d.layer4.4.beta, %para111_conv2d.layer4.4.moving_mean, %para112_conv2d.layer4.4.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.gamma>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.beta>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.moving_mean>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.4.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1541:CNode_1542{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531, [1]: param_x, [2]: param_conv2d.layer4.4.gamma, [3]: param_conv2d.layer4.4.beta, [4]: param_conv2d.layer4.4.moving_mean, [5]: param_conv2d.layer4.4.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1541:CNode_1543{[0]: ValueNode<Primitive> Return, [1]: CNode_1542}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1544 : 0x39668a20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1544(%para270_x) {
  %1(CNode_1545) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para270_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1544:CNode_1545{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1544:CNode_1546{[0]: ValueNode<Primitive> Return, [1]: CNode_1545}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1547 : 0x39663300
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1547 parent: [subgraph @after_grad_108](%para271_x) {
  %1(CNode_1548) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1538(%para271_x, %para53_conv2d.layer4.6.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 512, 3, 3), ref_key=:conv2d.layer4.6.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1547:CNode_1548{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1538, [1]: param_x, [2]: param_conv2d.layer4.6.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1547:CNode_1549{[0]: ValueNode<Primitive> Return, [1]: CNode_1548}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1550 : 0x39654540
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1550 parent: [subgraph @after_grad_108](%para272_x) {
  %1(CNode_1551) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531(%para272_x, %para54_conv2d.layer4.7.gamma, %para55_conv2d.layer4.7.beta, %para113_conv2d.layer4.7.moving_mean, %para114_conv2d.layer4.7.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.gamma>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.beta>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.moving_mean>, <Ref[Tensor[Float32]], (512), ref_key=:conv2d.layer4.7.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1550:CNode_1551{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531, [1]: param_x, [2]: param_conv2d.layer4.7.gamma, [3]: param_conv2d.layer4.7.beta, [4]: param_conv2d.layer4.7.moving_mean, [5]: param_conv2d.layer4.7.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1550:CNode_1552{[0]: ValueNode<Primitive> Return, [1]: CNode_1551}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1553 : 0x396533e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1553(%para273_x) {
  %1(CNode_1554) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para273_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1553:CNode_1554{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1553:CNode_1555{[0]: ValueNode<Primitive> Return, [1]: CNode_1554}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_1333 : 0x39673860
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1333 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_1216](%para274_, %para275_) {
  %1(CNode_1336) = $(mindspore_nn_layer_container_SequentialCell_construct_1216):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1526, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1530, @mindspore_nn_layer_activation_ReLU_construct_1534, @mindspore_nn_layer_conv_Conv2d_construct_1537, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1541, @mindspore_nn_layer_activation_ReLU_construct_1544, @mindspore_nn_layer_conv_Conv2d_construct_1547, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1550, @mindspore_nn_layer_activation_ReLU_construct_1553)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1335) = $(mindspore_nn_layer_container_SequentialCell_construct_1216):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_1556) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para274_@CNode_1557, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1558) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_1559, @↓mindspore_nn_layer_container_SequentialCell_construct_1560)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_1561) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_1333:CNode_1556{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1557, [2]: CNode_1335}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_1333:CNode_1558{[0]: ValueNode<Primitive> Switch, [1]: CNode_1556, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_1559, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_1560}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_1333:CNode_1561{[0]: CNode_1558}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_1333:CNode_1562{[0]: ValueNode<Primitive> Return, [1]: CNode_1561}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1563 : 0x39647100
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1563 parent: [subgraph @after_grad_108](%para276_x) {
  %1(CNode_1565) = call @✗mindspore_nn_layer_conv_Conv2d_construct_1564()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1563:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_conv2d.layer3.0.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1563:CNode_1565{[0]: ValueNode<FuncGraph> ✗mindspore_nn_layer_conv_Conv2d_construct_1564}
#   3: @mindspore_nn_layer_conv_Conv2d_construct_1563:CNode_1566{[0]: ValueNode<Primitive> Return, [1]: CNode_1565}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1567 : 0x39645860
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1567 parent: [subgraph @after_grad_108](%para277_x) {
  %1(CNode_1569) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para277_x, %para30_conv2d.layer3.1.gamma, %para31_conv2d.layer3.1.beta, %para123_conv2d.layer3.1.moving_mean, %para124_conv2d.layer3.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1567:CNode_1569{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.1.gamma, [3]: param_conv2d.layer3.1.beta, [4]: param_conv2d.layer3.1.moving_mean, [5]: param_conv2d.layer3.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1567:CNode_1570{[0]: ValueNode<Primitive> Return, [1]: CNode_1569}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1571 : 0x39644400
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1571(%para278_x) {
  %1(CNode_1572) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para278_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1571:CNode_1572{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1571:CNode_1573{[0]: ValueNode<Primitive> Return, [1]: CNode_1572}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1574 : 0x39642e90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1574 parent: [subgraph @after_grad_108](%para279_x) {
  %1(CNode_1576) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para279_x, %para32_conv2d.layer3.3.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1574:CNode_1576{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1575, [1]: param_x, [2]: param_conv2d.layer3.3.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1574:CNode_1577{[0]: ValueNode<Primitive> Return, [1]: CNode_1576}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1578 : 0x396415f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1578 parent: [subgraph @after_grad_108](%para280_x) {
  %1(CNode_1579) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para280_x, %para33_conv2d.layer3.4.gamma, %para34_conv2d.layer3.4.beta, %para125_conv2d.layer3.4.moving_mean, %para126_conv2d.layer3.4.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.4.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1578:CNode_1579{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.4.gamma, [3]: param_conv2d.layer3.4.beta, [4]: param_conv2d.layer3.4.moving_mean, [5]: param_conv2d.layer3.4.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1578:CNode_1580{[0]: ValueNode<Primitive> Return, [1]: CNode_1579}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1581 : 0x39640190
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1581(%para281_x) {
  %1(CNode_1582) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para281_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1581:CNode_1582{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1581:CNode_1583{[0]: ValueNode<Primitive> Return, [1]: CNode_1582}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1584 : 0x3963ec20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1584 parent: [subgraph @after_grad_108](%para282_x) {
  %1(CNode_1585) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para282_x, %para35_conv2d.layer3.6.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.6.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1584:CNode_1585{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1575, [1]: param_x, [2]: param_conv2d.layer3.6.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1584:CNode_1586{[0]: ValueNode<Primitive> Return, [1]: CNode_1585}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1587 : 0x3963d380
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1587 parent: [subgraph @after_grad_108](%para283_x) {
  %1(CNode_1588) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para283_x, %para36_conv2d.layer3.7.gamma, %para37_conv2d.layer3.7.beta, %para127_conv2d.layer3.7.moving_mean, %para128_conv2d.layer3.7.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.7.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1587:CNode_1588{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.7.gamma, [3]: param_conv2d.layer3.7.beta, [4]: param_conv2d.layer3.7.moving_mean, [5]: param_conv2d.layer3.7.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1587:CNode_1589{[0]: ValueNode<Primitive> Return, [1]: CNode_1588}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1590 : 0x3963bf20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1590(%para284_x) {
  %1(CNode_1591) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para284_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1590:CNode_1591{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1590:CNode_1592{[0]: ValueNode<Primitive> Return, [1]: CNode_1591}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1593 : 0x3963a9b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1593 parent: [subgraph @after_grad_108](%para285_x) {
  %1(CNode_1594) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para285_x, %para38_conv2d.layer3.9.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.9.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1593:CNode_1594{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1575, [1]: param_x, [2]: param_conv2d.layer3.9.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1593:CNode_1595{[0]: ValueNode<Primitive> Return, [1]: CNode_1594}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1596 : 0x39639110
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1596 parent: [subgraph @after_grad_108](%para286_x) {
  %1(CNode_1597) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para286_x, %para39_conv2d.layer3.10.gamma, %para40_conv2d.layer3.10.beta, %para129_conv2d.layer3.10.moving_mean, %para130_conv2d.layer3.10.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.10.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1596:CNode_1597{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.10.gamma, [3]: param_conv2d.layer3.10.beta, [4]: param_conv2d.layer3.10.moving_mean, [5]: param_conv2d.layer3.10.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1596:CNode_1598{[0]: ValueNode<Primitive> Return, [1]: CNode_1597}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1599 : 0x39637cb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1599(%para287_x) {
  %1(CNode_1600) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para287_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1599:CNode_1600{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1599:CNode_1601{[0]: ValueNode<Primitive> Return, [1]: CNode_1600}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1602 : 0x39636740
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1602 parent: [subgraph @after_grad_108](%para288_x) {
  %1(CNode_1603) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para288_x, %para41_conv2d.layer3.12.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.12.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1602:CNode_1603{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1575, [1]: param_x, [2]: param_conv2d.layer3.12.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1602:CNode_1604{[0]: ValueNode<Primitive> Return, [1]: CNode_1603}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1605 : 0x39634cb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1605 parent: [subgraph @after_grad_108](%para289_x) {
  %1(CNode_1606) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para289_x, %para42_conv2d.layer3.13.gamma, %para43_conv2d.layer3.13.beta, %para131_conv2d.layer3.13.moving_mean, %para132_conv2d.layer3.13.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.13.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1605:CNode_1606{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.13.gamma, [3]: param_conv2d.layer3.13.beta, [4]: param_conv2d.layer3.13.moving_mean, [5]: param_conv2d.layer3.13.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1605:CNode_1607{[0]: ValueNode<Primitive> Return, [1]: CNode_1606}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1608 : 0x396338a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1608(%para290_x) {
  %1(CNode_1609) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para290_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1608:CNode_1609{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1608:CNode_1610{[0]: ValueNode<Primitive> Return, [1]: CNode_1609}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1611 : 0x3962dd00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1611 parent: [subgraph @after_grad_108](%para291_x) {
  %1(CNode_1612) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para291_x, %para44_conv2d.layer3.15.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 256, 3, 3), ref_key=:conv2d.layer3.15.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1611:CNode_1612{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1575, [1]: param_x, [2]: param_conv2d.layer3.15.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1611:CNode_1613{[0]: ValueNode<Primitive> Return, [1]: CNode_1612}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1614 : 0x3961ea80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1614 parent: [subgraph @after_grad_108](%para292_x) {
  %1(CNode_1615) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para292_x, %para45_conv2d.layer3.16.gamma, %para46_conv2d.layer3.16.beta, %para133_conv2d.layer3.16.moving_mean, %para134_conv2d.layer3.16.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.gamma>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.beta>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.moving_mean>, <Ref[Tensor[Float32]], (256), ref_key=:conv2d.layer3.16.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1614:CNode_1615{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568, [1]: param_x, [2]: param_conv2d.layer3.16.gamma, [3]: param_conv2d.layer3.16.beta, [4]: param_conv2d.layer3.16.moving_mean, [5]: param_conv2d.layer3.16.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1614:CNode_1616{[0]: ValueNode<Primitive> Return, [1]: CNode_1615}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1617 : 0x3961d950
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1617(%para293_x) {
  %1(CNode_1618) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para293_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1617:CNode_1618{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1617:CNode_1619{[0]: ValueNode<Primitive> Return, [1]: CNode_1618}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_1338 : 0x3964ae30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1338 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_1215](%para294_, %para295_) {
  %1(CNode_1341) = $(mindspore_nn_layer_container_SequentialCell_construct_1215):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1563, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1567, @mindspore_nn_layer_activation_ReLU_construct_1571, @mindspore_nn_layer_conv_Conv2d_construct_1574, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1578, @mindspore_nn_layer_activation_ReLU_construct_1581, @mindspore_nn_layer_conv_Conv2d_construct_1584, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1587, @mindspore_nn_layer_activation_ReLU_construct_1590, @mindspore_nn_layer_conv_Conv2d_construct_1593, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1596, @mindspore_nn_layer_activation_ReLU_construct_1599, @mindspore_nn_layer_conv_Conv2d_construct_1602, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1605, @mindspore_nn_layer_activation_ReLU_construct_1608, @mindspore_nn_layer_conv_Conv2d_construct_1611, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1614, @mindspore_nn_layer_activation_ReLU_construct_1617)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1340) = $(mindspore_nn_layer_container_SequentialCell_construct_1215):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_1620) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para294_@CNode_1621, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1622) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_1623, @↓mindspore_nn_layer_container_SequentialCell_construct_1624)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_1625) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_1338:CNode_1620{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1621, [2]: CNode_1340}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_1338:CNode_1622{[0]: ValueNode<Primitive> Switch, [1]: CNode_1620, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_1623, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_1624}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_1338:CNode_1625{[0]: CNode_1622}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_1338:CNode_1626{[0]: ValueNode<Primitive> Return, [1]: CNode_1625}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1627 : 0x396114c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1627 parent: [subgraph @after_grad_108](%para296_x) {
  %1(CNode_1629) = call @✗mindspore_nn_layer_conv_Conv2d_construct_1628()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1627:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_conv2d.layer2.0.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1627:CNode_1629{[0]: ValueNode<FuncGraph> ✗mindspore_nn_layer_conv_Conv2d_construct_1628}
#   3: @mindspore_nn_layer_conv_Conv2d_construct_1627:CNode_1630{[0]: ValueNode<Primitive> Return, [1]: CNode_1629}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1631 : 0x3960fc20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1631 parent: [subgraph @after_grad_108](%para297_x) {
  %1(CNode_1633) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632(%para297_x, %para18_conv2d.layer2.1.gamma, %para19_conv2d.layer2.1.beta, %para135_conv2d.layer2.1.moving_mean, %para136_conv2d.layer2.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.gamma>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.beta>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.moving_mean>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1631:CNode_1633{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632, [1]: param_x, [2]: param_conv2d.layer2.1.gamma, [3]: param_conv2d.layer2.1.beta, [4]: param_conv2d.layer2.1.moving_mean, [5]: param_conv2d.layer2.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1631:CNode_1634{[0]: ValueNode<Primitive> Return, [1]: CNode_1633}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1635 : 0x3960e7c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1635(%para298_x) {
  %1(CNode_1636) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para298_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1635:CNode_1636{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1635:CNode_1637{[0]: ValueNode<Primitive> Return, [1]: CNode_1636}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1638 : 0x3960d250
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1638 parent: [subgraph @after_grad_108](%para299_x) {
  %1(CNode_1640) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1639(%para299_x, %para20_conv2d.layer2.3.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1638:CNode_1640{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1639, [1]: param_x, [2]: param_conv2d.layer2.3.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1638:CNode_1641{[0]: ValueNode<Primitive> Return, [1]: CNode_1640}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1642 : 0x3960b9b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1642 parent: [subgraph @after_grad_108](%para300_x) {
  %1(CNode_1643) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632(%para300_x, %para21_conv2d.layer2.4.gamma, %para22_conv2d.layer2.4.beta, %para137_conv2d.layer2.4.moving_mean, %para138_conv2d.layer2.4.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.gamma>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.beta>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.moving_mean>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.4.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1642:CNode_1643{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632, [1]: param_x, [2]: param_conv2d.layer2.4.gamma, [3]: param_conv2d.layer2.4.beta, [4]: param_conv2d.layer2.4.moving_mean, [5]: param_conv2d.layer2.4.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1642:CNode_1644{[0]: ValueNode<Primitive> Return, [1]: CNode_1643}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1645 : 0x3960a550
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1645(%para301_x) {
  %1(CNode_1646) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para301_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1645:CNode_1646{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1645:CNode_1647{[0]: ValueNode<Primitive> Return, [1]: CNode_1646}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1648 : 0x39608fe0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1648 parent: [subgraph @after_grad_108](%para302_x) {
  %1(CNode_1649) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1639(%para302_x, %para23_conv2d.layer2.6.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.6.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1648:CNode_1649{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1639, [1]: param_x, [2]: param_conv2d.layer2.6.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1648:CNode_1650{[0]: ValueNode<Primitive> Return, [1]: CNode_1649}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1651 : 0x39607550
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1651 parent: [subgraph @after_grad_108](%para303_x) {
  %1(CNode_1652) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632(%para303_x, %para24_conv2d.layer2.7.gamma, %para25_conv2d.layer2.7.beta, %para139_conv2d.layer2.7.moving_mean, %para140_conv2d.layer2.7.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.gamma>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.beta>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.moving_mean>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.7.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1651:CNode_1652{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632, [1]: param_x, [2]: param_conv2d.layer2.7.gamma, [3]: param_conv2d.layer2.7.beta, [4]: param_conv2d.layer2.7.moving_mean, [5]: param_conv2d.layer2.7.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1651:CNode_1653{[0]: ValueNode<Primitive> Return, [1]: CNode_1652}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1654 : 0x39606140
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1654(%para304_x) {
  %1(CNode_1655) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para304_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1654:CNode_1655{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1654:CNode_1656{[0]: ValueNode<Primitive> Return, [1]: CNode_1655}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1657 : 0x396008a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1657 parent: [subgraph @after_grad_108](%para305_x) {
  %1(CNode_1658) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1639(%para305_x, %para26_conv2d.layer2.9.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 128, 3, 3), ref_key=:conv2d.layer2.9.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1657:CNode_1658{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1639, [1]: param_x, [2]: param_conv2d.layer2.9.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1657:CNode_1659{[0]: ValueNode<Primitive> Return, [1]: CNode_1658}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1660 : 0x395f1920
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1660 parent: [subgraph @after_grad_108](%para306_x) {
  %1(CNode_1661) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632(%para306_x, %para27_conv2d.layer2.10.gamma, %para28_conv2d.layer2.10.beta, %para141_conv2d.layer2.10.moving_mean, %para142_conv2d.layer2.10.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.gamma>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.beta>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.moving_mean>, <Ref[Tensor[Float32]], (128), ref_key=:conv2d.layer2.10.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1660:CNode_1661{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632, [1]: param_x, [2]: param_conv2d.layer2.10.gamma, [3]: param_conv2d.layer2.10.beta, [4]: param_conv2d.layer2.10.moving_mean, [5]: param_conv2d.layer2.10.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1660:CNode_1662{[0]: ValueNode<Primitive> Return, [1]: CNode_1661}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1663 : 0x395f07d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1663(%para307_x) {
  %1(CNode_1664) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para307_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1663:CNode_1664{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1663:CNode_1665{[0]: ValueNode<Primitive> Return, [1]: CNode_1664}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_1343 : 0x396151f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1343 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_1214](%para308_, %para309_) {
  %1(CNode_1346) = $(mindspore_nn_layer_container_SequentialCell_construct_1214):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1627, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1631, @mindspore_nn_layer_activation_ReLU_construct_1635, @mindspore_nn_layer_conv_Conv2d_construct_1638, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1642, @mindspore_nn_layer_activation_ReLU_construct_1645, @mindspore_nn_layer_conv_Conv2d_construct_1648, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1651, @mindspore_nn_layer_activation_ReLU_construct_1654, @mindspore_nn_layer_conv_Conv2d_construct_1657, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1660, @mindspore_nn_layer_activation_ReLU_construct_1663)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1345) = $(mindspore_nn_layer_container_SequentialCell_construct_1214):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_1666) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para308_@CNode_1667, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1668) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_1669, @↓mindspore_nn_layer_container_SequentialCell_construct_1670)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_1671) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_1343:CNode_1666{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1667, [2]: CNode_1345}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_1343:CNode_1668{[0]: ValueNode<Primitive> Switch, [1]: CNode_1666, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_1669, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_1670}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_1343:CNode_1671{[0]: CNode_1668}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_1343:CNode_1672{[0]: ValueNode<Primitive> Return, [1]: CNode_1671}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1673 : 0x395e6c20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1673 parent: [subgraph @after_grad_108](%para310_x) {
  %1(CNode_1675) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1674(%para310_x, %para8_conv2d.layer1.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.0.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1673:CNode_1675{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1674, [1]: param_x, [2]: param_conv2d.layer1.0.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1673:CNode_1676{[0]: ValueNode<Primitive> Return, [1]: CNode_1675}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1677 : 0x395e5380
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1677 parent: [subgraph @after_grad_108](%para311_x) {
  %1(CNode_1678) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363(%para311_x, %para9_conv2d.layer1.1.gamma, %para10_conv2d.layer1.1.beta, %para143_conv2d.layer1.1.moving_mean, %para144_conv2d.layer1.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1677:CNode_1678{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363, [1]: param_x, [2]: param_conv2d.layer1.1.gamma, [3]: param_conv2d.layer1.1.beta, [4]: param_conv2d.layer1.1.moving_mean, [5]: param_conv2d.layer1.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1677:CNode_1679{[0]: ValueNode<Primitive> Return, [1]: CNode_1678}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1680 : 0x395e3f20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1680(%para312_x) {
  %1(CNode_1681) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para312_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1680:CNode_1681{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1680:CNode_1682{[0]: ValueNode<Primitive> Return, [1]: CNode_1681}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1683 : 0x395e29b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1683 parent: [subgraph @after_grad_108](%para313_x) {
  %1(CNode_1684) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1674(%para313_x, %para11_conv2d.layer1.3.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1683:CNode_1684{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1674, [1]: param_x, [2]: param_conv2d.layer1.3.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1683:CNode_1685{[0]: ValueNode<Primitive> Return, [1]: CNode_1684}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1686 : 0x395e1110
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1686 parent: [subgraph @after_grad_108](%para314_x) {
  %1(CNode_1687) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363(%para314_x, %para12_conv2d.layer1.4.gamma, %para13_conv2d.layer1.4.beta, %para145_conv2d.layer1.4.moving_mean, %para146_conv2d.layer1.4.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.4.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1686:CNode_1687{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363, [1]: param_x, [2]: param_conv2d.layer1.4.gamma, [3]: param_conv2d.layer1.4.beta, [4]: param_conv2d.layer1.4.moving_mean, [5]: param_conv2d.layer1.4.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1686:CNode_1688{[0]: ValueNode<Primitive> Return, [1]: CNode_1687}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1689 : 0x395dfd00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1689(%para315_x) {
  %1(CNode_1690) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para315_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1689:CNode_1690{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1689:CNode_1691{[0]: ValueNode<Primitive> Return, [1]: CNode_1690}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv2d_construct_1692 : 0x395da4a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv2d_construct_1692 parent: [subgraph @after_grad_108](%para316_x) {
  %1(CNode_1693) = call @L_mindspore_nn_layer_conv_Conv2d_construct_1674(%para316_x, %para14_conv2d.layer1.6.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 64, 3, 3), ref_key=:conv2d.layer1.6.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv2d_construct_1692:CNode_1693{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv2d_construct_1674, [1]: param_x, [2]: param_conv2d.layer1.6.weight}
#   2: @mindspore_nn_layer_conv_Conv2d_construct_1692:CNode_1694{[0]: ValueNode<Primitive> Return, [1]: CNode_1693}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm2d_construct_1695 : 0x395d8c00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm2d_construct_1695 parent: [subgraph @after_grad_108](%para317_x) {
  %1(CNode_1696) = call @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363(%para317_x, %para15_conv2d.layer1.7.gamma, %para16_conv2d.layer1.7.beta, %para147_conv2d.layer1.7.moving_mean, %para148_conv2d.layer1.7.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv2d.layer1.7.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1695:CNode_1696{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363, [1]: param_x, [2]: param_conv2d.layer1.7.gamma, [3]: param_conv2d.layer1.7.beta, [4]: param_conv2d.layer1.7.moving_mean, [5]: param_conv2d.layer1.7.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm2d_construct_1695:CNode_1697{[0]: ValueNode<Primitive> Return, [1]: CNode_1696}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_1698 : 0x395d7b30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_1698(%para318_x) {
  %1(CNode_1699) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para318_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_1698:CNode_1699{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_1698:CNode_1700{[0]: ValueNode<Primitive> Return, [1]: CNode_1699}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_1348 : 0x395e8190
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1348 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_1213](%para319_, %para320_) {
  %1(CNode_1351) = $(mindspore_nn_layer_container_SequentialCell_construct_1213):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1673, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1677, @mindspore_nn_layer_activation_ReLU_construct_1680, @mindspore_nn_layer_conv_Conv2d_construct_1683, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1686, @mindspore_nn_layer_activation_ReLU_construct_1689, @mindspore_nn_layer_conv_Conv2d_construct_1692, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1695, @mindspore_nn_layer_activation_ReLU_construct_1698)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1350) = $(mindspore_nn_layer_container_SequentialCell_construct_1213):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_1701) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para319_@CNode_1702, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1703) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_1704, @↓mindspore_nn_layer_container_SequentialCell_construct_1705)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_1706) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_1348:CNode_1701{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1702, [2]: CNode_1350}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_1348:CNode_1703{[0]: ValueNode<Primitive> Switch, [1]: CNode_1701, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_1704, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_1705}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_1348:CNode_1706{[0]: CNode_1703}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_1348:CNode_1707{[0]: ValueNode<Primitive> Return, [1]: CNode_1706}


subgraph attr:
training : 1
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357 : 0x395d3120
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_1212]() {
  %1(CNode_1708) = getattr(%para244_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
  %3(CNode_1710) = call @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:571/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357:CNode_1708{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357:x{[0]: CNode_1708, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357:CNode_1711{[0]: ValueNode<Primitive> Return, [1]: CNode_1710}
#   4: @✓mindspore_nn_layer_pooling_MaxPool2d_construct_1357:CNode_1710{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358 : 0x395bb170
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool2d_construct_1212]() {
  %1(CNode_1712) = call @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709(%para244_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:570/        if x.ndim == 3:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358:CNode_1713{[0]: ValueNode<Primitive> Return, [1]: CNode_1712}
#   2: @✗mindspore_nn_layer_pooling_MaxPool2d_construct_1358:CNode_1712{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363 : 0x395a9900
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363(%para321_x, %para322_, %para323_, %para324_, %para325_) {
  %1(CNode_1714) = S_Prim_Shape(%para321_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %2(CNode_1715) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "BatchNorm2d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %3(CNode_1716) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
  %4(CNode_1717) = S_Prim_is_(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %5(CNode_1718) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %6(CNode_1719) = Switch(%5, @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720, @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %7(CNode_1722) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %8(CNode_1723) = Depend[side_effect_propagate: I64(1)](%7, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1714{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1715{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_1714, [2]: ValueNode<StringImm> BatchNorm2d}
#   3: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1717{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#   4: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1718{[0]: ValueNode<Primitive> Cond, [1]: CNode_1717, [2]: ValueNode<BoolImm> false}
#   5: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1719{[0]: ValueNode<Primitive> Switch, [1]: CNode_1718, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721}
#   6: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1722{[0]: CNode_1719}
#   7: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363:CNode_1365{[0]: ValueNode<Primitive> Return, [1]: CNode_1723}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_conv_Conv2d_construct_1366 : 0x395a5af0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_conv_Conv2d_construct_1366 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1209]() {
  %1(CNode_1725) = call @↓mindspore_nn_layer_conv_Conv2d_construct_1724()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @✗mindspore_nn_layer_conv_Conv2d_construct_1366:CNode_1725{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_conv_Conv2d_construct_1724}
#   2: @✗mindspore_nn_layer_conv_Conv2d_construct_1366:CNode_1726{[0]: ValueNode<Primitive> Return, [1]: CNode_1725}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓↻6↓tfnet_model_TFNetModel_construct_1382 : 0x394ec010
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓↻6↓tfnet_model_TFNetModel_construct_1382 parent: [subgraph @↻6↓tfnet_model_TFNetModel_construct_1231](%para326_) {
  %1(CNode_1229) = $(↻6↓tfnet_model_TFNetModel_construct_1231):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para228_@CNode_1229, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %2(CNode_1727) = getattr(%para229_фpadded_features, "append")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:154/            padded_features.append(padded)/
  %3(padded_features) = %2(%para326_фpadded)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:154/            padded_features.append(padded)/
  %4(CNode_1728) = call @↵6↓tfnet_model_TFNetModel_construct_1113(%1, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
}
# Order:
#   1: @↓↻6↓tfnet_model_TFNetModel_construct_1382:CNode_1727{[0]: ValueNode<Primitive> getattr, [1]: param_фpadded_features, [2]: ValueNode<StringImm> append}
#   2: @↓↻6↓tfnet_model_TFNetModel_construct_1382:padded_features{[0]: CNode_1727, [1]: param_фpadded}
#   3: @↓↻6↓tfnet_model_TFNetModel_construct_1382:CNode_1729{[0]: ValueNode<Primitive> Return, [1]: CNode_1728}
#   4: @↓↻6↓tfnet_model_TFNetModel_construct_1382:CNode_1728{[0]: ValueNode<FuncGraph> ↵6↓tfnet_model_TFNetModel_construct_1113, [1]: CNode_1229, [2]: padded_features}


subgraph attr:
training : 1
subgraph instance: ✓↻6↓tfnet_model_TFNetModel_construct_1379 : 0x394d0690
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻6↓tfnet_model_TFNetModel_construct_1379 parent: [subgraph @↻6↓tfnet_model_TFNetModel_construct_1231]() {
  %1(CNode_1373) = $(↻6↓tfnet_model_TFNetModel_construct_1231):call @ms_iter_97(%para201_фfeature_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %2(features) = $(↻6↓tfnet_model_TFNetModel_construct_1231):S_Prim_getitem(%1, %para228_@CNode_1229)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %3(CNode_1115) = $(6↓tfnet_model_TFNetModel_construct_976):ClassType(%para222_фmax_len)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %4(max_len) = $(6↓tfnet_model_TFNetModel_construct_976):call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %5(padded) = call @pad_sequence_1730(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:149/                padded = self.pad_sequence(features, max_len)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:149/                padded = self.pad_sequence(features, max_len)/
}
# Order:
#   1: @✓↻6↓tfnet_model_TFNetModel_construct_1379:padded{[0]: ValueNode<FuncGraph> pad_sequence_1730, [1]: features, [2]: max_len}
#   2: @✓↻6↓tfnet_model_TFNetModel_construct_1379:CNode_1731{[0]: ValueNode<Primitive> Return, [1]: padded}


subgraph attr:
training : 1
subgraph instance: ✗↻6↓tfnet_model_TFNetModel_construct_1380 : 0x394c90e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻6↓tfnet_model_TFNetModel_construct_1380 parent: [subgraph @↻6↓tfnet_model_TFNetModel_construct_1231]() {
  %1(CNode_1115) = $(6↓tfnet_model_TFNetModel_construct_976):ClassType(%para222_фmax_len)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %2(max_len) = $(6↓tfnet_model_TFNetModel_construct_976):call @ms_max_436(I64(1), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %3(CNode_1732) = S_Prim_MakeTuple(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
  %4(CNode_1373) = $(↻6↓tfnet_model_TFNetModel_construct_1231):call @ms_iter_97(%para201_фfeature_list)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %5(features) = $(↻6↓tfnet_model_TFNetModel_construct_1231):S_Prim_getitem(%4, %para228_@CNode_1229)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:146/        for features in feature_list:/
  %6(CNode_1733) = getattr(%5, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
  %7(CNode_1734) = S_Prim_make_slice(I64(1), None, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
  %8(CNode_1735) = S_Prim_getitem(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
  %9(feature_shape) = S_Prim_add(%3, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
  %10(CNode_1736) = getattr(%5, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:153/                padded = ops.zeros(feature_shape, features.dtype)/
  %11(padded) = call @zeros_442(%9, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:153/                padded = ops.zeros(feature_shape, features.dtype)/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:152/                feature_shape = (max_len,) + features.shape[1:]/
}
# Order:
#   1: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1732{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: max_len}
#   2: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1733{[0]: ValueNode<Primitive> getattr, [1]: features, [2]: ValueNode<StringImm> shape}
#   3: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1734{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   4: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1735{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1733, [2]: CNode_1734}
#   5: @✗↻6↓tfnet_model_TFNetModel_construct_1380:feature_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_1732, [2]: CNode_1735}
#   6: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1736{[0]: ValueNode<Primitive> getattr, [1]: features, [2]: ValueNode<StringImm> dtype}
#   7: @✗↻6↓tfnet_model_TFNetModel_construct_1380:padded{[0]: ValueNode<FuncGraph> zeros_442, [1]: feature_shape, [2]: CNode_1736}
#   8: @✗↻6↓tfnet_model_TFNetModel_construct_1380:CNode_1737{[0]: ValueNode<Primitive> Return, [1]: padded}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 8↓tfnet_model_TFNetModel_construct_1392 : 0x3111a800
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @8↓tfnet_model_TFNetModel_construct_1392 parent: [subgraph @6↓tfnet_model_TFNetModel_construct_976](%para327_) {
  %1(CNode_1738) = getattr(%para327_фframewise, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %2(CNode_1739) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %3(CNode_1740) = S_Prim_not_equal(%2, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %4(CNode_1741) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %5(CNode_1742) = Switch(%4, @✓8↓tfnet_model_TFNetModel_construct_1743, @✗8↓tfnet_model_TFNetModel_construct_1744)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %6(CNode_1745) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
  %7(CNode_1747) = call @9↓tfnet_model_TFNetModel_construct_1746(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
}
# Order:
#   1: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1738{[0]: ValueNode<Primitive> getattr, [1]: param_фframewise, [2]: ValueNode<StringImm> shape}
#   2: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1739{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1738}
#   3: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1740{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_1739, [2]: ValueNode<Int64Imm> 3}
#   4: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1741{[0]: ValueNode<Primitive> Cond, [1]: CNode_1740, [2]: ValueNode<BoolImm> false}
#   5: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1742{[0]: ValueNode<Primitive> Switch, [1]: CNode_1741, [2]: ValueNode<FuncGraph> ✓8↓tfnet_model_TFNetModel_construct_1743, [3]: ValueNode<FuncGraph> ✗8↓tfnet_model_TFNetModel_construct_1744}
#   6: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1745{[0]: CNode_1742}
#   7: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1747{[0]: ValueNode<FuncGraph> 9↓tfnet_model_TFNetModel_construct_1746, [1]: CNode_1745}
#   8: @8↓tfnet_model_TFNetModel_construct_1392:CNode_1748{[0]: ValueNode<Primitive> Return, [1]: CNode_1747}


subgraph attr:
training : 1
subgraph instance: ✓7↓tfnet_model_TFNetModel_construct_1389 : 0x37c59690
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓7↓tfnet_model_TFNetModel_construct_1389 parent: [subgraph @6↓tfnet_model_TFNetModel_construct_976]() {
  %1(CNode_1115) = $(6↓tfnet_model_TFNetModel_construct_976):ClassType(%para222_фmax_len)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %2(max_len) = $(6↓tfnet_model_TFNetModel_construct_976):call @ms_max_436(I64(1), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %3(CNode_1749) = S_Prim_MakeTuple(%para177_фbatch, I64(512), %2)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:159/            framewise = ops.zeros((batch, 512, max_len), ms.float32)/
  %4(framewise) = call @zeros_442(%3, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:159/            framewise = ops.zeros((batch, 512, max_len), ms.float32)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:159/            framewise = ops.zeros((batch, 512, max_len), ms.float32)/
}
# Order:
#   1: @✓7↓tfnet_model_TFNetModel_construct_1389:CNode_1749{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фbatch, [2]: ValueNode<Int64Imm> 512, [3]: max_len}
#   2: @✓7↓tfnet_model_TFNetModel_construct_1389:framewise{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_1749, [2]: ValueNode<Float> Float32}
#   3: @✓7↓tfnet_model_TFNetModel_construct_1389:CNode_1750{[0]: ValueNode<Primitive> Return, [1]: framewise}


subgraph attr:
training : 1
subgraph instance: ✗7↓tfnet_model_TFNetModel_construct_1390 : 0x376de100
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗7↓tfnet_model_TFNetModel_construct_1390 parent: [subgraph @↵6↓tfnet_model_TFNetModel_construct_1113]() {
  %1(CNode_1751) = S_Prim_MakeTuple(%para229_фpadded_features)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
  %2(CNode_1752) = S_Prim_MakeTuple("axis")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
  %3(CNode_1753) = S_Prim_MakeTuple(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
  %4(CNode_1754) = S_Prim_make_dict(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
  %5(framewise) = UnpackCall_unpack_call(@stack_1755, %1, %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:161/            framewise = ops.stack(padded_features, axis=0)  # (B, T, C) -> (批次, 时间步, 通道)/
}
# Order:
#   1: @✗7↓tfnet_model_TFNetModel_construct_1390:CNode_1751{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фpadded_features}
#   2: @✗7↓tfnet_model_TFNetModel_construct_1390:CNode_1752{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> axis}
#   3: @✗7↓tfnet_model_TFNetModel_construct_1390:CNode_1753{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0}
#   4: @✗7↓tfnet_model_TFNetModel_construct_1390:CNode_1754{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_1752, [2]: CNode_1753}
#   5: @✗7↓tfnet_model_TFNetModel_construct_1390:framewise{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1756, [1]: ValueNode<FuncGraph> stack_1755, [2]: CNode_1751, [3]: CNode_1754}
#   6: @✗7↓tfnet_model_TFNetModel_construct_1390:CNode_1757{[0]: ValueNode<Primitive> Return, [1]: framewise}


subgraph attr:
training : 1
subgraph instance: ↻✓5↓tfnet_model_TFNetModel_construct_1397 : 0x37c67fa0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻✓5↓tfnet_model_TFNetModel_construct_1397 parent: [subgraph @↵✓5↓tfnet_model_TFNetModel_construct_1235]() {
  %1(CNode_1758) = call @ms_next_1075(%para248_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %2(CNode_1759) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %3(f) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %4(CNode_1760) = getattr(%3, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %5(CNode_1761) = S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %6(CNode_1762) = S_Prim_greater(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %7(CNode_1763) = Switch(%6, @✓↻✓5↓tfnet_model_TFNetModel_construct_1764, @✗↻✓5↓tfnet_model_TFNetModel_construct_1765)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %8(CNode_1766) = %7()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %9(CNode_1767) = call @↵✓5↓tfnet_model_TFNetModel_construct_1235(%2, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1758{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻✓5↓tfnet_model_TFNetModel_construct_1397:f{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1758, [2]: ValueNode<Int64Imm> 0}
#   3: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1759{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1758, [2]: ValueNode<Int64Imm> 1}
#   4: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1760{[0]: ValueNode<Primitive> getattr, [1]: f, [2]: ValueNode<StringImm> shape}
#   5: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1761{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1760, [2]: ValueNode<Int64Imm> 0}
#   6: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1762{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_1761, [2]: ValueNode<Int64Imm> 0}
#   7: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1768{[0]: ValueNode<Primitive> getattr, [1]: f, [2]: ValueNode<StringImm> shape}
#   8: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1769{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1768, [2]: ValueNode<Int64Imm> 0}
#   9: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1770{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_1769}
#  10: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1771{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_1770}
#  11: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1763{[0]: ValueNode<Primitive> Switch, [1]: CNode_1762, [2]: ValueNode<FuncGraph> ✓↻✓5↓tfnet_model_TFNetModel_construct_1764, [3]: ValueNode<FuncGraph> ✗↻✓5↓tfnet_model_TFNetModel_construct_1765}
#  12: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1766{[0]: CNode_1763}
#  13: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1767{[0]: ValueNode<FuncGraph> ↵✓5↓tfnet_model_TFNetModel_construct_1235, [1]: CNode_1759, [2]: CNode_1766}
#  14: @↻✓5↓tfnet_model_TFNetModel_construct_1397:CNode_1772{[0]: ValueNode<Primitive> Return, [1]: CNode_1767}


subgraph attr:
training : 1
subgraph instance: ↓✓5↓tfnet_model_TFNetModel_construct_1398 : 0x333f5b00
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✓5↓tfnet_model_TFNetModel_construct_1398 parent: [subgraph @↵✓5↓tfnet_model_TFNetModel_construct_1235]() {
  Return(%para249_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @↓✓5↓tfnet_model_TFNetModel_construct_1398:CNode_1773{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: get_data_type_str_1401 : 0x37aeaa50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2594/def get_data_type_str(input_data):/
subgraph @get_data_type_str_1401(%para328_input_data) {
  %1(CNode_1774) = S_Prim_MakeTuple(ClassType, ClassType, ClassType)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  %2(CNode_1775) = S_Prim_isinstance(%para328_input_data, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  %3(CNode_1776) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  %4(CNode_1777) = Switch(%3, @✓get_data_type_str_1778, @✗get_data_type_str_1779)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  %5(CNode_1780) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
}
# Order:
#   1: @get_data_type_str_1401:CNode_1774{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: ValueNode<ClassType> class 'float', [3]: ValueNode<ClassType> class 'bool'}
#   2: @get_data_type_str_1401:CNode_1775{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_input_data, [2]: CNode_1774}
#   3: @get_data_type_str_1401:CNode_1776{[0]: ValueNode<Primitive> Cond, [1]: CNode_1775, [2]: ValueNode<BoolImm> false}
#   4: @get_data_type_str_1401:CNode_1777{[0]: ValueNode<Primitive> Switch, [1]: CNode_1776, [2]: ValueNode<FuncGraph> ✓get_data_type_str_1778, [3]: ValueNode<FuncGraph> ✗get_data_type_str_1779}
#   5: @get_data_type_str_1401:CNode_1780{[0]: CNode_1777}
#   6: @get_data_type_str_1401:CNode_1781{[0]: ValueNode<Primitive> Return, [1]: CNode_1780}


subgraph attr:
after_block : 1
subgraph instance: ↓check_isconstant_1402 : 0x3765a930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
subgraph @↓check_isconstant_1402() {
  Return(None)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2601/def check_isconstant(input_data, func_name):/
}
# Order:
#   1: @↓check_isconstant_1402:CNode_1782{[0]: ValueNode<Primitive> Return, [1]: ValueNode<None> None}


subgraph attr:
subgraph instance: ✓↓✓ms_max_one_element_1408 : 0x37819a00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓↓✓ms_max_one_element_1408 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1783) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("The truth value of an array with more than one element is ambiguous.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2617/            const_utils.raise_value_error(/
  %2(CNode_1784) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_1786) = call @2↓✓ms_max_one_element_1785()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  %4(CNode_1787) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2617/            const_utils.raise_value_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2617/            const_utils.raise_value_error(/
}
# Order:
#   1: @✓↓✓ms_max_one_element_1408:CNode_1783{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> The truth value of an array with more than one element is ambiguous.}
#   2: @✓↓✓ms_max_one_element_1408:CNode_1788{[0]: ValueNode<Primitive> Return, [1]: CNode_1787}
#   3: @✓↓✓ms_max_one_element_1408:CNode_1786{[0]: ValueNode<FuncGraph> 2↓✓ms_max_one_element_1785}


subgraph attr:
subgraph instance: ✗↓✓ms_max_one_element_1409 : 0x37eae560
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗↓✓ms_max_one_element_1409 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1789) = call @2↓✓ms_max_one_element_1785()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2616/        if tensor_shape_len >= 2:/
}
# Order:
#   1: @✗↓✓ms_max_one_element_1409:CNode_1790{[0]: ValueNode<Primitive> Return, [1]: CNode_1789}
#   2: @✗↓✓ms_max_one_element_1409:CNode_1789{[0]: ValueNode<FuncGraph> 2↓✓ms_max_one_element_1785}


subgraph attr:
subgraph instance: 2✓↓ms_max_one_element_1416 : 0x37632480
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @2✓↓ms_max_one_element_1416 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1791) = ClassType()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2623/            return SequenceMax()(x)/
  %2(CNode_1792) = %1(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2623/            return SequenceMax()(x)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2623/            return SequenceMax()(x)/
}
# Order:
#   1: @2✓↓ms_max_one_element_1416:CNode_1791{[0]: ValueNode<ClassType> class 'mindspore.ops.operations._sequence_ops.SequenceMax'}
#   2: @2✓↓ms_max_one_element_1416:CNode_1792{[0]: CNode_1791, [1]: param_x}
#   3: @2✓↓ms_max_one_element_1416:CNode_1793{[0]: ValueNode<Primitive> Return, [1]: CNode_1792}


subgraph attr:
subgraph instance: ✗✓↓ms_max_one_element_1417 : 0x37a4a6b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗✓↓ms_max_one_element_1417 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1795) = call @↓✓↓ms_max_one_element_1794()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
}
# Order:
#   1: @✗✓↓ms_max_one_element_1417:CNode_1795{[0]: ValueNode<FuncGraph> ↓✓↓ms_max_one_element_1794}
#   2: @✗✓↓ms_max_one_element_1417:CNode_1796{[0]: ValueNode<Primitive> Return, [1]: CNode_1795}


subgraph attr:
subgraph instance: check_sequence_all_variable_scalar_1412 : 0x37d2b0f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @check_sequence_all_variable_scalar_1412(%para329_x, %para330_str_info) {
  %1(CNode_1797) = S_Prim_IsDimUnKnown(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
  %2(CNode_1798) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
  %3(CNode_1799) = Switch(%2, @✓check_sequence_all_variable_scalar_1800, @✗check_sequence_all_variable_scalar_1801)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
  %4(CNode_1802) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
}
# Order:
#   1: @check_sequence_all_variable_scalar_1412:CNode_1797{[0]: ValueNode<DoSignaturePrimitive> S_Prim_IsDimUnKnown, [1]: param_x}
#   2: @check_sequence_all_variable_scalar_1412:CNode_1798{[0]: ValueNode<Primitive> Cond, [1]: CNode_1797, [2]: ValueNode<BoolImm> false}
#   3: @check_sequence_all_variable_scalar_1412:CNode_1799{[0]: ValueNode<Primitive> Switch, [1]: CNode_1798, [2]: ValueNode<FuncGraph> ✓check_sequence_all_variable_scalar_1800, [3]: ValueNode<FuncGraph> ✗check_sequence_all_variable_scalar_1801}
#   4: @check_sequence_all_variable_scalar_1412:CNode_1802{[0]: CNode_1799}
#   5: @check_sequence_all_variable_scalar_1412:CNode_1803{[0]: ValueNode<Primitive> Return, [1]: CNode_1802}


subgraph attr:
after_block : 1
subgraph instance: 2↓ms_max_one_element_1420 : 0x3344a850
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @2↓ms_max_one_element_1420 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_1804) = call @check_isconstant_1138(%para214_x, "max()")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2635/    check_isconstant(x, "max()")/
  %2(CNode_1805) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_1806) = S_Prim_max_[constexpr_prim: Bool(1)](%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2636/    return max_(x)/
  %4(CNode_1807) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2636/    return max_(x)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2636/    return max_(x)/
}
# Order:
#   1: @2↓ms_max_one_element_1420:CNode_1804{[0]: ValueNode<FuncGraph> check_isconstant_1138, [1]: param_x, [2]: ValueNode<StringImm> max()}
#   2: @2↓ms_max_one_element_1420:CNode_1806{[0]: ValueNode<DoSignaturePrimitive> S_Prim_max_, [1]: param_x}
#   3: @2↓ms_max_one_element_1420:CNode_1808{[0]: ValueNode<Primitive> Return, [1]: CNode_1807}


subgraph attr:
subgraph instance: ↵↓max_tensor_1423 : 0x37aaec90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @↵↓max_tensor_1423 parent: [subgraph @↓max_tensor_1267](%para331_, %para332_) {
  %1(CNode_1425) = $(↓max_tensor_1267):S_Prim_inner_len(%para250_фdata)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %2(CNode_1809) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para331_@CNode_1810, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %3(CNode_1811) = Switch(%2, @↻↓max_tensor_1812, @2↓max_tensor_1813)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %4(CNode_1814) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
}
# Order:
#   1: @↵↓max_tensor_1423:CNode_1809{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_1810, [2]: CNode_1425}
#   2: @↵↓max_tensor_1423:CNode_1811{[0]: ValueNode<Primitive> Switch, [1]: CNode_1809, [2]: ValueNode<FuncGraph> ↻↓max_tensor_1812, [3]: ValueNode<FuncGraph> 2↓max_tensor_1813}
#   3: @↵↓max_tensor_1423:CNode_1814{[0]: CNode_1811}
#   4: @↵↓max_tensor_1423:CNode_1815{[0]: ValueNode<Primitive> Return, [1]: CNode_1814}


subgraph attr:
after_block : 1
subgraph instance: ↓↻get_tensor_num_1437 : 0x37c4b340
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↓↻get_tensor_num_1437 parent: [subgraph @↻get_tensor_num_1273](%para333_) {
  %1(CNode_1271) = $(↻get_tensor_num_1273):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para234_@CNode_1271, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(CNode_1816) = call @↵get_tensor_num_1157(%1, %para333_фtensor_num)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
}
# Order:
#   1: @↓↻get_tensor_num_1437:CNode_1817{[0]: ValueNode<Primitive> Return, [1]: CNode_1816}
#   2: @↓↻get_tensor_num_1437:CNode_1816{[0]: ValueNode<FuncGraph> ↵get_tensor_num_1157, [1]: CNode_1271, [2]: param_фtensor_num}


subgraph attr:
subgraph instance: ✓↻get_tensor_num_1434 : 0x3339a6f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @✓↻get_tensor_num_1434 parent: [subgraph @↻get_tensor_num_1273]() {
  %1(CNode_1430) = $(↻get_tensor_num_1273):call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(input_data) = $(↻get_tensor_num_1273):S_Prim_getitem(%1, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(tensor_shape) = call @shape_1142(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
  %4(tensor_shape_len) = S_Prim_inner_len(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2557/            tensor_shape_len = len(tensor_shape)/
  %5(CNode_1818) = S_Prim_not_equal(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %6(CNode_1819) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %7(CNode_1820) = Switch(%6, @↰✓↻get_tensor_num_1821, @↱✓↻get_tensor_num_1822)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %8(CNode_1823) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %9(CNode_1824) = Cond(%8, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %10(CNode_1825) = Switch(%9, @2✓↻get_tensor_num_1826, @✗✓↻get_tensor_num_1827)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %11(CNode_1828) = %10()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @✓↻get_tensor_num_1434:tensor_shape{[0]: ValueNode<FuncGraph> shape_1142, [1]: input_data}
#   2: @✓↻get_tensor_num_1434:tensor_shape_len{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: tensor_shape}
#   3: @✓↻get_tensor_num_1434:CNode_1818{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 0}
#   4: @✓↻get_tensor_num_1434:CNode_1819{[0]: ValueNode<Primitive> Cond, [1]: CNode_1818, [2]: ValueNode<BoolImm> false}
#   5: @✓↻get_tensor_num_1434:CNode_1820{[0]: ValueNode<Primitive> Switch, [1]: CNode_1819, [2]: ValueNode<FuncGraph> ↰✓↻get_tensor_num_1821, [3]: ValueNode<FuncGraph> ↱✓↻get_tensor_num_1822}
#   6: @✓↻get_tensor_num_1434:CNode_1823{[0]: CNode_1820}
#   7: @✓↻get_tensor_num_1434:CNode_1824{[0]: ValueNode<Primitive> Cond, [1]: CNode_1823, [2]: ValueNode<BoolImm> false}
#   8: @✓↻get_tensor_num_1434:CNode_1825{[0]: ValueNode<Primitive> Switch, [1]: CNode_1824, [2]: ValueNode<FuncGraph> 2✓↻get_tensor_num_1826, [3]: ValueNode<FuncGraph> ✗✓↻get_tensor_num_1827}
#   9: @✓↻get_tensor_num_1434:CNode_1828{[0]: CNode_1825}
#  10: @✓↻get_tensor_num_1434:CNode_1829{[0]: ValueNode<Primitive> Return, [1]: CNode_1828}


subgraph attr:
subgraph instance: ✗↻get_tensor_num_1435 : 0x37385890
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @✗↻get_tensor_num_1435 parent: [subgraph @↵get_tensor_num_1157]() {
  Return(%para235_фtensor_num)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2555/        if isinstance(input_data, Tensor):/
}
# Order:
#   1: @✗↻get_tensor_num_1435:CNode_1830{[0]: ValueNode<Primitive> Return, [1]: param_фtensor_num}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓2✗ms_max_1444 : 0x373c9250
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @2↓✓2✗ms_max_1444 parent: [subgraph @ms_max_436]() {
  %1(CNode_495) = call @exist_tensor_1831(%para186_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  %2(CNode_496) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  %3(CNode_497) = Switch(%2, @✓2↓✓2✗ms_max_1832, @✗2↓✓2✗ms_max_1833)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  %4(CNode_499) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
}
# Order:
#   1: @2↓✓2✗ms_max_1444:CNode_495{[0]: ValueNode<FuncGraph> exist_tensor_1831, [1]: param_data}
#   2: @2↓✓2✗ms_max_1444:CNode_496{[0]: ValueNode<Primitive> Cond, [1]: CNode_495, [2]: ValueNode<BoolImm> false}
#   3: @2↓✓2✗ms_max_1444:CNode_497{[0]: ValueNode<Primitive> Switch, [1]: CNode_496, [2]: ValueNode<FuncGraph> ✓2↓✓2✗ms_max_1832, [3]: ValueNode<FuncGraph> ✗2↓✓2✗ms_max_1833}
#   4: @2↓✓2✗ms_max_1444:CNode_499{[0]: CNode_497}
#   5: @2↓✓2✗ms_max_1444:CNode_500{[0]: ValueNode<Primitive> Return, [1]: CNode_499}


subgraph attr:
subgraph instance: mindspore_nn_loss_loss_CTCLoss_construct_1467 : 0x397b5210
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467(%para334_log_probs, %para335_targets, %para336_input_lengths, %para337_target_lengths) {
  %1(CNode_1834) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("log_probs", %para334_log_probs, "CTCLoss")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2689/        _check_is_tensor('log_probs', log_probs, self.cls_name)/
  %2(CNode_1835) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("targets", %para335_targets, "CTCLoss")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2690/        _check_is_tensor('targets', targets, self.cls_name)/
  %3(CNode_1836) = MakeTuple(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
  %4(CNode_1837) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
  %5(CNode_1838) = getattr(%para334_log_probs, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  %6(CNode_1839) = S_Prim_equal(%5, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  %7(CNode_1840) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  %8(CNode_1841) = Switch(%7, @✓mindspore_nn_loss_loss_CTCLoss_construct_1842, @✗mindspore_nn_loss_loss_CTCLoss_construct_1843)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  %9(CNode_1844) = %8()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  %10(CNode_1845) = Depend[side_effect_propagate: I64(1)](%9, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
}
# Order:
#   1: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1834{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> log_probs, [2]: param_log_probs, [3]: ValueNode<StringImm> CTCLoss}
#   2: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1835{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> targets, [2]: param_targets, [3]: ValueNode<StringImm> CTCLoss}
#   3: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1838{[0]: ValueNode<Primitive> getattr, [1]: param_log_probs, [2]: ValueNode<StringImm> ndim}
#   4: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1839{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_1838, [2]: ValueNode<Int64Imm> 2}
#   5: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1840{[0]: ValueNode<Primitive> Cond, [1]: CNode_1839, [2]: ValueNode<BoolImm> false}
#   6: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1841{[0]: ValueNode<Primitive> Switch, [1]: CNode_1840, [2]: ValueNode<FuncGraph> ✓mindspore_nn_loss_loss_CTCLoss_construct_1842, [3]: ValueNode<FuncGraph> ✗mindspore_nn_loss_loss_CTCLoss_construct_1843}
#   7: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1844{[0]: CNode_1841}
#   8: @mindspore_nn_loss_loss_CTCLoss_construct_1467:CNode_1846{[0]: ValueNode<Primitive> Return, [1]: CNode_1845}


subgraph attr:
subgraph instance: ↻↓ms_min_1480 : 0x395261b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↻↓ms_min_1480 parent: [subgraph @↵↓ms_min_1297]() {
  %1(CNode_1478) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para256_@CNode_1478, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %2(CNode_1847) = call @ms_iter_97(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %3(input_data) = S_Prim_getitem(%2, %para256_@CNode_1478)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  %4(CNode_1848) = call @check_isconstant_1138(%3, "min()")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2743/        check_isconstant(input_data, "min()")/
  %5(CNode_1849) = MakeTuple(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
  %6(CNode_1850) = StopGradient(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
  %7(CNode_1851) = call @↵↓ms_min_1297(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %8(CNode_1852) = Depend[side_effect_propagate: I64(1)](%7, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2742/    for input_data in data:/
}
# Order:
#   1: @↻↓ms_min_1480:CNode_1847{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_data}
#   2: @↻↓ms_min_1480:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1847, [2]: param_@CNode_1478}
#   3: @↻↓ms_min_1480:CNode_1478{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1478, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓ms_min_1480:CNode_1848{[0]: ValueNode<FuncGraph> check_isconstant_1138, [1]: input_data, [2]: ValueNode<StringImm> min()}
#   5: @↻↓ms_min_1480:CNode_1853{[0]: ValueNode<Primitive> Return, [1]: CNode_1852}
#   6: @↻↓ms_min_1480:CNode_1851{[0]: ValueNode<FuncGraph> ↵↓ms_min_1297, [1]: CNode_1478}


subgraph attr:
subgraph instance: 2↓ms_min_1481 : 0x39525140
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @2↓ms_min_1481 parent: [subgraph @ms_min_962]() {
  %1(CNode_1854) = UnpackCall_unpack_call(S_Prim_min_[constexpr_prim: Bool(1)], %para221_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2744/    return min_(*data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2744/    return min_(*data)/
}
# Order:
#   1: @2↓ms_min_1481:CNode_1854{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1855, [1]: ValueNode<DoSignaturePrimitive> S_Prim_min_, [2]: param_data}
#   2: @2↓ms_min_1481:CNode_1856{[0]: ValueNode<Primitive> Return, [1]: CNode_1854}


subgraph attr:
subgraph instance: ✓ms_min_one_element_1487 : 0x39584c20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓ms_min_one_element_1487 parent: [subgraph @ms_min_one_element_1301]() {
  %1(tensor_shape) = call @shape_1142(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2694/        tensor_shape = F.shape(x)/
  %2(tensor_shape_len) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2695/        tensor_shape_len = len(tensor_shape)/
  %3(CNode_1857) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
  %4(CNode_1858) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
  %5(CNode_1859) = Switch(%4, @2✓ms_min_one_element_1860, @✗✓ms_min_one_element_1861)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
  %6(CNode_1862) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
}
# Order:
#   1: @✓ms_min_one_element_1487:tensor_shape{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_x}
#   2: @✓ms_min_one_element_1487:tensor_shape_len{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: tensor_shape}
#   3: @✓ms_min_one_element_1487:CNode_1857{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 0}
#   4: @✓ms_min_one_element_1487:CNode_1858{[0]: ValueNode<Primitive> Cond, [1]: CNode_1857, [2]: ValueNode<BoolImm> false}
#   5: @✓ms_min_one_element_1487:CNode_1859{[0]: ValueNode<Primitive> Switch, [1]: CNode_1858, [2]: ValueNode<FuncGraph> 2✓ms_min_one_element_1860, [3]: ValueNode<FuncGraph> ✗✓ms_min_one_element_1861}
#   6: @✓ms_min_one_element_1487:CNode_1862{[0]: CNode_1859}
#   7: @✓ms_min_one_element_1487:CNode_1863{[0]: ValueNode<Primitive> Return, [1]: CNode_1862}


subgraph attr:
subgraph instance: ✗ms_min_one_element_1488 : 0x39553400
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗ms_min_one_element_1488 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_1865) = call @↓ms_min_one_element_1864()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2693/    if isinstance(x, Tensor):/
}
# Order:
#   1: @✗ms_min_one_element_1488:CNode_1865{[0]: ValueNode<FuncGraph> ↓ms_min_one_element_1864}
#   2: @✗ms_min_one_element_1488:CNode_1866{[0]: ValueNode<Primitive> Return, [1]: CNode_1865}


subgraph attr:
subgraph instance: 2✓2✗ms_min_1494 : 0x3953e120
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @2✓2✗ms_min_1494 parent: [subgraph @ms_min_962]() {
  %1(CNode_1867) = UnpackCall_unpack_call(@min_tensor_1868, %para221_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2734/            return min_tensor(*data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2734/            return min_tensor(*data)/
}
# Order:
#   1: @2✓2✗ms_min_1494:CNode_1867{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.1869, [1]: ValueNode<FuncGraph> min_tensor_1868, [2]: param_data}
#   2: @2✓2✗ms_min_1494:CNode_1870{[0]: ValueNode<Primitive> Return, [1]: CNode_1867}


subgraph attr:
subgraph instance: ✗✓2✗ms_min_1495 : 0x3952ce80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✗✓2✗ms_min_1495 parent: [subgraph @✓2✗ms_min_1307]() {
  %1(CNode_1872) = call @↓✓2✗ms_min_1871()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2733/        if tensor_num == len_data:/
}
# Order:
#   1: @✗✓2✗ms_min_1495:CNode_1872{[0]: ValueNode<FuncGraph> ↓✓2✗ms_min_1871}
#   2: @✗✓2✗ms_min_1495:CNode_1873{[0]: ValueNode<Primitive> Return, [1]: CNode_1872}


subgraph attr:
after_block : 1
subgraph instance: ↓2✗ms_min_1498 : 0x3951e130
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↓2✗ms_min_1498 parent: [subgraph @ms_min_962]() {
  %1(CNode_1875) = call @↓✗ms_min_1874()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2730/    elif len_data >= 2:/
}
# Order:
#   1: @↓2✗ms_min_1498:CNode_1875{[0]: ValueNode<FuncGraph> ↓✗ms_min_1874}
#   2: @↓2✗ms_min_1498:CNode_1876{[0]: ValueNode<Primitive> Return, [1]: CNode_1875}


subgraph attr:
training : 1
subgraph instance: ✓check_axis_valid_1510 : 0x39687af0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @✓check_axis_valid_1510() {
  %1(CNode_1877) = raise[side_effect_io: Bool(1)]("ValueError", "'start_dim' or 'end_dim' out of range.", "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:459/            raise ValueError("'start_dim' or 'end_dim' out of range.")/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:459/            raise ValueError("'start_dim' or 'end_dim' out of range.")/
}
# Order:
#   1: @✓check_axis_valid_1510:CNode_1877{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: ValueNode<StringImm> 'start_dim' or 'end_dim' out of range., [3]: ValueNode<StringImm> None}
#   2: @✓check_axis_valid_1510:CNode_1878{[0]: ValueNode<Primitive> Return, [1]: CNode_1877}


subgraph attr:
training : 1
subgraph instance: ✗check_axis_valid_1511 : 0x396857b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @✗check_axis_valid_1511() {
  %1(CNode_1880) = call @↓check_axis_valid_1879()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @✗check_axis_valid_1511:CNode_1880{[0]: ValueNode<FuncGraph> ↓check_axis_valid_1879}
#   2: @✗check_axis_valid_1511:CNode_1881{[0]: ValueNode<Primitive> Return, [1]: CNode_1880}


subgraph attr:
training : 1
subgraph instance: ↰check_axis_valid_1505 : 0x39684820
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @↰check_axis_valid_1505 parent: [subgraph @check_axis_valid_1317]() {
  %1(CNode_1501) = $(check_axis_valid_1317):S_Prim_negative(%para259_ndim)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  %2(CNode_1502) = $(check_axis_valid_1317):S_Prim_less(%para258_axis, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @↰check_axis_valid_1505:CNode_1882{[0]: ValueNode<Primitive> Return, [1]: CNode_1502}


subgraph attr:
training : 1
subgraph instance: ↱check_axis_valid_1506 : 0x396837b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @↱check_axis_valid_1506 parent: [subgraph @check_axis_valid_1317]() {
  %1(CNode_1883) = S_Prim_greater_equal(%para258_axis, %para259_ndim)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:458/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @↱check_axis_valid_1506:CNode_1883{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: param_axis, [2]: param_ndim}
#   2: @↱check_axis_valid_1506:CNode_1884{[0]: ValueNode<Primitive> Return, [1]: CNode_1883}


subgraph attr:
subgraph instance: ✓flatten_1522 : 0x39711680
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓flatten_1522() {
  %1(CNode_1885) = JoinedStr("For 'flatten', argument 'input' must be Tensor.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1732/        raise TypeError(f"For 'flatten', argument 'input' must be Tensor.")/
  %2(CNode_1886) = raise[side_effect_io: Bool(1)]("TypeError", %1, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1732/        raise TypeError(f"For 'flatten', argument 'input' must be Tensor.")/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1732/        raise TypeError(f"For 'flatten', argument 'input' must be Tensor.")/
}
# Order:
#   1: @✓flatten_1522:CNode_1885{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For 'flatten', argument 'input' must be Tensor.}
#   2: @✓flatten_1522:CNode_1886{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: CNode_1885, [3]: ValueNode<StringImm> None}
#   3: @✓flatten_1522:CNode_1887{[0]: ValueNode<Primitive> Return, [1]: CNode_1886}


subgraph attr:
subgraph instance: ✗flatten_1523 : 0x3968e840
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗flatten_1523 parent: [subgraph @flatten_1327]() {
  %1(CNode_1889) = call @↓flatten_1888()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1731/    if not isinstance(input, Tensor):/
}
# Order:
#   1: @✗flatten_1523:CNode_1889{[0]: ValueNode<FuncGraph> ↓flatten_1888}
#   2: @✗flatten_1523:CNode_1890{[0]: ValueNode<Primitive> Return, [1]: CNode_1889}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_conv_Conv2d_construct_1527 : 0x39671520
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_conv_Conv2d_construct_1527 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1526]() {
  %1(CNode_1892) = call @↓mindspore_nn_layer_conv_Conv2d_construct_1891()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @✗mindspore_nn_layer_conv_Conv2d_construct_1527:CNode_1892{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_conv_Conv2d_construct_1891}
#   2: @✗mindspore_nn_layer_conv_Conv2d_construct_1527:CNode_1893{[0]: ValueNode<Primitive> Return, [1]: CNode_1892}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531 : 0x39655de0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531(%para338_x, %para339_, %para340_, %para341_, %para342_) {
  %1(CNode_1894) = S_Prim_Shape(%para338_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %2(CNode_1895) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "BatchNorm2d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %3(CNode_1896) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
  %4(CNode_1897) = S_Prim_is_(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %5(CNode_1898) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %6(CNode_1899) = Switch(%5, @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900, @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %7(CNode_1902) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %8(CNode_1903) = Depend[side_effect_propagate: I64(1)](%7, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1894{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1895{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_1894, [2]: ValueNode<StringImm> BatchNorm2d}
#   3: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1897{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#   4: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1898{[0]: ValueNode<Primitive> Cond, [1]: CNode_1897, [2]: ValueNode<BoolImm> false}
#   5: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1899{[0]: ValueNode<Primitive> Switch, [1]: CNode_1898, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901}
#   6: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1902{[0]: CNode_1899}
#   7: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531:CNode_1533{[0]: ValueNode<Primitive> Return, [1]: CNode_1903}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv2d_construct_1538 : 0x396648b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1538(%para343_x, %para344_) {
  %1(CNode_1905) = call @L_✗mindspore_nn_layer_conv_Conv2d_construct_1904()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv2d_construct_1538:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_L_conv2d.layer4.3.weight}
#   2: @L_mindspore_nn_layer_conv_Conv2d_construct_1538:CNode_1905{[0]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_conv_Conv2d_construct_1904}
#   3: @L_mindspore_nn_layer_conv_Conv2d_construct_1538:CNode_1540{[0]: ValueNode<Primitive> Return, [1]: CNode_1905}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_1559 : 0x39676970
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_1559 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1333]() {
  %1(CNode_1557) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para274_@CNode_1557, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1906) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_1336) = $(mindspore_nn_layer_container_SequentialCell_construct_1216):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1526, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1530, @mindspore_nn_layer_activation_ReLU_construct_1534, @mindspore_nn_layer_conv_Conv2d_construct_1537, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1541, @mindspore_nn_layer_activation_ReLU_construct_1544, @mindspore_nn_layer_conv_Conv2d_construct_1547, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1550, @mindspore_nn_layer_activation_ReLU_construct_1553)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1907) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para274_@CNode_1557)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para275_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_1908) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1333(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_1909) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:CNode_1907{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_1336}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1907, [2]: param_@CNode_1557}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:CNode_1557{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1557, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:CNode_1908{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1333, [1]: CNode_1557, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_1559:CNode_1910{[0]: ValueNode<Primitive> Return, [1]: CNode_1909}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_1560 : 0x396759e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_1560 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1333]() {
  Return(%para275_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_1560:CNode_1911{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_conv_Conv2d_construct_1564 : 0x39648af0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_conv_Conv2d_construct_1564 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1563]() {
  %1(CNode_1913) = call @↓mindspore_nn_layer_conv_Conv2d_construct_1912()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @✗mindspore_nn_layer_conv_Conv2d_construct_1564:CNode_1913{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_conv_Conv2d_construct_1912}
#   2: @✗mindspore_nn_layer_conv_Conv2d_construct_1564:CNode_1914{[0]: ValueNode<Primitive> Return, [1]: CNode_1913}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568 : 0x39620320
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568(%para345_x, %para346_, %para347_, %para348_, %para349_) {
  %1(CNode_1915) = S_Prim_Shape(%para345_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %2(CNode_1916) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "BatchNorm2d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %3(CNode_1917) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
  %4(CNode_1918) = S_Prim_is_(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %5(CNode_1919) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %6(CNode_1920) = Switch(%5, @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921, @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %7(CNode_1923) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %8(CNode_1924) = Depend[side_effect_propagate: I64(1)](%7, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1915{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1916{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_1915, [2]: ValueNode<StringImm> BatchNorm2d}
#   3: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1918{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#   4: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1919{[0]: ValueNode<Primitive> Cond, [1]: CNode_1918, [2]: ValueNode<BoolImm> false}
#   5: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1920{[0]: ValueNode<Primitive> Switch, [1]: CNode_1919, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922}
#   6: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1923{[0]: CNode_1920}
#   7: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568:CNode_1570{[0]: ValueNode<Primitive> Return, [1]: CNode_1924}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv2d_construct_1575 : 0x3962f2b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1575(%para350_x, %para351_) {
  %1(CNode_1926) = call @L_✗mindspore_nn_layer_conv_Conv2d_construct_1925()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv2d_construct_1575:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_L_conv2d.layer3.3.weight}
#   2: @L_mindspore_nn_layer_conv_Conv2d_construct_1575:CNode_1926{[0]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_conv_Conv2d_construct_1925}
#   3: @L_mindspore_nn_layer_conv_Conv2d_construct_1575:CNode_1577{[0]: ValueNode<Primitive> Return, [1]: CNode_1926}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_1623 : 0x3964df40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_1623 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1338]() {
  %1(CNode_1621) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para294_@CNode_1621, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1927) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_1341) = $(mindspore_nn_layer_container_SequentialCell_construct_1215):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1563, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1567, @mindspore_nn_layer_activation_ReLU_construct_1571, @mindspore_nn_layer_conv_Conv2d_construct_1574, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1578, @mindspore_nn_layer_activation_ReLU_construct_1581, @mindspore_nn_layer_conv_Conv2d_construct_1584, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1587, @mindspore_nn_layer_activation_ReLU_construct_1590, @mindspore_nn_layer_conv_Conv2d_construct_1593, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1596, @mindspore_nn_layer_activation_ReLU_construct_1599, @mindspore_nn_layer_conv_Conv2d_construct_1602, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1605, @mindspore_nn_layer_activation_ReLU_construct_1608, @mindspore_nn_layer_conv_Conv2d_construct_1611, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1614, @mindspore_nn_layer_activation_ReLU_construct_1617)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1928) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para294_@CNode_1621)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para295_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_1929) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1338(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_1930) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:CNode_1928{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_1341}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1928, [2]: param_@CNode_1621}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:CNode_1621{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1621, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:CNode_1929{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1338, [1]: CNode_1621, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_1623:CNode_1931{[0]: ValueNode<Primitive> Return, [1]: CNode_1930}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_1624 : 0x3964cfb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_1624 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1338]() {
  Return(%para295_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_1624:CNode_1932{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_conv_Conv2d_construct_1628 : 0x39612eb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_conv_Conv2d_construct_1628 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1627]() {
  %1(CNode_1934) = call @↓mindspore_nn_layer_conv_Conv2d_construct_1933()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @✗mindspore_nn_layer_conv_Conv2d_construct_1628:CNode_1934{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_conv_Conv2d_construct_1933}
#   2: @✗mindspore_nn_layer_conv_Conv2d_construct_1628:CNode_1935{[0]: ValueNode<Primitive> Return, [1]: CNode_1934}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632 : 0x395f31c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632(%para352_x, %para353_, %para354_, %para355_, %para356_) {
  %1(CNode_1936) = S_Prim_Shape(%para352_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %2(CNode_1937) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "BatchNorm2d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %3(CNode_1938) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
  %4(CNode_1939) = S_Prim_is_(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %5(CNode_1940) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %6(CNode_1941) = Switch(%5, @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942, @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %7(CNode_1944) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %8(CNode_1945) = Depend[side_effect_propagate: I64(1)](%7, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1936{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1937{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_1936, [2]: ValueNode<StringImm> BatchNorm2d}
#   3: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1939{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#   4: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1940{[0]: ValueNode<Primitive> Cond, [1]: CNode_1939, [2]: ValueNode<BoolImm> false}
#   5: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1941{[0]: ValueNode<Primitive> Switch, [1]: CNode_1940, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943}
#   6: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1944{[0]: CNode_1941}
#   7: @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632:CNode_1634{[0]: ValueNode<Primitive> Return, [1]: CNode_1945}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv2d_construct_1639 : 0x39601e50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1639(%para357_x, %para358_) {
  %1(CNode_1947) = call @L_✗mindspore_nn_layer_conv_Conv2d_construct_1946()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv2d_construct_1639:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_L_conv2d.layer2.3.weight}
#   2: @L_mindspore_nn_layer_conv_Conv2d_construct_1639:CNode_1947{[0]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_conv_Conv2d_construct_1946}
#   3: @L_mindspore_nn_layer_conv_Conv2d_construct_1639:CNode_1641{[0]: ValueNode<Primitive> Return, [1]: CNode_1947}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_1669 : 0x39618300
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_1669 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1343]() {
  %1(CNode_1667) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para308_@CNode_1667, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1948) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_1346) = $(mindspore_nn_layer_container_SequentialCell_construct_1214):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1627, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1631, @mindspore_nn_layer_activation_ReLU_construct_1635, @mindspore_nn_layer_conv_Conv2d_construct_1638, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1642, @mindspore_nn_layer_activation_ReLU_construct_1645, @mindspore_nn_layer_conv_Conv2d_construct_1648, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1651, @mindspore_nn_layer_activation_ReLU_construct_1654, @mindspore_nn_layer_conv_Conv2d_construct_1657, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1660, @mindspore_nn_layer_activation_ReLU_construct_1663)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1949) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para308_@CNode_1667)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para309_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_1950) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1343(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_1951) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:CNode_1949{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_1346}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1949, [2]: param_@CNode_1667}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:CNode_1667{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1667, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:CNode_1950{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1343, [1]: CNode_1667, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_1669:CNode_1952{[0]: ValueNode<Primitive> Return, [1]: CNode_1951}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_1670 : 0x39617370
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_1670 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1343]() {
  Return(%para309_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_1670:CNode_1953{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv2d_construct_1674 : 0x395dba10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1674(%para359_x, %para360_) {
  %1(CNode_1955) = call @L_✗mindspore_nn_layer_conv_Conv2d_construct_1954()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv2d_construct_1674:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: param_x, [2]: param_L_conv2d.layer1.0.weight}
#   2: @L_mindspore_nn_layer_conv_Conv2d_construct_1674:CNode_1955{[0]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_conv_Conv2d_construct_1954}
#   3: @L_mindspore_nn_layer_conv_Conv2d_construct_1674:CNode_1676{[0]: ValueNode<Primitive> Return, [1]: CNode_1955}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_1704 : 0x395eb2a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_1704 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1348]() {
  %1(CNode_1702) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para319_@CNode_1702, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_1956) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_1351) = $(mindspore_nn_layer_container_SequentialCell_construct_1213):MakeTuple(@mindspore_nn_layer_conv_Conv2d_construct_1673, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1677, @mindspore_nn_layer_activation_ReLU_construct_1680, @mindspore_nn_layer_conv_Conv2d_construct_1683, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1686, @mindspore_nn_layer_activation_ReLU_construct_1689, @mindspore_nn_layer_conv_Conv2d_construct_1692, @mindspore_nn_layer_normalization_BatchNorm2d_construct_1695, @mindspore_nn_layer_activation_ReLU_construct_1698)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_1957) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para319_@CNode_1702)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para320_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_1958) = call @↵mindspore_nn_layer_container_SequentialCell_construct_1348(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_1959) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:CNode_1957{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_1351}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1957, [2]: param_@CNode_1702}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:CNode_1702{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1702, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:CNode_1958{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_1348, [1]: CNode_1702, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_1704:CNode_1960{[0]: ValueNode<Primitive> Return, [1]: CNode_1959}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_1705 : 0x395ea310
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_1705 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_1348]() {
  Return(%para320_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_1705:CNode_1961{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709 : 0x395bca80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709(%para361_, %para362_) {
  %1(CNode_1963) = call @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:573/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:573/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709:CNode_1963{[0]: ValueNode<FuncGraph> ✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962}
#   2: @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709:CNode_1964{[0]: ValueNode<Primitive> Return, [1]: CNode_1963}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720 : 0x395b45d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_1966) = call @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
}
# Order:
#   1: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720:CNode_1966{[0]: ValueNode<FuncGraph> L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965}
#   2: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1720:CNode_1967{[0]: ValueNode<Primitive> Return, [1]: CNode_1966}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721 : 0x395ad910
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_1969) = call @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721:CNode_1969{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968}
#   2: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1721:CNode_1970{[0]: ValueNode<Primitive> Return, [1]: CNode_1969}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_conv_Conv2d_construct_1724 : 0x395a6f80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_conv_Conv2d_construct_1724 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1209]() {
  %1(output) = $(mindspore_nn_layer_conv_Conv2d_construct_1209):S_Prim_Conv2D[kernel_size: (I64(7), I64(7)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(3), I64(3), I64(3), I64(3)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(3), I64(3), I64(3), I64(3)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para247_x, %para5_conv2d.conv1.weight)
      : (<null>, <Ref[Tensor[Float32]], (64, 3, 7, 7), ref_key=:conv2d.conv1.weight>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @↓mindspore_nn_layer_conv_Conv2d_construct_1724:CNode_1971{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: pad_sequence_1730 : 0x394d5610
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @pad_sequence_1730(%para363_tensor, %para364_length) {
  %1(CNode_1972) = getattr(%para363_tensor, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %2(current_length) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %3(CNode_1973) = ClassType(%para364_length)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %4(target_length) = call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %5(CNode_1974) = S_Prim_greater_equal(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
  %6(CNode_1975) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
  %7(CNode_1976) = Switch(%6, @✓pad_sequence_1977, @✗pad_sequence_1978)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
  %8(CNode_1979) = %7()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
}
# Order:
#   1: @pad_sequence_1730:CNode_1972{[0]: ValueNode<Primitive> getattr, [1]: param_tensor, [2]: ValueNode<StringImm> shape}
#   2: @pad_sequence_1730:current_length{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_1972, [2]: ValueNode<Int64Imm> 0}
#   3: @pad_sequence_1730:CNode_1973{[0]: ValueNode<ClassType> class 'int', [1]: param_length}
#   4: @pad_sequence_1730:target_length{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_1973}
#   5: @pad_sequence_1730:CNode_1974{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: current_length, [2]: target_length}
#   6: @pad_sequence_1730:CNode_1975{[0]: ValueNode<Primitive> Cond, [1]: CNode_1974, [2]: ValueNode<BoolImm> false}
#   7: @pad_sequence_1730:CNode_1976{[0]: ValueNode<Primitive> Switch, [1]: CNode_1975, [2]: ValueNode<FuncGraph> ✓pad_sequence_1977, [3]: ValueNode<FuncGraph> ✗pad_sequence_1978}
#   8: @pad_sequence_1730:CNode_1979{[0]: CNode_1976}
#   9: @pad_sequence_1730:CNode_1980{[0]: ValueNode<Primitive> Return, [1]: CNode_1979}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 9↓tfnet_model_TFNetModel_construct_1746 : 0x378270c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @9↓tfnet_model_TFNetModel_construct_1746 parent: [subgraph @4↓tfnet_model_TFNetModel_construct_647](%para365_) {
  %1(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %2(CNode_1982) = call @↵9↓tfnet_model_TFNetModel_construct_1981(I64(0), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
}
# Order:
#   1: @9↓tfnet_model_TFNetModel_construct_1746:CNode_1983{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 1}
#   2: @9↓tfnet_model_TFNetModel_construct_1746:framewise{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: param_фframewise, [2]: CNode_1983}
#   3: @9↓tfnet_model_TFNetModel_construct_1746:conv1d_outputs{[0]: ValueNode<FuncGraph> modules_TemporalConv_construct_1984, [1]: framewise, [2]: len_x_list}
#   4: @9↓tfnet_model_TFNetModel_construct_1746:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: conv1d_outputs, [2]: ValueNode<StringImm> visual_feat}
#   5: @9↓tfnet_model_TFNetModel_construct_1746:CNode_1985{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<StringImm> K5, [2]: ValueNode<StringImm> P2, [3]: ValueNode<StringImm> K5, [4]: ValueNode<StringImm> P2}
#   6: @9↓tfnet_model_TFNetModel_construct_1746:CNode_1986{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_1985}
#   7: @9↓tfnet_model_TFNetModel_construct_1746:CNode_1987{[0]: ValueNode<Primitive> Return, [1]: CNode_1982}
#   8: @9↓tfnet_model_TFNetModel_construct_1746:CNode_1982{[0]: ValueNode<FuncGraph> ↵9↓tfnet_model_TFNetModel_construct_1981, [1]: ValueNode<Int64Imm> 0, [2]: len_x_list}


subgraph attr:
training : 1
subgraph instance: ✓8↓tfnet_model_TFNetModel_construct_1743 : 0x374ef3e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓8↓tfnet_model_TFNetModel_construct_1743 parent: [subgraph @6↓tfnet_model_TFNetModel_construct_976]() {
  %1(CNode_1988) = call @ms_max_436(I64(1), %para177_фbatch)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:166/            framewise = ops.zeros((max(1, batch), 512, max(1, max_len)), ms.float32)/
  %2(CNode_1115) = $(6↓tfnet_model_TFNetModel_construct_976):ClassType(%para222_фmax_len)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %3(max_len) = $(6↓tfnet_model_TFNetModel_construct_976):call @ms_max_436(I64(1), %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:143/        max_len = max(1, int(max_len))  # 确保至少为1/
  %4(CNode_1989) = call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:166/            framewise = ops.zeros((max(1, batch), 512, max(1, max_len)), ms.float32)/
  %5(CNode_1990) = S_Prim_MakeTuple(%1, I64(512), %4)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:166/            framewise = ops.zeros((max(1, batch), 512, max(1, max_len)), ms.float32)/
  %6(framewise) = call @zeros_442(%5, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:166/            framewise = ops.zeros((max(1, batch), 512, max(1, max_len)), ms.float32)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:166/            framewise = ops.zeros((max(1, batch), 512, max(1, max_len)), ms.float32)/
}
# Order:
#   1: @✓8↓tfnet_model_TFNetModel_construct_1743:CNode_1988{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: param_фbatch}
#   2: @✓8↓tfnet_model_TFNetModel_construct_1743:CNode_1989{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: max_len}
#   3: @✓8↓tfnet_model_TFNetModel_construct_1743:CNode_1990{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_1988, [2]: ValueNode<Int64Imm> 512, [3]: CNode_1989}
#   4: @✓8↓tfnet_model_TFNetModel_construct_1743:framewise{[0]: ValueNode<FuncGraph> zeros_442, [1]: CNode_1990, [2]: ValueNode<Float> Float32}
#   5: @✓8↓tfnet_model_TFNetModel_construct_1743:CNode_1991{[0]: ValueNode<Primitive> Return, [1]: framewise}


subgraph attr:
training : 1
subgraph instance: ✗8↓tfnet_model_TFNetModel_construct_1744 : 0x37f910a0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗8↓tfnet_model_TFNetModel_construct_1744 parent: [subgraph @8↓tfnet_model_TFNetModel_construct_1392]() {
  Return(%para327_фframewise)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:164/        if len(framewise.shape) != 3:/
}
# Order:
#   1: @✗8↓tfnet_model_TFNetModel_construct_1744:CNode_1992{[0]: ValueNode<Primitive> Return, [1]: param_фframewise}


subgraph attr:
subgraph instance: stack_1755 : 0x3754a240
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2177/def stack(tensors, axis=0):/
subgraph @stack_1755(%para366_tensors, %para367_axis) {
  %1(CNode_1993) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2213/    _stack = _get_cache_prim(P.Stack)(axis)/
  %2(_stack) = %1(%para367_axis)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2213/    _stack = _get_cache_prim(P.Stack)(axis)/
  %3(CNode_1994) = %2(%para366_tensors)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2214/    return _stack(tensors)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2214/    return _stack(tensors)/
}
# Order:
#   1: @stack_1755:CNode_1993{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Stack'}
#   2: @stack_1755:_stack{[0]: CNode_1993, [1]: param_axis}
#   3: @stack_1755:CNode_1994{[0]: _stack, [1]: param_tensors}
#   4: @stack_1755:CNode_1995{[0]: ValueNode<Primitive> Return, [1]: CNode_1994}


subgraph attr:
training : 1
subgraph instance: ✓↻✓5↓tfnet_model_TFNetModel_construct_1764 : 0x37269da0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻✓5↓tfnet_model_TFNetModel_construct_1764 parent: [subgraph @↻✓5↓tfnet_model_TFNetModel_construct_1397]() {
  %1(CNode_1758) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):call @ms_next_1075(%para248_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %2(f) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %3(CNode_1768) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):getattr(%2, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %4(CNode_1769) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %5(CNode_1770) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):S_Prim_make_list(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  %6(CNode_1771) = $(↻✓5↓tfnet_model_TFNetModel_construct_1397):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para249_list, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @✓↻✓5↓tfnet_model_TFNetModel_construct_1764:CNode_1996{[0]: ValueNode<Primitive> Return, [1]: CNode_1771}


subgraph attr:
training : 1
subgraph instance: ✗↻✓5↓tfnet_model_TFNetModel_construct_1765 : 0x373ae930
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻✓5↓tfnet_model_TFNetModel_construct_1765 parent: [subgraph @↵✓5↓tfnet_model_TFNetModel_construct_1235]() {
  Return(%para249_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:139/            max_len = max(max(len_x_list), max([f.shape[0] for f in feature_list if f.shape[0] > 0]))/
}
# Order:
#   1: @✗↻✓5↓tfnet_model_TFNetModel_construct_1765:CNode_1997{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: ✓get_data_type_str_1778 : 0x375c3660
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2594/def get_data_type_str(input_data):/
subgraph @✓get_data_type_str_1778 parent: [subgraph @get_data_type_str_1401]() {
  %1(CNode_1998) = S_Prim_typeof(%para328_input_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2597/        return "variable " + str(F.typeof(input_data))/
  %2(CNode_1999) = ClassType(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2597/        return "variable " + str(F.typeof(input_data))/
  %3(CNode_2000) = S_Prim_add("variable ", %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2597/        return "variable " + str(F.typeof(input_data))/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2597/        return "variable " + str(F.typeof(input_data))/
}
# Order:
#   1: @✓get_data_type_str_1778:CNode_1998{[0]: ValueNode<DoSignaturePrimitive> S_Prim_typeof, [1]: param_input_data}
#   2: @✓get_data_type_str_1778:CNode_1999{[0]: ValueNode<ClassType> class 'str', [1]: CNode_1998}
#   3: @✓get_data_type_str_1778:CNode_2000{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: ValueNode<StringImm> variable , [2]: CNode_1999}
#   4: @✓get_data_type_str_1778:CNode_2001{[0]: ValueNode<Primitive> Return, [1]: CNode_2000}


subgraph attr:
subgraph instance: ✗get_data_type_str_1779 : 0x38f860d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2594/def get_data_type_str(input_data):/
subgraph @✗get_data_type_str_1779 parent: [subgraph @get_data_type_str_1401]() {
  %1(CNode_2003) = call @↓get_data_type_str_2002()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2596/    if isinstance(input_data, (int, float, bool)):/
}
# Order:
#   1: @✗get_data_type_str_1779:CNode_2003{[0]: ValueNode<FuncGraph> ↓get_data_type_str_2002}
#   2: @✗get_data_type_str_1779:CNode_2004{[0]: ValueNode<Primitive> Return, [1]: CNode_2003}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓ms_max_one_element_1785 : 0x376cb260
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @2↓✓ms_max_one_element_1785 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_2005) = getattr(%para214_x, "max")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2619/        return x.max()/
  %2(CNode_2006) = %1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2619/        return x.max()/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2619/        return x.max()/
}
# Order:
#   1: @2↓✓ms_max_one_element_1785:CNode_2005{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> max}
#   2: @2↓✓ms_max_one_element_1785:CNode_2006{[0]: CNode_2005}
#   3: @2↓✓ms_max_one_element_1785:CNode_2007{[0]: ValueNode<Primitive> Return, [1]: CNode_2006}


subgraph attr:
after_block : 1
subgraph instance: ↓✓↓ms_max_one_element_1794 : 0x3790bb90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @↓✓↓ms_max_one_element_1794 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_2008) = S_Prim_inner_len(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
  %2(CNode_2009) = S_Prim_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
  %3(CNode_2010) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
  %4(CNode_2011) = Switch(%3, @✓↓✓↓ms_max_one_element_2012, @✗↓✓↓ms_max_one_element_2013)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
  %5(CNode_2014) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
}
# Order:
#   1: @↓✓↓ms_max_one_element_1794:CNode_2008{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   2: @↓✓↓ms_max_one_element_1794:CNode_2009{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2008, [2]: ValueNode<Int64Imm> 0}
#   3: @↓✓↓ms_max_one_element_1794:CNode_2010{[0]: ValueNode<Primitive> Cond, [1]: CNode_2009, [2]: ValueNode<BoolImm> false}
#   4: @↓✓↓ms_max_one_element_1794:CNode_2011{[0]: ValueNode<Primitive> Switch, [1]: CNode_2010, [2]: ValueNode<FuncGraph> ✓↓✓↓ms_max_one_element_2012, [3]: ValueNode<FuncGraph> ✗↓✓↓ms_max_one_element_2013}
#   5: @↓✓↓ms_max_one_element_1794:CNode_2014{[0]: CNode_2011}
#   6: @↓✓↓ms_max_one_element_1794:CNode_2015{[0]: ValueNode<Primitive> Return, [1]: CNode_2014}


subgraph attr:
subgraph instance: ✓check_sequence_all_variable_scalar_1800 : 0x33314a00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✓check_sequence_all_variable_scalar_1800 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2016) = S_Prim_IsElementUnknown(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
  %2(CNode_2017) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
  %3(CNode_2018) = Switch(%2, @2✓check_sequence_all_variable_scalar_2019, @✗✓check_sequence_all_variable_scalar_2020)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
  %4(CNode_2021) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
}
# Order:
#   1: @✓check_sequence_all_variable_scalar_1800:CNode_2016{[0]: ValueNode<DoSignaturePrimitive> S_Prim_IsElementUnknown, [1]: param_x}
#   2: @✓check_sequence_all_variable_scalar_1800:CNode_2017{[0]: ValueNode<Primitive> Cond, [1]: CNode_2016, [2]: ValueNode<BoolImm> false}
#   3: @✓check_sequence_all_variable_scalar_1800:CNode_2018{[0]: ValueNode<Primitive> Switch, [1]: CNode_2017, [2]: ValueNode<FuncGraph> 2✓check_sequence_all_variable_scalar_2019, [3]: ValueNode<FuncGraph> ✗✓check_sequence_all_variable_scalar_2020}
#   4: @✓check_sequence_all_variable_scalar_1800:CNode_2021{[0]: CNode_2018}
#   5: @✓check_sequence_all_variable_scalar_1800:CNode_2022{[0]: ValueNode<Primitive> Return, [1]: CNode_2021}


subgraph attr:
subgraph instance: ✗check_sequence_all_variable_scalar_1801 : 0x33394350
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✗check_sequence_all_variable_scalar_1801 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2024) = call @↓check_sequence_all_variable_scalar_2023()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2578/    if F.is_sequence_shape_unknown(x):/
}
# Order:
#   1: @✗check_sequence_all_variable_scalar_1801:CNode_2024{[0]: ValueNode<FuncGraph> ↓check_sequence_all_variable_scalar_2023}
#   2: @✗check_sequence_all_variable_scalar_1801:CNode_2025{[0]: ValueNode<Primitive> Return, [1]: CNode_2024}


subgraph attr:
subgraph instance: ↻↓max_tensor_1812 : 0x3781bb50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @↻↓max_tensor_1812 parent: [subgraph @↵↓max_tensor_1423]() {
  %1(CNode_1810) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para331_@CNode_1810, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %2(CNode_2026) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
  %3(CNode_2027) = ClassType()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2532/        max_tensor_data = P.Maximum()(max_tensor_data, input_data)/
  %4(CNode_2028) = call @ms_iter_97(%para250_фdata)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %5(input_data) = S_Prim_getitem(%4, %para331_@CNode_1810)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  %6(max_tensor_data) = %3(%para332_фmax_tensor_data, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2532/        max_tensor_data = P.Maximum()(max_tensor_data, input_data)/
  %7(CNode_2029) = call @↵↓max_tensor_1423(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2651/            return max_tensor(*data)/
  %8(CNode_2030) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2531/    for input_data in data:/
}
# Order:
#   1: @↻↓max_tensor_1812:CNode_2028{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_фdata}
#   2: @↻↓max_tensor_1812:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2028, [2]: param_@CNode_1810}
#   3: @↻↓max_tensor_1812:CNode_1810{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_1810, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓max_tensor_1812:CNode_2027{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Maximum'}
#   5: @↻↓max_tensor_1812:max_tensor_data{[0]: CNode_2027, [1]: param_фmax_tensor_data, [2]: input_data}
#   6: @↻↓max_tensor_1812:CNode_2031{[0]: ValueNode<Primitive> Return, [1]: CNode_2030}
#   7: @↻↓max_tensor_1812:CNode_2029{[0]: ValueNode<FuncGraph> ↵↓max_tensor_1423, [1]: CNode_1810, [2]: max_tensor_data}


subgraph attr:
subgraph instance: 2↓max_tensor_1813 : 0x37d35450
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2526/def max_tensor(*data):/
subgraph @2↓max_tensor_1813 parent: [subgraph @↵↓max_tensor_1423]() {
  Return(%para332_фmax_tensor_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2533/    return max_tensor_data/
}
# Order:
#   1: @2↓max_tensor_1813:CNode_2032{[0]: ValueNode<Primitive> Return, [1]: param_фmax_tensor_data}


subgraph attr:
subgraph instance: 2✓↻get_tensor_num_1826 : 0x37b77de0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @2✓↻get_tensor_num_1826 parent: [subgraph @↵get_tensor_num_1157]() {
  %1(CNode_2033) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("The truth value of an array with more than one element is ambiguous.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2559/                const_utils.raise_value_error(/
  %2(CNode_2034) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
  %3(CNode_2036) = call @↓✓↻get_tensor_num_2035()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  %4(CNode_2037) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2559/                const_utils.raise_value_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2559/                const_utils.raise_value_error(/
}
# Order:
#   1: @2✓↻get_tensor_num_1826:CNode_2033{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> The truth value of an array with more than one element is ambiguous.}
#   2: @2✓↻get_tensor_num_1826:CNode_2038{[0]: ValueNode<Primitive> Return, [1]: CNode_2037}
#   3: @2✓↻get_tensor_num_1826:CNode_2036{[0]: ValueNode<FuncGraph> ↓✓↻get_tensor_num_2035}


subgraph attr:
subgraph instance: ✗✓↻get_tensor_num_1827 : 0x37582300
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @✗✓↻get_tensor_num_1827 parent: [subgraph @↵get_tensor_num_1157]() {
  %1(CNode_2039) = call @↓✓↻get_tensor_num_2035()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @✗✓↻get_tensor_num_1827:CNode_2040{[0]: ValueNode<Primitive> Return, [1]: CNode_2039}
#   2: @✗✓↻get_tensor_num_1827:CNode_2039{[0]: ValueNode<FuncGraph> ↓✓↻get_tensor_num_2035}


subgraph attr:
subgraph instance: ↰✓↻get_tensor_num_1821 : 0x33476020
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↰✓↻get_tensor_num_1821 parent: [subgraph @✓↻get_tensor_num_1434]() {
  %1(CNode_1430) = $(↻get_tensor_num_1273):call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(input_data) = $(↻get_tensor_num_1273):S_Prim_getitem(%1, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(tensor_shape) = $(✓↻get_tensor_num_1434):call @shape_1142(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
  %4(tensor_shape_len) = $(✓↻get_tensor_num_1434):S_Prim_inner_len(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2557/            tensor_shape_len = len(tensor_shape)/
  %5(CNode_2041) = S_Prim_equal(%4, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %6(CNode_2042) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %7(CNode_2043) = Switch(%6, @2↰✓↻get_tensor_num_2044, @↱↰✓↻get_tensor_num_2045)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %8(CNode_2046) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %9(CNode_2047) = S_Prim_logical_not(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @↰✓↻get_tensor_num_1821:CNode_2041{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 1}
#   2: @↰✓↻get_tensor_num_1821:CNode_2042{[0]: ValueNode<Primitive> Cond, [1]: CNode_2041, [2]: ValueNode<BoolImm> false}
#   3: @↰✓↻get_tensor_num_1821:CNode_2043{[0]: ValueNode<Primitive> Switch, [1]: CNode_2042, [2]: ValueNode<FuncGraph> 2↰✓↻get_tensor_num_2044, [3]: ValueNode<FuncGraph> ↱↰✓↻get_tensor_num_2045}
#   4: @↰✓↻get_tensor_num_1821:CNode_2046{[0]: CNode_2043}
#   5: @↰✓↻get_tensor_num_1821:CNode_2047{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_2046}
#   6: @↰✓↻get_tensor_num_1821:CNode_2048{[0]: ValueNode<Primitive> Return, [1]: CNode_2047}


subgraph attr:
subgraph instance: ↱✓↻get_tensor_num_1822 : 0x375a9570
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↱✓↻get_tensor_num_1822 parent: [subgraph @✓↻get_tensor_num_1434]() {
  %1(CNode_1430) = $(↻get_tensor_num_1273):call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(input_data) = $(↻get_tensor_num_1273):S_Prim_getitem(%1, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(tensor_shape) = $(✓↻get_tensor_num_1434):call @shape_1142(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
  %4(tensor_shape_len) = $(✓↻get_tensor_num_1434):S_Prim_inner_len(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2557/            tensor_shape_len = len(tensor_shape)/
  %5(CNode_1818) = $(✓↻get_tensor_num_1434):S_Prim_not_equal(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @↱✓↻get_tensor_num_1822:CNode_2049{[0]: ValueNode<Primitive> Return, [1]: CNode_1818}


subgraph attr:
subgraph instance: ✓2↓✓2✗ms_max_1832 : 0x37c6c0f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✓2↓✓2✗ms_max_1832 parent: [subgraph @ms_max_436]() {
  %1(CNode_2050) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("The truth value of an array with more than one element is ambiguous.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2657/            const_utils.raise_value_error(/
  %2(CNode_2051) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
  %3(CNode_2053) = call @3↓✓2✗ms_max_2052()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  %4(CNode_2054) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2657/            const_utils.raise_value_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2657/            const_utils.raise_value_error(/
}
# Order:
#   1: @✓2↓✓2✗ms_max_1832:CNode_2050{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> The truth value of an array with more than one element is ambiguous.}
#   2: @✓2↓✓2✗ms_max_1832:CNode_2055{[0]: ValueNode<Primitive> Return, [1]: CNode_2054}
#   3: @✓2↓✓2✗ms_max_1832:CNode_2053{[0]: ValueNode<FuncGraph> 3↓✓2✗ms_max_2052}


subgraph attr:
subgraph instance: ✗2↓✓2✗ms_max_1833 : 0x37dddb80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @✗2↓✓2✗ms_max_1833 parent: [subgraph @ms_max_436]() {
  %1(CNode_501) = call @3↓✓2✗ms_max_2052()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
}
# Order:
#   1: @✗2↓✓2✗ms_max_1833:CNode_502{[0]: ValueNode<Primitive> Return, [1]: CNode_501}
#   2: @✗2↓✓2✗ms_max_1833:CNode_501{[0]: ValueNode<FuncGraph> 3↓✓2✗ms_max_2052}


subgraph attr:
subgraph instance: exist_tensor_1831 : 0x37c778e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @exist_tensor_1831(%para368_data) {
  %1(CNode_2057) = call @↵exist_tensor_2056(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
}
# Order:
#   1: @exist_tensor_1831:CNode_2058{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @exist_tensor_1831:CNode_2059{[0]: ValueNode<Primitive> Return, [1]: CNode_2057}
#   3: @exist_tensor_1831:CNode_2057{[0]: ValueNode<FuncGraph> ↵exist_tensor_2056, [1]: ValueNode<Int64Imm> 0}


subgraph attr:
subgraph instance: ✓mindspore_nn_loss_loss_CTCLoss_construct_1842 : 0x397cb630
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @✓mindspore_nn_loss_loss_CTCLoss_construct_1842 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467]() {
  %1(CNode_2061) = call @_check_ctcloss_targets_shape_2060(%para335_targets)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2692/            _check_ctcloss_targets_shape(targets)/
  %2(CNode_2062) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
  %3(CNode_2063) = getattr(%para335_targets, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
  %4(CNode_2064) = S_Prim_equal(%3, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
  %5(CNode_2065) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
  %6(CNode_2066) = Switch(%5, @2✓mindspore_nn_loss_loss_CTCLoss_construct_2067, @✗✓mindspore_nn_loss_loss_CTCLoss_construct_2068)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
  %7(CNode_2069) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
  %8(CNode_2071) = call @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:693/                        loss = loss_fn(logits, seq_label, current_data_len, label_len_tensor)/
  %9(CNode_2072) = Depend[side_effect_propagate: I64(1)](%8, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:693/                        loss = loss_fn(logits, seq_label, current_data_len, label_len_tensor)/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
}
# Order:
#   1: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2061{[0]: ValueNode<FuncGraph> _check_ctcloss_targets_shape_2060, [1]: param_targets}
#   2: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2063{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> ndim}
#   3: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2064{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2063, [2]: ValueNode<Int64Imm> 1}
#   4: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2065{[0]: ValueNode<Primitive> Cond, [1]: CNode_2064, [2]: ValueNode<BoolImm> false}
#   5: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2066{[0]: ValueNode<Primitive> Switch, [1]: CNode_2065, [2]: ValueNode<FuncGraph> 2✓mindspore_nn_loss_loss_CTCLoss_construct_2067, [3]: ValueNode<FuncGraph> ✗✓mindspore_nn_loss_loss_CTCLoss_construct_2068}
#   6: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2069{[0]: CNode_2066}
#   7: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2071{[0]: ValueNode<FuncGraph> ↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070, [1]: CNode_2069}
#   8: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2072{[0]: ValueNode<Primitive> Depend, [1]: CNode_2071, [2]: CNode_2062}
#   9: @✓mindspore_nn_loss_loss_CTCLoss_construct_1842:CNode_2073{[0]: ValueNode<Primitive> Return, [1]: CNode_2072}


subgraph attr:
subgraph instance: ✗mindspore_nn_loss_loss_CTCLoss_construct_1843 : 0x397b9740
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @✗mindspore_nn_loss_loss_CTCLoss_construct_1843 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467]() {
  %1(CNode_2075) = call @↓mindspore_nn_loss_loss_CTCLoss_construct_2074()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2691/        if log_probs.ndim == 2:/
}
# Order:
#   1: @✗mindspore_nn_loss_loss_CTCLoss_construct_1843:CNode_2075{[0]: ValueNode<FuncGraph> ↓mindspore_nn_loss_loss_CTCLoss_construct_2074}
#   2: @✗mindspore_nn_loss_loss_CTCLoss_construct_1843:CNode_2076{[0]: ValueNode<Primitive> Return, [1]: CNode_2075}


subgraph attr:
subgraph instance: 2✓ms_min_one_element_1860 : 0x3958ec60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @2✓ms_min_one_element_1860 parent: [subgraph @✓ms_min_one_element_1487]() {
  %1(CNode_2077) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("Cannot iterate over a scalar tensor.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2697/            const_utils.raise_type_error(/
  %2(CNode_2078) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_2080) = call @↓✓ms_min_one_element_2079()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  %4(CNode_2081) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2697/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2697/            const_utils.raise_type_error(/
}
# Order:
#   1: @2✓ms_min_one_element_1860:CNode_2077{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> Cannot iterate over a scalar tensor.}
#   2: @2✓ms_min_one_element_1860:CNode_2082{[0]: ValueNode<Primitive> Return, [1]: CNode_2081}
#   3: @2✓ms_min_one_element_1860:CNode_2080{[0]: ValueNode<FuncGraph> ↓✓ms_min_one_element_2079}


subgraph attr:
subgraph instance: ✗✓ms_min_one_element_1861 : 0x39587410
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗✓ms_min_one_element_1861 parent: [subgraph @✓ms_min_one_element_1487]() {
  %1(CNode_2083) = call @↓✓ms_min_one_element_2079()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2696/        if tensor_shape_len == 0:/
}
# Order:
#   1: @✗✓ms_min_one_element_1861:CNode_2084{[0]: ValueNode<Primitive> Return, [1]: CNode_2083}
#   2: @✗✓ms_min_one_element_1861:CNode_2083{[0]: ValueNode<FuncGraph> ↓✓ms_min_one_element_2079}


subgraph attr:
after_block : 1
subgraph instance: ↓ms_min_one_element_1864 : 0x395569c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @↓ms_min_one_element_1864 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2085) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
  %2(CNode_2086) = S_Prim_isinstance(%para257_x, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
  %3(CNode_2087) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
  %4(CNode_2088) = Switch(%3, @✓↓ms_min_one_element_2089, @✗↓ms_min_one_element_2090)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
  %5(CNode_2091) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
}
# Order:
#   1: @↓ms_min_one_element_1864:CNode_2085{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'list', [2]: ValueNode<ClassType> class 'tuple'}
#   2: @↓ms_min_one_element_1864:CNode_2086{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_x, [2]: CNode_2085}
#   3: @↓ms_min_one_element_1864:CNode_2087{[0]: ValueNode<Primitive> Cond, [1]: CNode_2086, [2]: ValueNode<BoolImm> false}
#   4: @↓ms_min_one_element_1864:CNode_2088{[0]: ValueNode<Primitive> Switch, [1]: CNode_2087, [2]: ValueNode<FuncGraph> ✓↓ms_min_one_element_2089, [3]: ValueNode<FuncGraph> ✗↓ms_min_one_element_2090}
#   5: @↓ms_min_one_element_1864:CNode_2091{[0]: CNode_2088}
#   6: @↓ms_min_one_element_1864:CNode_2092{[0]: ValueNode<Primitive> Return, [1]: CNode_2091}


subgraph attr:
subgraph instance: min_tensor_1868 : 0x3953f2d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @min_tensor_1868(%para369_data) {
  %1(CNode_2093) = S_Prim_inner_len(%para369_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
  %2(CNode_2094) = S_Prim_equal(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
  %3(CNode_2095) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
  %4(CNode_2096) = Switch(%3, @✓min_tensor_2097, @✗min_tensor_2098)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
  %5(CNode_2099) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
  %6(CNode_2101) = call @↓min_tensor_2100(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2734/            return min_tensor(*data)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
}
# Order:
#   1: @min_tensor_1868:CNode_2093{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_data}
#   2: @min_tensor_1868:CNode_2094{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2093, [2]: ValueNode<Int64Imm> 1}
#   3: @min_tensor_1868:CNode_2095{[0]: ValueNode<Primitive> Cond, [1]: CNode_2094, [2]: ValueNode<BoolImm> false}
#   4: @min_tensor_1868:CNode_2096{[0]: ValueNode<Primitive> Switch, [1]: CNode_2095, [2]: ValueNode<FuncGraph> ✓min_tensor_2097, [3]: ValueNode<FuncGraph> ✗min_tensor_2098}
#   5: @min_tensor_1868:CNode_2099{[0]: CNode_2096}
#   6: @min_tensor_1868:CNode_2101{[0]: ValueNode<FuncGraph> ↓min_tensor_2100, [1]: CNode_2099}
#   7: @min_tensor_1868:CNode_2102{[0]: ValueNode<Primitive> Return, [1]: CNode_2101}


subgraph attr:
after_block : 1
subgraph instance: ↓✓2✗ms_min_1871 : 0x3952ed80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↓✓2✗ms_min_1871 parent: [subgraph @✓2✗ms_min_1307]() {
  %1(tensor_num) = $(✓2✗ms_min_1307):call @get_tensor_num_1008(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2731/        tensor_num = get_tensor_num(data)/
  %2(CNode_2103) = S_Prim_not_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
  %3(CNode_2104) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
  %4(CNode_2105) = Switch(%3, @✓↓✓2✗ms_min_2106, @✗↓✓2✗ms_min_2107)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
  %5(CNode_2108) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
}
# Order:
#   1: @↓✓2✗ms_min_1871:CNode_2103{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_num, [2]: ValueNode<Int64Imm> 0}
#   2: @↓✓2✗ms_min_1871:CNode_2104{[0]: ValueNode<Primitive> Cond, [1]: CNode_2103, [2]: ValueNode<BoolImm> false}
#   3: @↓✓2✗ms_min_1871:CNode_2105{[0]: ValueNode<Primitive> Switch, [1]: CNode_2104, [2]: ValueNode<FuncGraph> ✓↓✓2✗ms_min_2106, [3]: ValueNode<FuncGraph> ✗↓✓2✗ms_min_2107}
#   4: @↓✓2✗ms_min_1871:CNode_2108{[0]: CNode_2105}
#   5: @↓✓2✗ms_min_1871:CNode_2109{[0]: ValueNode<Primitive> Return, [1]: CNode_2108}


subgraph attr:
after_block : 1
subgraph instance: ↓✗ms_min_1874 : 0x3951fba0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @↓✗ms_min_1874 parent: [subgraph @ms_min_962]() {
  %1(CNode_2110) = call @↓ms_min_1198()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2727/    elif len_data == 1:/
}
# Order:
#   1: @↓✗ms_min_1874:CNode_2111{[0]: ValueNode<Primitive> Return, [1]: CNode_2110}
#   2: @↓✗ms_min_1874:CNode_2110{[0]: ValueNode<FuncGraph> ↓ms_min_1198}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓check_axis_valid_1879 : 0x39686b60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
subgraph @↓check_axis_valid_1879() {
  Return(None)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:457/    def check_axis_valid(self, axis, ndim):/
}
# Order:
#   1: @↓check_axis_valid_1879:CNode_2112{[0]: ValueNode<Primitive> Return, [1]: ValueNode<None> None}


subgraph attr:
after_block : 1
subgraph instance: ↓flatten_1888 : 0x39691000
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↓flatten_1888 parent: [subgraph @flatten_1327]() {
  %1(CNode_2113) = S_Prim_isinstance(%para263_start_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %2(CNode_2114) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %3(CNode_2115) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %4(CNode_2116) = Switch(%3, @↰↓flatten_2117, @↱↓flatten_2118)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %5(CNode_2119) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %6(CNode_2120) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %7(CNode_2121) = Switch(%6, @✓↓flatten_2122, @✗↓flatten_2123)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %8(CNode_2124) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @↓flatten_1888:CNode_2113{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_start_dim, [2]: ValueNode<ClassType> class 'int'}
#   2: @↓flatten_1888:CNode_2114{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_2113}
#   3: @↓flatten_1888:CNode_2115{[0]: ValueNode<Primitive> Cond, [1]: CNode_2114, [2]: ValueNode<BoolImm> false}
#   4: @↓flatten_1888:CNode_2116{[0]: ValueNode<Primitive> Switch, [1]: CNode_2115, [2]: ValueNode<FuncGraph> ↰↓flatten_2117, [3]: ValueNode<FuncGraph> ↱↓flatten_2118}
#   5: @↓flatten_1888:CNode_2119{[0]: CNode_2116}
#   6: @↓flatten_1888:CNode_2120{[0]: ValueNode<Primitive> Cond, [1]: CNode_2119, [2]: ValueNode<BoolImm> false}
#   7: @↓flatten_1888:CNode_2121{[0]: ValueNode<Primitive> Switch, [1]: CNode_2120, [2]: ValueNode<FuncGraph> ✓↓flatten_2122, [3]: ValueNode<FuncGraph> ✗↓flatten_2123}
#   8: @↓flatten_1888:CNode_2124{[0]: CNode_2121}
#   9: @↓flatten_1888:CNode_2125{[0]: ValueNode<Primitive> Return, [1]: CNode_2124}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_conv_Conv2d_construct_1891 : 0x396728d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_conv_Conv2d_construct_1891 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1526]() {
  %1(output) = $(mindspore_nn_layer_conv_Conv2d_construct_1526):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para265_x, %para47_conv2d.layer4.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (512, 256, 3, 3), ref_key=:conv2d.layer4.0.weight>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @↓mindspore_nn_layer_conv_Conv2d_construct_1891:CNode_2126{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900 : 0x39660930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2128) = call @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
}
# Order:
#   1: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900:CNode_2128{[0]: ValueNode<FuncGraph> L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127}
#   2: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1900:CNode_2129{[0]: ValueNode<Primitive> Return, [1]: CNode_2128}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901 : 0x39659c70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2131) = call @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901:CNode_2131{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130}
#   2: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1901:CNode_2132{[0]: ValueNode<Primitive> Return, [1]: CNode_2131}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_conv_Conv2d_construct_1904 : 0x396666e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_conv_Conv2d_construct_1904 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1538]() {
  %1(CNode_2134) = call @L_↓mindspore_nn_layer_conv_Conv2d_construct_2133()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1904:CNode_2134{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv2d_construct_2133}
#   2: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1904:CNode_2135{[0]: ValueNode<Primitive> Return, [1]: CNode_2134}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_conv_Conv2d_construct_1912 : 0x39649ea0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_conv_Conv2d_construct_1912 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1563]() {
  %1(output) = $(mindspore_nn_layer_conv_Conv2d_construct_1563):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para276_x, %para29_conv2d.layer3.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (256, 128, 3, 3), ref_key=:conv2d.layer3.0.weight>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @↓mindspore_nn_layer_conv_Conv2d_construct_1912:CNode_2136{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921 : 0x3962b330
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2138) = call @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
}
# Order:
#   1: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921:CNode_2138{[0]: ValueNode<FuncGraph> L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137}
#   2: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1921:CNode_2139{[0]: ValueNode<Primitive> Return, [1]: CNode_2138}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922 : 0x39624670
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2141) = call @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922:CNode_2141{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140}
#   2: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1922:CNode_2142{[0]: ValueNode<Primitive> Return, [1]: CNode_2141}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_conv_Conv2d_construct_1925 : 0x39631560
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_conv_Conv2d_construct_1925 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1575]() {
  %1(CNode_2144) = call @L_↓mindspore_nn_layer_conv_Conv2d_construct_2143()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1925:CNode_2144{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv2d_construct_2143}
#   2: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1925:CNode_2145{[0]: ValueNode<Primitive> Return, [1]: CNode_2144}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_conv_Conv2d_construct_1933 : 0x39614260
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_conv_Conv2d_construct_1933 parent: [subgraph @mindspore_nn_layer_conv_Conv2d_construct_1627]() {
  %1(output) = $(mindspore_nn_layer_conv_Conv2d_construct_1627):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(2), I64(2)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para296_x, %para17_conv2d.layer2.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (128, 64, 3, 3), ref_key=:conv2d.layer2.0.weight>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @↓mindspore_nn_layer_conv_Conv2d_construct_1933:CNode_2146{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942 : 0x395fded0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2148) = call @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
}
# Order:
#   1: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942:CNode_2148{[0]: ValueNode<FuncGraph> L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147}
#   2: @L_✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1942:CNode_2149{[0]: ValueNode<Primitive> Return, [1]: CNode_2148}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943 : 0x395f7210
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2151) = call @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943:CNode_2151{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150}
#   2: @L_✗mindspore_nn_layer_normalization_BatchNorm2d_construct_1943:CNode_2152{[0]: ValueNode<Primitive> Return, [1]: CNode_2151}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_conv_Conv2d_construct_1946 : 0x39603e00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_conv_Conv2d_construct_1946 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1639]() {
  %1(CNode_2154) = call @L_↓mindspore_nn_layer_conv_Conv2d_construct_2153()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1946:CNode_2154{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv2d_construct_2153}
#   2: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1946:CNode_2155{[0]: ValueNode<Primitive> Return, [1]: CNode_2154}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_conv_Conv2d_construct_1954 : 0x395dd9c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_conv_Conv2d_construct_1954 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1674]() {
  %1(CNode_2157) = call @L_↓mindspore_nn_layer_conv_Conv2d_construct_2156()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:362/        if self.has_bias:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1954:CNode_2157{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv2d_construct_2156}
#   2: @L_✗mindspore_nn_layer_conv_Conv2d_construct_1954:CNode_2158{[0]: ValueNode<Primitive> Return, [1]: CNode_2157}


subgraph attr:
training : 1
subgraph instance: ✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962 : 0x395be770
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709]() {
  %1(CNode_2159) = getattr(%para361_фx, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %2(x) = %1(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %3(out) = S_Prim_MaxPool3DWithArgmax[strides: (I64(1), I64(2), I64(2)), input_names: ["x"], argmax_type: "int64", pads: (I64(0), I64(1), I64(1)), ceil_mode: Bool(0), dilation: (I64(1), I64(1), I64(1)), ksize: (I64(1), I64(3), I64(3)), output_names: ["y", "argmax"], format: "NCDHW"](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:575/            out = self.max_pool(x)/
  %4(CNode_2160) = S_Prim_isinstance(%3, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:576/            if isinstance(out, tuple):/
  %5(CNode_2161) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:576/            if isinstance(out, tuple):/
  %6(CNode_2162) = Switch(%5, @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163, @✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:576/            if isinstance(out, tuple):/
  %7(CNode_2165) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:576/            if isinstance(out, tuple):/
  %8(CNode_2167) = call @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:576/            if isinstance(out, tuple):/
}
# Order:
#   1: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2159{[0]: ValueNode<Primitive> getattr, [1]: param_фx, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:x{[0]: CNode_2159, [1]: ValueNode<Int64Imm> 2}
#   3: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool3DWithArgmax, [1]: x}
#   4: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2160{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: out, [2]: ValueNode<ClassType> class 'tuple'}
#   5: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2161{[0]: ValueNode<Primitive> Cond, [1]: CNode_2160, [2]: ValueNode<BoolImm> false}
#   6: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2162{[0]: ValueNode<Primitive> Switch, [1]: CNode_2161, [2]: ValueNode<FuncGraph> 2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163, [3]: ValueNode<FuncGraph> ✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164}
#   7: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2165{[0]: CNode_2162}
#   8: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2167{[0]: ValueNode<FuncGraph> ↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166, [1]: CNode_2165}
#   9: @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962:CNode_2168{[0]: ValueNode<Primitive> Return, [1]: CNode_2167}


subgraph attr:
training : 1
subgraph instance: L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965 : 0x395b5980
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_2169) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para321_x, %para322_L_conv2d.bn1.gamma, %para323_L_conv2d.bn1.beta, %para324_L_conv2d.bn1.moving_mean, %para325_L_conv2d.bn1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  %2(CNode_2170) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
}
# Order:
#   1: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965:CNode_2169{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.bn1.gamma, [3]: param_L_conv2d.bn1.beta, [4]: param_L_conv2d.bn1.moving_mean, [5]: param_L_conv2d.bn1.moving_variance}
#   2: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965:CNode_2170{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2169, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_1965:CNode_2171{[0]: ValueNode<Primitive> Return, [1]: CNode_2170}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968 : 0x395aeb60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_2172) = Cond(None, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %2(CNode_2173) = Switch(%1, @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174, @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %3(CNode_2176) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968:CNode_2172{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<None> None, [2]: ValueNode<BoolImm> false}
#   2: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968:CNode_2173{[0]: ValueNode<Primitive> Switch, [1]: CNode_2172, [2]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174, [3]: ValueNode<FuncGraph> L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175}
#   3: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968:CNode_2176{[0]: CNode_2173}
#   4: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_1968:CNode_2177{[0]: ValueNode<Primitive> Return, [1]: CNode_2176}


subgraph attr:
training : 1
subgraph instance: ✓pad_sequence_1977 : 0x394eaa60
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @✓pad_sequence_1977 parent: [subgraph @pad_sequence_1730]() {
  %1(CNode_1973) = $(pad_sequence_1730):ClassType(%para364_length)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %2(target_length) = $(pad_sequence_1730):call @ms_max_436(I64(1), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %3(CNode_2178) = S_Prim_make_slice(None, %2, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:65/            return tensor[:target_length]/
  %4(CNode_2179) = S_Prim_getitem(%para363_tensor, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:65/            return tensor[:target_length]/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:65/            return tensor[:target_length]/
}
# Order:
#   1: @✓pad_sequence_1977:CNode_2178{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: target_length, [3]: ValueNode<None> None}
#   2: @✓pad_sequence_1977:CNode_2179{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_tensor, [2]: CNode_2178}
#   3: @✓pad_sequence_1977:CNode_2180{[0]: ValueNode<Primitive> Return, [1]: CNode_2179}


subgraph attr:
training : 1
subgraph instance: ✗pad_sequence_1978 : 0x394dd680
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @✗pad_sequence_1978 parent: [subgraph @pad_sequence_1730]() {
  %1(CNode_2182) = call @↓pad_sequence_2181()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:64/        if current_length >= target_length:/
}
# Order:
#   1: @✗pad_sequence_1978:CNode_2182{[0]: ValueNode<FuncGraph> ↓pad_sequence_2181}
#   2: @✗pad_sequence_1978:CNode_2183{[0]: ValueNode<Primitive> Return, [1]: CNode_2182}


subgraph attr:
training : 1
subgraph instance: modules_TemporalConv_construct_1984 : 0x38f5bff0
# In file /data/shengteng/training/modules.py:67/    def construct(self, frame_feat, lgt):/
subgraph @modules_TemporalConv_construct_1984 parent: [subgraph @after_grad_108](%para370_frame_feat, %para371_lgt) {
  %1(CNode_2184) = S_Prim_MakeTuple("visual_feat", "feat_len")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  %2(visual_feat) = call @mindspore_nn_layer_container_SequentialCell_construct_2185(%para370_frame_feat)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:69/        visual_feat = self.temporal_conv(frame_feat)/
  %3(CNode_2186) = S_Prim_MakeTuple(%2, %para371_lgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  %4(CNode_2187) = S_Prim_make_dict(%1, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
}
# Order:
#   1: @modules_TemporalConv_construct_1984:visual_feat{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_2185, [1]: param_frame_feat}
#   2: @modules_TemporalConv_construct_1984:CNode_2184{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> visual_feat, [2]: ValueNode<StringImm> feat_len}
#   3: @modules_TemporalConv_construct_1984:CNode_2186{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: visual_feat, [2]: param_lgt}
#   4: @modules_TemporalConv_construct_1984:CNode_2187{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_2184, [2]: CNode_2186}
#   5: @modules_TemporalConv_construct_1984:CNode_2188{[0]: ValueNode<Primitive> Return, [1]: CNode_2187}


subgraph attr:
training : 1
subgraph instance: ↵9↓tfnet_model_TFNetModel_construct_1981 : 0x378ce130
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵9↓tfnet_model_TFNetModel_construct_1981 parent: [subgraph @9↓tfnet_model_TFNetModel_construct_1746](%para372_, %para373_) {
  %1(CNode_1985) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_make_list("K5", "P2", "K5", "P2")
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %2(CNode_1986) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %3(CNode_2189) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para372_@CNode_2190, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %4(CNode_2191) = Switch(%3, @↻9↓tfnet_model_TFNetModel_construct_2192, @10↓tfnet_model_TFNetModel_construct_2193)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %5(CNode_2194) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
}
# Order:
#   1: @↵9↓tfnet_model_TFNetModel_construct_1981:CNode_2189{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2190, [2]: CNode_1986}
#   2: @↵9↓tfnet_model_TFNetModel_construct_1981:CNode_2191{[0]: ValueNode<Primitive> Switch, [1]: CNode_2189, [2]: ValueNode<FuncGraph> ↻9↓tfnet_model_TFNetModel_construct_2192, [3]: ValueNode<FuncGraph> 10↓tfnet_model_TFNetModel_construct_2193}
#   3: @↵9↓tfnet_model_TFNetModel_construct_1981:CNode_2194{[0]: CNode_2191}
#   4: @↵9↓tfnet_model_TFNetModel_construct_1981:CNode_2195{[0]: ValueNode<Primitive> Return, [1]: CNode_2194}


subgraph attr:
after_block : 1
subgraph instance: ↓get_data_type_str_2002 : 0x37a34e00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2594/def get_data_type_str(input_data):/
subgraph @↓get_data_type_str_2002 parent: [subgraph @get_data_type_str_1401]() {
  %1(CNode_2196) = S_Prim_typeof(%para328_input_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2598/    return str(F.typeof(input_data))/
  %2(CNode_2197) = ClassType(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2598/    return str(F.typeof(input_data))/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2598/    return str(F.typeof(input_data))/
}
# Order:
#   1: @↓get_data_type_str_2002:CNode_2196{[0]: ValueNode<DoSignaturePrimitive> S_Prim_typeof, [1]: param_input_data}
#   2: @↓get_data_type_str_2002:CNode_2197{[0]: ValueNode<ClassType> class 'str', [1]: CNode_2196}
#   3: @↓get_data_type_str_2002:CNode_2198{[0]: ValueNode<Primitive> Return, [1]: CNode_2197}


subgraph attr:
subgraph instance: ✓↓✓↓ms_max_one_element_2012 : 0x375aa680
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓↓✓↓ms_max_one_element_2012 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_2199) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("max() arg is an empty sequence.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2625/            const_utils.raise_value_error("max() arg is an empty sequence.")/
  %2(CNode_2200) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_2202) = call @2↓✓↓ms_max_one_element_2201()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  %4(CNode_2203) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2625/            const_utils.raise_value_error("max() arg is an empty sequence.")/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2625/            const_utils.raise_value_error("max() arg is an empty sequence.")/
}
# Order:
#   1: @✓↓✓↓ms_max_one_element_2012:CNode_2199{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> max() arg is an empty sequence.}
#   2: @✓↓✓↓ms_max_one_element_2012:CNode_2204{[0]: ValueNode<Primitive> Return, [1]: CNode_2203}
#   3: @✓↓✓↓ms_max_one_element_2012:CNode_2202{[0]: ValueNode<FuncGraph> 2↓✓↓ms_max_one_element_2201}


subgraph attr:
subgraph instance: ✗↓✓↓ms_max_one_element_2013 : 0x375db2d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗↓✓↓ms_max_one_element_2013 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_2205) = call @2↓✓↓ms_max_one_element_2201()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2624/        if len(x) == 0:/
}
# Order:
#   1: @✗↓✓↓ms_max_one_element_2013:CNode_2206{[0]: ValueNode<Primitive> Return, [1]: CNode_2205}
#   2: @✗↓✓↓ms_max_one_element_2013:CNode_2205{[0]: ValueNode<FuncGraph> 2↓✓↓ms_max_one_element_2201}


subgraph attr:
subgraph instance: 2✓check_sequence_all_variable_scalar_2019 : 0x37afeba0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @2✓check_sequence_all_variable_scalar_2019 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2207) = S_Prim_add(%para330_str_info, "() arg is an empty sequence.")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2580/            const_utils.raise_value_error(str_info + "() arg is an empty sequence.")/
  %2(CNode_2208) = S_Prim_raise_value_error[constexpr_prim: Bool(1)](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2580/            const_utils.raise_value_error(str_info + "() arg is an empty sequence.")/
  %3(CNode_2209) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
  %4(CNode_2211) = call @↓✓check_sequence_all_variable_scalar_2210()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  %5(CNode_2212) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2580/            const_utils.raise_value_error(str_info + "() arg is an empty sequence.")/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2580/            const_utils.raise_value_error(str_info + "() arg is an empty sequence.")/
}
# Order:
#   1: @2✓check_sequence_all_variable_scalar_2019:CNode_2207{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_str_info, [2]: ValueNode<StringImm> () arg is an empty sequence.}
#   2: @2✓check_sequence_all_variable_scalar_2019:CNode_2208{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: CNode_2207}
#   3: @2✓check_sequence_all_variable_scalar_2019:CNode_2213{[0]: ValueNode<Primitive> Return, [1]: CNode_2212}
#   4: @2✓check_sequence_all_variable_scalar_2019:CNode_2211{[0]: ValueNode<FuncGraph> ↓✓check_sequence_all_variable_scalar_2210}


subgraph attr:
subgraph instance: ✗✓check_sequence_all_variable_scalar_2020 : 0x376654c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✗✓check_sequence_all_variable_scalar_2020 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2214) = call @↓✓check_sequence_all_variable_scalar_2210()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2579/        if F.is_dynamic_sequence_element_unknown(x):/
}
# Order:
#   1: @✗✓check_sequence_all_variable_scalar_2020:CNode_2215{[0]: ValueNode<Primitive> Return, [1]: CNode_2214}
#   2: @✗✓check_sequence_all_variable_scalar_2020:CNode_2214{[0]: ValueNode<FuncGraph> ↓✓check_sequence_all_variable_scalar_2210}


subgraph attr:
after_block : 1
subgraph instance: ↓check_sequence_all_variable_scalar_2023 : 0x37d9ae10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↓check_sequence_all_variable_scalar_2023 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2217) = call @↵↓check_sequence_all_variable_scalar_2216(I64(0), Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
}
# Order:
#   1: @↓check_sequence_all_variable_scalar_2023:CNode_2218{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   2: @↓check_sequence_all_variable_scalar_2023:CNode_2219{[0]: ValueNode<Primitive> Return, [1]: CNode_2217}
#   3: @↓check_sequence_all_variable_scalar_2023:CNode_2217{[0]: ValueNode<FuncGraph> ↵↓check_sequence_all_variable_scalar_2216, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<BoolImm> false}


subgraph attr:
after_block : 1
subgraph instance: ↓✓↻get_tensor_num_2035 : 0x37c44070
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↓✓↻get_tensor_num_2035 parent: [subgraph @↵get_tensor_num_1157]() {
  %1(tensor_num) = S_Prim_add(%para235_фtensor_num, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2561/            tensor_num = tensor_num + 1/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
}
# Order:
#   1: @↓✓↻get_tensor_num_2035:tensor_num{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_фtensor_num, [2]: ValueNode<Int64Imm> 1}
#   2: @↓✓↻get_tensor_num_2035:CNode_2220{[0]: ValueNode<Primitive> Return, [1]: tensor_num}


subgraph attr:
subgraph instance: 2↰✓↻get_tensor_num_2044 : 0x37b93be0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @2↰✓↻get_tensor_num_2044 parent: [subgraph @✓↻get_tensor_num_1434]() {
  %1(CNode_1430) = $(↻get_tensor_num_1273):call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(input_data) = $(↻get_tensor_num_1273):S_Prim_getitem(%1, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(tensor_shape) = $(✓↻get_tensor_num_1434):call @shape_1142(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
  %4(CNode_2221) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  %5(CNode_2222) = S_Prim_equal(%4, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @2↰✓↻get_tensor_num_2044:CNode_2221{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: tensor_shape, [2]: ValueNode<Int64Imm> 0}
#   2: @2↰✓↻get_tensor_num_2044:CNode_2222{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2221, [2]: ValueNode<Int64Imm> 1}
#   3: @2↰✓↻get_tensor_num_2044:CNode_2223{[0]: ValueNode<Primitive> Return, [1]: CNode_2222}


subgraph attr:
subgraph instance: ↱↰✓↻get_tensor_num_2045 : 0x373a7ee0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2551/def get_tensor_num(data):/
subgraph @↱↰✓↻get_tensor_num_2045 parent: [subgraph @↰✓↻get_tensor_num_1821]() {
  %1(CNode_1430) = $(↻get_tensor_num_1273):call @ms_iter_97(%para223_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %2(input_data) = $(↻get_tensor_num_1273):S_Prim_getitem(%1, %para234_@CNode_1271)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2554/    for input_data in data:/
  %3(tensor_shape) = $(✓↻get_tensor_num_1434):call @shape_1142(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2556/            tensor_shape = F.shape(input_data)/
  %4(tensor_shape_len) = $(✓↻get_tensor_num_1434):S_Prim_inner_len(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2557/            tensor_shape_len = len(tensor_shape)/
  %5(CNode_2041) = $(↰✓↻get_tensor_num_1821):S_Prim_equal(%4, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2558/            if tensor_shape_len != 0 and not (tensor_shape_len == 1 and tensor_shape[0] == 1):/
}
# Order:
#   1: @↱↰✓↻get_tensor_num_2045:CNode_2224{[0]: ValueNode<Primitive> Return, [1]: CNode_2041}


subgraph attr:
after_block : 1
subgraph instance: 3↓✓2✗ms_max_2052 : 0x37c896b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2639/def ms_max(*data):/
subgraph @3↓✓2✗ms_max_2052 parent: [subgraph @ms_max_436]() {
  %1(CNode_503) = call @↓2✗ms_max_1011()
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:685/                            logits = ops.zeros((max(1, logits.shape[0]), max(1, logits.shape[1]), 3512), ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2648/        tensor_num = get_tensor_num(data)/
}
# Order:
#   1: @3↓✓2✗ms_max_2052:CNode_504{[0]: ValueNode<Primitive> Return, [1]: CNode_503}
#   2: @3↓✓2✗ms_max_2052:CNode_503{[0]: ValueNode<FuncGraph> ↓2✗ms_max_1011}


subgraph attr:
subgraph instance: ↵exist_tensor_2056 : 0x37c82000
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @↵exist_tensor_2056 parent: [subgraph @exist_tensor_1831](%para374_) {
  %1(CNode_2058) = $(exist_tensor_1831):S_Prim_inner_len(%para368_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %2(CNode_2225) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para374_@CNode_2226, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %3(CNode_2227) = Switch(%2, @↻exist_tensor_2228, @↓exist_tensor_2229)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %4(CNode_2230) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
}
# Order:
#   1: @↵exist_tensor_2056:CNode_2225{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2226, [2]: CNode_2058}
#   2: @↵exist_tensor_2056:CNode_2227{[0]: ValueNode<Primitive> Switch, [1]: CNode_2225, [2]: ValueNode<FuncGraph> ↻exist_tensor_2228, [3]: ValueNode<FuncGraph> ↓exist_tensor_2229}
#   3: @↵exist_tensor_2056:CNode_2230{[0]: CNode_2227}
#   4: @↵exist_tensor_2056:CNode_2231{[0]: ValueNode<Primitive> Return, [1]: CNode_2230}


subgraph attr:
subgraph instance: _check_ctcloss_targets_shape_2060 : 0x397cf3d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @_check_ctcloss_targets_shape_2060(%para375_targets) {
  %1(CNode_2232) = getattr(%para375_targets, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  %2(CNode_2233) = S_Prim_greater(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  %3(CNode_2234) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  %4(CNode_2235) = Switch(%3, @✓_check_ctcloss_targets_shape_2236, @✗_check_ctcloss_targets_shape_2237)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  %5(CNode_2238) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
}
# Order:
#   1: @_check_ctcloss_targets_shape_2060:CNode_2232{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> ndim}
#   2: @_check_ctcloss_targets_shape_2060:CNode_2233{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_2232, [2]: ValueNode<Int64Imm> 2}
#   3: @_check_ctcloss_targets_shape_2060:CNode_2234{[0]: ValueNode<Primitive> Cond, [1]: CNode_2233, [2]: ValueNode<BoolImm> false}
#   4: @_check_ctcloss_targets_shape_2060:CNode_2235{[0]: ValueNode<Primitive> Switch, [1]: CNode_2234, [2]: ValueNode<FuncGraph> ✓_check_ctcloss_targets_shape_2236, [3]: ValueNode<FuncGraph> ✗_check_ctcloss_targets_shape_2237}
#   5: @_check_ctcloss_targets_shape_2060:CNode_2238{[0]: CNode_2235}
#   6: @_check_ctcloss_targets_shape_2060:CNode_2239{[0]: ValueNode<Primitive> Return, [1]: CNode_2238}


subgraph attr:
after_block : 1
subgraph instance: ↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070 : 0x397df530
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467](%para376_) {
  %1(CNode_2240) = getattr(%para334_log_probs, "expand_dims")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2695/            log_probs = log_probs.expand_dims(-2)/
  %2(CNode_2241) = S_Prim_negative(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2695/            log_probs = log_probs.expand_dims(-2)/
  %3(log_probs) = %1(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2695/            log_probs = log_probs.expand_dims(-2)/
  %4(CNode_2243) = call @ctc_loss_2242(%3, %para376_фtargets, %para336_input_lengths, %para337_target_lengths, I64(0), "mean", Bool(0))
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2696/            neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  %5(neg_log_hood) = S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2696/            neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  %6(CNode_2244) = getattr(%5, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
  %7(CNode_2245) = S_Prim_MakeTuple("axis")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
  %8(CNode_2246) = S_Prim_MakeTuple(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
  %9(CNode_2247) = S_Prim_make_dict(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
  %10(CNode_2248) = UnpackCall_unpack_call(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2698/            return neg_log_hood.squeeze(axis=0)/
}
# Order:
#   1: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2240{[0]: ValueNode<Primitive> getattr, [1]: param_log_probs, [2]: ValueNode<StringImm> expand_dims}
#   2: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2241{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 2}
#   3: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:log_probs{[0]: CNode_2240, [1]: CNode_2241}
#   4: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2243{[0]: ValueNode<FuncGraph> ctc_loss_2242, [1]: log_probs, [2]: param_фtargets, [3]: param_input_lengths, [4]: param_target_lengths, [5]: ValueNode<Int64Imm> 0, [6]: ValueNode<StringImm> mean, [7]: ValueNode<BoolImm> false}
#   5: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:neg_log_hood{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2243, [2]: ValueNode<Int64Imm> 0}
#   6: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2244{[0]: ValueNode<Primitive> getattr, [1]: neg_log_hood, [2]: ValueNode<StringImm> squeeze}
#   7: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2245{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> axis}
#   8: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2246{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0}
#   9: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2247{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_2245, [2]: CNode_2246}
#  10: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2248{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.2249, [1]: CNode_2244, [2]: CNode_2247}
#  11: @↓✓mindspore_nn_loss_loss_CTCLoss_construct_2070:CNode_2250{[0]: ValueNode<Primitive> Return, [1]: CNode_2248}


subgraph attr:
subgraph instance: 2✓mindspore_nn_loss_loss_CTCLoss_construct_2067 : 0x397de050
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @2✓mindspore_nn_loss_loss_CTCLoss_construct_2067 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467]() {
  %1(CNode_2251) = getattr(%para335_targets, "expand_dims")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2694/                targets = targets.expand_dims(0)/
  %2(targets) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2694/                targets = targets.expand_dims(0)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2694/                targets = targets.expand_dims(0)/
}
# Order:
#   1: @2✓mindspore_nn_loss_loss_CTCLoss_construct_2067:CNode_2251{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> expand_dims}
#   2: @2✓mindspore_nn_loss_loss_CTCLoss_construct_2067:targets{[0]: CNode_2251, [1]: ValueNode<Int64Imm> 0}
#   3: @2✓mindspore_nn_loss_loss_CTCLoss_construct_2067:CNode_2252{[0]: ValueNode<Primitive> Return, [1]: targets}


subgraph attr:
subgraph instance: ✗✓mindspore_nn_loss_loss_CTCLoss_construct_2068 : 0x397dd1c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @✗✓mindspore_nn_loss_loss_CTCLoss_construct_2068 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467]() {
  Return(%para335_targets)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2693/            if targets.ndim == 1:/
}
# Order:
#   1: @✗✓mindspore_nn_loss_loss_CTCLoss_construct_2068:CNode_2253{[0]: ValueNode<Primitive> Return, [1]: param_targets}


subgraph attr:
after_block : 1
subgraph instance: ↓mindspore_nn_loss_loss_CTCLoss_construct_2074 : 0x397babc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2688/    def construct(self, log_probs, targets, input_lengths, target_lengths):/
subgraph @↓mindspore_nn_loss_loss_CTCLoss_construct_2074 parent: [subgraph @mindspore_nn_loss_loss_CTCLoss_construct_1467]() {
  %1(CNode_2254) = call @ctc_loss_2242(%para334_log_probs, %para335_targets, %para336_input_lengths, %para337_target_lengths, I64(0), "mean", Bool(0))
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2699/        neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  %2(neg_log_hood) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2699/        neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2701/        return neg_log_hood/
}
# Order:
#   1: @↓mindspore_nn_loss_loss_CTCLoss_construct_2074:CNode_2254{[0]: ValueNode<FuncGraph> ctc_loss_2242, [1]: param_log_probs, [2]: param_targets, [3]: param_input_lengths, [4]: param_target_lengths, [5]: ValueNode<Int64Imm> 0, [6]: ValueNode<StringImm> mean, [7]: ValueNode<BoolImm> false}
#   2: @↓mindspore_nn_loss_loss_CTCLoss_construct_2074:neg_log_hood{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2254, [2]: ValueNode<Int64Imm> 0}
#   3: @↓mindspore_nn_loss_loss_CTCLoss_construct_2074:CNode_2255{[0]: ValueNode<Primitive> Return, [1]: neg_log_hood}


subgraph attr:
after_block : 1
subgraph instance: ↓✓ms_min_one_element_2079 : 0x395886d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @↓✓ms_min_one_element_2079 parent: [subgraph @✓ms_min_one_element_1487]() {
  %1(tensor_shape) = $(✓ms_min_one_element_1487):call @shape_1142(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2694/        tensor_shape = F.shape(x)/
  %2(tensor_shape_len) = $(✓ms_min_one_element_1487):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2695/        tensor_shape_len = len(tensor_shape)/
  %3(CNode_2256) = S_Prim_greater_equal(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
  %4(CNode_2257) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
  %5(CNode_2258) = Switch(%4, @✓↓✓ms_min_one_element_2259, @✗↓✓ms_min_one_element_2260)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
  %6(CNode_2261) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
}
# Order:
#   1: @↓✓ms_min_one_element_2079:CNode_2256{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: tensor_shape_len, [2]: ValueNode<Int64Imm> 2}
#   2: @↓✓ms_min_one_element_2079:CNode_2257{[0]: ValueNode<Primitive> Cond, [1]: CNode_2256, [2]: ValueNode<BoolImm> false}
#   3: @↓✓ms_min_one_element_2079:CNode_2258{[0]: ValueNode<Primitive> Switch, [1]: CNode_2257, [2]: ValueNode<FuncGraph> ✓↓✓ms_min_one_element_2259, [3]: ValueNode<FuncGraph> ✗↓✓ms_min_one_element_2260}
#   4: @↓✓ms_min_one_element_2079:CNode_2261{[0]: CNode_2258}
#   5: @↓✓ms_min_one_element_2079:CNode_2262{[0]: ValueNode<Primitive> Return, [1]: CNode_2261}


subgraph attr:
subgraph instance: ✓↓ms_min_one_element_2089 : 0x3955dd70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓↓ms_min_one_element_2089 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2263) = call @check_sequence_all_variable_scalar_1412(%para257_x, "min")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
  %2(CNode_2264) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
  %3(CNode_2265) = Switch(%2, @2✓↓ms_min_one_element_2266, @✗✓↓ms_min_one_element_2267)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
  %4(CNode_2268) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
}
# Order:
#   1: @✓↓ms_min_one_element_2089:CNode_2263{[0]: ValueNode<FuncGraph> check_sequence_all_variable_scalar_1412, [1]: param_x, [2]: ValueNode<StringImm> min}
#   2: @✓↓ms_min_one_element_2089:CNode_2264{[0]: ValueNode<Primitive> Cond, [1]: CNode_2263, [2]: ValueNode<BoolImm> false}
#   3: @✓↓ms_min_one_element_2089:CNode_2265{[0]: ValueNode<Primitive> Switch, [1]: CNode_2264, [2]: ValueNode<FuncGraph> 2✓↓ms_min_one_element_2266, [3]: ValueNode<FuncGraph> ✗✓↓ms_min_one_element_2267}
#   4: @✓↓ms_min_one_element_2089:CNode_2268{[0]: CNode_2265}
#   5: @✓↓ms_min_one_element_2089:CNode_2269{[0]: ValueNode<Primitive> Return, [1]: CNode_2268}


subgraph attr:
subgraph instance: ✗↓ms_min_one_element_2090 : 0x3955a7c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗↓ms_min_one_element_2090 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2271) = call @2↓ms_min_one_element_2270()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2704/    if isinstance(x, (list, tuple)):/
}
# Order:
#   1: @✗↓ms_min_one_element_2090:CNode_2272{[0]: ValueNode<Primitive> Return, [1]: CNode_2271}
#   2: @✗↓ms_min_one_element_2090:CNode_2271{[0]: ValueNode<FuncGraph> 2↓ms_min_one_element_2270}


subgraph attr:
after_block : 1
subgraph instance: ↓min_tensor_2100 : 0x39543c80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @↓min_tensor_2100(%para377_) {
  %1(min_tensor_data) = S_Prim_getitem(%para377_фdata, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2668/    min_tensor_data = data[0]/
  %2(CNode_2274) = call @↵↓min_tensor_2273(I64(0), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2734/            return min_tensor(*data)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
}
# Order:
#   1: @↓min_tensor_2100:min_tensor_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фdata, [2]: ValueNode<Int64Imm> 0}
#   2: @↓min_tensor_2100:CNode_2275{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фdata}
#   3: @↓min_tensor_2100:CNode_2276{[0]: ValueNode<Primitive> Return, [1]: CNode_2274}
#   4: @↓min_tensor_2100:CNode_2274{[0]: ValueNode<FuncGraph> ↵↓min_tensor_2273, [1]: ValueNode<Int64Imm> 0, [2]: min_tensor_data}


subgraph attr:
subgraph instance: ✓min_tensor_2097 : 0x39542b00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @✓min_tensor_2097 parent: [subgraph @min_tensor_1868]() {
  %1(data) = S_Prim_getitem(%para369_data, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2667/        data = data[0]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2667/        data = data[0]/
}
# Order:
#   1: @✓min_tensor_2097:data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<Int64Imm> 0}
#   2: @✓min_tensor_2097:CNode_2277{[0]: ValueNode<Primitive> Return, [1]: data}


subgraph attr:
subgraph instance: ✗min_tensor_2098 : 0x39541cf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @✗min_tensor_2098 parent: [subgraph @min_tensor_1868]() {
  Return(%para369_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2666/    if len(data) == 1:/
}
# Order:
#   1: @✗min_tensor_2098:CNode_2278{[0]: ValueNode<Primitive> Return, [1]: param_data}


subgraph attr:
subgraph instance: ✓↓✓2✗ms_min_2106 : 0x3953b530
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✓↓✓2✗ms_min_2106 parent: [subgraph @ms_min_962]() {
  %1(CNode_2279) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("min() cannot contain both tensor and non-tensor type.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2736/            const_utils.raise_type_error(/
  %2(CNode_2280) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
  %3(CNode_2282) = call @2↓✓2✗ms_min_2281()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %4(CNode_2283) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2736/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2736/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓↓✓2✗ms_min_2106:CNode_2279{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> min() cannot contain both tensor and non-tensor type.}
#   2: @✓↓✓2✗ms_min_2106:CNode_2284{[0]: ValueNode<Primitive> Return, [1]: CNode_2283}
#   3: @✓↓✓2✗ms_min_2106:CNode_2282{[0]: ValueNode<FuncGraph> 2↓✓2✗ms_min_2281}


subgraph attr:
subgraph instance: ✗↓✓2✗ms_min_2107 : 0x395317a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✗↓✓2✗ms_min_2107 parent: [subgraph @ms_min_962]() {
  %1(CNode_2285) = call @2↓✓2✗ms_min_2281()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2735/        if tensor_num != 0:/
}
# Order:
#   1: @✗↓✓2✗ms_min_2107:CNode_2286{[0]: ValueNode<Primitive> Return, [1]: CNode_2285}
#   2: @✗↓✓2✗ms_min_2107:CNode_2285{[0]: ValueNode<FuncGraph> 2↓✓2✗ms_min_2281}


subgraph attr:
subgraph instance: ✓↓flatten_2122 : 0x39710190
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓↓flatten_2122() {
  %1(CNode_2287) = JoinedStr("For 'flatten', both 'start_dim' and 'end_dim' must be int.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1735/        raise TypeError(f"For 'flatten', both 'start_dim' and 'end_dim' must be int.")/
  %2(CNode_2288) = raise[side_effect_io: Bool(1)]("TypeError", %1, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1735/        raise TypeError(f"For 'flatten', both 'start_dim' and 'end_dim' must be int.")/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1735/        raise TypeError(f"For 'flatten', both 'start_dim' and 'end_dim' must be int.")/
}
# Order:
#   1: @✓↓flatten_2122:CNode_2287{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For 'flatten', both 'start_dim' and 'end_dim' must be int.}
#   2: @✓↓flatten_2122:CNode_2288{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> TypeError, [2]: CNode_2287, [3]: ValueNode<StringImm> None}
#   3: @✓↓flatten_2122:CNode_2289{[0]: ValueNode<Primitive> Return, [1]: CNode_2288}


subgraph attr:
subgraph instance: ✗↓flatten_2123 : 0x3969c3f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗↓flatten_2123 parent: [subgraph @flatten_1327]() {
  %1(CNode_2291) = call @2↓flatten_2290()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @✗↓flatten_2123:CNode_2291{[0]: ValueNode<FuncGraph> 2↓flatten_2290}
#   2: @✗↓flatten_2123:CNode_2292{[0]: ValueNode<Primitive> Return, [1]: CNode_2291}


subgraph attr:
subgraph instance: ↰↓flatten_2117 : 0x3969b560
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↰↓flatten_2117 parent: [subgraph @↓flatten_1888]() {
  %1(CNode_2113) = $(↓flatten_1888):S_Prim_isinstance(%para263_start_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %2(CNode_2114) = $(↓flatten_1888):S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @↰↓flatten_2117:CNode_2293{[0]: ValueNode<Primitive> Return, [1]: CNode_2114}


subgraph attr:
subgraph instance: ↱↓flatten_2118 : 0x39694b10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↱↓flatten_2118 parent: [subgraph @flatten_1327]() {
  %1(CNode_2294) = S_Prim_isinstance(%para264_end_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %2(CNode_2295) = S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %3(CNode_2296) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  %4(CNode_2297) = Switch(%3, @↰↱↓flatten_2298, @2↱↓flatten_2299)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  %5(CNode_2300) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @↱↓flatten_2118:CNode_2294{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_end_dim, [2]: ValueNode<ClassType> class 'int'}
#   2: @↱↓flatten_2118:CNode_2295{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_2294}
#   3: @↱↓flatten_2118:CNode_2296{[0]: ValueNode<Primitive> Cond, [1]: CNode_2295, [2]: ValueNode<BoolImm> false}
#   4: @↱↓flatten_2118:CNode_2297{[0]: ValueNode<Primitive> Switch, [1]: CNode_2296, [2]: ValueNode<FuncGraph> ↰↱↓flatten_2298, [3]: ValueNode<FuncGraph> 2↱↓flatten_2299}
#   5: @↱↓flatten_2118:CNode_2300{[0]: CNode_2297}
#   6: @↱↓flatten_2118:CNode_2301{[0]: ValueNode<Primitive> Return, [1]: CNode_2300}


subgraph attr:
training : 1
subgraph instance: L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127 : 0x39661ce0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2302) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para338_x, %para339_L_conv2d.layer4.1.gamma, %para340_L_conv2d.layer4.1.beta, %para341_L_conv2d.layer4.1.moving_mean, %para342_L_conv2d.layer4.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  %2(CNode_2303) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
}
# Order:
#   1: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127:CNode_2302{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer4.1.gamma, [3]: param_L_conv2d.layer4.1.beta, [4]: param_L_conv2d.layer4.1.moving_mean, [5]: param_L_conv2d.layer4.1.moving_variance}
#   2: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127:CNode_2303{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2302, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2127:CNode_2304{[0]: ValueNode<Primitive> Return, [1]: CNode_2303}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130 : 0x3965aec0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2305) = Cond(None, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %2(CNode_2306) = Switch(%1, @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307, @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %3(CNode_2309) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130:CNode_2305{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<None> None, [2]: ValueNode<BoolImm> false}
#   2: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130:CNode_2306{[0]: ValueNode<Primitive> Switch, [1]: CNode_2305, [2]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307, [3]: ValueNode<FuncGraph> L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308}
#   3: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130:CNode_2309{[0]: CNode_2306}
#   4: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2130:CNode_2310{[0]: ValueNode<Primitive> Return, [1]: CNode_2309}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv2d_construct_2133 : 0x39667a90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv2d_construct_2133 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1538]() {
  %1(output) = $(L_mindspore_nn_layer_conv_Conv2d_construct_1538):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(512), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para343_x, %para344_L_conv2d.layer4.3.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv2d_construct_2133:CNode_2311{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137 : 0x3962c6e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2312) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para345_x, %para346_L_conv2d.layer3.1.gamma, %para347_L_conv2d.layer3.1.beta, %para348_L_conv2d.layer3.1.moving_mean, %para349_L_conv2d.layer3.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  %2(CNode_2313) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
}
# Order:
#   1: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137:CNode_2312{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer3.1.gamma, [3]: param_L_conv2d.layer3.1.beta, [4]: param_L_conv2d.layer3.1.moving_mean, [5]: param_L_conv2d.layer3.1.moving_variance}
#   2: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137:CNode_2313{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2312, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2137:CNode_2314{[0]: ValueNode<Primitive> Return, [1]: CNode_2313}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140 : 0x396258c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2315) = Cond(None, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %2(CNode_2316) = Switch(%1, @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317, @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %3(CNode_2319) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140:CNode_2315{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<None> None, [2]: ValueNode<BoolImm> false}
#   2: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140:CNode_2316{[0]: ValueNode<Primitive> Switch, [1]: CNode_2315, [2]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317, [3]: ValueNode<FuncGraph> L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318}
#   3: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140:CNode_2319{[0]: CNode_2316}
#   4: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2140:CNode_2320{[0]: ValueNode<Primitive> Return, [1]: CNode_2319}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv2d_construct_2143 : 0x39632910
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv2d_construct_2143 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1575]() {
  %1(output) = $(L_mindspore_nn_layer_conv_Conv2d_construct_1575):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(256), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para350_x, %para351_L_conv2d.layer3.3.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv2d_construct_2143:CNode_2321{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147 : 0x395ff280
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2322) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para352_x, %para353_L_conv2d.layer2.1.gamma, %para354_L_conv2d.layer2.1.beta, %para355_L_conv2d.layer2.1.moving_mean, %para356_L_conv2d.layer2.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  %2(CNode_2323) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
}
# Order:
#   1: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147:CNode_2322{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer2.1.gamma, [3]: param_L_conv2d.layer2.1.beta, [4]: param_L_conv2d.layer2.1.moving_mean, [5]: param_L_conv2d.layer2.1.moving_variance}
#   2: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147:CNode_2323{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2322, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2✓mindspore_nn_layer_normalization_BatchNorm2d_construct_2147:CNode_2324{[0]: ValueNode<Primitive> Return, [1]: CNode_2323}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150 : 0x395f8460
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2325) = Cond(None, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %2(CNode_2326) = Switch(%1, @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327, @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %3(CNode_2329) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150:CNode_2325{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<None> None, [2]: ValueNode<BoolImm> false}
#   2: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150:CNode_2326{[0]: ValueNode<Primitive> Switch, [1]: CNode_2325, [2]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327, [3]: ValueNode<FuncGraph> L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328}
#   3: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150:CNode_2329{[0]: CNode_2326}
#   4: @L_↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2150:CNode_2330{[0]: ValueNode<Primitive> Return, [1]: CNode_2329}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv2d_construct_2153 : 0x396051b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv2d_construct_2153 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1639]() {
  %1(output) = $(L_mindspore_nn_layer_conv_Conv2d_construct_1639):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(128), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para357_x, %para358_L_conv2d.layer2.3.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv2d_construct_2153:CNode_2331{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv2d_construct_2156 : 0x395ded70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:360/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv2d_construct_2156 parent: [subgraph @L_mindspore_nn_layer_conv_Conv2d_construct_1674]() {
  %1(output) = $(L_mindspore_nn_layer_conv_Conv2d_construct_1674):S_Prim_Conv2D[kernel_size: (I64(3), I64(3)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(1), I64(1), I64(1), I64(1)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(1), I64(1), I64(1), I64(1)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%para359_x, %para360_L_conv2d.layer1.0.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:361/        output = self.conv2d(x, self.weight)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:364/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv2d_construct_2156:CNode_2332{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166 : 0x395c4fa0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool2d_construct_1709](%para378_) {
  %1(CNode_2334) = call @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
}
# Order:
#   1: @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166:CNode_2334{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333}
#   2: @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166:CNode_2335{[0]: ValueNode<Primitive> Return, [1]: CNode_2334}


subgraph attr:
training : 1
subgraph instance: 2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163 : 0x395c2ae0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163 parent: [subgraph @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962]() {
  %1(CNode_2159) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):getattr(%para361_фx, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %2(x) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):%1(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %3(out) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):S_Prim_MaxPool3DWithArgmax[strides: (I64(1), I64(2), I64(2)), input_names: ["x"], argmax_type: "int64", pads: (I64(0), I64(1), I64(1)), ceil_mode: Bool(0), dilation: (I64(1), I64(1), I64(1)), ksize: (I64(1), I64(3), I64(3)), output_names: ["y", "argmax"], format: "NCDHW"](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:575/            out = self.max_pool(x)/
  %4(CNode_2336) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %5(CNode_2337) = getattr(%4, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %6(CNode_2338) = %5(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %7(CNode_2339) = S_Prim_getitem(%3, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %8(CNode_2340) = getattr(%7, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %9(CNode_2341) = %8(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  %10(out) = S_Prim_MakeTuple(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:577/                out = out[0].squeeze(2), out[1].squeeze(2)/
}
# Order:
#   1: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2336{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: out, [2]: ValueNode<Int64Imm> 0}
#   2: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2337{[0]: ValueNode<Primitive> getattr, [1]: CNode_2336, [2]: ValueNode<StringImm> squeeze}
#   3: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2338{[0]: CNode_2337, [1]: ValueNode<Int64Imm> 2}
#   4: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2339{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: out, [2]: ValueNode<Int64Imm> 1}
#   5: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2340{[0]: ValueNode<Primitive> getattr, [1]: CNode_2339, [2]: ValueNode<StringImm> squeeze}
#   6: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2341{[0]: CNode_2340, [1]: ValueNode<Int64Imm> 2}
#   7: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_2338, [2]: CNode_2341}
#   8: @2✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2163:CNode_2342{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 1
subgraph instance: ✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164 : 0x395c16a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164 parent: [subgraph @✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962]() {
  %1(CNode_2159) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):getattr(%para361_фx, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %2(x) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):%1(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:574/            x = x.unsqueeze(2)/
  %3(out) = $(✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_1962):S_Prim_MaxPool3DWithArgmax[strides: (I64(1), I64(2), I64(2)), input_names: ["x"], argmax_type: "int64", pads: (I64(0), I64(1), I64(1)), ceil_mode: Bool(0), dilation: (I64(1), I64(1), I64(1)), ksize: (I64(1), I64(3), I64(3)), output_names: ["y", "argmax"], format: "NCDHW"](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:575/            out = self.max_pool(x)/
  %4(CNode_2343) = getattr(%3, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:579/                out = out.squeeze(2)/
  %5(out) = %4(I64(2))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:579/                out = out.squeeze(2)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:579/                out = out.squeeze(2)/
}
# Order:
#   1: @✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164:CNode_2343{[0]: ValueNode<Primitive> getattr, [1]: out, [2]: ValueNode<StringImm> squeeze}
#   2: @✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164:out{[0]: CNode_2343, [1]: ValueNode<Int64Imm> 2}
#   3: @✗✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2164:CNode_2344{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174 : 0x395b2fb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_2345) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para321_x, %para322_L_conv2d.bn1.gamma, %para323_L_conv2d.bn1.beta, %para324_L_conv2d.bn1.moving_mean, %para325_L_conv2d.bn1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  %2(CNode_2346) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174:CNode_2345{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.bn1.gamma, [3]: param_L_conv2d.bn1.beta, [4]: param_L_conv2d.bn1.moving_mean, [5]: param_L_conv2d.bn1.moving_variance}
#   2: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174:CNode_2346{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2345, [2]: ValueNode<Int64Imm> 0}
#   3: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2174:CNode_2347{[0]: ValueNode<Primitive> Return, [1]: CNode_2346}


subgraph attr:
training : 1
subgraph instance: L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175 : 0x395b05e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_2349) = call @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175:CNode_2349{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348}
#   2: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2175:CNode_2350{[0]: ValueNode<Primitive> Return, [1]: CNode_2349}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓pad_sequence_2181 : 0x394df4b0
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @↓pad_sequence_2181 parent: [subgraph @pad_sequence_1730]() {
  %1(CNode_1973) = $(pad_sequence_1730):ClassType(%para364_length)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %2(target_length) = $(pad_sequence_1730):call @ms_max_436(I64(1), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %3(CNode_1972) = $(pad_sequence_1730):getattr(%para363_tensor, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %4(current_length) = $(pad_sequence_1730):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %5(CNode_2351) = ClassType(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:68/        pad_length = target_length - int(current_length)/
  %6(pad_length) = S_Prim_sub(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:68/        pad_length = target_length - int(current_length)/
  %7(CNode_2352) = S_Prim_greater(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:69/        if pad_length > 0:/
  %8(CNode_2353) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:69/        if pad_length > 0:/
  %9(CNode_2354) = Switch(%8, @✓↓pad_sequence_2355, @✗↓pad_sequence_2356)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:69/        if pad_length > 0:/
  %10(CNode_2357) = %9()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:69/        if pad_length > 0:/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:69/        if pad_length > 0:/
}
# Order:
#   1: @↓pad_sequence_2181:CNode_2351{[0]: ValueNode<ClassType> class 'int', [1]: current_length}
#   2: @↓pad_sequence_2181:pad_length{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: target_length, [2]: CNode_2351}
#   3: @↓pad_sequence_2181:CNode_2352{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: pad_length, [2]: ValueNode<Int64Imm> 0}
#   4: @↓pad_sequence_2181:CNode_2353{[0]: ValueNode<Primitive> Cond, [1]: CNode_2352, [2]: ValueNode<BoolImm> false}
#   5: @↓pad_sequence_2181:CNode_2354{[0]: ValueNode<Primitive> Switch, [1]: CNode_2353, [2]: ValueNode<FuncGraph> ✓↓pad_sequence_2355, [3]: ValueNode<FuncGraph> ✗↓pad_sequence_2356}
#   6: @↓pad_sequence_2181:CNode_2357{[0]: CNode_2354}
#   7: @↓pad_sequence_2181:CNode_2358{[0]: ValueNode<Primitive> Return, [1]: CNode_2357}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_2185 : 0x372f13d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_2185 parent: [subgraph @after_grad_108](%para379_input_data) {
  %1(CNode_2360) = call @↵mindspore_nn_layer_container_SequentialCell_construct_2359(I64(0), %para379_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_2185:CNode_2361{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_2362}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_2185:CNode_2360{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_2359, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_2185:CNode_2363{[0]: ValueNode<Primitive> Return, [1]: CNode_2360}


subgraph attr:
training : 1
subgraph instance: ↻9↓tfnet_model_TFNetModel_construct_2192 : 0x39473450
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻9↓tfnet_model_TFNetModel_construct_2192 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(CNode_2190) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para372_@CNode_2190, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %2(CNode_2364) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
  %3(CNode_1985) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_make_list("K5", "P2", "K5", "P2")
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %4(CNode_2365) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %5(ks) = S_Prim_getitem(%4, %para372_@CNode_2190)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %6(CNode_2366) = S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
  %7(CNode_2367) = S_Prim_equal(%6, "P")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
  %8(CNode_2368) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
  %9(CNode_2369) = Switch(%8, @✓↻9↓tfnet_model_TFNetModel_construct_2370, @✗↻9↓tfnet_model_TFNetModel_construct_2371)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
  %10(CNode_2372) = %9()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
  %11(CNode_2374) = call @↓↻9↓tfnet_model_TFNetModel_construct_2373(%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  %12(CNode_2375) = Depend[side_effect_propagate: I64(1)](%11, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%12)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:176/            if ks[0] == 'P':/
}
# Order:
#   1: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2365{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_1985}
#   2: @↻9↓tfnet_model_TFNetModel_construct_2192:ks{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2365, [2]: param_@CNode_2190}
#   3: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2190{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2190, [2]: ValueNode<Int64Imm> 1}
#   4: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2366{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: ks, [2]: ValueNode<Int64Imm> 0}
#   5: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2367{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2366, [2]: ValueNode<StringImm> P}
#   6: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2368{[0]: ValueNode<Primitive> Cond, [1]: CNode_2367, [2]: ValueNode<BoolImm> false}
#   7: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2369{[0]: ValueNode<Primitive> Switch, [1]: CNode_2368, [2]: ValueNode<FuncGraph> ✓↻9↓tfnet_model_TFNetModel_construct_2370, [3]: ValueNode<FuncGraph> ✗↻9↓tfnet_model_TFNetModel_construct_2371}
#   8: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2372{[0]: CNode_2369}
#   9: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2374{[0]: ValueNode<FuncGraph> ↓↻9↓tfnet_model_TFNetModel_construct_2373, [1]: CNode_2372}
#  10: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2375{[0]: ValueNode<Primitive> Depend, [1]: CNode_2374, [2]: CNode_2364}
#  11: @↻9↓tfnet_model_TFNetModel_construct_2192:CNode_2376{[0]: ValueNode<Primitive> Return, [1]: CNode_2375}


subgraph attr:
training : 1
subgraph instance: 10↓tfnet_model_TFNetModel_construct_2193 : 0x38f1db20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @10↓tfnet_model_TFNetModel_construct_2193 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %4(conv1d_outputs) = $(9↓tfnet_model_TFNetModel_construct_1746):call @modules_TemporalConv_construct_1984(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:171/        conv1d_outputs = self.conv1d(framewise, len_x_list)/
  %5(x) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_getitem(%4, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:172/        x = conv1d_outputs['visual_feat']/
  %6(CNode_2377) = S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %7(x) = S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %8(CNode_2378) = getattr(%7, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
  %9(CNode_2379) = S_Prim_not_equal(%8, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
  %10(CNode_2380) = Cond(%9, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
  %11(CNode_2381) = Switch(%10, @✓10↓tfnet_model_TFNetModel_construct_2382, @✗10↓tfnet_model_TFNetModel_construct_2383)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
  %12(CNode_2384) = %11()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
  %13(CNode_2386) = call @11↓tfnet_model_TFNetModel_construct_2385(%12)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%13)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
}
# Order:
#   1: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2377{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 2, [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<Int64Imm> 1}
#   2: @10↓tfnet_model_TFNetModel_construct_2193:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: x, [2]: CNode_2377}
#   3: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2387{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 1}
#   4: @10↓tfnet_model_TFNetModel_construct_2193:framewise1{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: framewise, [2]: CNode_2387}
#   5: @10↓tfnet_model_TFNetModel_construct_2193:X{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Abs, [1]: framewise1}
#   6: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2388{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<Int64Imm> 1}
#   7: @10↓tfnet_model_TFNetModel_construct_2193:framewise1{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: X, [2]: CNode_2388}
#   8: @10↓tfnet_model_TFNetModel_construct_2193:conv1d_outputs1{[0]: ValueNode<FuncGraph> modules_TemporalConv_construct_2389, [1]: framewise1, [2]: len_x_list}
#   9: @10↓tfnet_model_TFNetModel_construct_2193:x1{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: conv1d_outputs1, [2]: ValueNode<StringImm> visual_feat}
#  10: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2390{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 2, [2]: ValueNode<Int64Imm> 0, [3]: ValueNode<Int64Imm> 1}
#  11: @10↓tfnet_model_TFNetModel_construct_2193:x1{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Transpose, [1]: x1, [2]: CNode_2390}
#  12: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2378{[0]: ValueNode<Primitive> getattr, [1]: x, [2]: ValueNode<StringImm> dtype}
#  13: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2379{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_2378, [2]: ValueNode<Float> Float32}
#  14: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2380{[0]: ValueNode<Primitive> Cond, [1]: CNode_2379, [2]: ValueNode<BoolImm> false}
#  15: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2381{[0]: ValueNode<Primitive> Switch, [1]: CNode_2380, [2]: ValueNode<FuncGraph> ✓10↓tfnet_model_TFNetModel_construct_2382, [3]: ValueNode<FuncGraph> ✗10↓tfnet_model_TFNetModel_construct_2383}
#  16: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2384{[0]: CNode_2381}
#  17: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2386{[0]: ValueNode<FuncGraph> 11↓tfnet_model_TFNetModel_construct_2385, [1]: CNode_2384}
#  18: @10↓tfnet_model_TFNetModel_construct_2193:CNode_2391{[0]: ValueNode<Primitive> Return, [1]: CNode_2386}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓↓ms_max_one_element_2201 : 0x37a43930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @2↓✓↓ms_max_one_element_2201 parent: [subgraph @ms_max_one_element_889]() {
  %1(tensor_num) = call @get_tensor_num_1008(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2626/        tensor_num = get_tensor_num(x)/
  %2(CNode_2392) = S_Prim_inner_len(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  %3(CNode_2393) = S_Prim_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  %4(CNode_2394) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  %5(CNode_2395) = Switch(%4, @✓2↓✓↓ms_max_one_element_2396, @✗2↓✓↓ms_max_one_element_2397)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  %6(CNode_2398) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
}
# Order:
#   1: @2↓✓↓ms_max_one_element_2201:tensor_num{[0]: ValueNode<FuncGraph> get_tensor_num_1008, [1]: param_x}
#   2: @2↓✓↓ms_max_one_element_2201:CNode_2392{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   3: @2↓✓↓ms_max_one_element_2201:CNode_2393{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_num, [2]: CNode_2392}
#   4: @2↓✓↓ms_max_one_element_2201:CNode_2394{[0]: ValueNode<Primitive> Cond, [1]: CNode_2393, [2]: ValueNode<BoolImm> false}
#   5: @2↓✓↓ms_max_one_element_2201:CNode_2395{[0]: ValueNode<Primitive> Switch, [1]: CNode_2394, [2]: ValueNode<FuncGraph> ✓2↓✓↓ms_max_one_element_2396, [3]: ValueNode<FuncGraph> ✗2↓✓↓ms_max_one_element_2397}
#   6: @2↓✓↓ms_max_one_element_2201:CNode_2398{[0]: CNode_2395}
#   7: @2↓✓↓ms_max_one_element_2201:CNode_2399{[0]: ValueNode<Primitive> Return, [1]: CNode_2398}


subgraph attr:
after_block : 1
subgraph instance: ↓✓check_sequence_all_variable_scalar_2210 : 0x37f6b290
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↓✓check_sequence_all_variable_scalar_2210 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2400) = S_Prim_getitem(%para329_x, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %2(CNode_2401) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %3(CNode_2402) = S_Prim_isinstance(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %4(CNode_2403) = S_Prim_logical_not(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %5(CNode_2404) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %6(CNode_2405) = Switch(%5, @✓↓✓check_sequence_all_variable_scalar_2406, @✗↓✓check_sequence_all_variable_scalar_2407)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  %7(CNode_2408) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
}
# Order:
#   1: @↓✓check_sequence_all_variable_scalar_2210:CNode_2400{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_x, [2]: ValueNode<Int64Imm> 0}
#   2: @↓✓check_sequence_all_variable_scalar_2210:CNode_2401{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: ValueNode<ClassType> class 'float'}
#   3: @↓✓check_sequence_all_variable_scalar_2210:CNode_2402{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: CNode_2400, [2]: CNode_2401}
#   4: @↓✓check_sequence_all_variable_scalar_2210:CNode_2403{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_2402}
#   5: @↓✓check_sequence_all_variable_scalar_2210:CNode_2404{[0]: ValueNode<Primitive> Cond, [1]: CNode_2403, [2]: ValueNode<BoolImm> false}
#   6: @↓✓check_sequence_all_variable_scalar_2210:CNode_2405{[0]: ValueNode<Primitive> Switch, [1]: CNode_2404, [2]: ValueNode<FuncGraph> ✓↓✓check_sequence_all_variable_scalar_2406, [3]: ValueNode<FuncGraph> ✗↓✓check_sequence_all_variable_scalar_2407}
#   7: @↓✓check_sequence_all_variable_scalar_2210:CNode_2408{[0]: CNode_2405}
#   8: @↓✓check_sequence_all_variable_scalar_2210:CNode_2409{[0]: ValueNode<Primitive> Return, [1]: CNode_2408}


subgraph attr:
subgraph instance: ↵↓check_sequence_all_variable_scalar_2216 : 0x37d42ac0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↵↓check_sequence_all_variable_scalar_2216 parent: [subgraph @↓check_sequence_all_variable_scalar_2023](%para380_, %para381_) {
  %1(CNode_2218) = $(↓check_sequence_all_variable_scalar_2023):S_Prim_inner_len(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %2(CNode_2410) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para380_@CNode_2411, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %3(CNode_2412) = Switch(%2, @↻↓check_sequence_all_variable_scalar_2413, @2↓check_sequence_all_variable_scalar_2414)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %4(CNode_2415) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
}
# Order:
#   1: @↵↓check_sequence_all_variable_scalar_2216:CNode_2410{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2411, [2]: CNode_2218}
#   2: @↵↓check_sequence_all_variable_scalar_2216:CNode_2412{[0]: ValueNode<Primitive> Switch, [1]: CNode_2410, [2]: ValueNode<FuncGraph> ↻↓check_sequence_all_variable_scalar_2413, [3]: ValueNode<FuncGraph> 2↓check_sequence_all_variable_scalar_2414}
#   3: @↵↓check_sequence_all_variable_scalar_2216:CNode_2415{[0]: CNode_2412}
#   4: @↵↓check_sequence_all_variable_scalar_2216:CNode_2416{[0]: ValueNode<Primitive> Return, [1]: CNode_2415}


subgraph attr:
subgraph instance: ↻exist_tensor_2228 : 0x37d9a140
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @↻exist_tensor_2228 parent: [subgraph @↵exist_tensor_2056]() {
  %1(CNode_2226) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para374_@CNode_2226, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %2(CNode_2417) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
  %3(CNode_2418) = call @ms_iter_97(%para368_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %4(input_data) = S_Prim_getitem(%3, %para374_@CNode_2226)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %5(CNode_2419) = S_Prim_isinstance(%4, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  %6(CNode_2420) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  %7(CNode_2421) = Switch(%6, @✓↻exist_tensor_2422, @✗↻exist_tensor_2423)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  %8(CNode_2424) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  %9(CNode_2425) = Depend[side_effect_propagate: I64(1)](%8, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
}
# Order:
#   1: @↻exist_tensor_2228:CNode_2418{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_data}
#   2: @↻exist_tensor_2228:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2418, [2]: param_@CNode_2226}
#   3: @↻exist_tensor_2228:CNode_2226{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2226, [2]: ValueNode<Int64Imm> 1}
#   4: @↻exist_tensor_2228:CNode_2419{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: input_data, [2]: ValueNode<ClassType> class 'mindspore.common.tensor.Tensor'}
#   5: @↻exist_tensor_2228:CNode_2420{[0]: ValueNode<Primitive> Cond, [1]: CNode_2419, [2]: ValueNode<BoolImm> false}
#   6: @↻exist_tensor_2228:CNode_2421{[0]: ValueNode<Primitive> Switch, [1]: CNode_2420, [2]: ValueNode<FuncGraph> ✓↻exist_tensor_2422, [3]: ValueNode<FuncGraph> ✗↻exist_tensor_2423}
#   7: @↻exist_tensor_2228:CNode_2424{[0]: CNode_2421}
#   8: @↻exist_tensor_2228:CNode_2426{[0]: ValueNode<Primitive> Return, [1]: CNode_2425}


subgraph attr:
subgraph instance: ↓exist_tensor_2229 : 0x37d2a4a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @↓exist_tensor_2229() {
  Return(Bool(0))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2573/    return False/
}
# Order:
#   1: @↓exist_tensor_2229:CNode_2427{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> false}


subgraph attr:
subgraph instance: ✓_check_ctcloss_targets_shape_2236 : 0x397db980
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @✓_check_ctcloss_targets_shape_2236 parent: [subgraph @_check_ctcloss_targets_shape_2060]() {
  %1(CNode_2428) = getattr(%para375_targets, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2596/        raise ValueError(f"For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets should"/
  %2(CNode_2429) = JoinedStr("For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets shouldbe 1 or 2, but got ", %1, ".")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2596/        raise ValueError(f"For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets should"/
  %3(CNode_2430) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2596/        raise ValueError(f"For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets should"/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2596/        raise ValueError(f"For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets should"/
}
# Order:
#   1: @✓_check_ctcloss_targets_shape_2236:CNode_2428{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> ndim}
#   2: @✓_check_ctcloss_targets_shape_2236:CNode_2429{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For CTCLoss, when the shape of log_probs is (T, C), the dimension of targets shouldbe 1 or 2, but got , [2]: CNode_2428, [3]: ValueNode<StringImm> .}
#   3: @✓_check_ctcloss_targets_shape_2236:CNode_2430{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_2429, [3]: ValueNode<StringImm> None}
#   4: @✓_check_ctcloss_targets_shape_2236:CNode_2431{[0]: ValueNode<Primitive> Return, [1]: CNode_2430}


subgraph attr:
subgraph instance: ✗_check_ctcloss_targets_shape_2237 : 0x397d17b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @✗_check_ctcloss_targets_shape_2237 parent: [subgraph @_check_ctcloss_targets_shape_2060]() {
  %1(CNode_2433) = call @↓_check_ctcloss_targets_shape_2432()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2595/    if targets.ndim > 2:/
}
# Order:
#   1: @✗_check_ctcloss_targets_shape_2237:CNode_2433{[0]: ValueNode<FuncGraph> ↓_check_ctcloss_targets_shape_2432}
#   2: @✗_check_ctcloss_targets_shape_2237:CNode_2434{[0]: ValueNode<Primitive> Return, [1]: CNode_2433}


subgraph attr:
subgraph instance: ctc_loss_2242 : 0x397bc510
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @ctc_loss_2242(%para382_log_probs, %para383_targets, %para384_input_lengths, %para385_target_lengths, %para386_blank, %para387_reduction, %para388_zero_infinity) {
  %1(CNode_2435) = S_Prim__check_ctc_loss_inputs[constexpr_prim: Bool(1)](%para386_blank, %para387_reduction, %para388_zero_infinity, "ctc_loss")
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4828/    _check_ctc_loss_inputs(blank, reduction, zero_infinity, 'ctc_loss')/
  %2(CNode_2436) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
  %3(CNode_2437) = S_Prim_equal(%para387_reduction, "sum")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
  %4(CNode_2438) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
  %5(CNode_2439) = Switch(%4, @✓ctc_loss_2440, @✗ctc_loss_2441)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
  %6(CNode_2442) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
  %7(CNode_2444) = call @↓ctc_loss_2443(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2699/        neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  %8(CNode_2445) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2699/        neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
}
# Order:
#   1: @ctc_loss_2242:CNode_2435{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_ctc_loss_inputs, [1]: param_blank, [2]: param_reduction, [3]: param_zero_infinity, [4]: ValueNode<StringImm> ctc_loss}
#   2: @ctc_loss_2242:CNode_2446{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> blank, [2]: ValueNode<StringImm> reduction, [3]: ValueNode<StringImm> zero_infinity}
#   3: @ctc_loss_2242:CNode_2447{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_blank, [2]: ValueNode<StringImm> none, [3]: param_zero_infinity}
#   4: @ctc_loss_2242:CNode_2448{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_2446, [2]: CNode_2447}
#   5: @ctc_loss_2242:ctc_loss_op{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.2449, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.CTCLossV2', [2]: CNode_2448}
#   6: @ctc_loss_2242:CNode_2450{[0]: ctc_loss_op, [1]: param_log_probs, [2]: param_targets, [3]: param_input_lengths, [4]: param_target_lengths}
#   7: @ctc_loss_2242:loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2450, [2]: ValueNode<Int64Imm> 0}
#   8: @ctc_loss_2242:log_alpha{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2450, [2]: ValueNode<Int64Imm> 1}
#   9: @ctc_loss_2242:CNode_2437{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_reduction, [2]: ValueNode<StringImm> sum}
#  10: @ctc_loss_2242:CNode_2438{[0]: ValueNode<Primitive> Cond, [1]: CNode_2437, [2]: ValueNode<BoolImm> false}
#  11: @ctc_loss_2242:CNode_2439{[0]: ValueNode<Primitive> Switch, [1]: CNode_2438, [2]: ValueNode<FuncGraph> ✓ctc_loss_2440, [3]: ValueNode<FuncGraph> ✗ctc_loss_2441}
#  12: @ctc_loss_2242:CNode_2442{[0]: CNode_2439}
#  13: @ctc_loss_2242:CNode_2444{[0]: ValueNode<FuncGraph> ↓ctc_loss_2443, [1]: CNode_2442}
#  14: @ctc_loss_2242:CNode_2445{[0]: ValueNode<Primitive> Depend, [1]: CNode_2444, [2]: CNode_2436}
#  15: @ctc_loss_2242:CNode_2451{[0]: ValueNode<Primitive> Return, [1]: CNode_2445}


subgraph attr:
subgraph instance: ✓↓✓ms_min_one_element_2259 : 0x3958cfa0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓↓✓ms_min_one_element_2259 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2452) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("The truth value of an array with more than one element is ambiguous.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2700/            const_utils.raise_value_error(/
  %2(CNode_2453) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_2455) = call @2↓✓ms_min_one_element_2454()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  %4(CNode_2456) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2700/            const_utils.raise_value_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2700/            const_utils.raise_value_error(/
}
# Order:
#   1: @✓↓✓ms_min_one_element_2259:CNode_2452{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> The truth value of an array with more than one element is ambiguous.}
#   2: @✓↓✓ms_min_one_element_2259:CNode_2457{[0]: ValueNode<Primitive> Return, [1]: CNode_2456}
#   3: @✓↓✓ms_min_one_element_2259:CNode_2455{[0]: ValueNode<FuncGraph> 2↓✓ms_min_one_element_2454}


subgraph attr:
subgraph instance: ✗↓✓ms_min_one_element_2260 : 0x3958a5c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗↓✓ms_min_one_element_2260 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2458) = call @2↓✓ms_min_one_element_2454()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2699/        if tensor_shape_len >= 2:/
}
# Order:
#   1: @✗↓✓ms_min_one_element_2260:CNode_2459{[0]: ValueNode<Primitive> Return, [1]: CNode_2458}
#   2: @✗↓✓ms_min_one_element_2260:CNode_2458{[0]: ValueNode<FuncGraph> 2↓✓ms_min_one_element_2454}


subgraph attr:
subgraph instance: 2✓↓ms_min_one_element_2266 : 0x39583d10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @2✓↓ms_min_one_element_2266 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2460) = ClassType()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2706/            return SequenceMin()(x)/
  %2(CNode_2461) = %1(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2706/            return SequenceMin()(x)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2706/            return SequenceMin()(x)/
}
# Order:
#   1: @2✓↓ms_min_one_element_2266:CNode_2460{[0]: ValueNode<ClassType> class 'mindspore.ops.operations._sequence_ops.SequenceMin'}
#   2: @2✓↓ms_min_one_element_2266:CNode_2461{[0]: CNode_2460, [1]: param_x}
#   3: @2✓↓ms_min_one_element_2266:CNode_2462{[0]: ValueNode<Primitive> Return, [1]: CNode_2461}


subgraph attr:
subgraph instance: ✗✓↓ms_min_one_element_2267 : 0x39561930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗✓↓ms_min_one_element_2267 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2464) = call @↓✓↓ms_min_one_element_2463()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2705/        if check_sequence_all_variable_scalar(x, "min"):/
}
# Order:
#   1: @✗✓↓ms_min_one_element_2267:CNode_2464{[0]: ValueNode<FuncGraph> ↓✓↓ms_min_one_element_2463}
#   2: @✗✓↓ms_min_one_element_2267:CNode_2465{[0]: ValueNode<Primitive> Return, [1]: CNode_2464}


subgraph attr:
after_block : 1
subgraph instance: 2↓ms_min_one_element_2270 : 0x3955bc20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @2↓ms_min_one_element_2270 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2466) = call @check_isconstant_1138(%para257_x, "min()")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2718/    check_isconstant(x, "min()")/
  %2(CNode_2467) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_2468) = S_Prim_min_[constexpr_prim: Bool(1)](%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2719/    return min_(x)/
  %4(CNode_2469) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2719/    return min_(x)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2719/    return min_(x)/
}
# Order:
#   1: @2↓ms_min_one_element_2270:CNode_2466{[0]: ValueNode<FuncGraph> check_isconstant_1138, [1]: param_x, [2]: ValueNode<StringImm> min()}
#   2: @2↓ms_min_one_element_2270:CNode_2468{[0]: ValueNode<DoSignaturePrimitive> S_Prim_min_, [1]: param_x}
#   3: @2↓ms_min_one_element_2270:CNode_2470{[0]: ValueNode<Primitive> Return, [1]: CNode_2469}


subgraph attr:
subgraph instance: ↵↓min_tensor_2273 : 0x39545a60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @↵↓min_tensor_2273 parent: [subgraph @↓min_tensor_2100](%para389_, %para390_) {
  %1(CNode_2275) = $(↓min_tensor_2100):S_Prim_inner_len(%para377_фdata)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %2(CNode_2471) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para389_@CNode_2472, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %3(CNode_2473) = Switch(%2, @↻↓min_tensor_2474, @2↓min_tensor_2475)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %4(CNode_2476) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
}
# Order:
#   1: @↵↓min_tensor_2273:CNode_2471{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2472, [2]: CNode_2275}
#   2: @↵↓min_tensor_2273:CNode_2473{[0]: ValueNode<Primitive> Switch, [1]: CNode_2471, [2]: ValueNode<FuncGraph> ↻↓min_tensor_2474, [3]: ValueNode<FuncGraph> 2↓min_tensor_2475}
#   3: @↵↓min_tensor_2273:CNode_2476{[0]: CNode_2473}
#   4: @↵↓min_tensor_2273:CNode_2477{[0]: ValueNode<Primitive> Return, [1]: CNode_2476}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓2✗ms_min_2281 : 0x395336e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @2↓✓2✗ms_min_2281 parent: [subgraph @ms_min_962]() {
  %1(CNode_2478) = call @exist_tensor_1831(%para221_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
  %2(CNode_2479) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
  %3(CNode_2480) = Switch(%2, @✓2↓✓2✗ms_min_2481, @✗2↓✓2✗ms_min_2482)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
  %4(CNode_2483) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
}
# Order:
#   1: @2↓✓2✗ms_min_2281:CNode_2478{[0]: ValueNode<FuncGraph> exist_tensor_1831, [1]: param_data}
#   2: @2↓✓2✗ms_min_2281:CNode_2479{[0]: ValueNode<Primitive> Cond, [1]: CNode_2478, [2]: ValueNode<BoolImm> false}
#   3: @2↓✓2✗ms_min_2281:CNode_2480{[0]: ValueNode<Primitive> Switch, [1]: CNode_2479, [2]: ValueNode<FuncGraph> ✓2↓✓2✗ms_min_2481, [3]: ValueNode<FuncGraph> ✗2↓✓2✗ms_min_2482}
#   4: @2↓✓2✗ms_min_2281:CNode_2483{[0]: CNode_2480}
#   5: @2↓✓2✗ms_min_2281:CNode_2484{[0]: ValueNode<Primitive> Return, [1]: CNode_2483}


subgraph attr:
after_block : 1
subgraph instance: 2↓flatten_2290 : 0x3969e960
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @2↓flatten_2290 parent: [subgraph @flatten_1327]() {
  %1(CNode_2485) = S_Prim_check_flatten_order[constexpr_prim: Bool(1)](%para262_order)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1736/    check_flatten_order_const(order)/
  %2(CNode_2486) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
  %3(CNode_2487) = S_Prim_equal(%para262_order, "F")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
  %4(CNode_2488) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
  %5(CNode_2489) = Switch(%4, @✓2↓flatten_2490, @✗2↓flatten_2491)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
  %6(CNode_2492) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
  %7(CNode_2493) = Depend[side_effect_propagate: I64(1)](%6, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
}
# Order:
#   1: @2↓flatten_2290:CNode_2485{[0]: ValueNode<DoSignaturePrimitive> S_Prim_check_flatten_order, [1]: param_order}
#   2: @2↓flatten_2290:CNode_2487{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_order, [2]: ValueNode<StringImm> F}
#   3: @2↓flatten_2290:CNode_2488{[0]: ValueNode<Primitive> Cond, [1]: CNode_2487, [2]: ValueNode<BoolImm> false}
#   4: @2↓flatten_2290:CNode_2489{[0]: ValueNode<Primitive> Switch, [1]: CNode_2488, [2]: ValueNode<FuncGraph> ✓2↓flatten_2490, [3]: ValueNode<FuncGraph> ✗2↓flatten_2491}
#   5: @2↓flatten_2290:CNode_2492{[0]: CNode_2489}
#   6: @2↓flatten_2290:CNode_2494{[0]: ValueNode<Primitive> Return, [1]: CNode_2493}


subgraph attr:
subgraph instance: ↰↱↓flatten_2298 : 0x3969a6d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↰↱↓flatten_2298 parent: [subgraph @↱↓flatten_2118]() {
  %1(CNode_2294) = $(↱↓flatten_2118):S_Prim_isinstance(%para264_end_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  %2(CNode_2295) = $(↱↓flatten_2118):S_Prim_logical_not(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
}
# Order:
#   1: @↰↱↓flatten_2298:CNode_2495{[0]: ValueNode<Primitive> Return, [1]: CNode_2295}


subgraph attr:
subgraph instance: 2↱↓flatten_2299 : 0x396968a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @2↱↓flatten_2299 parent: [subgraph @flatten_1327]() {
  %1(CNode_2496) = S_Prim_isinstance(%para263_start_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  %2(CNode_2497) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  %3(CNode_2498) = Switch(%2, @↰2↱↓flatten_2499, @3↱↓flatten_2500)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  %4(CNode_2501) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @2↱↓flatten_2299:CNode_2496{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_start_dim, [2]: ValueNode<ClassType> class 'bool'}
#   2: @2↱↓flatten_2299:CNode_2497{[0]: ValueNode<Primitive> Cond, [1]: CNode_2496, [2]: ValueNode<BoolImm> false}
#   3: @2↱↓flatten_2299:CNode_2498{[0]: ValueNode<Primitive> Switch, [1]: CNode_2497, [2]: ValueNode<FuncGraph> ↰2↱↓flatten_2499, [3]: ValueNode<FuncGraph> 3↱↓flatten_2500}
#   4: @2↱↓flatten_2299:CNode_2501{[0]: CNode_2498}
#   5: @2↱↓flatten_2299:CNode_2502{[0]: ValueNode<Primitive> Return, [1]: CNode_2501}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307 : 0x3965f310
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2503) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para338_x, %para339_L_conv2d.layer4.1.gamma, %para340_L_conv2d.layer4.1.beta, %para341_L_conv2d.layer4.1.moving_mean, %para342_L_conv2d.layer4.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  %2(CNode_2504) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307:CNode_2503{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer4.1.gamma, [3]: param_L_conv2d.layer4.1.beta, [4]: param_L_conv2d.layer4.1.moving_mean, [5]: param_L_conv2d.layer4.1.moving_variance}
#   2: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307:CNode_2504{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2503, [2]: ValueNode<Int64Imm> 0}
#   3: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2307:CNode_2505{[0]: ValueNode<Primitive> Return, [1]: CNode_2504}


subgraph attr:
training : 1
subgraph instance: L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308 : 0x3965c940
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2507) = call @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308:CNode_2507{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506}
#   2: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2308:CNode_2508{[0]: ValueNode<Primitive> Return, [1]: CNode_2507}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317 : 0x39629d10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2509) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para345_x, %para346_L_conv2d.layer3.1.gamma, %para347_L_conv2d.layer3.1.beta, %para348_L_conv2d.layer3.1.moving_mean, %para349_L_conv2d.layer3.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  %2(CNode_2510) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317:CNode_2509{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer3.1.gamma, [3]: param_L_conv2d.layer3.1.beta, [4]: param_L_conv2d.layer3.1.moving_mean, [5]: param_L_conv2d.layer3.1.moving_variance}
#   2: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317:CNode_2510{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2509, [2]: ValueNode<Int64Imm> 0}
#   3: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2317:CNode_2511{[0]: ValueNode<Primitive> Return, [1]: CNode_2510}


subgraph attr:
training : 1
subgraph instance: L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318 : 0x39627340
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2513) = call @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318:CNode_2513{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512}
#   2: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2318:CNode_2514{[0]: ValueNode<Primitive> Return, [1]: CNode_2513}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327 : 0x395fc8b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2515) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para352_x, %para353_L_conv2d.layer2.1.gamma, %para354_L_conv2d.layer2.1.beta, %para355_L_conv2d.layer2.1.moving_mean, %para356_L_conv2d.layer2.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  %2(CNode_2516) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327:CNode_2515{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer2.1.gamma, [3]: param_L_conv2d.layer2.1.beta, [4]: param_L_conv2d.layer2.1.moving_mean, [5]: param_L_conv2d.layer2.1.moving_variance}
#   2: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327:CNode_2516{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2515, [2]: ValueNode<Int64Imm> 0}
#   3: @L_✓↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2327:CNode_2517{[0]: ValueNode<Primitive> Return, [1]: CNode_2516}


subgraph attr:
training : 1
subgraph instance: L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328 : 0x395f9ee0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2519) = call @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328:CNode_2519{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518}
#   2: @L_✗↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2328:CNode_2520{[0]: ValueNode<Primitive> Return, [1]: CNode_2519}


subgraph attr:
training : 1
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333 : 0x395c6d80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333 parent: [subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166]() {
  %1(CNode_2521) = Cond(%para362_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %2(CNode_2522) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523, @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2524)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %3(CNode_2525) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
  %4(CNode_2527) = call @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333:CNode_2521{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333:CNode_2522{[0]: ValueNode<Primitive> Switch, [1]: CNode_2521, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2524}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333:CNode_2525{[0]: CNode_2522}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333:CNode_2527{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526, [1]: CNode_2525}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2333:CNode_2528{[0]: ValueNode<Primitive> Return, [1]: CNode_2527}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348 : 0x395b1990
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1363]() {
  %1(CNode_2529) = S_Prim_BatchNorm[output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(0), input_names: ["x", "scale", "offset", "mean", "variance"], momentum: F32(0.1), epsilon: F32(1e-05)](%para321_x, %para322_L_conv2d.bn1.gamma, %para323_L_conv2d.bn1.beta, %para324_L_conv2d.bn1.moving_mean, %para325_L_conv2d.bn1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  %2(CNode_2530) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348:CNode_2529{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.bn1.gamma, [3]: param_L_conv2d.bn1.beta, [4]: param_L_conv2d.bn1.moving_mean, [5]: param_L_conv2d.bn1.moving_variance}
#   2: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348:CNode_2530{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2529, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2348:CNode_2531{[0]: ValueNode<Primitive> Return, [1]: CNode_2530}


subgraph attr:
training : 1
subgraph instance: ✓↓pad_sequence_2355 : 0x394e2c60
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @✓↓pad_sequence_2355 parent: [subgraph @↓pad_sequence_2181]() {
  %1(CNode_1973) = $(pad_sequence_1730):ClassType(%para364_length)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %2(target_length) = $(pad_sequence_1730):call @ms_max_436(I64(1), %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:62/        target_length = max(1, int(length))  # 确保目标长度至少为1/
  %3(CNode_1972) = $(pad_sequence_1730):getattr(%para363_tensor, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %4(current_length) = $(pad_sequence_1730):S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:61/        current_length = tensor.shape[0]/
  %5(CNode_2351) = $(↓pad_sequence_2181):ClassType(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:68/        pad_length = target_length - int(current_length)/
  %6(pad_length) = $(↓pad_sequence_2181):S_Prim_sub(%2, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:68/        pad_length = target_length - int(current_length)/
  %7(CNode_2532) = S_Prim_MakeTuple(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:70/            pad_shape = (pad_length,) + tensor.shape[1:]/
  %8(CNode_2533) = getattr(%para363_tensor, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:70/            pad_shape = (pad_length,) + tensor.shape[1:]/
  %9(CNode_2534) = S_Prim_make_slice(I64(1), None, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:70/            pad_shape = (pad_length,) + tensor.shape[1:]/
  %10(CNode_2535) = S_Prim_getitem(%8, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:70/            pad_shape = (pad_length,) + tensor.shape[1:]/
  %11(pad_shape) = S_Prim_add(%7, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:70/            pad_shape = (pad_length,) + tensor.shape[1:]/
  %12(CNode_2536) = getattr(%para363_tensor, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:71/            pad_tensor = ops.zeros(pad_shape, tensor.dtype)/
  %13(pad_tensor) = call @zeros_442(%11, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:71/            pad_tensor = ops.zeros(pad_shape, tensor.dtype)/
  %14(CNode_2537) = S_Prim_make_list(%para363_tensor, %13)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  %15(CNode_2538) = S_Prim_MakeTuple(%14)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  %16(CNode_2539) = S_Prim_MakeTuple("axis")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  %17(CNode_2540) = S_Prim_MakeTuple(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  %18(CNode_2541) = S_Prim_make_dict(%16, %17)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  %19(CNode_2542) = UnpackCall_unpack_call(@concat_2543, %15, %18)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
  Return(%19)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:72/            return ops.concat([tensor, pad_tensor], axis=0)/
}
# Order:
#   1: @✓↓pad_sequence_2355:CNode_2532{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: pad_length}
#   2: @✓↓pad_sequence_2355:CNode_2533{[0]: ValueNode<Primitive> getattr, [1]: param_tensor, [2]: ValueNode<StringImm> shape}
#   3: @✓↓pad_sequence_2355:CNode_2534{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<Int64Imm> 1, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   4: @✓↓pad_sequence_2355:CNode_2535{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2533, [2]: CNode_2534}
#   5: @✓↓pad_sequence_2355:pad_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_2532, [2]: CNode_2535}
#   6: @✓↓pad_sequence_2355:CNode_2536{[0]: ValueNode<Primitive> getattr, [1]: param_tensor, [2]: ValueNode<StringImm> dtype}
#   7: @✓↓pad_sequence_2355:pad_tensor{[0]: ValueNode<FuncGraph> zeros_442, [1]: pad_shape, [2]: CNode_2536}
#   8: @✓↓pad_sequence_2355:CNode_2537{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: param_tensor, [2]: pad_tensor}
#   9: @✓↓pad_sequence_2355:CNode_2538{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_2537}
#  10: @✓↓pad_sequence_2355:CNode_2539{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> axis}
#  11: @✓↓pad_sequence_2355:CNode_2540{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0}
#  12: @✓↓pad_sequence_2355:CNode_2541{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_2539, [2]: CNode_2540}
#  13: @✓↓pad_sequence_2355:CNode_2542{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.2544, [1]: ValueNode<FuncGraph> concat_2543, [2]: CNode_2538, [3]: CNode_2541}
#  14: @✓↓pad_sequence_2355:CNode_2545{[0]: ValueNode<Primitive> Return, [1]: CNode_2542}


subgraph attr:
training : 1
subgraph instance: ✗↓pad_sequence_2356 : 0x394e20c0
# In file /data/shengteng/training/tfnet_model.py:59/    def pad_sequence(self, tensor, length):/
subgraph @✗↓pad_sequence_2356 parent: [subgraph @pad_sequence_1730]() {
  Return(%para363_tensor)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:74/            return tensor/
}
# Order:
#   1: @✗↓pad_sequence_2356:CNode_2546{[0]: ValueNode<Primitive> Return, [1]: param_tensor}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv1d_construct_2547 : 0x33285d00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv1d_construct_2547 parent: [subgraph @after_grad_108](%para391_x) {
  %1(CNode_2549) = call @L_mindspore_nn_layer_conv_Conv1d_construct_2548(%para391_x, %para57_conv1d.temporal_conv.0.bias, %para56_conv1d.temporal_conv.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.0.bias>, <Ref[Tensor[Float32]], (64, 512, 1, 5), ref_key=:conv1d.temporal_conv.0.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv1d_construct_2547:CNode_2549{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv1d_construct_2548, [1]: param_x, [2]: param_conv1d.temporal_conv.0.bias, [3]: param_conv1d.temporal_conv.0.weight}
#   2: @mindspore_nn_layer_conv_Conv1d_construct_2547:CNode_2550{[0]: ValueNode<Primitive> Return, [1]: CNode_2549}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm1d_construct_2551 : 0x3331a6f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm1d_construct_2551 parent: [subgraph @after_grad_108](%para392_x) {
  %1(CNode_2553) = call @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552(%para392_x, %para58_conv1d.temporal_conv.1.gamma, %para59_conv1d.temporal_conv.1.beta, %para119_conv1d.temporal_conv.1.moving_mean, %para120_conv1d.temporal_conv.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2551:CNode_2553{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552, [1]: param_x, [2]: param_conv1d.temporal_conv.1.gamma, [3]: param_conv1d.temporal_conv.1.beta, [4]: param_conv1d.temporal_conv.1.moving_mean, [5]: param_conv1d.temporal_conv.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2551:CNode_2554{[0]: ValueNode<Primitive> Return, [1]: CNode_2553}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_2555 : 0x334686c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_2555(%para393_x) {
  %1(CNode_2556) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para393_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_2555:CNode_2556{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_2555:CNode_2557{[0]: ValueNode<Primitive> Return, [1]: CNode_2556}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_MaxPool1d_construct_2558 : 0x37ddc9e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2558(%para394_x) {
  %1(CNode_2559) = getattr(%para394_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %2(CNode_2560) = S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %3(CNode_2561) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %4(CNode_2562) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563, @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %5(CNode_2565) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2559{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2560{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2559, [2]: ValueNode<Int64Imm> 2}
#   3: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2561{[0]: ValueNode<Primitive> Cond, [1]: CNode_2560, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2562{[0]: ValueNode<Primitive> Switch, [1]: CNode_2561, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564}
#   5: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2565{[0]: CNode_2562}
#   6: @mindspore_nn_layer_pooling_MaxPool1d_construct_2558:CNode_2566{[0]: ValueNode<Primitive> Return, [1]: CNode_2565}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv1d_construct_2567 : 0x37487be0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv1d_construct_2567 parent: [subgraph @after_grad_108](%para395_x) {
  %1(CNode_2569) = call @L_mindspore_nn_layer_conv_Conv1d_construct_2568(%para395_x, %para61_conv1d.temporal_conv.4.bias, %para60_conv1d.temporal_conv.4.weight)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.4.bias>, <Ref[Tensor[Float32]], (64, 64, 1, 5), ref_key=:conv1d.temporal_conv.4.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv1d_construct_2567:CNode_2569{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv1d_construct_2568, [1]: param_x, [2]: param_conv1d.temporal_conv.4.bias, [3]: param_conv1d.temporal_conv.4.weight}
#   2: @mindspore_nn_layer_conv_Conv1d_construct_2567:CNode_2570{[0]: ValueNode<Primitive> Return, [1]: CNode_2569}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm1d_construct_2571 : 0x37c530d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm1d_construct_2571 parent: [subgraph @after_grad_108](%para396_x) {
  %1(CNode_2572) = call @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552(%para396_x, %para62_conv1d.temporal_conv.5.gamma, %para63_conv1d.temporal_conv.5.beta, %para121_conv1d.temporal_conv.5.moving_mean, %para122_conv1d.temporal_conv.5.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d.temporal_conv.5.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2571:CNode_2572{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552, [1]: param_x, [2]: param_conv1d.temporal_conv.5.gamma, [3]: param_conv1d.temporal_conv.5.beta, [4]: param_conv1d.temporal_conv.5.moving_mean, [5]: param_conv1d.temporal_conv.5.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2571:CNode_2573{[0]: ValueNode<Primitive> Return, [1]: CNode_2572}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_2574 : 0x37d28c50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_2574(%para397_x) {
  %1(CNode_2575) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para397_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_2574:CNode_2575{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_2574:CNode_2576{[0]: ValueNode<Primitive> Return, [1]: CNode_2575}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_MaxPool1d_construct_2577 : 0x37fd3a20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2577(%para398_x) {
  %1(CNode_2578) = getattr(%para398_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %2(CNode_2579) = S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %3(CNode_2580) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %4(CNode_2581) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582, @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %5(CNode_2584) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2578{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2579{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2578, [2]: ValueNode<Int64Imm> 2}
#   3: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2580{[0]: ValueNode<Primitive> Cond, [1]: CNode_2579, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2581{[0]: ValueNode<Primitive> Switch, [1]: CNode_2580, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583}
#   5: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2584{[0]: CNode_2581}
#   6: @mindspore_nn_layer_pooling_MaxPool1d_construct_2577:CNode_2585{[0]: ValueNode<Primitive> Return, [1]: CNode_2584}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_2359 : 0x372e5b50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2359 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_2185](%para399_, %para400_) {
  %1(CNode_2362) = $(mindspore_nn_layer_container_SequentialCell_construct_2185):MakeTuple(@mindspore_nn_layer_conv_Conv1d_construct_2547, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2551, @mindspore_nn_layer_activation_ReLU_construct_2555, @mindspore_nn_layer_pooling_MaxPool1d_construct_2558, @mindspore_nn_layer_conv_Conv1d_construct_2567, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2571, @mindspore_nn_layer_activation_ReLU_construct_2574, @mindspore_nn_layer_pooling_MaxPool1d_construct_2577)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_2361) = $(mindspore_nn_layer_container_SequentialCell_construct_2185):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_2586) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para399_@CNode_2587, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_2588) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_2589, @↓mindspore_nn_layer_container_SequentialCell_construct_2590)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_2591) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_2359:CNode_2586{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2587, [2]: CNode_2361}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_2359:CNode_2588{[0]: ValueNode<Primitive> Switch, [1]: CNode_2586, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_2589, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_2590}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_2359:CNode_2591{[0]: CNode_2588}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_2359:CNode_2592{[0]: ValueNode<Primitive> Return, [1]: CNode_2591}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓↻9↓tfnet_model_TFNetModel_construct_2373 : 0x394b38e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓↻9↓tfnet_model_TFNetModel_construct_2373 parent: [subgraph @↻9↓tfnet_model_TFNetModel_construct_2192](%para401_) {
  %1(CNode_2190) = $(↻9↓tfnet_model_TFNetModel_construct_2192):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para372_@CNode_2190, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %2(CNode_2593) = call @↵9↓tfnet_model_TFNetModel_construct_1981(%1, %para401_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
}
# Order:
#   1: @↓↻9↓tfnet_model_TFNetModel_construct_2373:CNode_2594{[0]: ValueNode<Primitive> Return, [1]: CNode_2593}
#   2: @↓↻9↓tfnet_model_TFNetModel_construct_2373:CNode_2593{[0]: ValueNode<FuncGraph> ↵9↓tfnet_model_TFNetModel_construct_1981, [1]: CNode_2190, [2]: param_фlgt}


subgraph attr:
training : 1
subgraph instance: ✓↻9↓tfnet_model_TFNetModel_construct_2370 : 0x3949aed0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻9↓tfnet_model_TFNetModel_construct_2370 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(lgt) = call @G_✓↻9↓tfnet_model_TFNetModel_construct_2595()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @✓↻9↓tfnet_model_TFNetModel_construct_2370:lgt{[0]: ValueNode<FuncGraph> G_✓↻9↓tfnet_model_TFNetModel_construct_2595}
#   2: @✓↻9↓tfnet_model_TFNetModel_construct_2370:CNode_2596{[0]: ValueNode<Primitive> Return, [1]: lgt}


subgraph attr:
training : 1
subgraph instance: ✗↻9↓tfnet_model_TFNetModel_construct_2371 : 0x3947ba20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻9↓tfnet_model_TFNetModel_construct_2371 parent: [subgraph @↻9↓tfnet_model_TFNetModel_construct_2192]() {
  %1(lgt) = call @G_✗↻9↓tfnet_model_TFNetModel_construct_2597()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:179/                k = int(ks[1])/
}
# Order:
#   1: @✗↻9↓tfnet_model_TFNetModel_construct_2371:CNode_2598{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: ks, [2]: ValueNode<Int64Imm> 1}
#   2: @✗↻9↓tfnet_model_TFNetModel_construct_2371:k{[0]: ValueNode<ClassType> class 'int', [1]: CNode_2598}
#   3: @✗↻9↓tfnet_model_TFNetModel_construct_2371:lgt{[0]: ValueNode<FuncGraph> G_✗↻9↓tfnet_model_TFNetModel_construct_2597}
#   4: @✗↻9↓tfnet_model_TFNetModel_construct_2371:CNode_2599{[0]: ValueNode<Primitive> Return, [1]: lgt}


subgraph attr:
training : 1
subgraph instance: modules_TemporalConv_construct_2389 : 0x39093600
# In file /data/shengteng/training/modules.py:67/    def construct(self, frame_feat, lgt):/
subgraph @modules_TemporalConv_construct_2389 parent: [subgraph @after_grad_108](%para402_frame_feat, %para403_lgt) {
  %1(CNode_2600) = S_Prim_MakeTuple("visual_feat", "feat_len")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  %2(visual_feat) = call @mindspore_nn_layer_container_SequentialCell_construct_2601(%para402_frame_feat)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:69/        visual_feat = self.temporal_conv(frame_feat)/
  %3(CNode_2602) = S_Prim_MakeTuple(%2, %para403_lgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  %4(CNode_2603) = S_Prim_make_dict(%1, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:70/        return {/
}
# Order:
#   1: @modules_TemporalConv_construct_2389:visual_feat{[0]: ValueNode<FuncGraph> mindspore_nn_layer_container_SequentialCell_construct_2601, [1]: param_frame_feat}
#   2: @modules_TemporalConv_construct_2389:CNode_2600{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> visual_feat, [2]: ValueNode<StringImm> feat_len}
#   3: @modules_TemporalConv_construct_2389:CNode_2602{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: visual_feat, [2]: param_lgt}
#   4: @modules_TemporalConv_construct_2389:CNode_2603{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_2600, [2]: CNode_2602}
#   5: @modules_TemporalConv_construct_2389:CNode_2604{[0]: ValueNode<Primitive> Return, [1]: CNode_2603}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 11↓tfnet_model_TFNetModel_construct_2385 : 0x39152d70
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @11↓tfnet_model_TFNetModel_construct_2385 parent: [subgraph @10↓tfnet_model_TFNetModel_construct_2193](%para404_) {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(CNode_2387) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %4(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %5(X) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Abs[output_names: ["output"], input_names: ["input_x"]](%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:186/        X = self.abs(framewise1)  # 简化的FFT替代/
  %6(CNode_2388) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %7(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %8(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %9(conv1d_outputs1) = $(10↓tfnet_model_TFNetModel_construct_2193):call @modules_TemporalConv_construct_2389(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:189/        conv1d_outputs1 = self.conv1d1(framewise1, len_x_list)/
  %10(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_getitem(%9, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:190/        x1 = conv1d_outputs1['visual_feat']/
  %11(CNode_2390) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %12(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%10, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %13(CNode_2605) = getattr(%12, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
  %14(CNode_2606) = S_Prim_not_equal(%13, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
  %15(CNode_2607) = Cond(%14, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
  %16(CNode_2608) = Switch(%15, @✓11↓tfnet_model_TFNetModel_construct_2609, @✗11↓tfnet_model_TFNetModel_construct_2610)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
  %17(CNode_2611) = %16()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
  %18(CNode_2613) = call @12↓tfnet_model_TFNetModel_construct_2612(%17)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%18)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
}
# Order:
#   1: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2605{[0]: ValueNode<Primitive> getattr, [1]: x1, [2]: ValueNode<StringImm> dtype}
#   2: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2606{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_2605, [2]: ValueNode<Float> Float32}
#   3: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2607{[0]: ValueNode<Primitive> Cond, [1]: CNode_2606, [2]: ValueNode<BoolImm> false}
#   4: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2608{[0]: ValueNode<Primitive> Switch, [1]: CNode_2607, [2]: ValueNode<FuncGraph> ✓11↓tfnet_model_TFNetModel_construct_2609, [3]: ValueNode<FuncGraph> ✗11↓tfnet_model_TFNetModel_construct_2610}
#   5: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2611{[0]: CNode_2608}
#   6: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2613{[0]: ValueNode<FuncGraph> 12↓tfnet_model_TFNetModel_construct_2612, [1]: CNode_2611}
#   7: @11↓tfnet_model_TFNetModel_construct_2385:CNode_2614{[0]: ValueNode<Primitive> Return, [1]: CNode_2613}


subgraph attr:
training : 1
subgraph instance: ✓10↓tfnet_model_TFNetModel_construct_2382 : 0x39151ab0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓10↓tfnet_model_TFNetModel_construct_2382 parent: [subgraph @10↓tfnet_model_TFNetModel_construct_2193]() {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %4(conv1d_outputs) = $(9↓tfnet_model_TFNetModel_construct_1746):call @modules_TemporalConv_construct_1984(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:171/        conv1d_outputs = self.conv1d(framewise, len_x_list)/
  %5(x) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_getitem(%4, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:172/        x = conv1d_outputs['visual_feat']/
  %6(CNode_2377) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %7(x) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %8(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%7, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:195/            x = ops.cast(x, ms.float32)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:195/            x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓10↓tfnet_model_TFNetModel_construct_2382:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: x, [2]: ValueNode<Float> Float32}
#   2: @✓10↓tfnet_model_TFNetModel_construct_2382:CNode_2615{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: ✗10↓tfnet_model_TFNetModel_construct_2383 : 0x39150b20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗10↓tfnet_model_TFNetModel_construct_2383 parent: [subgraph @10↓tfnet_model_TFNetModel_construct_2193]() {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %4(conv1d_outputs) = $(9↓tfnet_model_TFNetModel_construct_1746):call @modules_TemporalConv_construct_1984(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:171/        conv1d_outputs = self.conv1d(framewise, len_x_list)/
  %5(x) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_getitem(%4, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:172/        x = conv1d_outputs['visual_feat']/
  %6(CNode_2377) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %7(x) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:181/        x = self.transpose(x, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:194/        if x.dtype != ms.float32:/
}
# Order:
#   1: @✗10↓tfnet_model_TFNetModel_construct_2383:CNode_2616{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
subgraph instance: ✓2↓✓↓ms_max_one_element_2396 : 0x3761d9f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓2↓✓↓ms_max_one_element_2396 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_2617) = call @max_tensor_1154(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2628/            return max_tensor(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2628/            return max_tensor(x)/
}
# Order:
#   1: @✓2↓✓↓ms_max_one_element_2396:CNode_2617{[0]: ValueNode<FuncGraph> max_tensor_1154, [1]: param_x}
#   2: @✓2↓✓↓ms_max_one_element_2396:CNode_2618{[0]: ValueNode<Primitive> Return, [1]: CNode_2617}


subgraph attr:
subgraph instance: ✗2↓✓↓ms_max_one_element_2397 : 0x3788c300
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗2↓✓↓ms_max_one_element_2397 parent: [subgraph @2↓✓↓ms_max_one_element_2201]() {
  %1(CNode_2620) = call @3↓✓↓ms_max_one_element_2619()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2627/        if tensor_num == len(x):/
}
# Order:
#   1: @✗2↓✓↓ms_max_one_element_2397:CNode_2620{[0]: ValueNode<FuncGraph> 3↓✓↓ms_max_one_element_2619}
#   2: @✗2↓✓↓ms_max_one_element_2397:CNode_2621{[0]: ValueNode<Primitive> Return, [1]: CNode_2620}


subgraph attr:
subgraph instance: ✓↓✓check_sequence_all_variable_scalar_2406 : 0x37718110
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✓↓✓check_sequence_all_variable_scalar_2406 parent: [subgraph @check_sequence_all_variable_scalar_1412]() {
  %1(CNode_2622) = S_Prim_add("When the input to ", %para330_str_info)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2583/                "When the input to " + str_info + "() is dynamic length sequence, only support scalar type input")/
  %2(CNode_2623) = S_Prim_add(%1, "() is dynamic length sequence, only support scalar type input")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2583/                "When the input to " + str_info + "() is dynamic length sequence, only support scalar type input")/
  %3(CNode_2624) = S_Prim_raise_value_error[constexpr_prim: Bool(1)](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2582/            const_utils.raise_value_error(/
  %4(CNode_2625) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
  %5(CNode_2627) = call @2↓✓check_sequence_all_variable_scalar_2626()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2582/            const_utils.raise_value_error(/
  %6(CNode_2628) = Depend[side_effect_propagate: I64(1)](%5, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2582/            const_utils.raise_value_error(/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2582/            const_utils.raise_value_error(/
}
# Order:
#   1: @✓↓✓check_sequence_all_variable_scalar_2406:CNode_2622{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: ValueNode<StringImm> When the input to , [2]: param_str_info}
#   2: @✓↓✓check_sequence_all_variable_scalar_2406:CNode_2623{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_2622, [2]: ValueNode<StringImm> () is dynamic length sequence, only support scalar type input}
#   3: @✓↓✓check_sequence_all_variable_scalar_2406:CNode_2624{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: CNode_2623}
#   4: @✓↓✓check_sequence_all_variable_scalar_2406:CNode_2627{[0]: ValueNode<FuncGraph> 2↓✓check_sequence_all_variable_scalar_2626}
#   5: @✓↓✓check_sequence_all_variable_scalar_2406:CNode_2629{[0]: ValueNode<Primitive> Return, [1]: CNode_2628}


subgraph attr:
subgraph instance: ✗↓✓check_sequence_all_variable_scalar_2407 : 0x37f419b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✗↓✓check_sequence_all_variable_scalar_2407() {
  %1(CNode_2630) = call @2↓✓check_sequence_all_variable_scalar_2626()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2581/        if not isinstance(x[0], (int, float)):/
}
# Order:
#   1: @✗↓✓check_sequence_all_variable_scalar_2407:CNode_2630{[0]: ValueNode<FuncGraph> 2↓✓check_sequence_all_variable_scalar_2626}
#   2: @✗↓✓check_sequence_all_variable_scalar_2407:CNode_2631{[0]: ValueNode<Primitive> Return, [1]: CNode_2630}


subgraph attr:
subgraph instance: ↻↓check_sequence_all_variable_scalar_2413 : 0x37814f90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↻↓check_sequence_all_variable_scalar_2413 parent: [subgraph @↵↓check_sequence_all_variable_scalar_2216]() {
  %1(CNode_2411) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para380_@CNode_2411, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %2(CNode_2632) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
  %3(CNode_2633) = call @ms_iter_97(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %4(i) = S_Prim_getitem(%3, %para380_@CNode_2411)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %5(CNode_2634) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %6(CNode_2635) = S_Prim_isinstance(%4, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %7(CNode_2636) = S_Prim_logical_not(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %8(CNode_2637) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %9(CNode_2638) = Switch(%8, @✓↻↓check_sequence_all_variable_scalar_2639, @✗↻↓check_sequence_all_variable_scalar_2640)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %10(CNode_2641) = %9()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  %11(CNode_2642) = Depend[side_effect_propagate: I64(1)](%10, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
}
# Order:
#   1: @↻↓check_sequence_all_variable_scalar_2413:CNode_2633{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_x}
#   2: @↻↓check_sequence_all_variable_scalar_2413:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2633, [2]: param_@CNode_2411}
#   3: @↻↓check_sequence_all_variable_scalar_2413:CNode_2411{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2411, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓check_sequence_all_variable_scalar_2413:CNode_2634{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'int', [2]: ValueNode<ClassType> class 'float'}
#   5: @↻↓check_sequence_all_variable_scalar_2413:CNode_2635{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: i, [2]: CNode_2634}
#   6: @↻↓check_sequence_all_variable_scalar_2413:CNode_2636{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_2635}
#   7: @↻↓check_sequence_all_variable_scalar_2413:CNode_2637{[0]: ValueNode<Primitive> Cond, [1]: CNode_2636, [2]: ValueNode<BoolImm> false}
#   8: @↻↓check_sequence_all_variable_scalar_2413:CNode_2638{[0]: ValueNode<Primitive> Switch, [1]: CNode_2637, [2]: ValueNode<FuncGraph> ✓↻↓check_sequence_all_variable_scalar_2639, [3]: ValueNode<FuncGraph> ✗↻↓check_sequence_all_variable_scalar_2640}
#   9: @↻↓check_sequence_all_variable_scalar_2413:CNode_2641{[0]: CNode_2638}
#  10: @↻↓check_sequence_all_variable_scalar_2413:CNode_2643{[0]: ValueNode<Primitive> Return, [1]: CNode_2642}


subgraph attr:
subgraph instance: 2↓check_sequence_all_variable_scalar_2414 : 0x37732dd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @2↓check_sequence_all_variable_scalar_2414 parent: [subgraph @↵↓check_sequence_all_variable_scalar_2216]() {
  Return(%para381_фcontain_variable_scalar)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2591/    return contain_variable_scalar/
}
# Order:
#   1: @2↓check_sequence_all_variable_scalar_2414:CNode_2644{[0]: ValueNode<Primitive> Return, [1]: param_фcontain_variable_scalar}


subgraph attr:
subgraph instance: ✓↻exist_tensor_2422 : 0x310ad0d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @✓↻exist_tensor_2422() {
  Return(Bool(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2569/            return True/
}
# Order:
#   1: @✓↻exist_tensor_2422:CNode_2645{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✗↻exist_tensor_2423 : 0x37eb2310
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @✗↻exist_tensor_2423 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_2647) = call @↓↻exist_tensor_2646()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2568/        if isinstance(input_data, Tensor):/
}
# Order:
#   1: @✗↻exist_tensor_2423:CNode_2647{[0]: ValueNode<FuncGraph> ↓↻exist_tensor_2646}
#   2: @✗↻exist_tensor_2423:CNode_2648{[0]: ValueNode<Primitive> Return, [1]: CNode_2647}


subgraph attr:
after_block : 1
subgraph instance: ↓_check_ctcloss_targets_shape_2432 : 0x397d2af0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @↓_check_ctcloss_targets_shape_2432 parent: [subgraph @_check_ctcloss_targets_shape_2060]() {
  %1(CNode_2649) = getattr(%para375_targets, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %2(CNode_2650) = S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %3(CNode_2651) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %4(CNode_2652) = Switch(%3, @↰↓_check_ctcloss_targets_shape_2653, @↱↓_check_ctcloss_targets_shape_2654)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %5(CNode_2655) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %6(CNode_2656) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %7(CNode_2657) = Switch(%6, @✓↓_check_ctcloss_targets_shape_2658, @✗↓_check_ctcloss_targets_shape_2659)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %8(CNode_2660) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
}
# Order:
#   1: @↓_check_ctcloss_targets_shape_2432:CNode_2649{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> ndim}
#   2: @↓_check_ctcloss_targets_shape_2432:CNode_2650{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2649, [2]: ValueNode<Int64Imm> 2}
#   3: @↓_check_ctcloss_targets_shape_2432:CNode_2651{[0]: ValueNode<Primitive> Cond, [1]: CNode_2650, [2]: ValueNode<BoolImm> false}
#   4: @↓_check_ctcloss_targets_shape_2432:CNode_2652{[0]: ValueNode<Primitive> Switch, [1]: CNode_2651, [2]: ValueNode<FuncGraph> ↰↓_check_ctcloss_targets_shape_2653, [3]: ValueNode<FuncGraph> ↱↓_check_ctcloss_targets_shape_2654}
#   5: @↓_check_ctcloss_targets_shape_2432:CNode_2655{[0]: CNode_2652}
#   6: @↓_check_ctcloss_targets_shape_2432:CNode_2656{[0]: ValueNode<Primitive> Cond, [1]: CNode_2655, [2]: ValueNode<BoolImm> false}
#   7: @↓_check_ctcloss_targets_shape_2432:CNode_2657{[0]: ValueNode<Primitive> Switch, [1]: CNode_2656, [2]: ValueNode<FuncGraph> ✓↓_check_ctcloss_targets_shape_2658, [3]: ValueNode<FuncGraph> ✗↓_check_ctcloss_targets_shape_2659}
#   8: @↓_check_ctcloss_targets_shape_2432:CNode_2660{[0]: CNode_2657}
#   9: @↓_check_ctcloss_targets_shape_2432:CNode_2661{[0]: ValueNode<Primitive> Return, [1]: CNode_2660}


subgraph attr:
after_block : 1
subgraph instance: ↓ctc_loss_2443 : 0x397c41e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @↓ctc_loss_2443 parent: [subgraph @ctc_loss_2242](%para405_) {
  %1(CNode_2662) = S_Prim_equal(%para387_reduction, "mean")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
  %2(CNode_2663) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
  %3(CNode_2664) = Switch(%2, @✓↓ctc_loss_2665, @✗↓ctc_loss_2666)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
  %4(CNode_2667) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
  %5(CNode_2669) = call @2↓ctc_loss_2668(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2699/        neg_log_hood, _ = F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
}
# Order:
#   1: @↓ctc_loss_2443:CNode_2662{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_reduction, [2]: ValueNode<StringImm> mean}
#   2: @↓ctc_loss_2443:CNode_2663{[0]: ValueNode<Primitive> Cond, [1]: CNode_2662, [2]: ValueNode<BoolImm> false}
#   3: @↓ctc_loss_2443:CNode_2664{[0]: ValueNode<Primitive> Switch, [1]: CNode_2663, [2]: ValueNode<FuncGraph> ✓↓ctc_loss_2665, [3]: ValueNode<FuncGraph> ✗↓ctc_loss_2666}
#   4: @↓ctc_loss_2443:CNode_2667{[0]: CNode_2664}
#   5: @↓ctc_loss_2443:CNode_2669{[0]: ValueNode<FuncGraph> 2↓ctc_loss_2668, [1]: CNode_2667}
#   6: @↓ctc_loss_2443:CNode_2670{[0]: ValueNode<Primitive> Return, [1]: CNode_2669}


subgraph attr:
subgraph instance: ✓ctc_loss_2440 : 0x397c2d70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @✓ctc_loss_2440 parent: [subgraph @ctc_loss_2242]() {
  %1(CNode_2446) = $(ctc_loss_2242):S_Prim_MakeTuple("blank", "reduction", "zero_infinity")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %2(CNode_2447) = $(ctc_loss_2242):S_Prim_MakeTuple(%para386_blank, "none", %para388_zero_infinity)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %3(CNode_2448) = $(ctc_loss_2242):S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %4(ctc_loss_op) = $(ctc_loss_2242):UnpackCall_unpack_call(ClassType, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %5(CNode_2450) = $(ctc_loss_2242):%4(%para382_log_probs, %para383_targets, %para384_input_lengths, %para385_target_lengths)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  %6(loss) = $(ctc_loss_2242):S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  %7(CNode_2671) = getattr(%6, "sum")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4832/        loss = loss.sum()/
  %8(loss) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4832/        loss = loss.sum()/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4832/        loss = loss.sum()/
}
# Order:
#   1: @✓ctc_loss_2440:CNode_2671{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> sum}
#   2: @✓ctc_loss_2440:loss{[0]: CNode_2671}
#   3: @✓ctc_loss_2440:CNode_2672{[0]: ValueNode<Primitive> Return, [1]: loss}


subgraph attr:
subgraph instance: ✗ctc_loss_2441 : 0x397c1f90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @✗ctc_loss_2441 parent: [subgraph @ctc_loss_2242]() {
  %1(CNode_2446) = $(ctc_loss_2242):S_Prim_MakeTuple("blank", "reduction", "zero_infinity")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %2(CNode_2447) = $(ctc_loss_2242):S_Prim_MakeTuple(%para386_blank, "none", %para388_zero_infinity)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %3(CNode_2448) = $(ctc_loss_2242):S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %4(ctc_loss_op) = $(ctc_loss_2242):UnpackCall_unpack_call(ClassType, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %5(CNode_2450) = $(ctc_loss_2242):%4(%para382_log_probs, %para383_targets, %para384_input_lengths, %para385_target_lengths)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  %6(loss) = $(ctc_loss_2242):S_Prim_getitem(%5, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4831/    if reduction == 'sum':/
}
# Order:
#   1: @✗ctc_loss_2441:CNode_2673{[0]: ValueNode<Primitive> Return, [1]: loss}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓ms_min_one_element_2454 : 0x3958b870
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @2↓✓ms_min_one_element_2454 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2674) = getattr(%para257_x, "min")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2702/        return x.min()/
  %2(CNode_2675) = %1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2702/        return x.min()/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2702/        return x.min()/
}
# Order:
#   1: @2↓✓ms_min_one_element_2454:CNode_2674{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> min}
#   2: @2↓✓ms_min_one_element_2454:CNode_2675{[0]: CNode_2674}
#   3: @2↓✓ms_min_one_element_2454:CNode_2676{[0]: ValueNode<Primitive> Return, [1]: CNode_2675}


subgraph attr:
after_block : 1
subgraph instance: ↓✓↓ms_min_one_element_2463 : 0x39564810
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @↓✓↓ms_min_one_element_2463 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2677) = S_Prim_inner_len(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
  %2(CNode_2678) = S_Prim_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
  %3(CNode_2679) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
  %4(CNode_2680) = Switch(%3, @✓↓✓↓ms_min_one_element_2681, @✗↓✓↓ms_min_one_element_2682)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
  %5(CNode_2683) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
}
# Order:
#   1: @↓✓↓ms_min_one_element_2463:CNode_2677{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   2: @↓✓↓ms_min_one_element_2463:CNode_2678{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2677, [2]: ValueNode<Int64Imm> 0}
#   3: @↓✓↓ms_min_one_element_2463:CNode_2679{[0]: ValueNode<Primitive> Cond, [1]: CNode_2678, [2]: ValueNode<BoolImm> false}
#   4: @↓✓↓ms_min_one_element_2463:CNode_2680{[0]: ValueNode<Primitive> Switch, [1]: CNode_2679, [2]: ValueNode<FuncGraph> ✓↓✓↓ms_min_one_element_2681, [3]: ValueNode<FuncGraph> ✗↓✓↓ms_min_one_element_2682}
#   5: @↓✓↓ms_min_one_element_2463:CNode_2683{[0]: CNode_2680}
#   6: @↓✓↓ms_min_one_element_2463:CNode_2684{[0]: ValueNode<Primitive> Return, [1]: CNode_2683}


subgraph attr:
subgraph instance: ↻↓min_tensor_2474 : 0x39548970
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @↻↓min_tensor_2474 parent: [subgraph @↵↓min_tensor_2273]() {
  %1(CNode_2472) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para389_@CNode_2472, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %2(CNode_2685) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
  %3(CNode_2686) = ClassType()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2670/        min_tensor_data = P.Minimum()(min_tensor_data, input_data)/
  %4(CNode_2687) = call @ms_iter_97(%para377_фdata)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %5(input_data) = S_Prim_getitem(%4, %para389_@CNode_2472)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  %6(min_tensor_data) = %3(%para390_фmin_tensor_data, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2670/        min_tensor_data = P.Minimum()(min_tensor_data, input_data)/
  %7(CNode_2688) = call @↵↓min_tensor_2273(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2734/            return min_tensor(*data)/
  %8(CNode_2689) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2669/    for input_data in data:/
}
# Order:
#   1: @↻↓min_tensor_2474:CNode_2687{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: param_фdata}
#   2: @↻↓min_tensor_2474:input_data{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2687, [2]: param_@CNode_2472}
#   3: @↻↓min_tensor_2474:CNode_2472{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2472, [2]: ValueNode<Int64Imm> 1}
#   4: @↻↓min_tensor_2474:CNode_2686{[0]: ValueNode<ClassType> class 'mindspore.ops.operations.math_ops.Minimum'}
#   5: @↻↓min_tensor_2474:min_tensor_data{[0]: CNode_2686, [1]: param_фmin_tensor_data, [2]: input_data}
#   6: @↻↓min_tensor_2474:CNode_2690{[0]: ValueNode<Primitive> Return, [1]: CNode_2689}
#   7: @↻↓min_tensor_2474:CNode_2688{[0]: ValueNode<FuncGraph> ↵↓min_tensor_2273, [1]: CNode_2472, [2]: min_tensor_data}


subgraph attr:
subgraph instance: 2↓min_tensor_2475 : 0x39547ae0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2664/def min_tensor(*data):/
subgraph @2↓min_tensor_2475 parent: [subgraph @↵↓min_tensor_2273]() {
  Return(%para390_фmin_tensor_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2671/    return min_tensor_data/
}
# Order:
#   1: @2↓min_tensor_2475:CNode_2691{[0]: ValueNode<Primitive> Return, [1]: param_фmin_tensor_data}


subgraph attr:
subgraph instance: ✓2↓✓2✗ms_min_2481 : 0x395392b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✓2↓✓2✗ms_min_2481 parent: [subgraph @ms_min_962]() {
  %1(CNode_2692) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("The truth value of an array with more than one element is ambiguous.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2740/            const_utils.raise_value_error(/
  %2(CNode_2693) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
  %3(CNode_2695) = call @3↓✓2✗ms_min_2694()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  %4(CNode_2696) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2740/            const_utils.raise_value_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2740/            const_utils.raise_value_error(/
}
# Order:
#   1: @✓2↓✓2✗ms_min_2481:CNode_2692{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> The truth value of an array with more than one element is ambiguous.}
#   2: @✓2↓✓2✗ms_min_2481:CNode_2697{[0]: ValueNode<Primitive> Return, [1]: CNode_2696}
#   3: @✓2↓✓2✗ms_min_2481:CNode_2695{[0]: ValueNode<FuncGraph> 3↓✓2✗ms_min_2694}


subgraph attr:
subgraph instance: ✗2↓✓2✗ms_min_2482 : 0x39536220
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @✗2↓✓2✗ms_min_2482 parent: [subgraph @ms_min_962]() {
  %1(CNode_2698) = call @3↓✓2✗ms_min_2694()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2739/        if exist_tensor(data):/
}
# Order:
#   1: @✗2↓✓2✗ms_min_2482:CNode_2699{[0]: ValueNode<Primitive> Return, [1]: CNode_2698}
#   2: @✗2↓✓2✗ms_min_2482:CNode_2698{[0]: ValueNode<FuncGraph> 3↓✓2✗ms_min_2694}


subgraph attr:
subgraph instance: ✓2↓flatten_2490 : 0x39706250
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓2↓flatten_2490 parent: [subgraph @flatten_1327]() {
  %1(x_rank) = S_Prim_Rank(%para261_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1738/        x_rank = rank_(input)/
  %2(CNode_2700) = S_Prim_MakeTuple(I64(0), I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  %3(CNode_2701) = S_Prim_in(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  %4(CNode_2702) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  %5(CNode_2703) = Switch(%4, @2✓2↓flatten_2704, @✗✓2↓flatten_2705)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  %6(CNode_2706) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
}
# Order:
#   1: @✓2↓flatten_2490:x_rank{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Rank, [1]: param_input}
#   2: @✓2↓flatten_2490:CNode_2700{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 1}
#   3: @✓2↓flatten_2490:CNode_2701{[0]: ValueNode<DoSignaturePrimitive> S_Prim_in, [1]: x_rank, [2]: CNode_2700}
#   4: @✓2↓flatten_2490:CNode_2702{[0]: ValueNode<Primitive> Cond, [1]: CNode_2701, [2]: ValueNode<BoolImm> false}
#   5: @✓2↓flatten_2490:CNode_2703{[0]: ValueNode<Primitive> Switch, [1]: CNode_2702, [2]: ValueNode<FuncGraph> 2✓2↓flatten_2704, [3]: ValueNode<FuncGraph> ✗✓2↓flatten_2705}
#   6: @✓2↓flatten_2490:CNode_2706{[0]: CNode_2703}
#   7: @✓2↓flatten_2490:CNode_2707{[0]: ValueNode<Primitive> Return, [1]: CNode_2706}


subgraph attr:
subgraph instance: ✗2↓flatten_2491 : 0x396a1f20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗2↓flatten_2491 parent: [subgraph @flatten_1327]() {
  %1(CNode_2709) = call @3↓flatten_2708(%para261_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1737/    if order == 'F':/
}
# Order:
#   1: @✗2↓flatten_2491:CNode_2710{[0]: ValueNode<Primitive> Return, [1]: CNode_2709}
#   2: @✗2↓flatten_2491:CNode_2709{[0]: ValueNode<FuncGraph> 3↓flatten_2708, [1]: param_input}


subgraph attr:
subgraph instance: ↰2↱↓flatten_2499 : 0x39699840
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↰2↱↓flatten_2499 parent: [subgraph @2↱↓flatten_2299]() {
  %1(CNode_2496) = $(2↱↓flatten_2299):S_Prim_isinstance(%para263_start_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
}
# Order:
#   1: @↰2↱↓flatten_2499:CNode_2711{[0]: ValueNode<Primitive> Return, [1]: CNode_2496}


subgraph attr:
subgraph instance: 3↱↓flatten_2500 : 0x39698680
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @3↱↓flatten_2500 parent: [subgraph @flatten_1327]() {
  %1(CNode_2712) = S_Prim_isinstance(%para264_end_dim, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1734/            isinstance(start_dim, bool) or isinstance(end_dim, bool):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1733/    if not isinstance(start_dim, int) or not isinstance(end_dim, int) or \/
}
# Order:
#   1: @3↱↓flatten_2500:CNode_2712{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_end_dim, [2]: ValueNode<ClassType> class 'bool'}
#   2: @3↱↓flatten_2500:CNode_2713{[0]: ValueNode<Primitive> Return, [1]: CNode_2712}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506 : 0x3965dcf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1531]() {
  %1(CNode_2714) = S_Prim_BatchNorm[output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(0), input_names: ["x", "scale", "offset", "mean", "variance"], momentum: F32(0.1), epsilon: F32(1e-05)](%para338_x, %para339_L_conv2d.layer4.1.gamma, %para340_L_conv2d.layer4.1.beta, %para341_L_conv2d.layer4.1.moving_mean, %para342_L_conv2d.layer4.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  %2(CNode_2715) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506:CNode_2714{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer4.1.gamma, [3]: param_L_conv2d.layer4.1.beta, [4]: param_L_conv2d.layer4.1.moving_mean, [5]: param_L_conv2d.layer4.1.moving_variance}
#   2: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506:CNode_2715{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2714, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2506:CNode_2716{[0]: ValueNode<Primitive> Return, [1]: CNode_2715}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512 : 0x396286f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1568]() {
  %1(CNode_2717) = S_Prim_BatchNorm[output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(0), input_names: ["x", "scale", "offset", "mean", "variance"], momentum: F32(0.1), epsilon: F32(1e-05)](%para345_x, %para346_L_conv2d.layer3.1.gamma, %para347_L_conv2d.layer3.1.beta, %para348_L_conv2d.layer3.1.moving_mean, %para349_L_conv2d.layer3.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  %2(CNode_2718) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512:CNode_2717{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer3.1.gamma, [3]: param_L_conv2d.layer3.1.beta, [4]: param_L_conv2d.layer3.1.moving_mean, [5]: param_L_conv2d.layer3.1.moving_variance}
#   2: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512:CNode_2718{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2717, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2512:CNode_2719{[0]: ValueNode<Primitive> Return, [1]: CNode_2718}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518 : 0x395fb290
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm2d_construct_1632]() {
  %1(CNode_2720) = S_Prim_BatchNorm[output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(0), input_names: ["x", "scale", "offset", "mean", "variance"], momentum: F32(0.1), epsilon: F32(1e-05)](%para352_x, %para353_L_conv2d.layer2.1.gamma, %para354_L_conv2d.layer2.1.beta, %para355_L_conv2d.layer2.1.moving_mean, %para356_L_conv2d.layer2.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  %2(CNode_2721) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518:CNode_2720{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv2d.layer2.1.gamma, [3]: param_L_conv2d.layer2.1.beta, [4]: param_L_conv2d.layer2.1.moving_mean, [5]: param_L_conv2d.layer2.1.moving_variance}
#   2: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518:CNode_2721{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2720, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2↓mindspore_nn_layer_normalization_BatchNorm2d_construct_2518:CNode_2722{[0]: ValueNode<Primitive> Return, [1]: CNode_2721}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526 : 0x395d07a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526(%para406_) {
  %1(CNode_2724) = call @✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:587/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526:CNode_2724{[0]: ValueNode<FuncGraph> ✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526:CNode_2725{[0]: ValueNode<Primitive> Return, [1]: CNode_2724}


subgraph attr:
training : 1
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523 : 0x395c9b80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523 parent: [subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166]() {
  %1(CNode_2726) = S_Prim_isinstance(%para378_фout, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %2(CNode_2727) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %3(CNode_2728) = Switch(%2, @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729, @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %4(CNode_2731) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
  %5(CNode_2733) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2732(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:224/        x = self.maxpool(x)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2726{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: param_фout, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2727{[0]: ValueNode<Primitive> Cond, [1]: CNode_2726, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2728{[0]: ValueNode<Primitive> Switch, [1]: CNode_2727, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2731{[0]: CNode_2728}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2733{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2732, [1]: CNode_2731}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2523:CNode_2734{[0]: ValueNode<Primitive> Return, [1]: CNode_2733}


subgraph attr:
training : 1
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2524 : 0x395c8ca0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2524 parent: [subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166]() {
  Return(%para378_фout)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:582/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2524:CNode_2735{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
subgraph instance: concat_2543 : 0x394e73c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2163/def concat(tensors, axis=0):/
subgraph @concat_2543(%para407_tensors, %para408_axis) {
  %1(CNode_2737) = call @cat_2736(%para407_tensors, %para408_axis)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2174/    return cat(tensors, axis)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:2174/    return cat(tensors, axis)/
}
# Order:
#   1: @concat_2543:CNode_2737{[0]: ValueNode<FuncGraph> cat_2736, [1]: param_tensors, [2]: param_axis}
#   2: @concat_2543:CNode_2738{[0]: ValueNode<Primitive> Return, [1]: CNode_2737}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv1d_construct_2548 : 0x332815e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv1d_construct_2548(%para409_x, %para410_, %para411_) {
  %1(x_shape) = S_Prim_Shape(%para409_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:580/        x_shape = self.shape(x)/
  %2(CNode_2739) = S_Prim__check_input_3d[constexpr_prim: Bool(1)](%1, "Conv1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:581/        _check_input_3d(x_shape, self.cls_name)/
  %3(CNode_2740) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
  %4(CNode_2742) = call @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
  %5(CNode_2743) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:x_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:CNode_2739{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_3d, [1]: x_shape, [2]: ValueNode<StringImm> Conv1d}
#   3: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_x, [2]: ValueNode<Int64Imm> 2}
#   4: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: x, [2]: param_L_conv1d1.temporal_conv.0.weight}
#   5: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:CNode_2742{[0]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_conv_Conv1d_construct_2741}
#   6: @L_mindspore_nn_layer_conv_Conv1d_construct_2548:CNode_2744{[0]: ValueNode<Primitive> Return, [1]: CNode_2743}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552 : 0x3739f6c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552(%para412_x, %para413_, %para414_, %para415_, %para416_) {
  %1(CNode_2745) = S_Prim_Shape(%para412_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %2(CNode_2746) = S_Prim__check_input_dim[constexpr_prim: Bool(1)](%1, "BatchNorm1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:139/        self._check_input_dim(self.shape(x), self.cls_name)/
  %3(CNode_2747) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
  %4(CNode_2748) = S_Prim_is_(None, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %5(CNode_2749) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %6(CNode_2750) = Switch(%5, @L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751, @L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %7(CNode_2753) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  %8(CNode_2754) = Depend[side_effect_propagate: I64(1)](%7, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2745{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2746{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_dim, [1]: CNode_2745, [2]: ValueNode<StringImm> BatchNorm1d}
#   3: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2748{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_, [1]: ValueNode<None> None, [2]: ValueNode<None> None}
#   4: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2749{[0]: ValueNode<Primitive> Cond, [1]: CNode_2748, [2]: ValueNode<BoolImm> false}
#   5: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2750{[0]: ValueNode<Primitive> Switch, [1]: CNode_2749, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752}
#   6: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2753{[0]: CNode_2750}
#   7: @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552:CNode_2755{[0]: ValueNode<Primitive> Return, [1]: CNode_2754}


subgraph attr:
training : 1
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563 : 0x333ba6e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2558]() {
  %1(CNode_2756) = getattr(%para394_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %3(CNode_2758) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563:CNode_2756{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563:x{[0]: CNode_2756, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563:CNode_2759{[0]: ValueNode<Primitive> Return, [1]: CNode_2758}
#   4: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2563:CNode_2758{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564 : 0x33467a00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2558]() {
  %1(CNode_2760) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757(%para394_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564:CNode_2761{[0]: ValueNode<Primitive> Return, [1]: CNode_2760}
#   2: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2564:CNode_2760{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_conv_Conv1d_construct_2568 : 0x332c3b80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_conv_Conv1d_construct_2568(%para417_x, %para418_, %para419_) {
  %1(x_shape) = S_Prim_Shape(%para417_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:580/        x_shape = self.shape(x)/
  %2(CNode_2762) = S_Prim__check_input_3d[constexpr_prim: Bool(1)](%1, "Conv1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:581/        _check_input_3d(x_shape, self.cls_name)/
  %3(CNode_2763) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
  %4(CNode_2765) = call @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
  %5(CNode_2766) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:x_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:CNode_2762{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_input_3d, [1]: x_shape, [2]: ValueNode<StringImm> Conv1d}
#   3: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_x, [2]: ValueNode<Int64Imm> 2}
#   4: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Conv2D, [1]: x, [2]: param_L_conv1d1.temporal_conv.4.weight}
#   5: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:CNode_2765{[0]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_conv_Conv1d_construct_2764}
#   6: @L_mindspore_nn_layer_conv_Conv1d_construct_2568:CNode_2767{[0]: ValueNode<Primitive> Return, [1]: CNode_2766}


subgraph attr:
training : 1
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582 : 0x38f5ab80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2577]() {
  %1(CNode_2768) = getattr(%para398_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %3(CNode_2770) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582:CNode_2768{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582:x{[0]: CNode_2768, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582:CNode_2771{[0]: ValueNode<Primitive> Return, [1]: CNode_2770}
#   4: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2582:CNode_2770{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583 : 0x37d4e550
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2577]() {
  %1(CNode_2772) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769(%para398_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583:CNode_2773{[0]: ValueNode<Primitive> Return, [1]: CNode_2772}
#   2: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2583:CNode_2772{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_2589 : 0x37da75e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_2589 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2359]() {
  %1(CNode_2587) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para399_@CNode_2587, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_2774) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_2362) = $(mindspore_nn_layer_container_SequentialCell_construct_2185):MakeTuple(@mindspore_nn_layer_conv_Conv1d_construct_2547, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2551, @mindspore_nn_layer_activation_ReLU_construct_2555, @mindspore_nn_layer_pooling_MaxPool1d_construct_2558, @mindspore_nn_layer_conv_Conv1d_construct_2567, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2571, @mindspore_nn_layer_activation_ReLU_construct_2574, @mindspore_nn_layer_pooling_MaxPool1d_construct_2577)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_2775) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para399_@CNode_2587)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para400_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_2776) = call @↵mindspore_nn_layer_container_SequentialCell_construct_2359(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_2777) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:CNode_2775{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_2362}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2775, [2]: param_@CNode_2587}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:CNode_2587{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2587, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:CNode_2776{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_2359, [1]: CNode_2587, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_2589:CNode_2778{[0]: ValueNode<Primitive> Return, [1]: CNode_2777}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_2590 : 0x311067c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_2590 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2359]() {
  Return(%para400_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_2590:CNode_2779{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
training : 1
subgraph instance: G_✓↻9↓tfnet_model_TFNetModel_construct_2595 : 0x3949db90
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_✓↻9↓tfnet_model_TFNetModel_construct_2595 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(CNode_2781) = call @↵✓↻9↓tfnet_model_TFNetModel_construct_2780(%para373_фlgt, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @G_✓↻9↓tfnet_model_TFNetModel_construct_2595:CNode_2782{[0]: ValueNode<Primitive> Return, [1]: CNode_2781}
#   2: @G_✓↻9↓tfnet_model_TFNetModel_construct_2595:CNode_2781{[0]: ValueNode<FuncGraph> ↵✓↻9↓tfnet_model_TFNetModel_construct_2780, [1]: param_фlgt, [2]: ValueNode<ValueList> []}


subgraph attr:
training : 1
subgraph instance: G_✗↻9↓tfnet_model_TFNetModel_construct_2597 : 0x39483ea0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_✗↻9↓tfnet_model_TFNetModel_construct_2597 parent: [subgraph @✗↻9↓tfnet_model_TFNetModel_construct_2371]() {
  %1(CNode_2784) = call @↵✗↻9↓tfnet_model_TFNetModel_construct_2783(%para373_фlgt, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @G_✗↻9↓tfnet_model_TFNetModel_construct_2597:CNode_2785{[0]: ValueNode<Primitive> Return, [1]: CNode_2784}
#   2: @G_✗↻9↓tfnet_model_TFNetModel_construct_2597:CNode_2784{[0]: ValueNode<FuncGraph> ↵✗↻9↓tfnet_model_TFNetModel_construct_2783, [1]: param_фlgt, [2]: ValueNode<ValueList> []}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_container_SequentialCell_construct_2601 : 0x39091b30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @mindspore_nn_layer_container_SequentialCell_construct_2601 parent: [subgraph @after_grad_108](%para420_input_data) {
  %1(CNode_2787) = call @↵mindspore_nn_layer_container_SequentialCell_construct_2786(I64(0), %para420_input_data)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @mindspore_nn_layer_container_SequentialCell_construct_2601:CNode_2788{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_2789}
#   2: @mindspore_nn_layer_container_SequentialCell_construct_2601:CNode_2787{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_2786, [1]: ValueNode<Int64Imm> 0, [2]: param_input_data}
#   3: @mindspore_nn_layer_container_SequentialCell_construct_2601:CNode_2790{[0]: ValueNode<Primitive> Return, [1]: CNode_2787}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 12↓tfnet_model_TFNetModel_construct_2612 : 0x3915ee20
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @12↓tfnet_model_TFNetModel_construct_2612 parent: [subgraph @11↓tfnet_model_TFNetModel_construct_2385](%para421_) {
  %1(CNode_2791) = S_Prim_logical_not(%para172_is_train)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
  %2(CNode_2792) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
  %3(CNode_2793) = Switch(%2, @✓12↓tfnet_model_TFNetModel_construct_2794, @✗12↓tfnet_model_TFNetModel_construct_2795)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
  %4(CNode_2796) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
  %5(CNode_2798) = call @13↓tfnet_model_TFNetModel_construct_2797(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
}
# Order:
#   1: @12↓tfnet_model_TFNetModel_construct_2612:outputs{[0]: ValueNode<FuncGraph> modules_BiLSTMLayer_construct_2799, [1]: param_фx, [2]: param_фlgt}
#   2: @12↓tfnet_model_TFNetModel_construct_2612:outputs1{[0]: ValueNode<FuncGraph> modules_BiLSTMLayer_construct_2800, [1]: param_фx1, [2]: param_фlgt}
#   3: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2801{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: outputs, [2]: ValueNode<StringImm> predictions}
#   4: @12↓tfnet_model_TFNetModel_construct_2612:log_probs1{[0]: ValueNode<FuncGraph> modules_NormLinear_construct_2802, [1]: CNode_2801}
#   5: @12↓tfnet_model_TFNetModel_construct_2612:log_probs2{[0]: ValueNode<FuncGraph> modules_NormLinear_construct_2802, [1]: param_фx}
#   6: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2803{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: outputs1, [2]: ValueNode<StringImm> predictions}
#   7: @12↓tfnet_model_TFNetModel_construct_2612:log_probs3{[0]: ValueNode<FuncGraph> modules_NormLinear_construct_2804, [1]: CNode_2803}
#   8: @12↓tfnet_model_TFNetModel_construct_2612:log_probs4{[0]: ValueNode<FuncGraph> modules_NormLinear_construct_2804, [1]: param_фx1}
#   9: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2805{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: outputs, [2]: ValueNode<StringImm> predictions}
#  10: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2806{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: outputs1, [2]: ValueNode<StringImm> predictions}
#  11: @12↓tfnet_model_TFNetModel_construct_2612:x2{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_2805, [2]: CNode_2806}
#  12: @12↓tfnet_model_TFNetModel_construct_2612:log_probs1{[0]: ValueNode<FuncGraph> modules_NormLinear_construct_2807, [1]: x2}
#  13: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2791{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: param_is_train}
#  14: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2792{[0]: ValueNode<Primitive> Cond, [1]: CNode_2791, [2]: ValueNode<BoolImm> false}
#  15: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2793{[0]: ValueNode<Primitive> Switch, [1]: CNode_2792, [2]: ValueNode<FuncGraph> ✓12↓tfnet_model_TFNetModel_construct_2794, [3]: ValueNode<FuncGraph> ✗12↓tfnet_model_TFNetModel_construct_2795}
#  16: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2796{[0]: CNode_2793}
#  17: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2798{[0]: ValueNode<FuncGraph> 13↓tfnet_model_TFNetModel_construct_2797, [1]: CNode_2796}
#  18: @12↓tfnet_model_TFNetModel_construct_2612:CNode_2808{[0]: ValueNode<Primitive> Return, [1]: CNode_2798}


subgraph attr:
training : 1
subgraph instance: ✓11↓tfnet_model_TFNetModel_construct_2609 : 0x3915dba0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓11↓tfnet_model_TFNetModel_construct_2609 parent: [subgraph @10↓tfnet_model_TFNetModel_construct_2193]() {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(CNode_2387) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %4(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %5(X) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Abs[output_names: ["output"], input_names: ["input_x"]](%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:186/        X = self.abs(framewise1)  # 简化的FFT替代/
  %6(CNode_2388) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %7(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %8(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %9(conv1d_outputs1) = $(10↓tfnet_model_TFNetModel_construct_2193):call @modules_TemporalConv_construct_2389(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:189/        conv1d_outputs1 = self.conv1d1(framewise1, len_x_list)/
  %10(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_getitem(%9, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:190/        x1 = conv1d_outputs1['visual_feat']/
  %11(CNode_2390) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %12(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%10, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %13(x1) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%12, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:197/            x1 = ops.cast(x1, ms.float32)/
  Return(%13)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:197/            x1 = ops.cast(x1, ms.float32)/
}
# Order:
#   1: @✓11↓tfnet_model_TFNetModel_construct_2609:x1{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: x1, [2]: ValueNode<Float> Float32}
#   2: @✓11↓tfnet_model_TFNetModel_construct_2609:CNode_2809{[0]: ValueNode<Primitive> Return, [1]: x1}


subgraph attr:
training : 1
subgraph instance: ✗11↓tfnet_model_TFNetModel_construct_2610 : 0x3915d080
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗11↓tfnet_model_TFNetModel_construct_2610 parent: [subgraph @10↓tfnet_model_TFNetModel_construct_2193]() {
  %1(CNode_1983) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %2(framewise) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%para365_фframewise, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:168/        framewise = self.transpose(framewise, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %3(CNode_2387) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %4(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:184/        framewise1 = self.transpose(framewise, (0, 2, 1))  # (B, T, C) -> (批次, 时间步, 通道)/
  %5(X) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Abs[output_names: ["output"], input_names: ["input_x"]](%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:186/        X = self.abs(framewise1)  # 简化的FFT替代/
  %6(CNode_2388) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(0), I64(2), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %7(framewise1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:187/        framewise1 = self.transpose(X, (0, 2, 1))  # (B, C, T) -> (批次, 通道, 时间步)/
  %8(len_x_list) = $(4↓tfnet_model_TFNetModel_construct_647):call @G_4↓tfnet_model_TFNetModel_construct_715()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:111/        len_x_list = [max(1, int(l)) for l in len_x_list]/
  %9(conv1d_outputs1) = $(10↓tfnet_model_TFNetModel_construct_2193):call @modules_TemporalConv_construct_2389(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:189/        conv1d_outputs1 = self.conv1d1(framewise1, len_x_list)/
  %10(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_getitem(%9, "visual_feat")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:190/        x1 = conv1d_outputs1['visual_feat']/
  %11(CNode_2390) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_MakeTuple(I64(2), I64(0), I64(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  %12(x1) = $(10↓tfnet_model_TFNetModel_construct_2193):S_Prim_Transpose[output_names: ["output"], input_names: ["x", "perm"]](%10, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:191/        x1 = self.transpose(x1, (2, 0, 1))  # (T, B, C) -> (时间步, 批次, 通道)/
  Return(%12)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:196/        if x1.dtype != ms.float32:/
}
# Order:
#   1: @✗11↓tfnet_model_TFNetModel_construct_2610:CNode_2810{[0]: ValueNode<Primitive> Return, [1]: x1}


subgraph attr:
after_block : 1
subgraph instance: 3↓✓↓ms_max_one_element_2619 : 0x37616dd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @3↓✓↓ms_max_one_element_2619 parent: [subgraph @2↓✓↓ms_max_one_element_2201]() {
  %1(tensor_num) = $(2↓✓↓ms_max_one_element_2201):call @get_tensor_num_1008(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2626/        tensor_num = get_tensor_num(x)/
  %2(CNode_2811) = S_Prim_not_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
  %3(CNode_2812) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
  %4(CNode_2813) = Switch(%3, @✓3↓✓↓ms_max_one_element_2814, @✗3↓✓↓ms_max_one_element_2815)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
  %5(CNode_2816) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
}
# Order:
#   1: @3↓✓↓ms_max_one_element_2619:CNode_2811{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_num, [2]: ValueNode<Int64Imm> 0}
#   2: @3↓✓↓ms_max_one_element_2619:CNode_2812{[0]: ValueNode<Primitive> Cond, [1]: CNode_2811, [2]: ValueNode<BoolImm> false}
#   3: @3↓✓↓ms_max_one_element_2619:CNode_2813{[0]: ValueNode<Primitive> Switch, [1]: CNode_2812, [2]: ValueNode<FuncGraph> ✓3↓✓↓ms_max_one_element_2814, [3]: ValueNode<FuncGraph> ✗3↓✓↓ms_max_one_element_2815}
#   4: @3↓✓↓ms_max_one_element_2619:CNode_2816{[0]: CNode_2813}
#   5: @3↓✓↓ms_max_one_element_2619:CNode_2817{[0]: ValueNode<Primitive> Return, [1]: CNode_2816}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓check_sequence_all_variable_scalar_2626 : 0x3771eaf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @2↓✓check_sequence_all_variable_scalar_2626() {
  Return(Bool(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2584/        return True/
}
# Order:
#   1: @2↓✓check_sequence_all_variable_scalar_2626:CNode_2818{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✓↻↓check_sequence_all_variable_scalar_2639 : 0x33d041c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✓↻↓check_sequence_all_variable_scalar_2639() {
  Return(Bool(0))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2588/            return False/
}
# Order:
#   1: @✓↻↓check_sequence_all_variable_scalar_2639:CNode_2819{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> false}


subgraph attr:
subgraph instance: ✗↻↓check_sequence_all_variable_scalar_2640 : 0x37ed16c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✗↻↓check_sequence_all_variable_scalar_2640 parent: [subgraph @↻↓check_sequence_all_variable_scalar_2413]() {
  %1(CNode_2821) = call @↓↻↓check_sequence_all_variable_scalar_2820()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2587/        if not isinstance(i, (int, float)):/
}
# Order:
#   1: @✗↻↓check_sequence_all_variable_scalar_2640:CNode_2821{[0]: ValueNode<FuncGraph> ↓↻↓check_sequence_all_variable_scalar_2820}
#   2: @✗↻↓check_sequence_all_variable_scalar_2640:CNode_2822{[0]: ValueNode<Primitive> Return, [1]: CNode_2821}


subgraph attr:
after_block : 1
subgraph instance: ↓↻exist_tensor_2646 : 0x37f10340
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @↓↻exist_tensor_2646 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_2418) = $(↻exist_tensor_2228):call @ms_iter_97(%para368_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %2(input_data) = $(↻exist_tensor_2228):S_Prim_getitem(%1, %para374_@CNode_2226)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %3(CNode_2823) = S_Prim_MakeTuple(ClassType, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
  %4(CNode_2824) = S_Prim_isinstance(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
  %5(CNode_2825) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
  %6(CNode_2826) = Switch(%5, @✓↓↻exist_tensor_2827, @✗↓↻exist_tensor_2828)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
  %7(CNode_2829) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
}
# Order:
#   1: @↓↻exist_tensor_2646:CNode_2823{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<ClassType> class 'list', [2]: ValueNode<ClassType> class 'tuple'}
#   2: @↓↻exist_tensor_2646:CNode_2824{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: input_data, [2]: CNode_2823}
#   3: @↓↻exist_tensor_2646:CNode_2825{[0]: ValueNode<Primitive> Cond, [1]: CNode_2824, [2]: ValueNode<BoolImm> false}
#   4: @↓↻exist_tensor_2646:CNode_2826{[0]: ValueNode<Primitive> Switch, [1]: CNode_2825, [2]: ValueNode<FuncGraph> ✓↓↻exist_tensor_2827, [3]: ValueNode<FuncGraph> ✗↓↻exist_tensor_2828}
#   5: @↓↻exist_tensor_2646:CNode_2829{[0]: CNode_2826}
#   6: @↓↻exist_tensor_2646:CNode_2830{[0]: ValueNode<Primitive> Return, [1]: CNode_2829}


subgraph attr:
subgraph instance: ✓↓_check_ctcloss_targets_shape_2658 : 0x397d9e10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @✓↓_check_ctcloss_targets_shape_2658 parent: [subgraph @_check_ctcloss_targets_shape_2060]() {
  %1(CNode_2831) = getattr(%para375_targets, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2599/        raise ValueError(f"For CTCLoss, the first dimension of 2-D targets should be 1,"/
  %2(CNode_2832) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2599/        raise ValueError(f"For CTCLoss, the first dimension of 2-D targets should be 1,"/
  %3(CNode_2833) = JoinedStr("For CTCLoss, the first dimension of 2-D targets should be 1,but got ", %2, ".")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2599/        raise ValueError(f"For CTCLoss, the first dimension of 2-D targets should be 1,"/
  %4(CNode_2834) = raise[side_effect_io: Bool(1)]("ValueError", %3, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2599/        raise ValueError(f"For CTCLoss, the first dimension of 2-D targets should be 1,"/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2599/        raise ValueError(f"For CTCLoss, the first dimension of 2-D targets should be 1,"/
}
# Order:
#   1: @✓↓_check_ctcloss_targets_shape_2658:CNode_2831{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> shape}
#   2: @✓↓_check_ctcloss_targets_shape_2658:CNode_2832{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2831, [2]: ValueNode<Int64Imm> 0}
#   3: @✓↓_check_ctcloss_targets_shape_2658:CNode_2833{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> For CTCLoss, the first dimension of 2-D targets should be 1,but got , [2]: CNode_2832, [3]: ValueNode<StringImm> .}
#   4: @✓↓_check_ctcloss_targets_shape_2658:CNode_2834{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_2833, [3]: ValueNode<StringImm> None}
#   5: @✓↓_check_ctcloss_targets_shape_2658:CNode_2835{[0]: ValueNode<Primitive> Return, [1]: CNode_2834}


subgraph attr:
subgraph instance: ✗↓_check_ctcloss_targets_shape_2659 : 0x397d7bd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @✗↓_check_ctcloss_targets_shape_2659() {
  %1(CNode_2837) = call @2↓_check_ctcloss_targets_shape_2836()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
}
# Order:
#   1: @✗↓_check_ctcloss_targets_shape_2659:CNode_2837{[0]: ValueNode<FuncGraph> 2↓_check_ctcloss_targets_shape_2836}
#   2: @✗↓_check_ctcloss_targets_shape_2659:CNode_2838{[0]: ValueNode<Primitive> Return, [1]: CNode_2837}


subgraph attr:
subgraph instance: ↰↓_check_ctcloss_targets_shape_2653 : 0x397d6400
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @↰↓_check_ctcloss_targets_shape_2653 parent: [subgraph @_check_ctcloss_targets_shape_2060]() {
  %1(CNode_2839) = getattr(%para375_targets, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %2(CNode_2840) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %3(CNode_2841) = S_Prim_not_equal(%2, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
}
# Order:
#   1: @↰↓_check_ctcloss_targets_shape_2653:CNode_2839{[0]: ValueNode<Primitive> getattr, [1]: param_targets, [2]: ValueNode<StringImm> shape}
#   2: @↰↓_check_ctcloss_targets_shape_2653:CNode_2840{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_2839, [2]: ValueNode<Int64Imm> 0}
#   3: @↰↓_check_ctcloss_targets_shape_2653:CNode_2841{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_2840, [2]: ValueNode<Int64Imm> 1}
#   4: @↰↓_check_ctcloss_targets_shape_2653:CNode_2842{[0]: ValueNode<Primitive> Return, [1]: CNode_2841}


subgraph attr:
subgraph instance: ↱↓_check_ctcloss_targets_shape_2654 : 0x397d5620
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @↱↓_check_ctcloss_targets_shape_2654 parent: [subgraph @↓_check_ctcloss_targets_shape_2432]() {
  %1(CNode_2649) = $(↓_check_ctcloss_targets_shape_2432):getattr(%para375_targets, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  %2(CNode_2650) = $(↓_check_ctcloss_targets_shape_2432):S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2598/    if targets.ndim == 2 and targets.shape[0] != 1:/
}
# Order:
#   1: @↱↓_check_ctcloss_targets_shape_2654:CNode_2843{[0]: ValueNode<Primitive> Return, [1]: CNode_2650}


subgraph attr:
after_block : 1
subgraph instance: 2↓ctc_loss_2668 : 0x397ca1c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @2↓ctc_loss_2668 parent: [subgraph @ctc_loss_2242](%para422_) {
  %1(CNode_2446) = $(ctc_loss_2242):S_Prim_MakeTuple("blank", "reduction", "zero_infinity")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %2(CNode_2447) = $(ctc_loss_2242):S_Prim_MakeTuple(%para386_blank, "none", %para388_zero_infinity)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %3(CNode_2448) = $(ctc_loss_2242):S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %4(ctc_loss_op) = $(ctc_loss_2242):UnpackCall_unpack_call(ClassType, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4829/    ctc_loss_op = NN_OPS.CTCLossV2(blank=blank, reduction="none", zero_infinity=zero_infinity)/
  %5(CNode_2450) = $(ctc_loss_2242):%4(%para382_log_probs, %para383_targets, %para384_input_lengths, %para385_target_lengths)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  %6(log_alpha) = $(ctc_loss_2242):S_Prim_getitem(%5, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4830/    loss, log_alpha = ctc_loss_op(log_probs, targets, input_lengths, target_lengths)/
  %7(CNode_2844) = S_Prim_MakeTuple(%para422_фloss, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4840/    return (loss, log_alpha)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4840/    return (loss, log_alpha)/
}
# Order:
#   1: @2↓ctc_loss_2668:CNode_2844{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фloss, [2]: log_alpha}
#   2: @2↓ctc_loss_2668:CNode_2845{[0]: ValueNode<Primitive> Return, [1]: CNode_2844}


subgraph attr:
subgraph instance: ✓↓ctc_loss_2665 : 0x397c74f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @✓↓ctc_loss_2665 parent: [subgraph @↓ctc_loss_2443]() {
  %1(CNode_2846) = getattr(%para405_фloss, "astype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4836/        loss = loss.astype("float32")/
  %2(loss) = %1("float32")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4836/        loss = loss.astype("float32")/
  %3(CNode_2847) = getattr(%para385_target_lengths, "clip")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4835/        target_length_t = target_lengths.clip(1., None)/
  %4(target_length_t) = %3(F32(1), None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4835/        target_length_t = target_lengths.clip(1., None)/
  %5(loss) = S_Prim_div(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4837/        loss = loss / target_length_t/
  %6(CNode_2848) = getattr(%5, "mean")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4838/        loss = loss.mean()/
  %7(loss) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4838/        loss = loss.mean()/
  %8(CNode_2849) = getattr(%7, "astype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4839/        loss = loss.astype(input_type)/
  %9(input_type) = getattr(%para405_фloss, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4834/        input_type = loss.dtype/
  %10(loss) = %8(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4839/        loss = loss.astype(input_type)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4834/        input_type = loss.dtype/
}
# Order:
#   1: @✓↓ctc_loss_2665:input_type{[0]: ValueNode<Primitive> getattr, [1]: param_фloss, [2]: ValueNode<StringImm> dtype}
#   2: @✓↓ctc_loss_2665:CNode_2847{[0]: ValueNode<Primitive> getattr, [1]: param_target_lengths, [2]: ValueNode<StringImm> clip}
#   3: @✓↓ctc_loss_2665:target_length_t{[0]: CNode_2847, [1]: ValueNode<FP32Imm> 1, [2]: ValueNode<None> None}
#   4: @✓↓ctc_loss_2665:CNode_2846{[0]: ValueNode<Primitive> getattr, [1]: param_фloss, [2]: ValueNode<StringImm> astype}
#   5: @✓↓ctc_loss_2665:loss{[0]: CNode_2846, [1]: ValueNode<StringImm> float32}
#   6: @✓↓ctc_loss_2665:loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: loss, [2]: target_length_t}
#   7: @✓↓ctc_loss_2665:CNode_2848{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> mean}
#   8: @✓↓ctc_loss_2665:loss{[0]: CNode_2848}
#   9: @✓↓ctc_loss_2665:CNode_2849{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> astype}
#  10: @✓↓ctc_loss_2665:loss{[0]: CNode_2849, [1]: input_type}
#  11: @✓↓ctc_loss_2665:CNode_2850{[0]: ValueNode<Primitive> Return, [1]: loss}


subgraph attr:
subgraph instance: ✗↓ctc_loss_2666 : 0x397c66e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4758/def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction="mean", zero_infinity=False):/
subgraph @✗↓ctc_loss_2666 parent: [subgraph @↓ctc_loss_2443]() {
  Return(%para405_фloss)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/nn_func.py:4833/    if reduction == 'mean':/
}
# Order:
#   1: @✗↓ctc_loss_2666:CNode_2851{[0]: ValueNode<Primitive> Return, [1]: param_фloss}


subgraph attr:
subgraph instance: ✓↓✓↓ms_min_one_element_2681 : 0x395802e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓↓✓↓ms_min_one_element_2681 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2852) = S_Prim_raise_value_error[constexpr_prim: Bool(1)]("min() arg is an empty sequence.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2708/            const_utils.raise_value_error("min() arg is an empty sequence.")/
  %2(CNode_2853) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_2855) = call @2↓✓↓ms_min_one_element_2854()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  %4(CNode_2856) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2708/            const_utils.raise_value_error("min() arg is an empty sequence.")/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2708/            const_utils.raise_value_error("min() arg is an empty sequence.")/
}
# Order:
#   1: @✓↓✓↓ms_min_one_element_2681:CNode_2852{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_value_error, [1]: ValueNode<StringImm> min() arg is an empty sequence.}
#   2: @✓↓✓↓ms_min_one_element_2681:CNode_2857{[0]: ValueNode<Primitive> Return, [1]: CNode_2856}
#   3: @✓↓✓↓ms_min_one_element_2681:CNode_2855{[0]: ValueNode<FuncGraph> 2↓✓↓ms_min_one_element_2854}


subgraph attr:
subgraph instance: ✗↓✓↓ms_min_one_element_2682 : 0x39568150
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗↓✓↓ms_min_one_element_2682 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_2858) = call @2↓✓↓ms_min_one_element_2854()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2707/        if len(x) == 0:/
}
# Order:
#   1: @✗↓✓↓ms_min_one_element_2682:CNode_2859{[0]: ValueNode<Primitive> Return, [1]: CNode_2858}
#   2: @✗↓✓↓ms_min_one_element_2682:CNode_2858{[0]: ValueNode<FuncGraph> 2↓✓↓ms_min_one_element_2854}


subgraph attr:
after_block : 1
subgraph instance: 3↓✓2✗ms_min_2694 : 0x39537830
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2722/def ms_min(*data):/
subgraph @3↓✓2✗ms_min_2694 parent: [subgraph @ms_min_962]() {
  %1(CNode_2860) = call @↓2✗ms_min_1498()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:121/            lgt_i = min(int(len_x_list[i]), int(temp))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2731/        tensor_num = get_tensor_num(data)/
}
# Order:
#   1: @3↓✓2✗ms_min_2694:CNode_2861{[0]: ValueNode<Primitive> Return, [1]: CNode_2860}
#   2: @3↓✓2✗ms_min_2694:CNode_2860{[0]: ValueNode<FuncGraph> ↓2✗ms_min_1498}


subgraph attr:
subgraph instance: 2✓2↓flatten_2704 : 0x3970ee10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @2✓2↓flatten_2704 parent: [subgraph @flatten_1327]() {
  %1(CNode_2862) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1741/            return reshape_(input, (-1,))/
  %2(CNode_2863) = S_Prim_MakeTuple(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1741/            return reshape_(input, (-1,))/
  %3(CNode_2864) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para261_input, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1741/            return reshape_(input, (-1,))/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1741/            return reshape_(input, (-1,))/
}
# Order:
#   1: @2✓2↓flatten_2704:CNode_2862{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @2✓2↓flatten_2704:CNode_2863{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_2862}
#   3: @2✓2↓flatten_2704:CNode_2864{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_input, [2]: CNode_2863}
#   4: @2✓2↓flatten_2704:CNode_2865{[0]: ValueNode<Primitive> Return, [1]: CNode_2864}


subgraph attr:
subgraph instance: ✗✓2↓flatten_2705 : 0x39709ae0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗✓2↓flatten_2705 parent: [subgraph @✓2↓flatten_2490]() {
  %1(CNode_2867) = call @↓✓2↓flatten_2866()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1740/        if x_rank in (0, 1):/
}
# Order:
#   1: @✗✓2↓flatten_2705:CNode_2867{[0]: ValueNode<FuncGraph> ↓✓2↓flatten_2866}
#   2: @✗✓2↓flatten_2705:CNode_2868{[0]: ValueNode<Primitive> Return, [1]: CNode_2867}


subgraph attr:
after_block : 1
subgraph instance: 3↓flatten_2708 : 0x396a3fa0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @3↓flatten_2708 parent: [subgraph @flatten_1327](%para423_) {
  %1(CNode_2869) = S_Prim_equal(%para263_start_dim, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %2(CNode_2870) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %3(CNode_2871) = Switch(%2, @↰3↓flatten_2872, @↱3↓flatten_2873)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %4(CNode_2874) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %5(CNode_2875) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %6(CNode_2876) = Switch(%5, @✓3↓flatten_2877, @✗3↓flatten_2878)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %7(CNode_2879) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
}
# Order:
#   1: @3↓flatten_2708:x_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_фinput}
#   2: @3↓flatten_2708:x_rank{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Rank, [1]: param_фinput}
#   3: @3↓flatten_2708:CNode_2869{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_start_dim, [2]: ValueNode<Int64Imm> 1}
#   4: @3↓flatten_2708:CNode_2870{[0]: ValueNode<Primitive> Cond, [1]: CNode_2869, [2]: ValueNode<BoolImm> false}
#   5: @3↓flatten_2708:CNode_2871{[0]: ValueNode<Primitive> Switch, [1]: CNode_2870, [2]: ValueNode<FuncGraph> ↰3↓flatten_2872, [3]: ValueNode<FuncGraph> ↱3↓flatten_2873}
#   6: @3↓flatten_2708:CNode_2874{[0]: CNode_2871}
#   7: @3↓flatten_2708:CNode_2875{[0]: ValueNode<Primitive> Cond, [1]: CNode_2874, [2]: ValueNode<BoolImm> false}
#   8: @3↓flatten_2708:CNode_2876{[0]: ValueNode<Primitive> Switch, [1]: CNode_2875, [2]: ValueNode<FuncGraph> ✓3↓flatten_2877, [3]: ValueNode<FuncGraph> ✗3↓flatten_2878}
#   9: @3↓flatten_2708:CNode_2879{[0]: CNode_2876}
#  10: @3↓flatten_2708:CNode_2880{[0]: ValueNode<Primitive> Return, [1]: CNode_2879}


subgraph attr:
training : 1
subgraph instance: ✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723 : 0x395d1e60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2526]() {
  %1(CNode_2881) = S_Prim_getitem(%para406_фout, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:588/            return out[0]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:588/            return out[0]/
}
# Order:
#   1: @✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723:CNode_2881{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фout, [2]: ValueNode<Int64Imm> 0}
#   2: @✓3↓mindspore_nn_layer_pooling_MaxPool2d_construct_2723:CNode_2882{[0]: ValueNode<Primitive> Return, [1]: CNode_2881}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2732 : 0x395cf660
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2732(%para424_) {
  Return(%para424_фout)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:583/            if isinstance(out, tuple):/
}
# Order:
#   1: @↓✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2732:CNode_2883{[0]: ValueNode<Primitive> Return, [1]: param_фout}


subgraph attr:
training : 1
subgraph instance: 2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729 : 0x395cd1a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729 parent: [subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166]() {
  %1(CNode_2884) = S_Prim_getitem(%para378_фout, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %2(CNode_2885) = getattr(%1, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %3(CNode_2886) = %2(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %4(CNode_2887) = S_Prim_getitem(%para378_фout, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %5(CNode_2888) = getattr(%4, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %6(CNode_2889) = %5(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  %7(out) = S_Prim_MakeTuple(%3, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:584/                out = (out[0].squeeze(0), out[1].squeeze(0))/
}
# Order:
#   1: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2884{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фout, [2]: ValueNode<Int64Imm> 0}
#   2: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2885{[0]: ValueNode<Primitive> getattr, [1]: CNode_2884, [2]: ValueNode<StringImm> squeeze}
#   3: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2886{[0]: CNode_2885, [1]: ValueNode<Int64Imm> 0}
#   4: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2887{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фout, [2]: ValueNode<Int64Imm> 1}
#   5: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2888{[0]: ValueNode<Primitive> getattr, [1]: CNode_2887, [2]: ValueNode<StringImm> squeeze}
#   6: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2889{[0]: CNode_2888, [1]: ValueNode<Int64Imm> 0}
#   7: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_2886, [2]: CNode_2889}
#   8: @2✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2729:CNode_2890{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
training : 1
subgraph instance: ✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730 : 0x395cbc80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:568/    def construct(self, x):/
subgraph @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730 parent: [subgraph @↓✓↓mindspore_nn_layer_pooling_MaxPool2d_construct_2166]() {
  %1(CNode_2891) = getattr(%para378_фout, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
  %2(out) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:586/                out = out.squeeze(0)/
}
# Order:
#   1: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730:CNode_2891{[0]: ValueNode<Primitive> getattr, [1]: param_фout, [2]: ValueNode<StringImm> squeeze}
#   2: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730:out{[0]: CNode_2891, [1]: ValueNode<Int64Imm> 0}
#   3: @✗✓2↓mindspore_nn_layer_pooling_MaxPool2d_construct_2730:CNode_2892{[0]: ValueNode<Primitive> Return, [1]: out}


subgraph attr:
subgraph instance: cat_2736 : 0x394e8a50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:247/def cat(tensors, axis=0):/
subgraph @cat_2736(%para425_tensors, %para426_axis) {
  %1(CNode_2893) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:299/    _concat = _get_cache_prim(P.Concat)(axis)/
  %2(_concat) = %1(%para426_axis)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:299/    _concat = _get_cache_prim(P.Concat)(axis)/
  %3(CNode_2894) = %2(%para425_tensors)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:300/    return _concat(tensors)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:300/    return _concat(tensors)/
}
# Order:
#   1: @cat_2736:CNode_2893{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Concat'}
#   2: @cat_2736:_concat{[0]: CNode_2893, [1]: param_axis}
#   3: @cat_2736:CNode_2894{[0]: _concat, [1]: param_tensors}
#   4: @cat_2736:CNode_2895{[0]: ValueNode<Primitive> Return, [1]: CNode_2894}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_conv_Conv1d_construct_2741 : 0x374bc290
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741 parent: [subgraph @L_mindspore_nn_layer_conv_Conv1d_construct_2548]() {
  %1(CNode_2897) = call @L_↓mindspore_nn_layer_conv_Conv1d_construct_2896()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
}
# Order:
#   1: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BiasAdd, [1]: output, [2]: param_L_conv1d1.temporal_conv.0.bias}
#   2: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741:CNode_2897{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv1d_construct_2896}
#   3: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741:CNode_2898{[0]: ValueNode<Primitive> Return, [1]: CNode_2897}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751 : 0x3756fbf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_2900) = call @L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:141/            if self.training:/
}
# Order:
#   1: @L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751:CNode_2900{[0]: ValueNode<FuncGraph> L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899}
#   2: @L_✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2751:CNode_2901{[0]: ValueNode<Primitive> Return, [1]: CNode_2900}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752 : 0x333e2c20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_2903) = call @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752:CNode_2903{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902}
#   2: @L_✗mindspore_nn_layer_normalization_BatchNorm1d_construct_2752:CNode_2904{[0]: ValueNode<Primitive> Return, [1]: CNode_2903}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757 : 0x334118f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757(%para427_, %para428_) {
  %1(CNode_2906) = call @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757:CNode_2906{[0]: ValueNode<FuncGraph> ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905}
#   2: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757:CNode_2907{[0]: ValueNode<Primitive> Return, [1]: CNode_2906}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_conv_Conv1d_construct_2764 : 0x33285060
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764 parent: [subgraph @L_mindspore_nn_layer_conv_Conv1d_construct_2568]() {
  %1(CNode_2909) = call @L_↓mindspore_nn_layer_conv_Conv1d_construct_2908()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
}
# Order:
#   1: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BiasAdd, [1]: output, [2]: param_L_conv1d1.temporal_conv.4.bias}
#   2: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764:CNode_2909{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_conv_Conv1d_construct_2908}
#   3: @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764:CNode_2910{[0]: ValueNode<Primitive> Return, [1]: CNode_2909}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769 : 0x37df3940
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769(%para429_, %para430_) {
  %1(CNode_2912) = call @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769:CNode_2912{[0]: ValueNode<FuncGraph> ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911}
#   2: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769:CNode_2913{[0]: ValueNode<Primitive> Return, [1]: CNode_2912}


subgraph attr:
training : 1
subgraph instance: ↵✓↻9↓tfnet_model_TFNetModel_construct_2780 : 0x394a2690
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵✓↻9↓tfnet_model_TFNetModel_construct_2780(%para431_iter, %para432_list) {
  %1(CNode_2914) = call @hasnext_934(%para431_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %2(CNode_2915) = Switch(%1, @↻✓↻9↓tfnet_model_TFNetModel_construct_2916, @↓✓↻9↓tfnet_model_TFNetModel_construct_2917)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %3(CNode_2918) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @↵✓↻9↓tfnet_model_TFNetModel_construct_2780:CNode_2914{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵✓↻9↓tfnet_model_TFNetModel_construct_2780:CNode_2915{[0]: ValueNode<Primitive> Switch, [1]: CNode_2914, [2]: ValueNode<FuncGraph> ↻✓↻9↓tfnet_model_TFNetModel_construct_2916, [3]: ValueNode<FuncGraph> ↓✓↻9↓tfnet_model_TFNetModel_construct_2917}
#   3: @↵✓↻9↓tfnet_model_TFNetModel_construct_2780:CNode_2918{[0]: CNode_2915}
#   4: @↵✓↻9↓tfnet_model_TFNetModel_construct_2780:CNode_2919{[0]: ValueNode<Primitive> Return, [1]: CNode_2918}


subgraph attr:
training : 1
subgraph instance: ↵✗↻9↓tfnet_model_TFNetModel_construct_2783 : 0x39489720
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵✗↻9↓tfnet_model_TFNetModel_construct_2783 parent: [subgraph @✗↻9↓tfnet_model_TFNetModel_construct_2371](%para433_iter, %para434_list) {
  %1(CNode_2920) = call @hasnext_934(%para433_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %2(CNode_2921) = Switch(%1, @↻✗↻9↓tfnet_model_TFNetModel_construct_2922, @↓✗↻9↓tfnet_model_TFNetModel_construct_2923)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %3(CNode_2924) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @↵✗↻9↓tfnet_model_TFNetModel_construct_2783:CNode_2920{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵✗↻9↓tfnet_model_TFNetModel_construct_2783:CNode_2921{[0]: ValueNode<Primitive> Switch, [1]: CNode_2920, [2]: ValueNode<FuncGraph> ↻✗↻9↓tfnet_model_TFNetModel_construct_2922, [3]: ValueNode<FuncGraph> ↓✗↻9↓tfnet_model_TFNetModel_construct_2923}
#   3: @↵✗↻9↓tfnet_model_TFNetModel_construct_2783:CNode_2924{[0]: CNode_2921}
#   4: @↵✗↻9↓tfnet_model_TFNetModel_construct_2783:CNode_2925{[0]: ValueNode<Primitive> Return, [1]: CNode_2924}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv1d_construct_2926 : 0x39149cc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv1d_construct_2926 parent: [subgraph @after_grad_108](%para435_x) {
  %1(CNode_2927) = call @L_mindspore_nn_layer_conv_Conv1d_construct_2548(%para435_x, %para65_conv1d1.temporal_conv.0.bias, %para64_conv1d1.temporal_conv.0.weight)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.0.bias>, <Ref[Tensor[Float32]], (64, 512, 1, 5), ref_key=:conv1d1.temporal_conv.0.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv1d_construct_2926:CNode_2927{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv1d_construct_2548, [1]: param_x, [2]: param_conv1d1.temporal_conv.0.bias, [3]: param_conv1d1.temporal_conv.0.weight}
#   2: @mindspore_nn_layer_conv_Conv1d_construct_2926:CNode_2744{[0]: ValueNode<Primitive> Return, [1]: CNode_2927}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm1d_construct_2928 : 0x39148420
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm1d_construct_2928 parent: [subgraph @after_grad_108](%para436_x) {
  %1(CNode_2929) = call @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552(%para436_x, %para66_conv1d1.temporal_conv.1.gamma, %para67_conv1d1.temporal_conv.1.beta, %para115_conv1d1.temporal_conv.1.moving_mean, %para116_conv1d1.temporal_conv.1.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.1.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2928:CNode_2929{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552, [1]: param_x, [2]: param_conv1d1.temporal_conv.1.gamma, [3]: param_conv1d1.temporal_conv.1.beta, [4]: param_conv1d1.temporal_conv.1.moving_mean, [5]: param_conv1d1.temporal_conv.1.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2928:CNode_2755{[0]: ValueNode<Primitive> Return, [1]: CNode_2929}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_2930 : 0x391471b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_2930(%para437_x) {
  %1(CNode_2931) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para437_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_2930:CNode_2931{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_2930:CNode_2932{[0]: ValueNode<Primitive> Return, [1]: CNode_2931}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_MaxPool1d_construct_2933 : 0x3912ec50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2933(%para438_x) {
  %1(CNode_2934) = getattr(%para438_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %2(CNode_2935) = S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %3(CNode_2936) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %4(CNode_2937) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938, @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %5(CNode_2940) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2934{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2935{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2934, [2]: ValueNode<Int64Imm> 2}
#   3: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2936{[0]: ValueNode<Primitive> Cond, [1]: CNode_2935, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2937{[0]: ValueNode<Primitive> Switch, [1]: CNode_2936, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939}
#   5: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2940{[0]: CNode_2937}
#   6: @mindspore_nn_layer_pooling_MaxPool1d_construct_2933:CNode_2941{[0]: ValueNode<Primitive> Return, [1]: CNode_2940}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_conv_Conv1d_construct_2942 : 0x3912d6d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @mindspore_nn_layer_conv_Conv1d_construct_2942 parent: [subgraph @after_grad_108](%para439_x) {
  %1(CNode_2943) = call @L_mindspore_nn_layer_conv_Conv1d_construct_2568(%para439_x, %para69_conv1d1.temporal_conv.4.bias, %para68_conv1d1.temporal_conv.4.weight)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.4.bias>, <Ref[Tensor[Float32]], (64, 64, 1, 5), ref_key=:conv1d1.temporal_conv.4.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:584/        if self.has_bias:/
}
# Order:
#   1: @mindspore_nn_layer_conv_Conv1d_construct_2942:CNode_2943{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_conv_Conv1d_construct_2568, [1]: param_x, [2]: param_conv1d1.temporal_conv.4.bias, [3]: param_conv1d1.temporal_conv.4.weight}
#   2: @mindspore_nn_layer_conv_Conv1d_construct_2942:CNode_2767{[0]: ValueNode<Primitive> Return, [1]: CNode_2943}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_normalization_BatchNorm1d_construct_2944 : 0x3912be30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @mindspore_nn_layer_normalization_BatchNorm1d_construct_2944 parent: [subgraph @after_grad_108](%para440_x) {
  %1(CNode_2945) = call @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552(%para440_x, %para70_conv1d1.temporal_conv.5.gamma, %para71_conv1d1.temporal_conv.5.beta, %para117_conv1d1.temporal_conv.5.moving_mean, %para118_conv1d1.temporal_conv.5.moving_variance)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.gamma>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.beta>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.moving_mean>, <Ref[Tensor[Float32]], (64), ref_key=:conv1d1.temporal_conv.5.moving_variance>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:140/        if self.use_batch_statistics is None:/
}
# Order:
#   1: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2944:CNode_2945{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552, [1]: param_x, [2]: param_conv1d1.temporal_conv.5.gamma, [3]: param_conv1d1.temporal_conv.5.beta, [4]: param_conv1d1.temporal_conv.5.moving_mean, [5]: param_conv1d1.temporal_conv.5.moving_variance}
#   2: @mindspore_nn_layer_normalization_BatchNorm1d_construct_2944:CNode_2946{[0]: ValueNode<Primitive> Return, [1]: CNode_2945}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_2947 : 0x3912abc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_2947(%para441_x) {
  %1(CNode_2948) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para441_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_2947:CNode_2948{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_2947:CNode_2949{[0]: ValueNode<Primitive> Return, [1]: CNode_2948}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_pooling_MaxPool1d_construct_2950 : 0x390a1d70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2950(%para442_x) {
  %1(CNode_2951) = getattr(%para442_x, "ndim")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %2(CNode_2952) = S_Prim_equal(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %3(CNode_2953) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %4(CNode_2954) = Switch(%3, @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955, @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  %5(CNode_2957) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2951{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> ndim}
#   2: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2952{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2951, [2]: ValueNode<Int64Imm> 2}
#   3: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2953{[0]: ValueNode<Primitive> Cond, [1]: CNode_2952, [2]: ValueNode<BoolImm> false}
#   4: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2954{[0]: ValueNode<Primitive> Switch, [1]: CNode_2953, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956}
#   5: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2957{[0]: CNode_2954}
#   6: @mindspore_nn_layer_pooling_MaxPool1d_construct_2950:CNode_2958{[0]: ValueNode<Primitive> Return, [1]: CNode_2957}


subgraph attr:
training : 1
subgraph instance: ↵mindspore_nn_layer_container_SequentialCell_construct_2786 : 0x3914b240
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2786 parent: [subgraph @mindspore_nn_layer_container_SequentialCell_construct_2601](%para443_, %para444_) {
  %1(CNode_2789) = $(mindspore_nn_layer_container_SequentialCell_construct_2601):MakeTuple(@mindspore_nn_layer_conv_Conv1d_construct_2926, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2928, @mindspore_nn_layer_activation_ReLU_construct_2930, @mindspore_nn_layer_pooling_MaxPool1d_construct_2933, @mindspore_nn_layer_conv_Conv1d_construct_2942, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2944, @mindspore_nn_layer_activation_ReLU_construct_2947, @mindspore_nn_layer_pooling_MaxPool1d_construct_2950)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_2788) = $(mindspore_nn_layer_container_SequentialCell_construct_2601):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %3(CNode_2959) = MultitypeFuncGraph_less{(List, List), (Tensor, Number), (Tensor, Tensor), (Tuple, Tuple), (Number, Tensor), (String, String), (Number, Number)}(%para443_@CNode_2960, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_2961) = Switch(%3, @↻mindspore_nn_layer_container_SequentialCell_construct_2962, @↓mindspore_nn_layer_container_SequentialCell_construct_2963)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(CNode_2964) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↵mindspore_nn_layer_container_SequentialCell_construct_2786:CNode_2959{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-less.14, [1]: param_@CNode_2960, [2]: CNode_2788}
#   2: @↵mindspore_nn_layer_container_SequentialCell_construct_2786:CNode_2961{[0]: ValueNode<Primitive> Switch, [1]: CNode_2959, [2]: ValueNode<FuncGraph> ↻mindspore_nn_layer_container_SequentialCell_construct_2962, [3]: ValueNode<FuncGraph> ↓mindspore_nn_layer_container_SequentialCell_construct_2963}
#   3: @↵mindspore_nn_layer_container_SequentialCell_construct_2786:CNode_2964{[0]: CNode_2961}
#   4: @↵mindspore_nn_layer_container_SequentialCell_construct_2786:CNode_2965{[0]: ValueNode<Primitive> Return, [1]: CNode_2964}


subgraph attr:
training : 1
subgraph instance: modules_NormLinear_construct_2807 : 0x393ed930
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @modules_NormLinear_construct_2807 parent: [subgraph @after_grad_108](%para445_x) {
  %1(x_shape) = getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_2966) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_2967) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_2968) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %5(CNode_2969) = Switch(%4, @↰modules_NormLinear_construct_2970, @↱modules_NormLinear_construct_2971)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %6(CNode_2972) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %7(CNode_2973) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %8(CNode_2974) = Switch(%7, @✓modules_NormLinear_construct_2975, @✗modules_NormLinear_construct_2976)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %9(CNode_2977) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @modules_NormLinear_construct_2807:x_shape{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @modules_NormLinear_construct_2807:CNode_2966{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   3: @modules_NormLinear_construct_2807:CNode_2967{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2966, [2]: ValueNode<Int64Imm> 0}
#   4: @modules_NormLinear_construct_2807:CNode_2968{[0]: ValueNode<Primitive> Cond, [1]: CNode_2967, [2]: ValueNode<BoolImm> false}
#   5: @modules_NormLinear_construct_2807:CNode_2969{[0]: ValueNode<Primitive> Switch, [1]: CNode_2968, [2]: ValueNode<FuncGraph> ↰modules_NormLinear_construct_2970, [3]: ValueNode<FuncGraph> ↱modules_NormLinear_construct_2971}
#   6: @modules_NormLinear_construct_2807:CNode_2972{[0]: CNode_2969}
#   7: @modules_NormLinear_construct_2807:CNode_2973{[0]: ValueNode<Primitive> Cond, [1]: CNode_2972, [2]: ValueNode<BoolImm> false}
#   8: @modules_NormLinear_construct_2807:CNode_2974{[0]: ValueNode<Primitive> Switch, [1]: CNode_2973, [2]: ValueNode<FuncGraph> ✓modules_NormLinear_construct_2975, [3]: ValueNode<FuncGraph> ✗modules_NormLinear_construct_2976}
#   9: @modules_NormLinear_construct_2807:CNode_2977{[0]: CNode_2974}
#  10: @modules_NormLinear_construct_2807:CNode_2978{[0]: ValueNode<Primitive> Return, [1]: CNode_2977}


subgraph attr:
training : 1
subgraph instance: modules_BiLSTMLayer_construct_2800 : 0x391c6870
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @modules_BiLSTMLayer_construct_2800 parent: [subgraph @after_grad_108](%para446_x, %para447_lgt) {
  %1(CNode_2979) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %2(CNode_2980) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %3(CNode_2981) = S_Prim_not_equal(%2, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %4(CNode_2982) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %5(CNode_2983) = Switch(%4, @✓modules_BiLSTMLayer_construct_2984, @✗modules_BiLSTMLayer_construct_2985)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %6(CNode_2986) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
}
# Order:
#   1: @modules_BiLSTMLayer_construct_2800:CNode_2979{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @modules_BiLSTMLayer_construct_2800:CNode_2980{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_2979}
#   3: @modules_BiLSTMLayer_construct_2800:CNode_2981{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_2980, [2]: ValueNode<Int64Imm> 3}
#   4: @modules_BiLSTMLayer_construct_2800:CNode_2982{[0]: ValueNode<Primitive> Cond, [1]: CNode_2981, [2]: ValueNode<BoolImm> false}
#   5: @modules_BiLSTMLayer_construct_2800:CNode_2983{[0]: ValueNode<Primitive> Switch, [1]: CNode_2982, [2]: ValueNode<FuncGraph> ✓modules_BiLSTMLayer_construct_2984, [3]: ValueNode<FuncGraph> ✗modules_BiLSTMLayer_construct_2985}
#   6: @modules_BiLSTMLayer_construct_2800:CNode_2986{[0]: CNode_2983}
#   7: @modules_BiLSTMLayer_construct_2800:CNode_2987{[0]: ValueNode<Primitive> Return, [1]: CNode_2986}


subgraph attr:
training : 1
subgraph instance: modules_BiLSTMLayer_construct_2799 : 0x392aed20
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @modules_BiLSTMLayer_construct_2799 parent: [subgraph @after_grad_108](%para448_x, %para449_lgt) {
  %1(CNode_2988) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %2(CNode_2989) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %3(CNode_2990) = S_Prim_not_equal(%2, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %4(CNode_2991) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %5(CNode_2992) = Switch(%4, @✓modules_BiLSTMLayer_construct_2993, @✗modules_BiLSTMLayer_construct_2994)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  %6(CNode_2995) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
}
# Order:
#   1: @modules_BiLSTMLayer_construct_2799:CNode_2988{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @modules_BiLSTMLayer_construct_2799:CNode_2989{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: CNode_2988}
#   3: @modules_BiLSTMLayer_construct_2799:CNode_2990{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_2989, [2]: ValueNode<Int64Imm> 3}
#   4: @modules_BiLSTMLayer_construct_2799:CNode_2991{[0]: ValueNode<Primitive> Cond, [1]: CNode_2990, [2]: ValueNode<BoolImm> false}
#   5: @modules_BiLSTMLayer_construct_2799:CNode_2992{[0]: ValueNode<Primitive> Switch, [1]: CNode_2991, [2]: ValueNode<FuncGraph> ✓modules_BiLSTMLayer_construct_2993, [3]: ValueNode<FuncGraph> ✗modules_BiLSTMLayer_construct_2994}
#   6: @modules_BiLSTMLayer_construct_2799:CNode_2995{[0]: CNode_2992}
#   7: @modules_BiLSTMLayer_construct_2799:CNode_2996{[0]: ValueNode<Primitive> Return, [1]: CNode_2995}


subgraph attr:
training : 1
subgraph instance: modules_NormLinear_construct_2804 : 0x3916bac0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @modules_NormLinear_construct_2804 parent: [subgraph @after_grad_108](%para450_x) {
  %1(x_shape) = getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_2997) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_2998) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_2999) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %5(CNode_3000) = Switch(%4, @↰modules_NormLinear_construct_3001, @↱modules_NormLinear_construct_3002)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %6(CNode_3003) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %7(CNode_3004) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %8(CNode_3005) = Switch(%7, @✓modules_NormLinear_construct_3006, @✗modules_NormLinear_construct_3007)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %9(CNode_3008) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @modules_NormLinear_construct_2804:x_shape{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @modules_NormLinear_construct_2804:CNode_2997{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   3: @modules_NormLinear_construct_2804:CNode_2998{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_2997, [2]: ValueNode<Int64Imm> 0}
#   4: @modules_NormLinear_construct_2804:CNode_2999{[0]: ValueNode<Primitive> Cond, [1]: CNode_2998, [2]: ValueNode<BoolImm> false}
#   5: @modules_NormLinear_construct_2804:CNode_3000{[0]: ValueNode<Primitive> Switch, [1]: CNode_2999, [2]: ValueNode<FuncGraph> ↰modules_NormLinear_construct_3001, [3]: ValueNode<FuncGraph> ↱modules_NormLinear_construct_3002}
#   6: @modules_NormLinear_construct_2804:CNode_3003{[0]: CNode_3000}
#   7: @modules_NormLinear_construct_2804:CNode_3004{[0]: ValueNode<Primitive> Cond, [1]: CNode_3003, [2]: ValueNode<BoolImm> false}
#   8: @modules_NormLinear_construct_2804:CNode_3005{[0]: ValueNode<Primitive> Switch, [1]: CNode_3004, [2]: ValueNode<FuncGraph> ✓modules_NormLinear_construct_3006, [3]: ValueNode<FuncGraph> ✗modules_NormLinear_construct_3007}
#   9: @modules_NormLinear_construct_2804:CNode_3008{[0]: CNode_3005}
#  10: @modules_NormLinear_construct_2804:CNode_3009{[0]: ValueNode<Primitive> Return, [1]: CNode_3008}


subgraph attr:
training : 1
subgraph instance: modules_NormLinear_construct_2802 : 0x39101a80
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @modules_NormLinear_construct_2802 parent: [subgraph @after_grad_108](%para451_x) {
  %1(x_shape) = getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3010) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_3011) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_3012) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %5(CNode_3013) = Switch(%4, @↰modules_NormLinear_construct_3014, @↱modules_NormLinear_construct_3015)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %6(CNode_3016) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %7(CNode_3017) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %8(CNode_3018) = Switch(%7, @✓modules_NormLinear_construct_3019, @✗modules_NormLinear_construct_3020)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %9(CNode_3021) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @modules_NormLinear_construct_2802:x_shape{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @modules_NormLinear_construct_2802:CNode_3010{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   3: @modules_NormLinear_construct_2802:CNode_3011{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3010, [2]: ValueNode<Int64Imm> 0}
#   4: @modules_NormLinear_construct_2802:CNode_3012{[0]: ValueNode<Primitive> Cond, [1]: CNode_3011, [2]: ValueNode<BoolImm> false}
#   5: @modules_NormLinear_construct_2802:CNode_3013{[0]: ValueNode<Primitive> Switch, [1]: CNode_3012, [2]: ValueNode<FuncGraph> ↰modules_NormLinear_construct_3014, [3]: ValueNode<FuncGraph> ↱modules_NormLinear_construct_3015}
#   6: @modules_NormLinear_construct_2802:CNode_3016{[0]: CNode_3013}
#   7: @modules_NormLinear_construct_2802:CNode_3017{[0]: ValueNode<Primitive> Cond, [1]: CNode_3016, [2]: ValueNode<BoolImm> false}
#   8: @modules_NormLinear_construct_2802:CNode_3018{[0]: ValueNode<Primitive> Switch, [1]: CNode_3017, [2]: ValueNode<FuncGraph> ✓modules_NormLinear_construct_3019, [3]: ValueNode<FuncGraph> ✗modules_NormLinear_construct_3020}
#   9: @modules_NormLinear_construct_2802:CNode_3021{[0]: CNode_3018}
#  10: @modules_NormLinear_construct_2802:CNode_3022{[0]: ValueNode<Primitive> Return, [1]: CNode_3021}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 13↓tfnet_model_TFNetModel_construct_2797 : 0x394411b0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @13↓tfnet_model_TFNetModel_construct_2797 parent: [subgraph @12↓tfnet_model_TFNetModel_construct_2612](%para452_) {
  %1(CNode_3023) = Cond(%para373_фlgt, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %2(CNode_3024) = Switch(%1, @↰13↓tfnet_model_TFNetModel_construct_3025, @↱13↓tfnet_model_TFNetModel_construct_3026)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %3(CNode_3027) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %4(CNode_3028) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %5(CNode_3029) = Switch(%4, @✓13↓tfnet_model_TFNetModel_construct_3030, @✗13↓tfnet_model_TFNetModel_construct_3031)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %6(CNode_3032) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %7(CNode_3034) = call @14↓tfnet_model_TFNetModel_construct_3033(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
}
# Order:
#   1: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3023{[0]: ValueNode<Primitive> Cond, [1]: param_фlgt, [2]: ValueNode<BoolImm> false}
#   2: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3024{[0]: ValueNode<Primitive> Switch, [1]: CNode_3023, [2]: ValueNode<FuncGraph> ↰13↓tfnet_model_TFNetModel_construct_3025, [3]: ValueNode<FuncGraph> ↱13↓tfnet_model_TFNetModel_construct_3026}
#   3: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3027{[0]: CNode_3024}
#   4: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3028{[0]: ValueNode<Primitive> Cond, [1]: CNode_3027, [2]: ValueNode<BoolImm> false}
#   5: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3029{[0]: ValueNode<Primitive> Switch, [1]: CNode_3028, [2]: ValueNode<FuncGraph> ✓13↓tfnet_model_TFNetModel_construct_3030, [3]: ValueNode<FuncGraph> ✗13↓tfnet_model_TFNetModel_construct_3031}
#   6: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3032{[0]: CNode_3029}
#   7: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3034{[0]: ValueNode<FuncGraph> 14↓tfnet_model_TFNetModel_construct_3033, [1]: CNode_3032}
#   8: @13↓tfnet_model_TFNetModel_construct_2797:CNode_3035{[0]: ValueNode<Primitive> Return, [1]: CNode_3034}


subgraph attr:
training : 1
subgraph instance: ✓12↓tfnet_model_TFNetModel_construct_2794 : 0x39440220
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓12↓tfnet_model_TFNetModel_construct_2794 parent: [subgraph @12↓tfnet_model_TFNetModel_construct_2612]() {
  %1(outputs) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_BiLSTMLayer_construct_2799(%para404_фx, %para373_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:198/        outputs = self.temporal_model(x, lgt)/
  %2(CNode_2805) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%1, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %3(outputs1) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_BiLSTMLayer_construct_2800(%para421_фx1, %para373_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:199/        outputs1 = self.temporal_model1(x1, lgt)/
  %4(CNode_2806) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%3, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %5(x2) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_add(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %6(log_probs1) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2807(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:209/        log_probs5 = self.classifier55(x2)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:212/            log_probs1 = log_probs5/
}
# Order:
#   1: @✓12↓tfnet_model_TFNetModel_construct_2794:CNode_3036{[0]: ValueNode<Primitive> Return, [1]: log_probs1}


subgraph attr:
training : 1
subgraph instance: ✗12↓tfnet_model_TFNetModel_construct_2795 : 0x3943f290
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗12↓tfnet_model_TFNetModel_construct_2795 parent: [subgraph @12↓tfnet_model_TFNetModel_construct_2612]() {
  %1(outputs) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_BiLSTMLayer_construct_2799(%para404_фx, %para373_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:198/        outputs = self.temporal_model(x, lgt)/
  %2(CNode_2801) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%1, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:202/        log_probs1 = self.classifier11(outputs['predictions'])/
  %3(log_probs1) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2802(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:202/        log_probs1 = self.classifier11(outputs['predictions'])/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:211/        if not is_train:/
}
# Order:
#   1: @✗12↓tfnet_model_TFNetModel_construct_2795:CNode_3037{[0]: ValueNode<Primitive> Return, [1]: log_probs1}


subgraph attr:
subgraph instance: ✓3↓✓↓ms_max_one_element_2814 : 0x30614f70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓3↓✓↓ms_max_one_element_2814 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3038) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("max() cannot contain both tensor and non-tensor type.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2630/            const_utils.raise_type_error(/
  %2(CNode_3039) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_3041) = call @4↓✓↓ms_max_one_element_3040()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  %4(CNode_3042) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2630/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2630/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓3↓✓↓ms_max_one_element_2814:CNode_3038{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> max() cannot contain both tensor and non-tensor type.}
#   2: @✓3↓✓↓ms_max_one_element_2814:CNode_3043{[0]: ValueNode<Primitive> Return, [1]: CNode_3042}
#   3: @✓3↓✓↓ms_max_one_element_2814:CNode_3041{[0]: ValueNode<FuncGraph> 4↓✓↓ms_max_one_element_3040}


subgraph attr:
subgraph instance: ✗3↓✓↓ms_max_one_element_2815 : 0x3111e090
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗3↓✓↓ms_max_one_element_2815 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3044) = call @4↓✓↓ms_max_one_element_3040()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2629/        if tensor_num != 0:/
}
# Order:
#   1: @✗3↓✓↓ms_max_one_element_2815:CNode_3045{[0]: ValueNode<Primitive> Return, [1]: CNode_3044}
#   2: @✗3↓✓↓ms_max_one_element_2815:CNode_3044{[0]: ValueNode<FuncGraph> 4↓✓↓ms_max_one_element_3040}


subgraph attr:
after_block : 1
subgraph instance: ↓↻↓check_sequence_all_variable_scalar_2820 : 0x374bacc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↓↻↓check_sequence_all_variable_scalar_2820 parent: [subgraph @↻↓check_sequence_all_variable_scalar_2413]() {
  %1(CNode_3046) = S_Prim_logical_not(%para381_фcontain_variable_scalar)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %2(CNode_3047) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %3(CNode_3048) = Switch(%2, @↰↓↻↓check_sequence_all_variable_scalar_3049, @↱↓↻↓check_sequence_all_variable_scalar_3050)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %4(CNode_3051) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %5(CNode_3052) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %6(CNode_3053) = Switch(%5, @✓↓↻↓check_sequence_all_variable_scalar_3054, @✗↓↻↓check_sequence_all_variable_scalar_3055)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %7(CNode_3056) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %8(CNode_3058) = call @2↓↻↓check_sequence_all_variable_scalar_3057(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
}
# Order:
#   1: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3046{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: param_фcontain_variable_scalar}
#   2: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3047{[0]: ValueNode<Primitive> Cond, [1]: CNode_3046, [2]: ValueNode<BoolImm> false}
#   3: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3048{[0]: ValueNode<Primitive> Switch, [1]: CNode_3047, [2]: ValueNode<FuncGraph> ↰↓↻↓check_sequence_all_variable_scalar_3049, [3]: ValueNode<FuncGraph> ↱↓↻↓check_sequence_all_variable_scalar_3050}
#   4: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3051{[0]: CNode_3048}
#   5: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3052{[0]: ValueNode<Primitive> Cond, [1]: CNode_3051, [2]: ValueNode<BoolImm> false}
#   6: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3053{[0]: ValueNode<Primitive> Switch, [1]: CNode_3052, [2]: ValueNode<FuncGraph> ✓↓↻↓check_sequence_all_variable_scalar_3054, [3]: ValueNode<FuncGraph> ✗↓↻↓check_sequence_all_variable_scalar_3055}
#   7: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3056{[0]: CNode_3053}
#   8: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3058{[0]: ValueNode<FuncGraph> 2↓↻↓check_sequence_all_variable_scalar_3057, [1]: CNode_3056}
#   9: @↓↻↓check_sequence_all_variable_scalar_2820:CNode_3059{[0]: ValueNode<Primitive> Return, [1]: CNode_3058}


subgraph attr:
subgraph instance: ✓↓↻exist_tensor_2827 : 0x37b1e1f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @✓↓↻exist_tensor_2827 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_2418) = $(↻exist_tensor_2228):call @ms_iter_97(%para368_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %2(input_data) = $(↻exist_tensor_2228):S_Prim_getitem(%1, %para374_@CNode_2226)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %3(CNode_3060) = call @exist_tensor_1831(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
  %4(CNode_3061) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
  %5(CNode_3062) = Switch(%4, @2✓↓↻exist_tensor_3063, @✗✓↓↻exist_tensor_3064)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
  %6(CNode_3065) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
}
# Order:
#   1: @✓↓↻exist_tensor_2827:CNode_3060{[0]: ValueNode<FuncGraph> exist_tensor_1831, [1]: input_data}
#   2: @✓↓↻exist_tensor_2827:CNode_3061{[0]: ValueNode<Primitive> Cond, [1]: CNode_3060, [2]: ValueNode<BoolImm> false}
#   3: @✓↓↻exist_tensor_2827:CNode_3062{[0]: ValueNode<Primitive> Switch, [1]: CNode_3061, [2]: ValueNode<FuncGraph> 2✓↓↻exist_tensor_3063, [3]: ValueNode<FuncGraph> ✗✓↓↻exist_tensor_3064}
#   4: @✓↓↻exist_tensor_2827:CNode_3065{[0]: CNode_3062}
#   5: @✓↓↻exist_tensor_2827:CNode_3066{[0]: ValueNode<Primitive> Return, [1]: CNode_3065}


subgraph attr:
subgraph instance: ✗↓↻exist_tensor_2828 : 0x37f70c10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @✗↓↻exist_tensor_2828 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_3068) = call @2↓↻exist_tensor_3067()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2570/        if isinstance(input_data, (list, tuple)):/
}
# Order:
#   1: @✗↓↻exist_tensor_2828:CNode_3069{[0]: ValueNode<Primitive> Return, [1]: CNode_3068}
#   2: @✗↓↻exist_tensor_2828:CNode_3068{[0]: ValueNode<FuncGraph> 2↓↻exist_tensor_3067}


subgraph attr:
after_block : 1
subgraph instance: 2↓_check_ctcloss_targets_shape_2836 : 0x397d8e80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
subgraph @2↓_check_ctcloss_targets_shape_2836() {
  Return(None)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:2593/def _check_ctcloss_targets_shape(targets):/
}
# Order:
#   1: @2↓_check_ctcloss_targets_shape_2836:CNode_3070{[0]: ValueNode<Primitive> Return, [1]: ValueNode<None> None}


subgraph attr:
after_block : 1
subgraph instance: 2↓✓↓ms_min_one_element_2854 : 0x3956ad20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @2↓✓↓ms_min_one_element_2854 parent: [subgraph @ms_min_one_element_1301]() {
  %1(tensor_num) = call @get_tensor_num_1008(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2709/        tensor_num = get_tensor_num(x)/
  %2(CNode_3071) = S_Prim_inner_len(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  %3(CNode_3072) = S_Prim_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  %4(CNode_3073) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  %5(CNode_3074) = Switch(%4, @✓2↓✓↓ms_min_one_element_3075, @✗2↓✓↓ms_min_one_element_3076)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  %6(CNode_3077) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
}
# Order:
#   1: @2↓✓↓ms_min_one_element_2854:tensor_num{[0]: ValueNode<FuncGraph> get_tensor_num_1008, [1]: param_x}
#   2: @2↓✓↓ms_min_one_element_2854:CNode_3071{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_x}
#   3: @2↓✓↓ms_min_one_element_2854:CNode_3072{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: tensor_num, [2]: CNode_3071}
#   4: @2↓✓↓ms_min_one_element_2854:CNode_3073{[0]: ValueNode<Primitive> Cond, [1]: CNode_3072, [2]: ValueNode<BoolImm> false}
#   5: @2↓✓↓ms_min_one_element_2854:CNode_3074{[0]: ValueNode<Primitive> Switch, [1]: CNode_3073, [2]: ValueNode<FuncGraph> ✓2↓✓↓ms_min_one_element_3075, [3]: ValueNode<FuncGraph> ✗2↓✓↓ms_min_one_element_3076}
#   6: @2↓✓↓ms_min_one_element_2854:CNode_3077{[0]: CNode_3074}
#   7: @2↓✓↓ms_min_one_element_2854:CNode_3078{[0]: ValueNode<Primitive> Return, [1]: CNode_3077}


subgraph attr:
after_block : 1
subgraph instance: ↓✓2↓flatten_2866 : 0x3970bc40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↓✓2↓flatten_2866 parent: [subgraph @✓2↓flatten_2490]() {
  %1(CNode_3079) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1744/        input = _get_cache_prim(P.Transpose)()(input, new_order)/
  %2(CNode_3080) = %1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1744/        input = _get_cache_prim(P.Transpose)()(input, new_order)/
  %3(x_rank) = $(✓2↓flatten_2490):S_Prim_Rank(%para261_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1738/        x_rank = rank_(input)/
  %4(perm) = S_Prim_make_range(I64(0), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1742/        perm = ops.make_range(0, x_rank)/
  %5(new_order) = S_Prim_tuple_reversed(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1743/        new_order = ops.tuple_reversed(perm)/
  %6(input) = %2(%para261_input, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1744/        input = _get_cache_prim(P.Transpose)()(input, new_order)/
  %7(CNode_3081) = call @3↓flatten_2708(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:466/        return F.flatten(x, start_dim=self.start_dim, end_dim=self.end_dim)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1738/        x_rank = rank_(input)/
}
# Order:
#   1: @↓✓2↓flatten_2866:perm{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_range, [1]: ValueNode<Int64Imm> 0, [2]: x_rank}
#   2: @↓✓2↓flatten_2866:new_order{[0]: ValueNode<DoSignaturePrimitive> S_Prim_tuple_reversed, [1]: perm}
#   3: @↓✓2↓flatten_2866:CNode_3079{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.array_ops.Transpose'}
#   4: @↓✓2↓flatten_2866:CNode_3080{[0]: CNode_3079}
#   5: @↓✓2↓flatten_2866:input{[0]: CNode_3080, [1]: param_input, [2]: new_order}
#   6: @↓✓2↓flatten_2866:CNode_3082{[0]: ValueNode<Primitive> Return, [1]: CNode_3081}
#   7: @↓✓2↓flatten_2866:CNode_3081{[0]: ValueNode<FuncGraph> 3↓flatten_2708, [1]: input}


subgraph attr:
subgraph instance: ✓3↓flatten_2877 : 0x396ffc50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓3↓flatten_2877 parent: [subgraph @3↓flatten_2708]() {
  %1(x_rank) = $(3↓flatten_2708):S_Prim_Rank(%para423_фinput)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1748/    x_rank = rank_(input)/
  %2(CNode_3083) = S_Prim_MakeTuple(I64(0), I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  %3(CNode_3084) = S_Prim_in(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  %4(CNode_3085) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  %5(CNode_3086) = Switch(%4, @2✓3↓flatten_3087, @✗✓3↓flatten_3088)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  %6(CNode_3089) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
}
# Order:
#   1: @✓3↓flatten_2877:CNode_3083{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 1}
#   2: @✓3↓flatten_2877:CNode_3084{[0]: ValueNode<DoSignaturePrimitive> S_Prim_in, [1]: x_rank, [2]: CNode_3083}
#   3: @✓3↓flatten_2877:CNode_3085{[0]: ValueNode<Primitive> Cond, [1]: CNode_3084, [2]: ValueNode<BoolImm> false}
#   4: @✓3↓flatten_2877:CNode_3086{[0]: ValueNode<Primitive> Switch, [1]: CNode_3085, [2]: ValueNode<FuncGraph> 2✓3↓flatten_3087, [3]: ValueNode<FuncGraph> ✗✓3↓flatten_3088}
#   5: @✓3↓flatten_2877:CNode_3089{[0]: CNode_3086}
#   6: @✓3↓flatten_2877:CNode_3090{[0]: ValueNode<Primitive> Return, [1]: CNode_3089}


subgraph attr:
subgraph instance: ✗3↓flatten_2878 : 0x390b6a40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗3↓flatten_2878 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_3092) = call @4↓flatten_3091()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
}
# Order:
#   1: @✗3↓flatten_2878:CNode_3092{[0]: ValueNode<FuncGraph> 4↓flatten_3091}
#   2: @✗3↓flatten_2878:CNode_3093{[0]: ValueNode<Primitive> Return, [1]: CNode_3092}


subgraph attr:
subgraph instance: ↰3↓flatten_2872 : 0x390b55b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↰3↓flatten_2872 parent: [subgraph @flatten_1327]() {
  %1(CNode_3094) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  %2(CNode_3095) = S_Prim_equal(%para264_end_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
}
# Order:
#   1: @↰3↓flatten_2872:CNode_3094{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↰3↓flatten_2872:CNode_3095{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: param_end_dim, [2]: CNode_3094}
#   3: @↰3↓flatten_2872:CNode_3096{[0]: ValueNode<Primitive> Return, [1]: CNode_3095}


subgraph attr:
subgraph instance: ↱3↓flatten_2873 : 0x396a7f10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↱3↓flatten_2873 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_2869) = $(3↓flatten_2708):S_Prim_equal(%para263_start_dim, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1749/    if start_dim == 1 and end_dim == -1:/
}
# Order:
#   1: @↱3↓flatten_2873:CNode_3097{[0]: ValueNode<Primitive> Return, [1]: CNode_2869}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv1d_construct_2896 : 0x372ed270
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv1d_construct_2896 parent: [subgraph @L_✓mindspore_nn_layer_conv_Conv1d_construct_2741]() {
  %1(x) = $(L_mindspore_nn_layer_conv_Conv1d_construct_2548):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para409_x, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:582/        x = self.expand_dims(x, 2)/
  %2(output) = $(L_mindspore_nn_layer_conv_Conv1d_construct_2548):S_Prim_Conv2D[kernel_size: (I64(1), I64(5)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(2), I64(2)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(0), I64(0), I64(2), I64(2)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%1, %para411_L_conv1d1.temporal_conv.0.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:583/        output = self.conv2d(x, self.weight)/
  %3(output) = $(L_✓mindspore_nn_layer_conv_Conv1d_construct_2741):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"], data_format: "NCHW"](%2, %para410_L_conv1d1.temporal_conv.0.bias)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
  %4(output) = S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:587/        output = self.squeeze(output)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:588/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv1d_construct_2896:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   2: @L_↓mindspore_nn_layer_conv_Conv1d_construct_2896:CNode_3098{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899 : 0x37d35c90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_3099) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para412_x, %para413_L_conv1d1.temporal_conv.1.gamma, %para414_L_conv1d1.temporal_conv.1.beta, %para415_L_conv1d1.temporal_conv.1.moving_mean, %para416_L_conv1d1.temporal_conv.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  %2(CNode_3100) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:142/                return self.bn_train(x,/
}
# Order:
#   1: @L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899:CNode_3099{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv1d1.temporal_conv.1.gamma, [3]: param_L_conv1d1.temporal_conv.1.beta, [4]: param_L_conv1d1.temporal_conv.1.moving_mean, [5]: param_L_conv1d1.temporal_conv.1.moving_variance}
#   2: @L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899:CNode_3100{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3099, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2✓mindspore_nn_layer_normalization_BatchNorm1d_construct_2899:CNode_3101{[0]: ValueNode<Primitive> Return, [1]: CNode_3100}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902 : 0x37c5caf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_3102) = Cond(None, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %2(CNode_3103) = Switch(%1, @L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104, @L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  %3(CNode_3106) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902:CNode_3102{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<None> None, [2]: ValueNode<BoolImm> false}
#   2: @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902:CNode_3103{[0]: ValueNode<Primitive> Switch, [1]: CNode_3102, [2]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104, [3]: ValueNode<FuncGraph> L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105}
#   3: @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902:CNode_3106{[0]: CNode_3103}
#   4: @L_↓mindspore_nn_layer_normalization_BatchNorm1d_construct_2902:CNode_3107{[0]: ValueNode<Primitive> Return, [1]: CNode_3106}


subgraph attr:
training : 1
subgraph instance: ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905 : 0x373a25b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2757]() {
  %1(CNode_3108) = call @shape_1142(%para427_фx)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %2(CNode_3109) = S_Prim__shape_check[constexpr_prim: Bool(1)](%1, "MaxPool1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %3(CNode_3110) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
  %4(CNode_3112) = call @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %5(CNode_3113) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
}
# Order:
#   1: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:CNode_3108{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_фx}
#   2: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:CNode_3109{[0]: ValueNode<DoSignaturePrimitive> S_Prim__shape_check, [1]: CNode_3108, [2]: ValueNode<StringImm> MaxPool1d}
#   3: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_фx, [2]: ValueNode<Int64Imm> 2}
#   4: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool, [1]: x}
#   5: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   6: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:CNode_3112{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111}
#   7: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905:CNode_3114{[0]: ValueNode<Primitive> Return, [1]: CNode_3113}


subgraph attr:
training : 1
subgraph instance: L_↓mindspore_nn_layer_conv_Conv1d_construct_2908 : 0x33280d70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:579/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_conv_Conv1d_construct_2908 parent: [subgraph @L_✓mindspore_nn_layer_conv_Conv1d_construct_2764]() {
  %1(x) = $(L_mindspore_nn_layer_conv_Conv1d_construct_2568):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para417_x, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:582/        x = self.expand_dims(x, 2)/
  %2(output) = $(L_mindspore_nn_layer_conv_Conv1d_construct_2568):S_Prim_Conv2D[kernel_size: (I64(1), I64(5)), mode: I64(1), out_channel: I64(64), input_names: ["x", "w"], pad: (I64(0), I64(0), I64(2), I64(2)), pad_mode: I64(0), format: "NCHW", pad_list: (I64(0), I64(0), I64(2), I64(2)), groups: I64(1), stride: (I64(1), I64(1), I64(1), I64(1)), group: I64(1), dilation: (I64(1), I64(1), I64(1), I64(1)), output_names: ["output"]](%1, %para419_L_conv1d1.temporal_conv.4.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:583/        output = self.conv2d(x, self.weight)/
  %3(output) = $(L_✓mindspore_nn_layer_conv_Conv1d_construct_2764):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"], data_format: "NCHW"](%2, %para418_L_conv1d1.temporal_conv.4.bias)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:585/            output = self.bias_add(output, self.bias)/
  %4(output) = S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:587/        output = self.squeeze(output)/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:588/        return output/
}
# Order:
#   1: @L_↓mindspore_nn_layer_conv_Conv1d_construct_2908:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   2: @L_↓mindspore_nn_layer_conv_Conv1d_construct_2908:CNode_3115{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911 : 0x33421580
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_2769]() {
  %1(CNode_3116) = call @shape_1142(%para429_фx)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %2(CNode_3117) = S_Prim__shape_check[constexpr_prim: Bool(1)](%1, "MaxPool1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %3(CNode_3118) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
  %4(CNode_3120) = call @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %5(CNode_3121) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
}
# Order:
#   1: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:CNode_3116{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_фx}
#   2: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:CNode_3117{[0]: ValueNode<DoSignaturePrimitive> S_Prim__shape_check, [1]: CNode_3116, [2]: ValueNode<StringImm> MaxPool1d}
#   3: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_фx, [2]: ValueNode<Int64Imm> 2}
#   4: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool, [1]: x}
#   5: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   6: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:CNode_3120{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119}
#   7: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911:CNode_3122{[0]: ValueNode<Primitive> Return, [1]: CNode_3121}


subgraph attr:
training : 1
subgraph instance: ↻✓↻9↓tfnet_model_TFNetModel_construct_2916 : 0x394aa630
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻✓↻9↓tfnet_model_TFNetModel_construct_2916 parent: [subgraph @↵✓↻9↓tfnet_model_TFNetModel_construct_2780]() {
  %1(CNode_3123) = call @ms_next_1075(%para431_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %2(CNode_3124) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %3(CNode_3125) = Switch(Bool(1), @✓↻✓↻9↓tfnet_model_TFNetModel_construct_3126, @✗↻✓↻9↓tfnet_model_TFNetModel_construct_3127)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %4(CNode_3128) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %5(CNode_3129) = call @↵✓↻9↓tfnet_model_TFNetModel_construct_2780(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3123{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3123, [2]: ValueNode<Int64Imm> 0}
#   3: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3124{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3123, [2]: ValueNode<Int64Imm> 1}
#   4: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3130{[0]: ValueNode<DoSignaturePrimitive> S_Prim_floordiv, [1]: i, [2]: ValueNode<Int64Imm> 2}
#   5: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3131{[0]: ValueNode<ClassType> class 'int', [1]: CNode_3130}
#   6: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3132{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_3131}
#   7: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3133{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_3132}
#   8: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3134{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_3133}
#   9: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3125{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> ✓↻✓↻9↓tfnet_model_TFNetModel_construct_3126, [3]: ValueNode<FuncGraph> ✗↻✓↻9↓tfnet_model_TFNetModel_construct_3127}
#  10: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3128{[0]: CNode_3125}
#  11: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3135{[0]: ValueNode<Primitive> Return, [1]: CNode_3129}
#  12: @↻✓↻9↓tfnet_model_TFNetModel_construct_2916:CNode_3129{[0]: ValueNode<FuncGraph> ↵✓↻9↓tfnet_model_TFNetModel_construct_2780, [1]: CNode_3124, [2]: CNode_3128}


subgraph attr:
training : 1
subgraph instance: ↓✓↻9↓tfnet_model_TFNetModel_construct_2917 : 0x394aae00
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✓↻9↓tfnet_model_TFNetModel_construct_2917 parent: [subgraph @↵✓↻9↓tfnet_model_TFNetModel_construct_2780]() {
  Return(%para432_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @↓✓↻9↓tfnet_model_TFNetModel_construct_2917:CNode_3136{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
training : 1
subgraph instance: ↻✗↻9↓tfnet_model_TFNetModel_construct_2922 : 0x394916c0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻✗↻9↓tfnet_model_TFNetModel_construct_2922 parent: [subgraph @↵✗↻9↓tfnet_model_TFNetModel_construct_2783]() {
  %1(CNode_3137) = call @ms_next_1075(%para433_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %2(CNode_3138) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %3(CNode_3139) = Switch(Bool(1), @✓↻✗↻9↓tfnet_model_TFNetModel_construct_3140, @✗↻✗↻9↓tfnet_model_TFNetModel_construct_3141)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %4(CNode_3142) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %5(CNode_3143) = call @↵✗↻9↓tfnet_model_TFNetModel_construct_2783(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3137{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:i{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3137, [2]: ValueNode<Int64Imm> 0}
#   3: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3138{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3137, [2]: ValueNode<Int64Imm> 1}
#   4: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3144{[0]: ValueNode<ClassType> class 'int', [1]: i}
#   5: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3145{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: CNode_3144, [2]: k}
#   6: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3146{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_3145, [2]: ValueNode<Int64Imm> 1}
#   7: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3147{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_3146}
#   8: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3148{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_3147}
#   9: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3149{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_3148}
#  10: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3139{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> ✓↻✗↻9↓tfnet_model_TFNetModel_construct_3140, [3]: ValueNode<FuncGraph> ✗↻✗↻9↓tfnet_model_TFNetModel_construct_3141}
#  11: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3142{[0]: CNode_3139}
#  12: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3150{[0]: ValueNode<Primitive> Return, [1]: CNode_3143}
#  13: @↻✗↻9↓tfnet_model_TFNetModel_construct_2922:CNode_3143{[0]: ValueNode<FuncGraph> ↵✗↻9↓tfnet_model_TFNetModel_construct_2783, [1]: CNode_3138, [2]: CNode_3142}


subgraph attr:
training : 1
subgraph instance: ↓✗↻9↓tfnet_model_TFNetModel_construct_2923 : 0x39491e90
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✗↻9↓tfnet_model_TFNetModel_construct_2923 parent: [subgraph @↵✗↻9↓tfnet_model_TFNetModel_construct_2783]() {
  Return(%para434_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @↓✗↻9↓tfnet_model_TFNetModel_construct_2923:CNode_3151{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
training : 1
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938 : 0x39145050
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2933]() {
  %1(CNode_3152) = getattr(%para438_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %3(CNode_3154) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938:CNode_3152{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938:x{[0]: CNode_3152, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938:CNode_3155{[0]: ValueNode<Primitive> Return, [1]: CNode_3154}
#   4: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2938:CNode_3154{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939 : 0x39131780
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2933]() {
  %1(CNode_3156) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153(%para438_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939:CNode_3157{[0]: ValueNode<Primitive> Return, [1]: CNode_3156}
#   2: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2939:CNode_3156{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
training : 1
subgraph instance: ✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955 : 0x39128a60
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2950]() {
  %1(CNode_3158) = getattr(%para442_x, "unsqueeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %2(x) = %1(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
  %3(CNode_3160) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159(%2, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:724/            x = x.unsqueeze(0)/
}
# Order:
#   1: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955:CNode_3158{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> unsqueeze}
#   2: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955:x{[0]: CNode_3158, [1]: ValueNode<Int64Imm> 0}
#   3: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955:CNode_3161{[0]: ValueNode<Primitive> Return, [1]: CNode_3160}
#   4: @✓mindspore_nn_layer_pooling_MaxPool1d_construct_2955:CNode_3160{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159, [1]: x, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: ✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956 : 0x391151f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956 parent: [subgraph @mindspore_nn_layer_pooling_MaxPool1d_construct_2950]() {
  %1(CNode_3162) = call @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159(%para442_x, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:723/        if x.ndim == 2:/
}
# Order:
#   1: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956:CNode_3163{[0]: ValueNode<Primitive> Return, [1]: CNode_3162}
#   2: @✗mindspore_nn_layer_pooling_MaxPool1d_construct_2956:CNode_3162{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159, [1]: param_x, [2]: ValueNode<BoolImm> false}


subgraph attr:
training : 1
subgraph instance: ↻mindspore_nn_layer_container_SequentialCell_construct_2962 : 0x3914e310
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↻mindspore_nn_layer_container_SequentialCell_construct_2962 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2786]() {
  %1(CNode_2960) = MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para443_@CNode_2960, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %2(CNode_3164) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
  %3(CNode_2789) = $(mindspore_nn_layer_container_SequentialCell_construct_2601):MakeTuple(@mindspore_nn_layer_conv_Conv1d_construct_2926, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2928, @mindspore_nn_layer_activation_ReLU_construct_2930, @mindspore_nn_layer_pooling_MaxPool1d_construct_2933, @mindspore_nn_layer_conv_Conv1d_construct_2942, @mindspore_nn_layer_normalization_BatchNorm1d_construct_2944, @mindspore_nn_layer_activation_ReLU_construct_2947, @mindspore_nn_layer_pooling_MaxPool1d_construct_2950)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %4(CNode_3165) = call @ms_iter_97(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %5(cell) = S_Prim_getitem(%4, %para443_@CNode_2960)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %6(input_data) = %5(%para444_фinput_data)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:295/            input_data = cell(input_data)/
  %7(CNode_3166) = call @↵mindspore_nn_layer_container_SequentialCell_construct_2786(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  %8(CNode_3167) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
}
# Order:
#   1: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:CNode_3165{[0]: ValueNode<FuncGraph> ms_iter_97, [1]: CNode_2789}
#   2: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:cell{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3165, [2]: param_@CNode_2960}
#   3: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:CNode_2960{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_@CNode_2960, [2]: ValueNode<Int64Imm> 1}
#   4: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:input_data{[0]: cell, [1]: param_фinput_data}
#   5: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:CNode_3166{[0]: ValueNode<FuncGraph> ↵mindspore_nn_layer_container_SequentialCell_construct_2786, [1]: CNode_2960, [2]: input_data}
#   6: @↻mindspore_nn_layer_container_SequentialCell_construct_2962:CNode_3168{[0]: ValueNode<Primitive> Return, [1]: CNode_3167}


subgraph attr:
training : 1
subgraph instance: ↓mindspore_nn_layer_container_SequentialCell_construct_2963 : 0x3914d380
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:293/    def construct(self, input_data):/
subgraph @↓mindspore_nn_layer_container_SequentialCell_construct_2963 parent: [subgraph @↵mindspore_nn_layer_container_SequentialCell_construct_2786]() {
  Return(%para444_фinput_data)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:296/        return input_data/
}
# Order:
#   1: @↓mindspore_nn_layer_container_SequentialCell_construct_2963:CNode_3169{[0]: ValueNode<Primitive> Return, [1]: param_фinput_data}


subgraph attr:
training : 1
subgraph instance: ✓modules_NormLinear_construct_2975 : 0x3943dc90
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓modules_NormLinear_construct_2975 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(x_shape) = $(modules_NormLinear_construct_2807):getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3170) = JoinedStr("Invalid input shape: ", %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  %3(CNode_3171) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
}
# Order:
#   1: @✓modules_NormLinear_construct_2975:CNode_3170{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Invalid input shape: , [2]: x_shape}
#   2: @✓modules_NormLinear_construct_2975:CNode_3171{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3170, [3]: ValueNode<StringImm> None}
#   3: @✓modules_NormLinear_construct_2975:CNode_3172{[0]: ValueNode<Primitive> Return, [1]: CNode_3171}


subgraph attr:
training : 1
subgraph instance: ✗modules_NormLinear_construct_2976 : 0x393f7010
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗modules_NormLinear_construct_2976 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(CNode_3174) = call @↓modules_NormLinear_construct_3173()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @✗modules_NormLinear_construct_2976:CNode_3174{[0]: ValueNode<FuncGraph> ↓modules_NormLinear_construct_3173}
#   2: @✗modules_NormLinear_construct_2976:CNode_3175{[0]: ValueNode<Primitive> Return, [1]: CNode_3174}


subgraph attr:
training : 1
subgraph instance: ↰modules_NormLinear_construct_2970 : 0x393f6080
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↰modules_NormLinear_construct_2970 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(x_shape) = $(modules_NormLinear_construct_2807):getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_2966) = $(modules_NormLinear_construct_2807):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_2967) = $(modules_NormLinear_construct_2807):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↰modules_NormLinear_construct_2970:CNode_3176{[0]: ValueNode<Primitive> Return, [1]: CNode_2967}


subgraph attr:
training : 1
subgraph instance: ↱modules_NormLinear_construct_2971 : 0x393f4830
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↱modules_NormLinear_construct_2971 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(x_shape) = $(modules_NormLinear_construct_2807):getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3177) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_3178) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_3179) = S_Prim_equal(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↱modules_NormLinear_construct_2971:CNode_3177{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↱modules_NormLinear_construct_2971:CNode_3178{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3177}
#   3: @↱modules_NormLinear_construct_2971:CNode_3179{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3178, [2]: ValueNode<Int64Imm> 0}
#   4: @↱modules_NormLinear_construct_2971:CNode_3180{[0]: ValueNode<Primitive> Return, [1]: CNode_3179}


subgraph attr:
training : 1
subgraph instance: ✓modules_BiLSTMLayer_construct_2984 : 0x392ad3f0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓modules_BiLSTMLayer_construct_2984 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3181) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  %2(CNode_3182) = JoinedStr("Expected 3D input (T, B, C), got shape ", %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  %3(CNode_3183) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
}
# Order:
#   1: @✓modules_BiLSTMLayer_construct_2984:CNode_3181{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @✓modules_BiLSTMLayer_construct_2984:CNode_3182{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Expected 3D input (T, B, C), got shape , [2]: CNode_3181}
#   3: @✓modules_BiLSTMLayer_construct_2984:CNode_3183{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3182, [3]: ValueNode<StringImm> None}
#   4: @✓modules_BiLSTMLayer_construct_2984:CNode_3184{[0]: ValueNode<Primitive> Return, [1]: CNode_3183}


subgraph attr:
training : 1
subgraph instance: ✗modules_BiLSTMLayer_construct_2985 : 0x391cbfe0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✗modules_BiLSTMLayer_construct_2985 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3186) = call @↓modules_BiLSTMLayer_construct_3185()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
}
# Order:
#   1: @✗modules_BiLSTMLayer_construct_2985:CNode_3186{[0]: ValueNode<FuncGraph> ↓modules_BiLSTMLayer_construct_3185}
#   2: @✗modules_BiLSTMLayer_construct_2985:CNode_3187{[0]: ValueNode<Primitive> Return, [1]: CNode_3186}


subgraph attr:
training : 1
subgraph instance: ✓modules_BiLSTMLayer_construct_2993 : 0x39100290
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓modules_BiLSTMLayer_construct_2993 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3188) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  %2(CNode_3189) = JoinedStr("Expected 3D input (T, B, C), got shape ", %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  %3(CNode_3190) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:156/            raise ValueError(f"Expected 3D input (T, B, C), got shape {x.shape}")/
}
# Order:
#   1: @✓modules_BiLSTMLayer_construct_2993:CNode_3188{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @✓modules_BiLSTMLayer_construct_2993:CNode_3189{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Expected 3D input (T, B, C), got shape , [2]: CNode_3188}
#   3: @✓modules_BiLSTMLayer_construct_2993:CNode_3190{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3189, [3]: ValueNode<StringImm> None}
#   4: @✓modules_BiLSTMLayer_construct_2993:CNode_3191{[0]: ValueNode<Primitive> Return, [1]: CNode_3190}


subgraph attr:
training : 1
subgraph instance: ✗modules_BiLSTMLayer_construct_2994 : 0x392b44c0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✗modules_BiLSTMLayer_construct_2994 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3193) = call @↓modules_BiLSTMLayer_construct_3192()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:155/        if len(x.shape) != 3:/
}
# Order:
#   1: @✗modules_BiLSTMLayer_construct_2994:CNode_3193{[0]: ValueNode<FuncGraph> ↓modules_BiLSTMLayer_construct_3192}
#   2: @✗modules_BiLSTMLayer_construct_2994:CNode_3194{[0]: ValueNode<Primitive> Return, [1]: CNode_3193}


subgraph attr:
training : 1
subgraph instance: ✓modules_NormLinear_construct_3006 : 0x391c5270
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓modules_NormLinear_construct_3006 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(x_shape) = $(modules_NormLinear_construct_2804):getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3195) = JoinedStr("Invalid input shape: ", %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  %3(CNode_3196) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
}
# Order:
#   1: @✓modules_NormLinear_construct_3006:CNode_3195{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Invalid input shape: , [2]: x_shape}
#   2: @✓modules_NormLinear_construct_3006:CNode_3196{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3195, [3]: ValueNode<StringImm> None}
#   3: @✓modules_NormLinear_construct_3006:CNode_3197{[0]: ValueNode<Primitive> Return, [1]: CNode_3196}


subgraph attr:
training : 1
subgraph instance: ✗modules_NormLinear_construct_3007 : 0x39175520
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗modules_NormLinear_construct_3007 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(CNode_3199) = call @↓modules_NormLinear_construct_3198()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @✗modules_NormLinear_construct_3007:CNode_3199{[0]: ValueNode<FuncGraph> ↓modules_NormLinear_construct_3198}
#   2: @✗modules_NormLinear_construct_3007:CNode_3200{[0]: ValueNode<Primitive> Return, [1]: CNode_3199}


subgraph attr:
training : 1
subgraph instance: ↰modules_NormLinear_construct_3001 : 0x39174590
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↰modules_NormLinear_construct_3001 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(x_shape) = $(modules_NormLinear_construct_2804):getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_2997) = $(modules_NormLinear_construct_2804):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_2998) = $(modules_NormLinear_construct_2804):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↰modules_NormLinear_construct_3001:CNode_3201{[0]: ValueNode<Primitive> Return, [1]: CNode_2998}


subgraph attr:
training : 1
subgraph instance: ↱modules_NormLinear_construct_3002 : 0x3916c820
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↱modules_NormLinear_construct_3002 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(x_shape) = $(modules_NormLinear_construct_2804):getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3202) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_3203) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_3204) = S_Prim_equal(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↱modules_NormLinear_construct_3002:CNode_3202{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↱modules_NormLinear_construct_3002:CNode_3203{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3202}
#   3: @↱modules_NormLinear_construct_3002:CNode_3204{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3203, [2]: ValueNode<Int64Imm> 0}
#   4: @↱modules_NormLinear_construct_3002:CNode_3205{[0]: ValueNode<Primitive> Return, [1]: CNode_3204}


subgraph attr:
training : 1
subgraph instance: ✓modules_NormLinear_construct_3019 : 0x393ec330
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓modules_NormLinear_construct_3019 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(x_shape) = $(modules_NormLinear_construct_2802):getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3206) = JoinedStr("Invalid input shape: ", %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  %3(CNode_3207) = raise[side_effect_io: Bool(1)]("ValueError", %2, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:95/            raise ValueError(f"Invalid input shape: {x_shape}")/
}
# Order:
#   1: @✓modules_NormLinear_construct_3019:CNode_3206{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Invalid input shape: , [2]: x_shape}
#   2: @✓modules_NormLinear_construct_3019:CNode_3207{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3206, [3]: ValueNode<StringImm> None}
#   3: @✓modules_NormLinear_construct_3019:CNode_3208{[0]: ValueNode<Primitive> Return, [1]: CNode_3207}


subgraph attr:
training : 1
subgraph instance: ✗modules_NormLinear_construct_3020 : 0x3910b380
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗modules_NormLinear_construct_3020 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(CNode_3210) = call @↓modules_NormLinear_construct_3209()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @✗modules_NormLinear_construct_3020:CNode_3210{[0]: ValueNode<FuncGraph> ↓modules_NormLinear_construct_3209}
#   2: @✗modules_NormLinear_construct_3020:CNode_3211{[0]: ValueNode<Primitive> Return, [1]: CNode_3210}


subgraph attr:
training : 1
subgraph instance: ↰modules_NormLinear_construct_3014 : 0x3910a580
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↰modules_NormLinear_construct_3014 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(x_shape) = $(modules_NormLinear_construct_2802):getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3010) = $(modules_NormLinear_construct_2802):S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_3011) = $(modules_NormLinear_construct_2802):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↰modules_NormLinear_construct_3014:CNode_3212{[0]: ValueNode<Primitive> Return, [1]: CNode_3011}


subgraph attr:
training : 1
subgraph instance: ↱modules_NormLinear_construct_3015 : 0x39108aa0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↱modules_NormLinear_construct_3015 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(x_shape) = $(modules_NormLinear_construct_2802):getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3213) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %3(CNode_3214) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  %4(CNode_3215) = S_Prim_equal(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:94/        if len(x_shape) == 0 or x_shape[-1] == 0:/
}
# Order:
#   1: @↱modules_NormLinear_construct_3015:CNode_3213{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↱modules_NormLinear_construct_3015:CNode_3214{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3213}
#   3: @↱modules_NormLinear_construct_3015:CNode_3215{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3214, [2]: ValueNode<Int64Imm> 0}
#   4: @↱modules_NormLinear_construct_3015:CNode_3216{[0]: ValueNode<Primitive> Return, [1]: CNode_3215}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 14↓tfnet_model_TFNetModel_construct_3033 : 0x39463b40
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @14↓tfnet_model_TFNetModel_construct_3033 parent: [subgraph @13↓tfnet_model_TFNetModel_construct_2797](%para453_) {
  %1(CNode_3217) = S_Prim_inner_len(%para453_фsafe_lgt)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %2(CNode_3218) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %3(CNode_3219) = S_Prim_not_equal(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %4(CNode_3220) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %5(CNode_3221) = Switch(%4, @✓14↓tfnet_model_TFNetModel_construct_3222, @✗14↓tfnet_model_TFNetModel_construct_3223)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %6(CNode_3224) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
  %7(CNode_3226) = call @15↓tfnet_model_TFNetModel_construct_3225(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
}
# Order:
#   1: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3217{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фsafe_lgt}
#   2: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3218{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   3: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3219{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3217, [2]: CNode_3218}
#   4: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3220{[0]: ValueNode<Primitive> Cond, [1]: CNode_3219, [2]: ValueNode<BoolImm> false}
#   5: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3221{[0]: ValueNode<Primitive> Switch, [1]: CNode_3220, [2]: ValueNode<FuncGraph> ✓14↓tfnet_model_TFNetModel_construct_3222, [3]: ValueNode<FuncGraph> ✗14↓tfnet_model_TFNetModel_construct_3223}
#   6: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3224{[0]: CNode_3221}
#   7: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3226{[0]: ValueNode<FuncGraph> 15↓tfnet_model_TFNetModel_construct_3225, [1]: CNode_3224}
#   8: @14↓tfnet_model_TFNetModel_construct_3033:CNode_3227{[0]: ValueNode<Primitive> Return, [1]: CNode_3226}


subgraph attr:
training : 1
subgraph instance: ✓13↓tfnet_model_TFNetModel_construct_3030 : 0x3944b3e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓13↓tfnet_model_TFNetModel_construct_3030 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(safe_lgt) = call @G_✓13↓tfnet_model_TFNetModel_construct_3228()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @✓13↓tfnet_model_TFNetModel_construct_3030:safe_lgt{[0]: ValueNode<FuncGraph> G_✓13↓tfnet_model_TFNetModel_construct_3228}
#   2: @✓13↓tfnet_model_TFNetModel_construct_3030:CNode_3229{[0]: ValueNode<Primitive> Return, [1]: safe_lgt}


subgraph attr:
training : 1
subgraph instance: ✗13↓tfnet_model_TFNetModel_construct_3031 : 0x39449ae0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗13↓tfnet_model_TFNetModel_construct_3031 parent: [subgraph @2↓tfnet_model_TFNetModel_construct_578]() {
  %1(CNode_3230) = S_Prim_make_list(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:219/            safe_lgt = [1] * int(batch)/
  %2(CNode_3231) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:219/            safe_lgt = [1] * int(batch)/
  %3(safe_lgt) = S_Prim_mul(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:219/            safe_lgt = [1] * int(batch)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:219/            safe_lgt = [1] * int(batch)/
}
# Order:
#   1: @✗13↓tfnet_model_TFNetModel_construct_3031:CNode_3230{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1}
#   2: @✗13↓tfnet_model_TFNetModel_construct_3031:CNode_3231{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   3: @✗13↓tfnet_model_TFNetModel_construct_3031:safe_lgt{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_3230, [2]: CNode_3231}
#   4: @✗13↓tfnet_model_TFNetModel_construct_3031:CNode_3232{[0]: ValueNode<Primitive> Return, [1]: safe_lgt}


subgraph attr:
training : 1
subgraph instance: ↰13↓tfnet_model_TFNetModel_construct_3025 : 0x394484e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↰13↓tfnet_model_TFNetModel_construct_3025 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(CNode_3233) = S_Prim_inner_len(%para373_фlgt)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  %2(CNode_3234) = S_Prim_greater(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
}
# Order:
#   1: @↰13↓tfnet_model_TFNetModel_construct_3025:CNode_3233{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фlgt}
#   2: @↰13↓tfnet_model_TFNetModel_construct_3025:CNode_3234{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: CNode_3233, [2]: ValueNode<Int64Imm> 0}
#   3: @↰13↓tfnet_model_TFNetModel_construct_3025:CNode_3235{[0]: ValueNode<Primitive> Return, [1]: CNode_3234}


subgraph attr:
training : 1
subgraph instance: ↱13↓tfnet_model_TFNetModel_construct_3026 : 0x39447a80
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↱13↓tfnet_model_TFNetModel_construct_3026 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  Return(%para373_фlgt)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:216/        if lgt and len(lgt) > 0:/
}
# Order:
#   1: @↱13↓tfnet_model_TFNetModel_construct_3026:CNode_3236{[0]: ValueNode<Primitive> Return, [1]: param_фlgt}


subgraph attr:
after_block : 1
subgraph instance: 4↓✓↓ms_max_one_element_3040 : 0x333155c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @4↓✓↓ms_max_one_element_3040 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3237) = call @exist_tensor_1831(%para214_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
  %2(CNode_3238) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
  %3(CNode_3239) = Switch(%2, @✓4↓✓↓ms_max_one_element_3240, @✗4↓✓↓ms_max_one_element_3241)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
  %4(CNode_3242) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
}
# Order:
#   1: @4↓✓↓ms_max_one_element_3040:CNode_3237{[0]: ValueNode<FuncGraph> exist_tensor_1831, [1]: param_x}
#   2: @4↓✓↓ms_max_one_element_3040:CNode_3238{[0]: ValueNode<Primitive> Cond, [1]: CNode_3237, [2]: ValueNode<BoolImm> false}
#   3: @4↓✓↓ms_max_one_element_3040:CNode_3239{[0]: ValueNode<Primitive> Switch, [1]: CNode_3238, [2]: ValueNode<FuncGraph> ✓4↓✓↓ms_max_one_element_3240, [3]: ValueNode<FuncGraph> ✗4↓✓↓ms_max_one_element_3241}
#   4: @4↓✓↓ms_max_one_element_3040:CNode_3242{[0]: CNode_3239}
#   5: @4↓✓↓ms_max_one_element_3040:CNode_3243{[0]: ValueNode<Primitive> Return, [1]: CNode_3242}


subgraph attr:
after_block : 1
subgraph instance: 2↓↻↓check_sequence_all_variable_scalar_3057 : 0x37383ce0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @2↓↻↓check_sequence_all_variable_scalar_3057 parent: [subgraph @↻↓check_sequence_all_variable_scalar_2413](%para454_) {
  %1(CNode_2411) = $(↻↓check_sequence_all_variable_scalar_2413):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para380_@CNode_2411, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %2(CNode_3244) = call @↵↓check_sequence_all_variable_scalar_2216(%1, %para454_фcontain_variable_scalar)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
}
# Order:
#   1: @2↓↻↓check_sequence_all_variable_scalar_3057:CNode_3245{[0]: ValueNode<Primitive> Return, [1]: CNode_3244}
#   2: @2↓↻↓check_sequence_all_variable_scalar_3057:CNode_3244{[0]: ValueNode<FuncGraph> ↵↓check_sequence_all_variable_scalar_2216, [1]: CNode_2411, [2]: param_фcontain_variable_scalar}


subgraph attr:
subgraph instance: ✓↓↻↓check_sequence_all_variable_scalar_3054 : 0x376c9670
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✓↓↻↓check_sequence_all_variable_scalar_3054() {
  Return(Bool(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2590/            contain_variable_scalar = True/
}
# Order:
#   1: @✓↓↻↓check_sequence_all_variable_scalar_3054:CNode_3246{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✗↓↻↓check_sequence_all_variable_scalar_3055 : 0x3772d270
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @✗↓↻↓check_sequence_all_variable_scalar_3055 parent: [subgraph @↵↓check_sequence_all_variable_scalar_2216]() {
  Return(%para381_фcontain_variable_scalar)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
}
# Order:
#   1: @✗↓↻↓check_sequence_all_variable_scalar_3055:CNode_3247{[0]: ValueNode<Primitive> Return, [1]: param_фcontain_variable_scalar}


subgraph attr:
subgraph instance: ↰↓↻↓check_sequence_all_variable_scalar_3049 : 0x37f3f3f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↰↓↻↓check_sequence_all_variable_scalar_3049 parent: [subgraph @↻↓check_sequence_all_variable_scalar_2413]() {
  %1(CNode_2633) = $(↻↓check_sequence_all_variable_scalar_2413):call @ms_iter_97(%para329_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %2(i) = $(↻↓check_sequence_all_variable_scalar_2413):S_Prim_getitem(%1, %para380_@CNode_2411)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2586/    for i in x:/
  %3(CNode_3248) = S_Prim_IsConstant(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  %4(CNode_3249) = S_Prim_logical_not(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
}
# Order:
#   1: @↰↓↻↓check_sequence_all_variable_scalar_3049:CNode_3248{[0]: ValueNode<DoSignaturePrimitive> S_Prim_IsConstant, [1]: i}
#   2: @↰↓↻↓check_sequence_all_variable_scalar_3049:CNode_3249{[0]: ValueNode<DoSignaturePrimitive> S_Prim_logical_not, [1]: CNode_3248}
#   3: @↰↓↻↓check_sequence_all_variable_scalar_3049:CNode_3250{[0]: ValueNode<Primitive> Return, [1]: CNode_3249}


subgraph attr:
subgraph instance: ↱↓↻↓check_sequence_all_variable_scalar_3050 : 0x372ccfb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2576/def check_sequence_all_variable_scalar(x, str_info):/
subgraph @↱↓↻↓check_sequence_all_variable_scalar_3050 parent: [subgraph @↓↻↓check_sequence_all_variable_scalar_2820]() {
  %1(CNode_3046) = $(↓↻↓check_sequence_all_variable_scalar_2820):S_Prim_logical_not(%para381_фcontain_variable_scalar)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2589/        if not contain_variable_scalar and not F.isconstant(i):/
}
# Order:
#   1: @↱↓↻↓check_sequence_all_variable_scalar_3050:CNode_3251{[0]: ValueNode<Primitive> Return, [1]: CNode_3046}


subgraph attr:
subgraph instance: 2✓↓↻exist_tensor_3063 : 0x371dbb00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @2✓↓↻exist_tensor_3063() {
  Return(Bool(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2572/                return True/
}
# Order:
#   1: @2✓↓↻exist_tensor_3063:CNode_3252{[0]: ValueNode<Primitive> Return, [1]: ValueNode<BoolImm> true}


subgraph attr:
subgraph instance: ✗✓↓↻exist_tensor_3064 : 0x3758b3b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @✗✓↓↻exist_tensor_3064 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_3254) = call @↓✓↓↻exist_tensor_3253()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
}
# Order:
#   1: @✗✓↓↻exist_tensor_3064:CNode_3254{[0]: ValueNode<FuncGraph> ↓✓↓↻exist_tensor_3253}
#   2: @✗✓↓↻exist_tensor_3064:CNode_3255{[0]: ValueNode<Primitive> Return, [1]: CNode_3254}


subgraph attr:
after_block : 1
subgraph instance: 2↓↻exist_tensor_3067 : 0x37785bd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @2↓↻exist_tensor_3067 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_2226) = $(↻exist_tensor_2228):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para374_@CNode_2226, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
  %2(CNode_3256) = call @↵exist_tensor_2056(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2567/    for input_data in data:/
}
# Order:
#   1: @2↓↻exist_tensor_3067:CNode_3257{[0]: ValueNode<Primitive> Return, [1]: CNode_3256}
#   2: @2↓↻exist_tensor_3067:CNode_3256{[0]: ValueNode<FuncGraph> ↵exist_tensor_2056, [1]: CNode_2226}


subgraph attr:
subgraph instance: ✓2↓✓↓ms_min_one_element_3075 : 0x3957f140
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓2↓✓↓ms_min_one_element_3075 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3258) = call @min_tensor_1868(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2711/            return min_tensor(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2711/            return min_tensor(x)/
}
# Order:
#   1: @✓2↓✓↓ms_min_one_element_3075:CNode_3258{[0]: ValueNode<FuncGraph> min_tensor_1868, [1]: param_x}
#   2: @✓2↓✓↓ms_min_one_element_3075:CNode_3259{[0]: ValueNode<Primitive> Return, [1]: CNode_3258}


subgraph attr:
subgraph instance: ✗2↓✓↓ms_min_one_element_3076 : 0x3956ecc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗2↓✓↓ms_min_one_element_3076 parent: [subgraph @2↓✓↓ms_min_one_element_2854]() {
  %1(CNode_3261) = call @3↓✓↓ms_min_one_element_3260()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2710/        if tensor_num == len(x):/
}
# Order:
#   1: @✗2↓✓↓ms_min_one_element_3076:CNode_3261{[0]: ValueNode<FuncGraph> 3↓✓↓ms_min_one_element_3260}
#   2: @✗2↓✓↓ms_min_one_element_3076:CNode_3262{[0]: ValueNode<Primitive> Return, [1]: CNode_3261}


subgraph attr:
subgraph instance: 2✓3↓flatten_3087 : 0x39704a50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @2✓3↓flatten_3087 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_3263) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1751/            return reshape_(input, (-1,))/
  %2(CNode_3264) = S_Prim_MakeTuple(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1751/            return reshape_(input, (-1,))/
  %3(CNode_3265) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para423_фinput, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1751/            return reshape_(input, (-1,))/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1751/            return reshape_(input, (-1,))/
}
# Order:
#   1: @2✓3↓flatten_3087:CNode_3263{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @2✓3↓flatten_3087:CNode_3264{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3263}
#   3: @2✓3↓flatten_3087:CNode_3265{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_фinput, [2]: CNode_3264}
#   4: @2✓3↓flatten_3087:CNode_3266{[0]: ValueNode<Primitive> Return, [1]: CNode_3265}


subgraph attr:
subgraph instance: ✗✓3↓flatten_3088 : 0x39701cf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗✓3↓flatten_3088 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_3268) = call @↓✓3↓flatten_3267()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1750/        if x_rank in (0, 1):/
}
# Order:
#   1: @✗✓3↓flatten_3088:CNode_3268{[0]: ValueNode<FuncGraph> ↓✓3↓flatten_3267}
#   2: @✗✓3↓flatten_3088:CNode_3269{[0]: ValueNode<Primitive> Return, [1]: CNode_3268}


subgraph attr:
after_block : 1
subgraph instance: 4↓flatten_3091 : 0x390b8b30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @4↓flatten_3091 parent: [subgraph @3↓flatten_2708]() {
  %1(x_rank) = $(3↓flatten_2708):S_Prim_Rank(%para423_фinput)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1748/    x_rank = rank_(input)/
  %2(idx) = call @canonicalize_axis_3270(%para263_start_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1755/    start_dim = canonicalize_axis(start_dim, x_rank)/
  %3(end_dim) = call @canonicalize_axis_3270(%para264_end_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1756/    end_dim = canonicalize_axis(end_dim, x_rank)/
  %4(CNode_3272) = call @check_dim_valid_3271(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1757/    check_dim_valid(start_dim, end_dim)/
  %5(CNode_3273) = StopGradient(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
  %6(CNode_3274) = S_Prim_MakeTuple(I64(0), I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  %7(CNode_3275) = S_Prim_in(%1, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  %8(CNode_3276) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  %9(CNode_3277) = Switch(%8, @✓4↓flatten_3278, @✗4↓flatten_3279)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  %10(CNode_3280) = %9()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  %11(CNode_3281) = Depend[side_effect_propagate: I64(1)](%10, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
}
# Order:
#   1: @4↓flatten_3091:idx{[0]: ValueNode<FuncGraph> canonicalize_axis_3270, [1]: param_start_dim, [2]: x_rank}
#   2: @4↓flatten_3091:end_dim{[0]: ValueNode<FuncGraph> canonicalize_axis_3270, [1]: param_end_dim, [2]: x_rank}
#   3: @4↓flatten_3091:CNode_3272{[0]: ValueNode<FuncGraph> check_dim_valid_3271, [1]: idx, [2]: end_dim}
#   4: @4↓flatten_3091:CNode_3274{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 1}
#   5: @4↓flatten_3091:CNode_3275{[0]: ValueNode<DoSignaturePrimitive> S_Prim_in, [1]: x_rank, [2]: CNode_3274}
#   6: @4↓flatten_3091:CNode_3276{[0]: ValueNode<Primitive> Cond, [1]: CNode_3275, [2]: ValueNode<BoolImm> false}
#   7: @4↓flatten_3091:CNode_3277{[0]: ValueNode<Primitive> Switch, [1]: CNode_3276, [2]: ValueNode<FuncGraph> ✓4↓flatten_3278, [3]: ValueNode<FuncGraph> ✗4↓flatten_3279}
#   8: @4↓flatten_3091:CNode_3280{[0]: CNode_3277}
#   9: @4↓flatten_3091:CNode_3282{[0]: ValueNode<Primitive> Return, [1]: CNode_3281}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104 : 0x333c44e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_3283) = S_Prim_BatchNorm[side_effect_mem: Bool(1), input_names: ["x", "scale", "offset", "mean", "variance"], epsilon: F32(1e-05), output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(1), momentum: F32(0.1)](%para412_x, %para413_L_conv1d1.temporal_conv.1.gamma, %para414_L_conv1d1.temporal_conv.1.beta, %para415_L_conv1d1.temporal_conv.1.moving_mean, %para416_L_conv1d1.temporal_conv.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  %2(CNode_3284) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:155/            return self.bn_train(x,/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104:CNode_3283{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv1d1.temporal_conv.1.gamma, [3]: param_L_conv1d1.temporal_conv.1.beta, [4]: param_L_conv1d1.temporal_conv.1.moving_mean, [5]: param_L_conv1d1.temporal_conv.1.moving_variance}
#   2: @L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104:CNode_3284{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3283, [2]: ValueNode<Int64Imm> 0}
#   3: @L_✓↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3104:CNode_3285{[0]: ValueNode<Primitive> Return, [1]: CNode_3284}


subgraph attr:
training : 1
subgraph instance: L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105 : 0x332d98e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_3287) = call @L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:154/        if self.use_batch_statistics:/
}
# Order:
#   1: @L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105:CNode_3287{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286}
#   2: @L_✗↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3105:CNode_3288{[0]: ValueNode<Primitive> Return, [1]: CNode_3287}


subgraph attr:
training : 1
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111 : 0x37eafb50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905]() {
  %1(CNode_3289) = Cond(%para428_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %2(CNode_3290) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291, @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3292)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %3(CNode_3293) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %4(CNode_3295) = call @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111:CNode_3289{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111:CNode_3290{[0]: ValueNode<Primitive> Switch, [1]: CNode_3289, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3292}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111:CNode_3293{[0]: CNode_3290}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111:CNode_3295{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294, [1]: CNode_3293}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3111:CNode_3296{[0]: ValueNode<Primitive> Return, [1]: CNode_3295}


subgraph attr:
training : 1
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119 : 0x332a1eb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911]() {
  %1(CNode_3297) = Cond(%para430_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %2(CNode_3298) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299, @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3300)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %3(CNode_3301) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %4(CNode_3303) = call @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119:CNode_3297{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119:CNode_3298{[0]: ValueNode<Primitive> Switch, [1]: CNode_3297, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3300}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119:CNode_3301{[0]: CNode_3298}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119:CNode_3303{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302, [1]: CNode_3301}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3119:CNode_3304{[0]: ValueNode<Primitive> Return, [1]: CNode_3303}


subgraph attr:
training : 1
subgraph instance: ✓↻✓↻9↓tfnet_model_TFNetModel_construct_3126 : 0x394b2110
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻✓↻9↓tfnet_model_TFNetModel_construct_3126 parent: [subgraph @↻✓↻9↓tfnet_model_TFNetModel_construct_2916]() {
  %1(CNode_3123) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):call @ms_next_1075(%para431_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %2(i) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %3(CNode_3130) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):S_Prim_floordiv(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %4(CNode_3131) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):ClassType(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %5(CNode_3132) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):call @ms_max_436(I64(1), %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %6(CNode_3133) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):S_Prim_make_list(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  %7(CNode_3134) = $(↻✓↻9↓tfnet_model_TFNetModel_construct_2916):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para432_list, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @✓↻✓↻9↓tfnet_model_TFNetModel_construct_3126:CNode_3305{[0]: ValueNode<Primitive> Return, [1]: CNode_3134}


subgraph attr:
training : 1
subgraph instance: ✗↻✓↻9↓tfnet_model_TFNetModel_construct_3127 : 0x394b29e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻✓↻9↓tfnet_model_TFNetModel_construct_3127 parent: [subgraph @↵✓↻9↓tfnet_model_TFNetModel_construct_2780]() {
  Return(%para432_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:177/                lgt = [max(1, int(i // 2)) for i in lgt]/
}
# Order:
#   1: @✗↻✓↻9↓tfnet_model_TFNetModel_construct_3127:CNode_3306{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
training : 1
subgraph instance: ✓↻✗↻9↓tfnet_model_TFNetModel_construct_3140 : 0x39499700
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻✗↻9↓tfnet_model_TFNetModel_construct_3140 parent: [subgraph @↻✗↻9↓tfnet_model_TFNetModel_construct_2922]() {
  %1(CNode_3137) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):call @ms_next_1075(%para433_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %2(i) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %3(CNode_3144) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):ClassType(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %4(CNode_1985) = $(9↓tfnet_model_TFNetModel_construct_1746):S_Prim_make_list("K5", "P2", "K5", "P2")
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %5(CNode_2365) = $(↻9↓tfnet_model_TFNetModel_construct_2192):call @ms_iter_97(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %6(ks) = $(↻9↓tfnet_model_TFNetModel_construct_2192):S_Prim_getitem(%5, %para372_@CNode_2190)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:175/        for ks in ['K5', 'P2', 'K5', 'P2']:/
  %7(CNode_2598) = $(✗↻9↓tfnet_model_TFNetModel_construct_2371):S_Prim_getitem(%6, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:179/                k = int(ks[1])/
  %8(k) = $(✗↻9↓tfnet_model_TFNetModel_construct_2371):ClassType(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:179/                k = int(ks[1])/
  %9(CNode_3145) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):S_Prim_sub(%3, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %10(CNode_3146) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):S_Prim_add(%9, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %11(CNode_3147) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):call @ms_max_436(I64(1), %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %12(CNode_3148) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):S_Prim_make_list(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  %13(CNode_3149) = $(↻✗↻9↓tfnet_model_TFNetModel_construct_2922):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para434_list, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
  Return(%13)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @✓↻✗↻9↓tfnet_model_TFNetModel_construct_3140:CNode_3307{[0]: ValueNode<Primitive> Return, [1]: CNode_3149}


subgraph attr:
training : 1
subgraph instance: ✗↻✗↻9↓tfnet_model_TFNetModel_construct_3141 : 0x39499fd0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻✗↻9↓tfnet_model_TFNetModel_construct_3141 parent: [subgraph @↵✗↻9↓tfnet_model_TFNetModel_construct_2783]() {
  Return(%para434_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:180/                lgt = [max(1, int(i) - k + 1) for i in lgt]/
}
# Order:
#   1: @✗↻✗↻9↓tfnet_model_TFNetModel_construct_3141:CNode_3308{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153 : 0x39132e70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153(%para455_, %para456_) {
  %1(CNode_3310) = call @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153:CNode_3310{[0]: ValueNode<FuncGraph> ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309}
#   2: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153:CNode_3311{[0]: ValueNode<Primitive> Return, [1]: CNode_3310}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159 : 0x39116880
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159(%para457_, %para458_) {
  %1(CNode_3313) = call @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:726/        if self.use_pad:/
}
# Order:
#   1: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159:CNode_3313{[0]: ValueNode<FuncGraph> ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312}
#   2: @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159:CNode_3314{[0]: ValueNode<Primitive> Return, [1]: CNode_3313}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓modules_NormLinear_construct_3173 : 0x393fc440
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↓modules_NormLinear_construct_3173 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(x_shape) = $(modules_NormLinear_construct_2807):getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3315) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3316) = getattr(%para106_classifier55.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier55.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %5(CNode_3317) = S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %6(CNode_3318) = S_Prim_not_equal(%3, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %7(CNode_3319) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %8(CNode_3320) = Switch(%7, @✓↓modules_NormLinear_construct_3321, @✗↓modules_NormLinear_construct_3322)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %9(CNode_3323) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @↓modules_NormLinear_construct_3173:CNode_3315{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↓modules_NormLinear_construct_3173:in_feat{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3315}
#   3: @↓modules_NormLinear_construct_3173:CNode_3316{[0]: ValueNode<Primitive> getattr, [1]: param_classifier55.weight, [2]: ValueNode<StringImm> shape}
#   4: @↓modules_NormLinear_construct_3173:CNode_3317{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3316, [2]: ValueNode<Int64Imm> 0}
#   5: @↓modules_NormLinear_construct_3173:CNode_3318{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: in_feat, [2]: CNode_3317}
#   6: @↓modules_NormLinear_construct_3173:CNode_3319{[0]: ValueNode<Primitive> Cond, [1]: CNode_3318, [2]: ValueNode<BoolImm> false}
#   7: @↓modules_NormLinear_construct_3173:CNode_3320{[0]: ValueNode<Primitive> Switch, [1]: CNode_3319, [2]: ValueNode<FuncGraph> ✓↓modules_NormLinear_construct_3321, [3]: ValueNode<FuncGraph> ✗↓modules_NormLinear_construct_3322}
#   8: @↓modules_NormLinear_construct_3173:CNode_3323{[0]: CNode_3320}
#   9: @↓modules_NormLinear_construct_3173:CNode_3324{[0]: ValueNode<Primitive> Return, [1]: CNode_3323}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓modules_BiLSTMLayer_construct_3185 : 0x391d3210
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓modules_BiLSTMLayer_construct_3185 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3325) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3326) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3327) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %4(CNode_3328) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %5(CNode_3329) = Switch(%4, @↰↓modules_BiLSTMLayer_construct_3330, @↱↓modules_BiLSTMLayer_construct_3331)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %6(CNode_3332) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %7(CNode_3333) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %8(CNode_3334) = Switch(%7, @✓↓modules_BiLSTMLayer_construct_3335, @✗↓modules_BiLSTMLayer_construct_3336)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %9(CNode_3337) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %10(CNode_3339) = call @2↓modules_BiLSTMLayer_construct_3338(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:199/        outputs1 = self.temporal_model1(x1, lgt)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↓modules_BiLSTMLayer_construct_3185:CNode_3325{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @↓modules_BiLSTMLayer_construct_3185:CNode_3326{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3325, [2]: ValueNode<Int64Imm> 0}
#   3: @↓modules_BiLSTMLayer_construct_3185:CNode_3327{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3326, [2]: ValueNode<Int64Imm> 0}
#   4: @↓modules_BiLSTMLayer_construct_3185:CNode_3328{[0]: ValueNode<Primitive> Cond, [1]: CNode_3327, [2]: ValueNode<BoolImm> false}
#   5: @↓modules_BiLSTMLayer_construct_3185:CNode_3329{[0]: ValueNode<Primitive> Switch, [1]: CNode_3328, [2]: ValueNode<FuncGraph> ↰↓modules_BiLSTMLayer_construct_3330, [3]: ValueNode<FuncGraph> ↱↓modules_BiLSTMLayer_construct_3331}
#   6: @↓modules_BiLSTMLayer_construct_3185:CNode_3332{[0]: CNode_3329}
#   7: @↓modules_BiLSTMLayer_construct_3185:CNode_3333{[0]: ValueNode<Primitive> Cond, [1]: CNode_3332, [2]: ValueNode<BoolImm> false}
#   8: @↓modules_BiLSTMLayer_construct_3185:CNode_3334{[0]: ValueNode<Primitive> Switch, [1]: CNode_3333, [2]: ValueNode<FuncGraph> ✓↓modules_BiLSTMLayer_construct_3335, [3]: ValueNode<FuncGraph> ✗↓modules_BiLSTMLayer_construct_3336}
#   9: @↓modules_BiLSTMLayer_construct_3185:CNode_3337{[0]: CNode_3334}
#  10: @↓modules_BiLSTMLayer_construct_3185:CNode_3339{[0]: ValueNode<FuncGraph> 2↓modules_BiLSTMLayer_construct_3338, [1]: CNode_3337}
#  11: @↓modules_BiLSTMLayer_construct_3185:CNode_3340{[0]: ValueNode<Primitive> Return, [1]: CNode_3339}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓modules_BiLSTMLayer_construct_3192 : 0x392bb720
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓modules_BiLSTMLayer_construct_3192 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3341) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3342) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3343) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %4(CNode_3344) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %5(CNode_3345) = Switch(%4, @↰↓modules_BiLSTMLayer_construct_3346, @↱↓modules_BiLSTMLayer_construct_3347)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %6(CNode_3348) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %7(CNode_3349) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %8(CNode_3350) = Switch(%7, @✓↓modules_BiLSTMLayer_construct_3351, @✗↓modules_BiLSTMLayer_construct_3352)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %9(CNode_3353) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %10(CNode_3355) = call @2↓modules_BiLSTMLayer_construct_3354(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:198/        outputs = self.temporal_model(x, lgt)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↓modules_BiLSTMLayer_construct_3192:CNode_3341{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @↓modules_BiLSTMLayer_construct_3192:CNode_3342{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3341, [2]: ValueNode<Int64Imm> 0}
#   3: @↓modules_BiLSTMLayer_construct_3192:CNode_3343{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3342, [2]: ValueNode<Int64Imm> 0}
#   4: @↓modules_BiLSTMLayer_construct_3192:CNode_3344{[0]: ValueNode<Primitive> Cond, [1]: CNode_3343, [2]: ValueNode<BoolImm> false}
#   5: @↓modules_BiLSTMLayer_construct_3192:CNode_3345{[0]: ValueNode<Primitive> Switch, [1]: CNode_3344, [2]: ValueNode<FuncGraph> ↰↓modules_BiLSTMLayer_construct_3346, [3]: ValueNode<FuncGraph> ↱↓modules_BiLSTMLayer_construct_3347}
#   6: @↓modules_BiLSTMLayer_construct_3192:CNode_3348{[0]: CNode_3345}
#   7: @↓modules_BiLSTMLayer_construct_3192:CNode_3349{[0]: ValueNode<Primitive> Cond, [1]: CNode_3348, [2]: ValueNode<BoolImm> false}
#   8: @↓modules_BiLSTMLayer_construct_3192:CNode_3350{[0]: ValueNode<Primitive> Switch, [1]: CNode_3349, [2]: ValueNode<FuncGraph> ✓↓modules_BiLSTMLayer_construct_3351, [3]: ValueNode<FuncGraph> ✗↓modules_BiLSTMLayer_construct_3352}
#   9: @↓modules_BiLSTMLayer_construct_3192:CNode_3353{[0]: CNode_3350}
#  10: @↓modules_BiLSTMLayer_construct_3192:CNode_3355{[0]: ValueNode<FuncGraph> 2↓modules_BiLSTMLayer_construct_3354, [1]: CNode_3353}
#  11: @↓modules_BiLSTMLayer_construct_3192:CNode_3356{[0]: ValueNode<Primitive> Return, [1]: CNode_3355}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓modules_NormLinear_construct_3198 : 0x3917a950
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↓modules_NormLinear_construct_3198 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(x_shape) = $(modules_NormLinear_construct_2804):getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3357) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3358) = getattr(%para105_classifier44.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier44.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %5(CNode_3359) = S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %6(CNode_3360) = S_Prim_not_equal(%3, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %7(CNode_3361) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %8(CNode_3362) = Switch(%7, @✓↓modules_NormLinear_construct_3363, @✗↓modules_NormLinear_construct_3364)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %9(CNode_3365) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @↓modules_NormLinear_construct_3198:CNode_3357{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↓modules_NormLinear_construct_3198:in_feat{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3357}
#   3: @↓modules_NormLinear_construct_3198:CNode_3358{[0]: ValueNode<Primitive> getattr, [1]: param_classifier44.weight, [2]: ValueNode<StringImm> shape}
#   4: @↓modules_NormLinear_construct_3198:CNode_3359{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3358, [2]: ValueNode<Int64Imm> 0}
#   5: @↓modules_NormLinear_construct_3198:CNode_3360{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: in_feat, [2]: CNode_3359}
#   6: @↓modules_NormLinear_construct_3198:CNode_3361{[0]: ValueNode<Primitive> Cond, [1]: CNode_3360, [2]: ValueNode<BoolImm> false}
#   7: @↓modules_NormLinear_construct_3198:CNode_3362{[0]: ValueNode<Primitive> Switch, [1]: CNode_3361, [2]: ValueNode<FuncGraph> ✓↓modules_NormLinear_construct_3363, [3]: ValueNode<FuncGraph> ✗↓modules_NormLinear_construct_3364}
#   8: @↓modules_NormLinear_construct_3198:CNode_3365{[0]: CNode_3362}
#   9: @↓modules_NormLinear_construct_3198:CNode_3366{[0]: ValueNode<Primitive> Return, [1]: CNode_3365}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓modules_NormLinear_construct_3209 : 0x39110780
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @↓modules_NormLinear_construct_3209 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(x_shape) = $(modules_NormLinear_construct_2802):getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3367) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3368) = getattr(%para104_classifier22.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier22.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %5(CNode_3369) = S_Prim_getitem(%4, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %6(CNode_3370) = S_Prim_not_equal(%3, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %7(CNode_3371) = Cond(%6, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %8(CNode_3372) = Switch(%7, @✓↓modules_NormLinear_construct_3373, @✗↓modules_NormLinear_construct_3374)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  %9(CNode_3375) = %8()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%9)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @↓modules_NormLinear_construct_3209:CNode_3367{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @↓modules_NormLinear_construct_3209:in_feat{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_3367}
#   3: @↓modules_NormLinear_construct_3209:CNode_3368{[0]: ValueNode<Primitive> getattr, [1]: param_classifier22.weight, [2]: ValueNode<StringImm> shape}
#   4: @↓modules_NormLinear_construct_3209:CNode_3369{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3368, [2]: ValueNode<Int64Imm> 0}
#   5: @↓modules_NormLinear_construct_3209:CNode_3370{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: in_feat, [2]: CNode_3369}
#   6: @↓modules_NormLinear_construct_3209:CNode_3371{[0]: ValueNode<Primitive> Cond, [1]: CNode_3370, [2]: ValueNode<BoolImm> false}
#   7: @↓modules_NormLinear_construct_3209:CNode_3372{[0]: ValueNode<Primitive> Switch, [1]: CNode_3371, [2]: ValueNode<FuncGraph> ✓↓modules_NormLinear_construct_3373, [3]: ValueNode<FuncGraph> ✗↓modules_NormLinear_construct_3374}
#   8: @↓modules_NormLinear_construct_3209:CNode_3375{[0]: CNode_3372}
#   9: @↓modules_NormLinear_construct_3209:CNode_3376{[0]: ValueNode<Primitive> Return, [1]: CNode_3375}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 15↓tfnet_model_TFNetModel_construct_3225 : 0x39471df0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @15↓tfnet_model_TFNetModel_construct_3225 parent: [subgraph @13↓tfnet_model_TFNetModel_construct_2797](%para459_) {
  %1(log_probs2) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2802(%para404_фx)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:203/        log_probs2 = self.classifier22(x)/
  %2(outputs1) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_BiLSTMLayer_construct_2800(%para421_фx1, %para373_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:199/        outputs1 = self.temporal_model1(x1, lgt)/
  %3(CNode_2803) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%2, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:204/        log_probs3 = self.classifier33(outputs1['predictions'])/
  %4(log_probs3) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2804(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:204/        log_probs3 = self.classifier33(outputs1['predictions'])/
  %5(log_probs4) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2804(%para421_фx1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:205/        log_probs4 = self.classifier44(x1)/
  %6(outputs) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_BiLSTMLayer_construct_2799(%para404_фx, %para373_фlgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:198/        outputs = self.temporal_model(x, lgt)/
  %7(CNode_2805) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%6, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %8(CNode_2806) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_getitem(%2, "predictions")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %9(x2) = $(12↓tfnet_model_TFNetModel_construct_2612):S_Prim_add(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:208/        x2 = outputs['predictions'] + outputs1['predictions']/
  %10(log_probs1) = $(12↓tfnet_model_TFNetModel_construct_2612):call @modules_NormLinear_construct_2807(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:209/        log_probs5 = self.classifier55(x2)/
  %11(CNode_3377) = S_Prim_MakeTuple("safe_lgt")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:225/        lgt_tensor = Tensor(np.array(safe_lgt, dtype=np.int32))/
  %12(CNode_3378) = S_Prim_MakeTuple(%para459_фsafe_lgt)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:225/        lgt_tensor = Tensor(np.array(safe_lgt, dtype=np.int32))/
  %13(CNode_3379) = S_Prim_make_dict(%11, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:225/        lgt_tensor = Tensor(np.array(safe_lgt, dtype=np.int32))/
  %14(lgt_tensor) = PyInterpret[side_effect_io: Bool(1)](Script['Tensor(np.array(safe_lgt, dtype=np.int32))'], InterpretedObject, %13)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:225/        lgt_tensor = Tensor(np.array(safe_lgt, dtype=np.int32))/
  %15(CNode_3380) = S_Prim_MakeTuple(%para452_фlog_probs1, %1, %4, %5, %10, %14, None, None, None)
      : (<null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:227/        return log_probs1, log_probs2, log_probs3, log_probs4, log_probs5, lgt_tensor, None, None, None/
  Return(%15)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:227/        return log_probs1, log_probs2, log_probs3, log_probs4, log_probs5, lgt_tensor, None, None, None/
}
# Order:
#   1: @15↓tfnet_model_TFNetModel_construct_3225:CNode_3377{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> safe_lgt}
#   2: @15↓tfnet_model_TFNetModel_construct_3225:CNode_3378{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фsafe_lgt}
#   3: @15↓tfnet_model_TFNetModel_construct_3225:CNode_3379{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_3377, [2]: CNode_3378}
#   4: @15↓tfnet_model_TFNetModel_construct_3225:lgt_tensor{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(np.array(safe_lgt, dtype=np.int32))', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'ms': <module 'mindspore' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/__init__.py'>, 'ops': <module 'mindspore.ops' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/__init__.py'>, 'max': <built-in function max>, 'int': <class 'int'>, 'isinstance': <built-in function isinstance>, 'list': <class 'list'>, 'tuple': <class 'tuple'>, 'np': <module 'numpy' from '/root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/numpy/__init__.py'>, 'len': <built-in function len>, 'range': <class 'range'>, 'min': <built-in function min>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>}), [3]: CNode_3379}
#   5: @15↓tfnet_model_TFNetModel_construct_3225:CNode_3380{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фlog_probs1, [2]: log_probs2, [3]: log_probs3, [4]: log_probs4, [5]: log_probs1, [6]: lgt_tensor, [7]: ValueNode<None> None, [8]: ValueNode<None> None, [9]: ValueNode<None> None}
#   6: @15↓tfnet_model_TFNetModel_construct_3225:CNode_3381{[0]: ValueNode<Primitive> Return, [1]: CNode_3380}


subgraph attr:
training : 1
subgraph instance: ✓14↓tfnet_model_TFNetModel_construct_3222 : 0x39467d70
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓14↓tfnet_model_TFNetModel_construct_3222 parent: [subgraph @14↓tfnet_model_TFNetModel_construct_3033]() {
  %1(CNode_3382) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %2(CNode_3383) = S_Prim_make_slice(None, %1, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %3(CNode_3384) = S_Prim_getitem(%para453_фsafe_lgt, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %4(CNode_3385) = S_Prim_make_list(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %5(CNode_3386) = ClassType(%para177_фbatch)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %6(CNode_3387) = S_Prim_inner_len(%para453_фsafe_lgt)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %7(CNode_3388) = S_Prim_sub(%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %8(CNode_3389) = call @ms_max_436(I64(0), %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %9(CNode_3390) = S_Prim_mul(%4, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  %10(safe_lgt) = S_Prim_add(%3, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:223/            safe_lgt = safe_lgt[:int(batch)] + [1] * max(0, int(batch) - len(safe_lgt))/
}
# Order:
#   1: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3382{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   2: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3383{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: CNode_3382, [3]: ValueNode<None> None}
#   3: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3384{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_фsafe_lgt, [2]: CNode_3383}
#   4: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3385{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: ValueNode<Int64Imm> 1}
#   5: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3386{[0]: ValueNode<ClassType> class 'int', [1]: param_фbatch}
#   6: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3387{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: param_фsafe_lgt}
#   7: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3388{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: CNode_3386, [2]: CNode_3387}
#   8: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3389{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 0, [2]: CNode_3388}
#   9: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3390{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: CNode_3385, [2]: CNode_3389}
#  10: @✓14↓tfnet_model_TFNetModel_construct_3222:safe_lgt{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_3384, [2]: CNode_3390}
#  11: @✓14↓tfnet_model_TFNetModel_construct_3222:CNode_3391{[0]: ValueNode<Primitive> Return, [1]: safe_lgt}


subgraph attr:
training : 1
subgraph instance: ✗14↓tfnet_model_TFNetModel_construct_3223 : 0x3946a400
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗14↓tfnet_model_TFNetModel_construct_3223 parent: [subgraph @14↓tfnet_model_TFNetModel_construct_3033]() {
  Return(%para453_фsafe_lgt)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:222/        if len(safe_lgt) != int(batch):/
}
# Order:
#   1: @✗14↓tfnet_model_TFNetModel_construct_3223:CNode_3392{[0]: ValueNode<Primitive> Return, [1]: param_фsafe_lgt}


subgraph attr:
training : 1
subgraph instance: G_✓13↓tfnet_model_TFNetModel_construct_3228 : 0x3944e0e0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @G_✓13↓tfnet_model_TFNetModel_construct_3228 parent: [subgraph @↵9↓tfnet_model_TFNetModel_construct_1981]() {
  %1(CNode_3394) = call @↵✓13↓tfnet_model_TFNetModel_construct_3393(%para373_фlgt, [])
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @G_✓13↓tfnet_model_TFNetModel_construct_3228:CNode_3395{[0]: ValueNode<Primitive> Return, [1]: CNode_3394}
#   2: @G_✓13↓tfnet_model_TFNetModel_construct_3228:CNode_3394{[0]: ValueNode<FuncGraph> ↵✓13↓tfnet_model_TFNetModel_construct_3393, [1]: param_фlgt, [2]: ValueNode<ValueList> []}


subgraph attr:
subgraph instance: ✓4↓✓↓ms_max_one_element_3240 : 0x332a0930
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✓4↓✓↓ms_max_one_element_3240 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3396) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("max() cannot support tensor in list or tuple nested now.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2633/            const_utils.raise_type_error(/
  %2(CNode_3397) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
  %3(CNode_3399) = call @5↓✓↓ms_max_one_element_3398()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  %4(CNode_3400) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2633/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2633/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓4↓✓↓ms_max_one_element_3240:CNode_3396{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> max() cannot support tensor in list or tuple nested now.}
#   2: @✓4↓✓↓ms_max_one_element_3240:CNode_3401{[0]: ValueNode<Primitive> Return, [1]: CNode_3400}
#   3: @✓4↓✓↓ms_max_one_element_3240:CNode_3399{[0]: ValueNode<FuncGraph> 5↓✓↓ms_max_one_element_3398}


subgraph attr:
subgraph instance: ✗4↓✓↓ms_max_one_element_3241 : 0x3329ddc0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @✗4↓✓↓ms_max_one_element_3241 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3402) = call @5↓✓↓ms_max_one_element_3398()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2632/        if exist_tensor(x):/
}
# Order:
#   1: @✗4↓✓↓ms_max_one_element_3241:CNode_3403{[0]: ValueNode<Primitive> Return, [1]: CNode_3402}
#   2: @✗4↓✓↓ms_max_one_element_3241:CNode_3402{[0]: ValueNode<FuncGraph> 5↓✓↓ms_max_one_element_3398}


subgraph attr:
after_block : 1
subgraph instance: ↓✓↓↻exist_tensor_3253 : 0x3725f590
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2565/def exist_tensor(data):/
subgraph @↓✓↓↻exist_tensor_3253 parent: [subgraph @↻exist_tensor_2228]() {
  %1(CNode_3404) = call @2↓↻exist_tensor_3067()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2656/        if exist_tensor(data):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2571/            if exist_tensor(input_data):/
}
# Order:
#   1: @↓✓↓↻exist_tensor_3253:CNode_3405{[0]: ValueNode<Primitive> Return, [1]: CNode_3404}
#   2: @↓✓↓↻exist_tensor_3253:CNode_3404{[0]: ValueNode<FuncGraph> 2↓↻exist_tensor_3067}


subgraph attr:
after_block : 1
subgraph instance: 3↓✓↓ms_min_one_element_3260 : 0x39570b00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @3↓✓↓ms_min_one_element_3260 parent: [subgraph @2↓✓↓ms_min_one_element_2854]() {
  %1(tensor_num) = $(2↓✓↓ms_min_one_element_2854):call @get_tensor_num_1008(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2709/        tensor_num = get_tensor_num(x)/
  %2(CNode_3406) = S_Prim_not_equal(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
  %3(CNode_3407) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
  %4(CNode_3408) = Switch(%3, @✓3↓✓↓ms_min_one_element_3409, @✗3↓✓↓ms_min_one_element_3410)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
  %5(CNode_3411) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
}
# Order:
#   1: @3↓✓↓ms_min_one_element_3260:CNode_3406{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: tensor_num, [2]: ValueNode<Int64Imm> 0}
#   2: @3↓✓↓ms_min_one_element_3260:CNode_3407{[0]: ValueNode<Primitive> Cond, [1]: CNode_3406, [2]: ValueNode<BoolImm> false}
#   3: @3↓✓↓ms_min_one_element_3260:CNode_3408{[0]: ValueNode<Primitive> Switch, [1]: CNode_3407, [2]: ValueNode<FuncGraph> ✓3↓✓↓ms_min_one_element_3409, [3]: ValueNode<FuncGraph> ✗3↓✓↓ms_min_one_element_3410}
#   4: @3↓✓↓ms_min_one_element_3260:CNode_3411{[0]: CNode_3408}
#   5: @3↓✓↓ms_min_one_element_3260:CNode_3412{[0]: ValueNode<Primitive> Return, [1]: CNode_3411}


subgraph attr:
after_block : 1
subgraph instance: ↓✓3↓flatten_3267 : 0x39703000
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @↓✓3↓flatten_3267 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_3413) = call @_get_cache_prim_676(ClassType)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1752/        return _get_cache_prim(P.Flatten)()(input)/
  %2(CNode_3414) = %1()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1752/        return _get_cache_prim(P.Flatten)()(input)/
  %3(CNode_3415) = %2(%para423_фinput)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1752/        return _get_cache_prim(P.Flatten)()(input)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1752/        return _get_cache_prim(P.Flatten)()(input)/
}
# Order:
#   1: @↓✓3↓flatten_3267:CNode_3413{[0]: ValueNode<FuncGraph> _get_cache_prim_676, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.Flatten'}
#   2: @↓✓3↓flatten_3267:CNode_3414{[0]: CNode_3413}
#   3: @↓✓3↓flatten_3267:CNode_3415{[0]: CNode_3414, [1]: param_фinput}
#   4: @↓✓3↓flatten_3267:CNode_3416{[0]: ValueNode<Primitive> Return, [1]: CNode_3415}


subgraph attr:
subgraph instance: check_dim_valid_3271 : 0x396fa800
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1721/    def check_dim_valid(start_dim, end_dim):/
subgraph @check_dim_valid_3271(%para460_start_dim, %para461_end_dim) {
  %1(CNode_3417) = S_Prim_greater(%para460_start_dim, %para461_end_dim)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
  %2(CNode_3418) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
  %3(CNode_3419) = Switch(%2, @✓check_dim_valid_3420, @✗check_dim_valid_3421)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
  %4(CNode_3422) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
}
# Order:
#   1: @check_dim_valid_3271:CNode_3417{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater, [1]: param_start_dim, [2]: param_end_dim}
#   2: @check_dim_valid_3271:CNode_3418{[0]: ValueNode<Primitive> Cond, [1]: CNode_3417, [2]: ValueNode<BoolImm> false}
#   3: @check_dim_valid_3271:CNode_3419{[0]: ValueNode<Primitive> Switch, [1]: CNode_3418, [2]: ValueNode<FuncGraph> ✓check_dim_valid_3420, [3]: ValueNode<FuncGraph> ✗check_dim_valid_3421}
#   4: @check_dim_valid_3271:CNode_3422{[0]: CNode_3419}
#   5: @check_dim_valid_3271:CNode_3423{[0]: ValueNode<Primitive> Return, [1]: CNode_3422}


subgraph attr:
subgraph instance: canonicalize_axis_3270 : 0x39285960
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1725/    def canonicalize_axis(axis, x_rank):/
subgraph @canonicalize_axis_3270(%para462_axis, %para463_x_rank) {
  %1(CNode_3424) = S_Prim_not_equal(%para463_x_rank, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %2(CNode_3425) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %3(CNode_3426) = Switch(%2, @↰canonicalize_axis_3427, @↱canonicalize_axis_3428)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %4(ndim) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %5(CNode_3430) = call @check_axis_valid_3429(%para462_axis, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1727/        check_axis_valid(axis, ndim)/
  %6(CNode_3431) = StopGradient(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1725/    def canonicalize_axis(axis, x_rank):/
  %7(CNode_3432) = S_Prim_greater_equal(%para462_axis, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  %8(CNode_3433) = Cond(%7, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  %9(CNode_3434) = Switch(%8, @↰canonicalize_axis_3435, @↱canonicalize_axis_3436)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  %10(CNode_3437) = %9()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  %11(CNode_3438) = Depend[side_effect_propagate: I64(1)](%10, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  Return(%11)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
}
# Order:
#   1: @canonicalize_axis_3270:CNode_3424{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: param_x_rank, [2]: ValueNode<Int64Imm> 0}
#   2: @canonicalize_axis_3270:CNode_3425{[0]: ValueNode<Primitive> Cond, [1]: CNode_3424, [2]: ValueNode<BoolImm> false}
#   3: @canonicalize_axis_3270:CNode_3426{[0]: ValueNode<Primitive> Switch, [1]: CNode_3425, [2]: ValueNode<FuncGraph> ↰canonicalize_axis_3427, [3]: ValueNode<FuncGraph> ↱canonicalize_axis_3428}
#   4: @canonicalize_axis_3270:ndim{[0]: CNode_3426}
#   5: @canonicalize_axis_3270:CNode_3430{[0]: ValueNode<FuncGraph> check_axis_valid_3429, [1]: param_axis, [2]: ndim}
#   6: @canonicalize_axis_3270:CNode_3432{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: param_axis, [2]: ValueNode<Int64Imm> 0}
#   7: @canonicalize_axis_3270:CNode_3433{[0]: ValueNode<Primitive> Cond, [1]: CNode_3432, [2]: ValueNode<BoolImm> false}
#   8: @canonicalize_axis_3270:CNode_3434{[0]: ValueNode<Primitive> Switch, [1]: CNode_3433, [2]: ValueNode<FuncGraph> ↰canonicalize_axis_3435, [3]: ValueNode<FuncGraph> ↱canonicalize_axis_3436}
#   9: @canonicalize_axis_3270:CNode_3437{[0]: CNode_3434}
#  10: @canonicalize_axis_3270:CNode_3439{[0]: ValueNode<Primitive> Return, [1]: CNode_3438}


subgraph attr:
subgraph instance: ✓4↓flatten_3278 : 0x39284160
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓4↓flatten_3278 parent: [subgraph @3↓flatten_2708]() {
  %1(CNode_3440) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1760/        return reshape_(input, (-1,))/
  %2(CNode_3441) = S_Prim_MakeTuple(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1760/        return reshape_(input, (-1,))/
  %3(CNode_3442) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para423_фinput, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1760/        return reshape_(input, (-1,))/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1760/        return reshape_(input, (-1,))/
}
# Order:
#   1: @✓4↓flatten_3278:CNode_3440{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @✓4↓flatten_3278:CNode_3441{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3440}
#   3: @✓4↓flatten_3278:CNode_3442{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_фinput, [2]: CNode_3441}
#   4: @✓4↓flatten_3278:CNode_3443{[0]: ValueNode<Primitive> Return, [1]: CNode_3442}


subgraph attr:
subgraph instance: ✗4↓flatten_3279 : 0x39080800
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗4↓flatten_3279 parent: [subgraph @4↓flatten_3091]() {
  %1(CNode_3445) = call @5↓flatten_3444()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1759/    if x_rank in (0, 1):/
}
# Order:
#   1: @✗4↓flatten_3279:CNode_3445{[0]: ValueNode<FuncGraph> 5↓flatten_3444}
#   2: @✗4↓flatten_3279:CNode_3446{[0]: ValueNode<Primitive> Return, [1]: CNode_3445}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286 : 0x37624bb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:138/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286 parent: [subgraph @L_mindspore_nn_layer_normalization_BatchNorm1d_construct_2552]() {
  %1(CNode_3447) = S_Prim_BatchNorm[output_names: ["y", "batch_mean", "batch_variance", "reserve_space_1", "reserve_space_2"], format: "NCHW", is_training: Bool(0), input_names: ["x", "scale", "offset", "mean", "variance"], momentum: F32(0.1), epsilon: F32(1e-05)](%para412_x, %para413_L_conv1d1.temporal_conv.1.gamma, %para414_L_conv1d1.temporal_conv.1.beta, %para415_L_conv1d1.temporal_conv.1.moving_mean, %para416_L_conv1d1.temporal_conv.1.moving_variance)
      : (<null>, <null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  %2(CNode_3448) = S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/normalization.py:161/        return self.bn_infer(x,/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286:CNode_3447{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BatchNorm, [1]: param_x, [2]: param_L_conv1d1.temporal_conv.1.gamma, [3]: param_L_conv1d1.temporal_conv.1.beta, [4]: param_L_conv1d1.temporal_conv.1.moving_mean, [5]: param_L_conv1d1.temporal_conv.1.moving_variance}
#   2: @L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286:CNode_3448{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3447, [2]: ValueNode<Int64Imm> 0}
#   3: @L_2↓mindspore_nn_layer_normalization_BatchNorm1d_construct_3286:CNode_3449{[0]: ValueNode<Primitive> Return, [1]: CNode_3448}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294 : 0x334341b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294(%para464_) {
  %1(CNode_3451) = call @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294:CNode_3451{[0]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294:CNode_3452{[0]: ValueNode<Primitive> Return, [1]: CNode_3451}


subgraph attr:
training : 1
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291 : 0x332dfb50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para427_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3453) = S_Prim_isinstance(%3, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %5(CNode_3454) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %6(CNode_3455) = Switch(%5, @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456, @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %7(CNode_3458) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %8(CNode_3460) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3459(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3453{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: output, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3454{[0]: ValueNode<Primitive> Cond, [1]: CNode_3453, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3455{[0]: ValueNode<Primitive> Switch, [1]: CNode_3454, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3458{[0]: CNode_3455}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3460{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3459, [1]: CNode_3458}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3291:CNode_3461{[0]: ValueNode<Primitive> Return, [1]: CNode_3460}


subgraph attr:
training : 1
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3292 : 0x333241f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3292 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para427_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3292:CNode_3462{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302 : 0x38fb66b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302(%para465_) {
  %1(CNode_3464) = call @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302:CNode_3464{[0]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302:CNode_3465{[0]: ValueNode<Primitive> Return, [1]: CNode_3464}


subgraph attr:
training : 1
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299 : 0x33310dd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para429_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3466) = S_Prim_isinstance(%3, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %5(CNode_3467) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %6(CNode_3468) = Switch(%5, @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469, @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %7(CNode_3471) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %8(CNode_3473) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3472(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3466{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: output, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3467{[0]: ValueNode<Primitive> Cond, [1]: CNode_3466, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3468{[0]: ValueNode<Primitive> Switch, [1]: CNode_3467, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3471{[0]: CNode_3468}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3473{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3472, [1]: CNode_3471}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3299:CNode_3474{[0]: ValueNode<Primitive> Return, [1]: CNode_3473}


subgraph attr:
training : 1
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3300 : 0x310f1c00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3300 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para429_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3300:CNode_3475{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309 : 0x39134b00
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3153]() {
  %1(CNode_3476) = call @shape_1142(%para455_фx)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %2(CNode_3477) = S_Prim__shape_check[constexpr_prim: Bool(1)](%1, "MaxPool1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %3(CNode_3478) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
  %4(CNode_3480) = call @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %5(CNode_3481) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
}
# Order:
#   1: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:CNode_3476{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_фx}
#   2: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:CNode_3477{[0]: ValueNode<DoSignaturePrimitive> S_Prim__shape_check, [1]: CNode_3476, [2]: ValueNode<StringImm> MaxPool1d}
#   3: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_фx, [2]: ValueNode<Int64Imm> 2}
#   4: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool, [1]: x}
#   5: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   6: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:CNode_3480{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479}
#   7: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309:CNode_3482{[0]: ValueNode<Primitive> Return, [1]: CNode_3481}


subgraph attr:
training : 1
subgraph instance: ✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312 : 0x39118510
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312 parent: [subgraph @↓mindspore_nn_layer_pooling_MaxPool1d_construct_3159]() {
  %1(CNode_3483) = call @shape_1142(%para457_фx)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %2(CNode_3484) = S_Prim__shape_check[constexpr_prim: Bool(1)](%1, "MaxPool1d")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %3(CNode_3485) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
  %4(CNode_3487) = call @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  %5(CNode_3488) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:734/            _shape_check(self.shape(x), self.cls_name)/
}
# Order:
#   1: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:CNode_3483{[0]: ValueNode<FuncGraph> shape_1142, [1]: param_фx}
#   2: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:CNode_3484{[0]: ValueNode<DoSignaturePrimitive> S_Prim__shape_check, [1]: CNode_3483, [2]: ValueNode<StringImm> MaxPool1d}
#   3: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ExpandDims, [1]: param_фx, [2]: ValueNode<Int64Imm> 2}
#   4: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MaxPool, [1]: x}
#   5: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Squeeze, [1]: output}
#   6: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:CNode_3487{[0]: ValueNode<FuncGraph> 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486}
#   7: @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312:CNode_3489{[0]: ValueNode<Primitive> Return, [1]: CNode_3488}


subgraph attr:
training : 1
subgraph instance: ✓↓modules_NormLinear_construct_3321 : 0x3943a3b0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓↓modules_NormLinear_construct_3321 parent: [subgraph @↓modules_NormLinear_construct_3173]() {
  %1(x_shape) = $(modules_NormLinear_construct_2807):getattr(%para445_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3315) = $(↓modules_NormLinear_construct_3173):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = $(↓modules_NormLinear_construct_3173):S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3490) = getattr(%para106_classifier55.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier55.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %5(CNode_3491) = JoinedStr("Input feature size ", %3, " doesn't match weight shape ", %4)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %6(CNode_3492) = raise[side_effect_io: Bool(1)]("ValueError", %5, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
}
# Order:
#   1: @✓↓modules_NormLinear_construct_3321:CNode_3490{[0]: ValueNode<Primitive> getattr, [1]: param_classifier55.weight, [2]: ValueNode<StringImm> shape}
#   2: @✓↓modules_NormLinear_construct_3321:CNode_3491{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Input feature size , [2]: in_feat, [3]: ValueNode<StringImm>  doesn't match weight shape , [4]: CNode_3490}
#   3: @✓↓modules_NormLinear_construct_3321:CNode_3492{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3491, [3]: ValueNode<StringImm> None}
#   4: @✓↓modules_NormLinear_construct_3321:CNode_3493{[0]: ValueNode<Primitive> Return, [1]: CNode_3492}


subgraph attr:
training : 1
subgraph instance: ✗↓modules_NormLinear_construct_3322 : 0x39402980
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗↓modules_NormLinear_construct_3322 parent: [subgraph @↓modules_NormLinear_construct_3173]() {
  %1(CNode_3495) = call @2↓modules_NormLinear_construct_3494()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @✗↓modules_NormLinear_construct_3322:CNode_3495{[0]: ValueNode<FuncGraph> 2↓modules_NormLinear_construct_3494}
#   2: @✗↓modules_NormLinear_construct_3322:CNode_3496{[0]: ValueNode<Primitive> Return, [1]: CNode_3495}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓modules_BiLSTMLayer_construct_3338 : 0x392abc90
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2↓modules_BiLSTMLayer_construct_3338 parent: [subgraph @modules_BiLSTMLayer_construct_2800](%para466_) {
  %1(CNode_3497) = S_Prim_MakeTuple("predictions", "feat_len")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  %2(CNode_3498) = S_Prim_MakeTuple(%para466_фoutput, %para447_lgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  %3(CNode_3499) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
}
# Order:
#   1: @2↓modules_BiLSTMLayer_construct_3338:CNode_3497{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> predictions, [2]: ValueNode<StringImm> feat_len}
#   2: @2↓modules_BiLSTMLayer_construct_3338:CNode_3498{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фoutput, [2]: param_lgt}
#   3: @2↓modules_BiLSTMLayer_construct_3338:CNode_3499{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_3497, [2]: CNode_3498}
#   4: @2↓modules_BiLSTMLayer_construct_3338:CNode_3500{[0]: ValueNode<Primitive> Return, [1]: CNode_3499}


subgraph attr:
training : 1
subgraph instance: ✓↓modules_BiLSTMLayer_construct_3335 : 0x3929dd40
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓↓modules_BiLSTMLayer_construct_3335 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3501) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %2(C) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %3(CNode_3502) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
  %4(CNode_3504) = call @2✓↓modules_BiLSTMLayer_construct_3503()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
  %5(CNode_3505) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
}
# Order:
#   1: @✓↓modules_BiLSTMLayer_construct_3335:CNode_3501{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @✓↓modules_BiLSTMLayer_construct_3335:T{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3501, [2]: ValueNode<Int64Imm> 0}
#   3: @✓↓modules_BiLSTMLayer_construct_3335:B{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3501, [2]: ValueNode<Int64Imm> 1}
#   4: @✓↓modules_BiLSTMLayer_construct_3335:C{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3501, [2]: ValueNode<Int64Imm> 2}
#   5: @✓↓modules_BiLSTMLayer_construct_3335:CNode_3504{[0]: ValueNode<FuncGraph> 2✓↓modules_BiLSTMLayer_construct_3503}
#   6: @✓↓modules_BiLSTMLayer_construct_3335:CNode_3506{[0]: ValueNode<Primitive> Return, [1]: CNode_3505}


subgraph attr:
training : 1
subgraph instance: ✗↓modules_BiLSTMLayer_construct_3336 : 0x391e52d0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✗↓modules_BiLSTMLayer_construct_3336 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3507) = getattr(%para446_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %2(CNode_3508) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %3(CNode_3509) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %4(CNode_3510) = Switch(%3, @✓✗↓modules_BiLSTMLayer_construct_3511, @2✗↓modules_BiLSTMLayer_construct_3512)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %5(CNode_3513) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %6(CNode_3515) = call @↓✗↓modules_BiLSTMLayer_construct_3514(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:199/        outputs1 = self.temporal_model1(x1, lgt)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
}
# Order:
#   1: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3507{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3508{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3507, [2]: ValueNode<Float> Float32}
#   3: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3509{[0]: ValueNode<Primitive> Cond, [1]: CNode_3508, [2]: ValueNode<BoolImm> false}
#   4: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3510{[0]: ValueNode<Primitive> Switch, [1]: CNode_3509, [2]: ValueNode<FuncGraph> ✓✗↓modules_BiLSTMLayer_construct_3511, [3]: ValueNode<FuncGraph> 2✗↓modules_BiLSTMLayer_construct_3512}
#   5: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3513{[0]: CNode_3510}
#   6: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3515{[0]: ValueNode<FuncGraph> ↓✗↓modules_BiLSTMLayer_construct_3514, [1]: CNode_3513}
#   7: @✗↓modules_BiLSTMLayer_construct_3336:CNode_3516{[0]: ValueNode<Primitive> Return, [1]: CNode_3515}


subgraph attr:
training : 1
subgraph instance: ↰↓modules_BiLSTMLayer_construct_3330 : 0x391e4340
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↰↓modules_BiLSTMLayer_construct_3330 parent: [subgraph @↓modules_BiLSTMLayer_construct_3185]() {
  %1(CNode_3325) = $(↓modules_BiLSTMLayer_construct_3185):getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3326) = $(↓modules_BiLSTMLayer_construct_3185):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3327) = $(↓modules_BiLSTMLayer_construct_3185):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↰↓modules_BiLSTMLayer_construct_3330:CNode_3517{[0]: ValueNode<Primitive> Return, [1]: CNode_3327}


subgraph attr:
training : 1
subgraph instance: ↱↓modules_BiLSTMLayer_construct_3331 : 0x391dc0b0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↱↓modules_BiLSTMLayer_construct_3331 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3518) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3519) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3520) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %4(CNode_3521) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %5(CNode_3522) = Switch(%4, @↰↱↓modules_BiLSTMLayer_construct_3523, @2↱↓modules_BiLSTMLayer_construct_3524)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %6(CNode_3525) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3518{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3519{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3518, [2]: ValueNode<Int64Imm> 1}
#   3: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3520{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3519, [2]: ValueNode<Int64Imm> 0}
#   4: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3521{[0]: ValueNode<Primitive> Cond, [1]: CNode_3520, [2]: ValueNode<BoolImm> false}
#   5: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3522{[0]: ValueNode<Primitive> Switch, [1]: CNode_3521, [2]: ValueNode<FuncGraph> ↰↱↓modules_BiLSTMLayer_construct_3523, [3]: ValueNode<FuncGraph> 2↱↓modules_BiLSTMLayer_construct_3524}
#   6: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3525{[0]: CNode_3522}
#   7: @↱↓modules_BiLSTMLayer_construct_3331:CNode_3526{[0]: ValueNode<Primitive> Return, [1]: CNode_3525}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓modules_BiLSTMLayer_construct_3354 : 0x390fea40
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2↓modules_BiLSTMLayer_construct_3354 parent: [subgraph @modules_BiLSTMLayer_construct_2799](%para467_) {
  %1(CNode_3527) = S_Prim_MakeTuple("predictions", "feat_len")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  %2(CNode_3528) = S_Prim_MakeTuple(%para467_фoutput, %para449_lgt)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  %3(CNode_3529) = S_Prim_make_dict(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:179/        return {/
}
# Order:
#   1: @2↓modules_BiLSTMLayer_construct_3354:CNode_3527{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: ValueNode<StringImm> predictions, [2]: ValueNode<StringImm> feat_len}
#   2: @2↓modules_BiLSTMLayer_construct_3354:CNode_3528{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: param_фoutput, [2]: param_lgt}
#   3: @2↓modules_BiLSTMLayer_construct_3354:CNode_3529{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_3527, [2]: CNode_3528}
#   4: @2↓modules_BiLSTMLayer_construct_3354:CNode_3530{[0]: ValueNode<Primitive> Return, [1]: CNode_3529}


subgraph attr:
training : 1
subgraph instance: ✓↓modules_BiLSTMLayer_construct_3351 : 0x39369ed0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓↓modules_BiLSTMLayer_construct_3351 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3531) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %2(C) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %3(CNode_3532) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
  %4(CNode_3534) = call @2✓↓modules_BiLSTMLayer_construct_3533()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
  %5(CNode_3535) = Depend[side_effect_propagate: I64(1)](%4, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:162/            if self.bidirectional:/
}
# Order:
#   1: @✓↓modules_BiLSTMLayer_construct_3351:CNode_3531{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @✓↓modules_BiLSTMLayer_construct_3351:T{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3531, [2]: ValueNode<Int64Imm> 0}
#   3: @✓↓modules_BiLSTMLayer_construct_3351:B{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3531, [2]: ValueNode<Int64Imm> 1}
#   4: @✓↓modules_BiLSTMLayer_construct_3351:C{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3531, [2]: ValueNode<Int64Imm> 2}
#   5: @✓↓modules_BiLSTMLayer_construct_3351:CNode_3534{[0]: ValueNode<FuncGraph> 2✓↓modules_BiLSTMLayer_construct_3533}
#   6: @✓↓modules_BiLSTMLayer_construct_3351:CNode_3536{[0]: ValueNode<Primitive> Return, [1]: CNode_3535}


subgraph attr:
training : 1
subgraph instance: ✗↓modules_BiLSTMLayer_construct_3352 : 0x392cd7e0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✗↓modules_BiLSTMLayer_construct_3352 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3537) = getattr(%para448_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %2(CNode_3538) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %3(CNode_3539) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %4(CNode_3540) = Switch(%3, @✓✗↓modules_BiLSTMLayer_construct_3541, @2✗↓modules_BiLSTMLayer_construct_3542)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %5(CNode_3543) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
  %6(CNode_3545) = call @↓✗↓modules_BiLSTMLayer_construct_3544(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:198/        outputs = self.temporal_model(x, lgt)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
}
# Order:
#   1: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3537{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3538{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3537, [2]: ValueNode<Float> Float32}
#   3: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3539{[0]: ValueNode<Primitive> Cond, [1]: CNode_3538, [2]: ValueNode<BoolImm> false}
#   4: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3540{[0]: ValueNode<Primitive> Switch, [1]: CNode_3539, [2]: ValueNode<FuncGraph> ✓✗↓modules_BiLSTMLayer_construct_3541, [3]: ValueNode<FuncGraph> 2✗↓modules_BiLSTMLayer_construct_3542}
#   5: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3543{[0]: CNode_3540}
#   6: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3545{[0]: ValueNode<FuncGraph> ↓✗↓modules_BiLSTMLayer_construct_3544, [1]: CNode_3543}
#   7: @✗↓modules_BiLSTMLayer_construct_3352:CNode_3546{[0]: ValueNode<Primitive> Return, [1]: CNode_3545}


subgraph attr:
training : 1
subgraph instance: ↰↓modules_BiLSTMLayer_construct_3346 : 0x392cc850
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↰↓modules_BiLSTMLayer_construct_3346 parent: [subgraph @↓modules_BiLSTMLayer_construct_3192]() {
  %1(CNode_3341) = $(↓modules_BiLSTMLayer_construct_3192):getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3342) = $(↓modules_BiLSTMLayer_construct_3192):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3343) = $(↓modules_BiLSTMLayer_construct_3192):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↰↓modules_BiLSTMLayer_construct_3346:CNode_3547{[0]: ValueNode<Primitive> Return, [1]: CNode_3343}


subgraph attr:
training : 1
subgraph instance: ↱↓modules_BiLSTMLayer_construct_3347 : 0x392c45c0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↱↓modules_BiLSTMLayer_construct_3347 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3548) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3549) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3550) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %4(CNode_3551) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %5(CNode_3552) = Switch(%4, @↰↱↓modules_BiLSTMLayer_construct_3553, @2↱↓modules_BiLSTMLayer_construct_3554)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %6(CNode_3555) = %5()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3548{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3549{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3548, [2]: ValueNode<Int64Imm> 1}
#   3: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3550{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3549, [2]: ValueNode<Int64Imm> 0}
#   4: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3551{[0]: ValueNode<Primitive> Cond, [1]: CNode_3550, [2]: ValueNode<BoolImm> false}
#   5: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3552{[0]: ValueNode<Primitive> Switch, [1]: CNode_3551, [2]: ValueNode<FuncGraph> ↰↱↓modules_BiLSTMLayer_construct_3553, [3]: ValueNode<FuncGraph> 2↱↓modules_BiLSTMLayer_construct_3554}
#   6: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3555{[0]: CNode_3552}
#   7: @↱↓modules_BiLSTMLayer_construct_3347:CNode_3556{[0]: ValueNode<Primitive> Return, [1]: CNode_3555}


subgraph attr:
training : 1
subgraph instance: ✓↓modules_NormLinear_construct_3363 : 0x391c3980
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓↓modules_NormLinear_construct_3363 parent: [subgraph @↓modules_NormLinear_construct_3198]() {
  %1(x_shape) = $(modules_NormLinear_construct_2804):getattr(%para450_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3357) = $(↓modules_NormLinear_construct_3198):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = $(↓modules_NormLinear_construct_3198):S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3557) = getattr(%para105_classifier44.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier44.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %5(CNode_3558) = JoinedStr("Input feature size ", %3, " doesn't match weight shape ", %4)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %6(CNode_3559) = raise[side_effect_io: Bool(1)]("ValueError", %5, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
}
# Order:
#   1: @✓↓modules_NormLinear_construct_3363:CNode_3557{[0]: ValueNode<Primitive> getattr, [1]: param_classifier44.weight, [2]: ValueNode<StringImm> shape}
#   2: @✓↓modules_NormLinear_construct_3363:CNode_3558{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Input feature size , [2]: in_feat, [3]: ValueNode<StringImm>  doesn't match weight shape , [4]: CNode_3557}
#   3: @✓↓modules_NormLinear_construct_3363:CNode_3559{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3558, [3]: ValueNode<StringImm> None}
#   4: @✓↓modules_NormLinear_construct_3363:CNode_3560{[0]: ValueNode<Primitive> Return, [1]: CNode_3559}


subgraph attr:
training : 1
subgraph instance: ✗↓modules_NormLinear_construct_3364 : 0x39180e90
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗↓modules_NormLinear_construct_3364 parent: [subgraph @↓modules_NormLinear_construct_3198]() {
  %1(CNode_3562) = call @2↓modules_NormLinear_construct_3561()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @✗↓modules_NormLinear_construct_3364:CNode_3562{[0]: ValueNode<FuncGraph> 2↓modules_NormLinear_construct_3561}
#   2: @✗↓modules_NormLinear_construct_3364:CNode_3563{[0]: ValueNode<Primitive> Return, [1]: CNode_3562}


subgraph attr:
training : 1
subgraph instance: ✓↓modules_NormLinear_construct_3373 : 0x393e8a50
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓↓modules_NormLinear_construct_3373 parent: [subgraph @↓modules_NormLinear_construct_3209]() {
  %1(x_shape) = $(modules_NormLinear_construct_2802):getattr(%para451_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:91/        x_shape = x.shape  # 例如：(T, B, C) 或 (N, C)/
  %2(CNode_3367) = $(↓modules_NormLinear_construct_3209):S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %3(in_feat) = $(↓modules_NormLinear_construct_3209):S_Prim_getitem(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:97/        in_feat = x_shape[-1]/
  %4(CNode_3564) = getattr(%para104_classifier22.weight, "shape")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier22.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %5(CNode_3565) = JoinedStr("Input feature size ", %3, " doesn't match weight shape ", %4)
      : (<null>, <null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  %6(CNode_3566) = raise[side_effect_io: Bool(1)]("ValueError", %5, "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:101/            raise ValueError(f"Input feature size {in_feat} doesn't match weight shape {self.weight.shape}")/
}
# Order:
#   1: @✓↓modules_NormLinear_construct_3373:CNode_3564{[0]: ValueNode<Primitive> getattr, [1]: param_classifier22.weight, [2]: ValueNode<StringImm> shape}
#   2: @✓↓modules_NormLinear_construct_3373:CNode_3565{[0]: ValueNode<Primitive> JoinedStr, [1]: ValueNode<StringImm> Input feature size , [2]: in_feat, [3]: ValueNode<StringImm>  doesn't match weight shape , [4]: CNode_3564}
#   3: @✓↓modules_NormLinear_construct_3373:CNode_3566{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: CNode_3565, [3]: ValueNode<StringImm> None}
#   4: @✓↓modules_NormLinear_construct_3373:CNode_3567{[0]: ValueNode<Primitive> Return, [1]: CNode_3566}


subgraph attr:
training : 1
subgraph instance: ✗↓modules_NormLinear_construct_3374 : 0x393aefc0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗↓modules_NormLinear_construct_3374 parent: [subgraph @↓modules_NormLinear_construct_3209]() {
  %1(CNode_3569) = call @2↓modules_NormLinear_construct_3568()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:100/        if in_feat != self.weight.shape[0]:/
}
# Order:
#   1: @✗↓modules_NormLinear_construct_3374:CNode_3569{[0]: ValueNode<FuncGraph> 2↓modules_NormLinear_construct_3568}
#   2: @✗↓modules_NormLinear_construct_3374:CNode_3570{[0]: ValueNode<Primitive> Return, [1]: CNode_3569}


subgraph attr:
training : 1
subgraph instance: ↵✓13↓tfnet_model_TFNetModel_construct_3393 : 0x39452be0
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↵✓13↓tfnet_model_TFNetModel_construct_3393(%para468_iter, %para469_list) {
  %1(CNode_3571) = call @hasnext_934(%para468_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %2(CNode_3572) = Switch(%1, @↻✓13↓tfnet_model_TFNetModel_construct_3573, @↓✓13↓tfnet_model_TFNetModel_construct_3574)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %3(CNode_3575) = %2()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @↵✓13↓tfnet_model_TFNetModel_construct_3393:CNode_3571{[0]: ValueNode<FuncGraph> hasnext_934, [1]: param_iter}
#   2: @↵✓13↓tfnet_model_TFNetModel_construct_3393:CNode_3572{[0]: ValueNode<Primitive> Switch, [1]: CNode_3571, [2]: ValueNode<FuncGraph> ↻✓13↓tfnet_model_TFNetModel_construct_3573, [3]: ValueNode<FuncGraph> ↓✓13↓tfnet_model_TFNetModel_construct_3574}
#   3: @↵✓13↓tfnet_model_TFNetModel_construct_3393:CNode_3575{[0]: CNode_3572}
#   4: @↵✓13↓tfnet_model_TFNetModel_construct_3393:CNode_3576{[0]: ValueNode<Primitive> Return, [1]: CNode_3575}


subgraph attr:
after_block : 1
subgraph instance: 5↓✓↓ms_max_one_element_3398 : 0x3334ab50
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2608/def ms_max_one_element(x):/
subgraph @5↓✓↓ms_max_one_element_3398 parent: [subgraph @ms_max_one_element_889]() {
  %1(CNode_3577) = call @2↓ms_max_one_element_1420()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2646/        return ms_max_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2622/        if check_sequence_all_variable_scalar(x, "max"):/
}
# Order:
#   1: @5↓✓↓ms_max_one_element_3398:CNode_3578{[0]: ValueNode<Primitive> Return, [1]: CNode_3577}
#   2: @5↓✓↓ms_max_one_element_3398:CNode_3577{[0]: ValueNode<FuncGraph> 2↓ms_max_one_element_1420}


subgraph attr:
subgraph instance: ✓3↓✓↓ms_min_one_element_3409 : 0x3957c530
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓3↓✓↓ms_min_one_element_3409 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3579) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("min() cannot contain both tensor and non-tensor type.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2713/            const_utils.raise_type_error(/
  %2(CNode_3580) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_3582) = call @4↓✓↓ms_min_one_element_3581()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  %4(CNode_3583) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2713/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2713/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓3↓✓↓ms_min_one_element_3409:CNode_3579{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> min() cannot contain both tensor and non-tensor type.}
#   2: @✓3↓✓↓ms_min_one_element_3409:CNode_3584{[0]: ValueNode<Primitive> Return, [1]: CNode_3583}
#   3: @✓3↓✓↓ms_min_one_element_3409:CNode_3582{[0]: ValueNode<FuncGraph> 4↓✓↓ms_min_one_element_3581}


subgraph attr:
subgraph instance: ✗3↓✓↓ms_min_one_element_3410 : 0x395733f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗3↓✓↓ms_min_one_element_3410 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3585) = call @4↓✓↓ms_min_one_element_3581()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2712/        if tensor_num != 0:/
}
# Order:
#   1: @✗3↓✓↓ms_min_one_element_3410:CNode_3586{[0]: ValueNode<Primitive> Return, [1]: CNode_3585}
#   2: @✗3↓✓↓ms_min_one_element_3410:CNode_3585{[0]: ValueNode<FuncGraph> 4↓✓↓ms_min_one_element_3581}


subgraph attr:
subgraph instance: ✓check_dim_valid_3420 : 0x396fea80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1721/    def check_dim_valid(start_dim, end_dim):/
subgraph @✓check_dim_valid_3420() {
  %1(CNode_3587) = raise[side_effect_io: Bool(1)]("ValueError", "For 'flatten', 'start_dim' cannot come after 'end_dim'.", "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1723/            raise ValueError("For 'flatten', 'start_dim' cannot come after 'end_dim'.")/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1723/            raise ValueError("For 'flatten', 'start_dim' cannot come after 'end_dim'.")/
}
# Order:
#   1: @✓check_dim_valid_3420:CNode_3587{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: ValueNode<StringImm> For 'flatten', 'start_dim' cannot come after 'end_dim'., [3]: ValueNode<StringImm> None}
#   2: @✓check_dim_valid_3420:CNode_3588{[0]: ValueNode<Primitive> Return, [1]: CNode_3587}


subgraph attr:
subgraph instance: ✗check_dim_valid_3421 : 0x396fc840
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1721/    def check_dim_valid(start_dim, end_dim):/
subgraph @✗check_dim_valid_3421() {
  %1(CNode_3590) = call @↓check_dim_valid_3589()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1722/        if start_dim > end_dim:/
}
# Order:
#   1: @✗check_dim_valid_3421:CNode_3590{[0]: ValueNode<FuncGraph> ↓check_dim_valid_3589}
#   2: @✗check_dim_valid_3421:CNode_3591{[0]: ValueNode<Primitive> Return, [1]: CNode_3590}


subgraph attr:
subgraph instance: check_axis_valid_3429 : 0x396f25c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1717/    def check_axis_valid(axis, ndim):/
subgraph @check_axis_valid_3429(%para470_axis, %para471_ndim) {
  %1(CNode_3592) = S_Prim_negative(%para471_ndim)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %2(CNode_3593) = S_Prim_less(%para470_axis, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %3(CNode_3594) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %4(CNode_3595) = Switch(%3, @↰check_axis_valid_3596, @↱check_axis_valid_3597)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %5(CNode_3598) = %4()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %6(CNode_3599) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %7(CNode_3600) = Switch(%6, @✓check_axis_valid_3601, @✗check_axis_valid_3602)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %8(CNode_3603) = %7()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @check_axis_valid_3429:CNode_3592{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: param_ndim}
#   2: @check_axis_valid_3429:CNode_3593{[0]: ValueNode<DoSignaturePrimitive> S_Prim_less, [1]: param_axis, [2]: CNode_3592}
#   3: @check_axis_valid_3429:CNode_3594{[0]: ValueNode<Primitive> Cond, [1]: CNode_3593, [2]: ValueNode<BoolImm> false}
#   4: @check_axis_valid_3429:CNode_3595{[0]: ValueNode<Primitive> Switch, [1]: CNode_3594, [2]: ValueNode<FuncGraph> ↰check_axis_valid_3596, [3]: ValueNode<FuncGraph> ↱check_axis_valid_3597}
#   5: @check_axis_valid_3429:CNode_3598{[0]: CNode_3595}
#   6: @check_axis_valid_3429:CNode_3599{[0]: ValueNode<Primitive> Cond, [1]: CNode_3598, [2]: ValueNode<BoolImm> false}
#   7: @check_axis_valid_3429:CNode_3600{[0]: ValueNode<Primitive> Switch, [1]: CNode_3599, [2]: ValueNode<FuncGraph> ✓check_axis_valid_3601, [3]: ValueNode<FuncGraph> ✗check_axis_valid_3602}
#   8: @check_axis_valid_3429:CNode_3603{[0]: CNode_3600}
#   9: @check_axis_valid_3429:CNode_3604{[0]: ValueNode<Primitive> Return, [1]: CNode_3603}


subgraph attr:
subgraph instance: ↰canonicalize_axis_3427 : 0x396f1730
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
subgraph @↰canonicalize_axis_3427 parent: [subgraph @canonicalize_axis_3270]() {
  Return(%para463_x_rank)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
}
# Order:
#   1: @↰canonicalize_axis_3427:CNode_3605{[0]: ValueNode<Primitive> Return, [1]: param_x_rank}


subgraph attr:
subgraph instance: ↱canonicalize_axis_3428 : 0x396f08a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
subgraph @↱canonicalize_axis_3428() {
  Return(I64(1))
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
}
# Order:
#   1: @↱canonicalize_axis_3428:CNode_3606{[0]: ValueNode<Primitive> Return, [1]: ValueNode<Int64Imm> 1}


subgraph attr:
subgraph instance: ↰canonicalize_axis_3435 : 0x396efa10
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
subgraph @↰canonicalize_axis_3435 parent: [subgraph @canonicalize_axis_3270]() {
  Return(%para462_axis)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
}
# Order:
#   1: @↰canonicalize_axis_3435:CNode_3607{[0]: ValueNode<Primitive> Return, [1]: param_axis}


subgraph attr:
subgraph instance: ↱canonicalize_axis_3436 : 0x392899c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
subgraph @↱canonicalize_axis_3436 parent: [subgraph @canonicalize_axis_3270]() {
  %1(CNode_3424) = $(canonicalize_axis_3270):S_Prim_not_equal(%para463_x_rank, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %2(CNode_3425) = $(canonicalize_axis_3270):Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %3(CNode_3426) = $(canonicalize_axis_3270):Switch(%2, @↰canonicalize_axis_3427, @↱canonicalize_axis_3428)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %4(ndim) = $(canonicalize_axis_3270):%3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1726/        ndim = x_rank if x_rank != 0 else 1/
  %5(CNode_3608) = S_Prim_add(%para462_axis, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1728/        return axis if axis >= 0 else axis + ndim/
}
# Order:
#   1: @↱canonicalize_axis_3436:CNode_3608{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: param_axis, [2]: ndim}
#   2: @↱canonicalize_axis_3436:CNode_3609{[0]: ValueNode<Primitive> Return, [1]: CNode_3608}


subgraph attr:
after_block : 1
subgraph instance: 5↓flatten_3444 : 0x39081a80
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @5↓flatten_3444 parent: [subgraph @4↓flatten_3091]() {
  %1(x_rank) = $(3↓flatten_2708):S_Prim_Rank(%para423_фinput)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1748/    x_rank = rank_(input)/
  %2(idx) = $(4↓flatten_3091):call @canonicalize_axis_3270(%para263_start_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1755/    start_dim = canonicalize_axis(start_dim, x_rank)/
  %3(end_dim) = $(4↓flatten_3091):call @canonicalize_axis_3270(%para264_end_dim, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1756/    end_dim = canonicalize_axis(end_dim, x_rank)/
  %4(CNode_3610) = S_Prim_equal(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
  %5(CNode_3611) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
  %6(CNode_3612) = Switch(%5, @✓5↓flatten_3613, @✗5↓flatten_3614)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
  %7(CNode_3615) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
}
# Order:
#   1: @5↓flatten_3444:CNode_3610{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: idx, [2]: end_dim}
#   2: @5↓flatten_3444:CNode_3611{[0]: ValueNode<Primitive> Cond, [1]: CNode_3610, [2]: ValueNode<BoolImm> false}
#   3: @5↓flatten_3444:CNode_3612{[0]: ValueNode<Primitive> Switch, [1]: CNode_3611, [2]: ValueNode<FuncGraph> ✓5↓flatten_3613, [3]: ValueNode<FuncGraph> ✗5↓flatten_3614}
#   4: @5↓flatten_3444:CNode_3615{[0]: CNode_3612}
#   5: @5↓flatten_3444:CNode_3616{[0]: ValueNode<Primitive> Return, [1]: CNode_3615}


subgraph attr:
training : 1
subgraph instance: ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450 : 0x373d3230
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294]() {
  %1(CNode_3618) = call @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3617()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450:CNode_3618{[0]: ValueNode<FuncGraph> 4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3617}
#   2: @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3450:CNode_3619{[0]: ValueNode<Primitive> Return, [1]: CNode_3618}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3459 : 0x37e3da30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3459(%para472_) {
  Return(%para472_фoutput)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3459:CNode_3620{[0]: ValueNode<Primitive> Return, [1]: param_фoutput}


subgraph attr:
training : 1
subgraph instance: 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456 : 0x37600ac0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para427_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3621) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %5(CNode_3622) = getattr(%4, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %6(CNode_3623) = %5(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %7(CNode_3624) = S_Prim_getitem(%3, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %8(CNode_3625) = getattr(%7, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %9(CNode_3626) = %8(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %10(output) = S_Prim_MakeTuple(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
}
# Order:
#   1: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3621{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: ValueNode<Int64Imm> 0}
#   2: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3622{[0]: ValueNode<Primitive> getattr, [1]: CNode_3621, [2]: ValueNode<StringImm> squeeze}
#   3: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3623{[0]: CNode_3622, [1]: ValueNode<Int64Imm> 0}
#   4: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3624{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: ValueNode<Int64Imm> 1}
#   5: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3625{[0]: ValueNode<Primitive> getattr, [1]: CNode_3624, [2]: ValueNode<StringImm> squeeze}
#   6: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3626{[0]: CNode_3625, [1]: ValueNode<Int64Imm> 0}
#   7: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3623, [2]: CNode_3626}
#   8: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3456:CNode_3627{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457 : 0x33d064a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para427_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2905):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3628) = getattr(%3, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
  %5(output) = %4(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
}
# Order:
#   1: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457:CNode_3628{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> squeeze}
#   2: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457:output{[0]: CNode_3628, [1]: ValueNode<Int64Imm> 0}
#   3: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3457:CNode_3629{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463 : 0x37b9b320
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302]() {
  %1(CNode_3631) = call @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3630()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463:CNode_3631{[0]: ValueNode<FuncGraph> 4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3630}
#   2: @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3463:CNode_3632{[0]: ValueNode<Primitive> Return, [1]: CNode_3631}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3472 : 0x38fa5260
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3472(%para473_) {
  Return(%para473_фoutput)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3472:CNode_3633{[0]: ValueNode<Primitive> Return, [1]: param_фoutput}


subgraph attr:
training : 1
subgraph instance: 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469 : 0x38fcc710
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para429_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3634) = S_Prim_getitem(%3, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %5(CNode_3635) = getattr(%4, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %6(CNode_3636) = %5(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %7(CNode_3637) = S_Prim_getitem(%3, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %8(CNode_3638) = getattr(%7, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %9(CNode_3639) = %8(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  %10(output) = S_Prim_MakeTuple(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:740/                output = (output[0].squeeze(0), output[1].squeeze(0))/
}
# Order:
#   1: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3634{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: ValueNode<Int64Imm> 0}
#   2: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3635{[0]: ValueNode<Primitive> getattr, [1]: CNode_3634, [2]: ValueNode<StringImm> squeeze}
#   3: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3636{[0]: CNode_3635, [1]: ValueNode<Int64Imm> 0}
#   4: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3637{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: ValueNode<Int64Imm> 1}
#   5: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3638{[0]: ValueNode<Primitive> getattr, [1]: CNode_3637, [2]: ValueNode<StringImm> squeeze}
#   6: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3639{[0]: CNode_3638, [1]: ValueNode<Int64Imm> 0}
#   7: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3636, [2]: CNode_3639}
#   8: @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3469:CNode_3640{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470 : 0x3763edb0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para429_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_2911):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3641) = getattr(%3, "squeeze")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
  %5(output) = %4(I64(0))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:742/                output = output.squeeze(0)/
}
# Order:
#   1: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470:CNode_3641{[0]: ValueNode<Primitive> getattr, [1]: output, [2]: ValueNode<StringImm> squeeze}
#   2: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470:output{[0]: CNode_3641, [1]: ValueNode<Int64Imm> 0}
#   3: @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3470:CNode_3642{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479 : 0x39137b70
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309]() {
  %1(CNode_3643) = Cond(%para456_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %2(CNode_3644) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645, @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3646)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %3(CNode_3647) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %4(CNode_3649) = call @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479:CNode_3643{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479:CNode_3644{[0]: ValueNode<Primitive> Switch, [1]: CNode_3643, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3646}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479:CNode_3647{[0]: CNode_3644}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479:CNode_3649{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648, [1]: CNode_3647}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3479:CNode_3650{[0]: ValueNode<Primitive> Return, [1]: CNode_3649}


subgraph attr:
training : 1
subgraph instance: 2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486 : 0x3911b580
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312]() {
  %1(CNode_3651) = Cond(%para458_фexpand_batch, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %2(CNode_3652) = Switch(%1, @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653, @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3654)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %3(CNode_3655) = %2()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
  %4(CNode_3657) = call @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486:CNode_3651{[0]: ValueNode<Primitive> Cond, [1]: param_фexpand_batch, [2]: ValueNode<BoolImm> false}
#   2: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486:CNode_3652{[0]: ValueNode<Primitive> Switch, [1]: CNode_3651, [2]: ValueNode<FuncGraph> ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653, [3]: ValueNode<FuncGraph> ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3654}
#   3: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486:CNode_3655{[0]: CNode_3652}
#   4: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486:CNode_3657{[0]: ValueNode<FuncGraph> 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656, [1]: CNode_3655}
#   5: @2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3486:CNode_3658{[0]: ValueNode<Primitive> Return, [1]: CNode_3657}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓modules_NormLinear_construct_3494 : 0x39407a90
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @2↓modules_NormLinear_construct_3494 parent: [subgraph @↓modules_NormLinear_construct_3173]() {
  %1(CNode_3659) = getattr(%para445_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %2(CNode_3660) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %3(CNode_3661) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %4(CNode_3662) = Switch(%3, @✓2↓modules_NormLinear_construct_3663, @✗2↓modules_NormLinear_construct_3664)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %5(CNode_3665) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %6(CNode_3667) = call @3↓modules_NormLinear_construct_3666(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:209/        log_probs5 = self.classifier55(x2)/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @2↓modules_NormLinear_construct_3494:CNode_3659{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @2↓modules_NormLinear_construct_3494:CNode_3660{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3659, [2]: ValueNode<Float> Float32}
#   3: @2↓modules_NormLinear_construct_3494:CNode_3661{[0]: ValueNode<Primitive> Cond, [1]: CNode_3660, [2]: ValueNode<BoolImm> false}
#   4: @2↓modules_NormLinear_construct_3494:CNode_3662{[0]: ValueNode<Primitive> Switch, [1]: CNode_3661, [2]: ValueNode<FuncGraph> ✓2↓modules_NormLinear_construct_3663, [3]: ValueNode<FuncGraph> ✗2↓modules_NormLinear_construct_3664}
#   5: @2↓modules_NormLinear_construct_3494:CNode_3665{[0]: CNode_3662}
#   6: @2↓modules_NormLinear_construct_3494:CNode_3667{[0]: ValueNode<FuncGraph> 3↓modules_NormLinear_construct_3666, [1]: CNode_3665}
#   7: @2↓modules_NormLinear_construct_3494:CNode_3668{[0]: ValueNode<Primitive> Return, [1]: CNode_3667}


subgraph attr:
training : 1
subgraph instance: 2✓↓modules_BiLSTMLayer_construct_3503 : 0x392a4720
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2✓↓modules_BiLSTMLayer_construct_3503 parent: [subgraph @✓↓modules_BiLSTMLayer_construct_3335]() {
  %1(CNode_3670) = call @↓✓↓modules_BiLSTMLayer_construct_3669()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
}
# Order:
#   1: @2✓↓modules_BiLSTMLayer_construct_3503:CNode_3671{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: T}
#   2: @2✓↓modules_BiLSTMLayer_construct_3503:CNode_3672{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: B}
#   3: @2✓↓modules_BiLSTMLayer_construct_3503:output_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3671, [2]: CNode_3672, [3]: ValueNode<Int64Imm> 64}
#   4: @2✓↓modules_BiLSTMLayer_construct_3503:CNode_3670{[0]: ValueNode<FuncGraph> ↓✓↓modules_BiLSTMLayer_construct_3669}
#   5: @2✓↓modules_BiLSTMLayer_construct_3503:CNode_3673{[0]: ValueNode<Primitive> Return, [1]: CNode_3670}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✗↓modules_BiLSTMLayer_construct_3514 : 0x391eba90
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓✗↓modules_BiLSTMLayer_construct_3514 parent: [subgraph @after_grad_108](%para474_) {
  %1(CNode_3675) = call @✓↓✗↓modules_BiLSTMLayer_construct_3674()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:173/            if self.bidirectional:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:173/            if self.bidirectional:/
}
# Order:
#   1: @↓✗↓modules_BiLSTMLayer_construct_3514:CNode_3676{[0]: ValueNode<FuncGraph> mindspore_nn_layer_rnns_LSTM_construct_3677, [1]: param_фx}
#   2: @↓✗↓modules_BiLSTMLayer_construct_3514:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3676, [2]: ValueNode<Int64Imm> 0}
#   3: @↓✗↓modules_BiLSTMLayer_construct_3514:CNode_3675{[0]: ValueNode<FuncGraph> ✓↓✗↓modules_BiLSTMLayer_construct_3674}
#   4: @↓✗↓modules_BiLSTMLayer_construct_3514:CNode_3678{[0]: ValueNode<Primitive> Return, [1]: CNode_3675}


subgraph attr:
training : 1
subgraph instance: ✓✗↓modules_BiLSTMLayer_construct_3511 : 0x391ea810
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓✗↓modules_BiLSTMLayer_construct_3511 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para446_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:170/                x = ops.cast(x, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:170/                x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓✗↓modules_BiLSTMLayer_construct_3511:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   2: @✓✗↓modules_BiLSTMLayer_construct_3511:CNode_3679{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: 2✗↓modules_BiLSTMLayer_construct_3512 : 0x391e99c0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2✗↓modules_BiLSTMLayer_construct_3512 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  Return(%para446_x)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
}
# Order:
#   1: @2✗↓modules_BiLSTMLayer_construct_3512:CNode_3680{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
training : 1
subgraph instance: ↰↱↓modules_BiLSTMLayer_construct_3523 : 0x391e33b0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↰↱↓modules_BiLSTMLayer_construct_3523 parent: [subgraph @↱↓modules_BiLSTMLayer_construct_3331]() {
  %1(CNode_3518) = $(↱↓modules_BiLSTMLayer_construct_3331):getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3519) = $(↱↓modules_BiLSTMLayer_construct_3331):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3520) = $(↱↓modules_BiLSTMLayer_construct_3331):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↰↱↓modules_BiLSTMLayer_construct_3523:CNode_3681{[0]: ValueNode<Primitive> Return, [1]: CNode_3520}


subgraph attr:
training : 1
subgraph instance: 2↱↓modules_BiLSTMLayer_construct_3524 : 0x391e1ec0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2↱↓modules_BiLSTMLayer_construct_3524 parent: [subgraph @modules_BiLSTMLayer_construct_2800]() {
  %1(CNode_3682) = getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3683) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3684) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @2↱↓modules_BiLSTMLayer_construct_3524:CNode_3682{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @2↱↓modules_BiLSTMLayer_construct_3524:CNode_3683{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3682, [2]: ValueNode<Int64Imm> 2}
#   3: @2↱↓modules_BiLSTMLayer_construct_3524:CNode_3684{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3683, [2]: ValueNode<Int64Imm> 0}
#   4: @2↱↓modules_BiLSTMLayer_construct_3524:CNode_3685{[0]: ValueNode<Primitive> Return, [1]: CNode_3684}


subgraph attr:
training : 1
subgraph instance: 2✓↓modules_BiLSTMLayer_construct_3533 : 0x390f74a0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2✓↓modules_BiLSTMLayer_construct_3533 parent: [subgraph @✓↓modules_BiLSTMLayer_construct_3351]() {
  %1(CNode_3687) = call @↓✓↓modules_BiLSTMLayer_construct_3686()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
}
# Order:
#   1: @2✓↓modules_BiLSTMLayer_construct_3533:CNode_3688{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: T}
#   2: @2✓↓modules_BiLSTMLayer_construct_3533:CNode_3689{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: B}
#   3: @2✓↓modules_BiLSTMLayer_construct_3533:output_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3688, [2]: CNode_3689, [3]: ValueNode<Int64Imm> 64}
#   4: @2✓↓modules_BiLSTMLayer_construct_3533:CNode_3687{[0]: ValueNode<FuncGraph> ↓✓↓modules_BiLSTMLayer_construct_3686}
#   5: @2✓↓modules_BiLSTMLayer_construct_3533:CNode_3690{[0]: ValueNode<Primitive> Return, [1]: CNode_3687}


subgraph attr:
after_block : 1
training : 1
subgraph instance: ↓✗↓modules_BiLSTMLayer_construct_3544 : 0x392d3fa0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓✗↓modules_BiLSTMLayer_construct_3544 parent: [subgraph @after_grad_108](%para475_) {
  %1(CNode_3692) = call @✓↓✗↓modules_BiLSTMLayer_construct_3691()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:173/            if self.bidirectional:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:173/            if self.bidirectional:/
}
# Order:
#   1: @↓✗↓modules_BiLSTMLayer_construct_3544:CNode_3693{[0]: ValueNode<FuncGraph> mindspore_nn_layer_rnns_LSTM_construct_3694, [1]: param_фx}
#   2: @↓✗↓modules_BiLSTMLayer_construct_3544:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3693, [2]: ValueNode<Int64Imm> 0}
#   3: @↓✗↓modules_BiLSTMLayer_construct_3544:CNode_3692{[0]: ValueNode<FuncGraph> ✓↓✗↓modules_BiLSTMLayer_construct_3691}
#   4: @↓✗↓modules_BiLSTMLayer_construct_3544:CNode_3695{[0]: ValueNode<Primitive> Return, [1]: CNode_3692}


subgraph attr:
training : 1
subgraph instance: ✓✗↓modules_BiLSTMLayer_construct_3541 : 0x392d2d20
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓✗↓modules_BiLSTMLayer_construct_3541 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para448_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:170/                x = ops.cast(x, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:170/                x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓✗↓modules_BiLSTMLayer_construct_3541:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   2: @✓✗↓modules_BiLSTMLayer_construct_3541:CNode_3696{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: 2✗↓modules_BiLSTMLayer_construct_3542 : 0x392d1ed0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2✗↓modules_BiLSTMLayer_construct_3542 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  Return(%para448_x)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:169/            if x.dtype != ms.float32:/
}
# Order:
#   1: @2✗↓modules_BiLSTMLayer_construct_3542:CNode_3697{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
training : 1
subgraph instance: ↰↱↓modules_BiLSTMLayer_construct_3553 : 0x392cb8c0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↰↱↓modules_BiLSTMLayer_construct_3553 parent: [subgraph @↱↓modules_BiLSTMLayer_construct_3347]() {
  %1(CNode_3548) = $(↱↓modules_BiLSTMLayer_construct_3347):getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3549) = $(↱↓modules_BiLSTMLayer_construct_3347):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3550) = $(↱↓modules_BiLSTMLayer_construct_3347):S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @↰↱↓modules_BiLSTMLayer_construct_3553:CNode_3698{[0]: ValueNode<Primitive> Return, [1]: CNode_3550}


subgraph attr:
training : 1
subgraph instance: 2↱↓modules_BiLSTMLayer_construct_3554 : 0x392ca3d0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @2↱↓modules_BiLSTMLayer_construct_3554 parent: [subgraph @modules_BiLSTMLayer_construct_2799]() {
  %1(CNode_3699) = getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %2(CNode_3700) = S_Prim_getitem(%1, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  %3(CNode_3701) = S_Prim_equal(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:159/        if x.shape[0] == 0 or x.shape[1] == 0 or x.shape[2] == 0:/
}
# Order:
#   1: @2↱↓modules_BiLSTMLayer_construct_3554:CNode_3699{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> shape}
#   2: @2↱↓modules_BiLSTMLayer_construct_3554:CNode_3700{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3699, [2]: ValueNode<Int64Imm> 2}
#   3: @2↱↓modules_BiLSTMLayer_construct_3554:CNode_3701{[0]: ValueNode<DoSignaturePrimitive> S_Prim_equal, [1]: CNode_3700, [2]: ValueNode<Int64Imm> 0}
#   4: @2↱↓modules_BiLSTMLayer_construct_3554:CNode_3702{[0]: ValueNode<Primitive> Return, [1]: CNode_3701}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓modules_NormLinear_construct_3561 : 0x39185fa0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @2↓modules_NormLinear_construct_3561 parent: [subgraph @↓modules_NormLinear_construct_3198]() {
  %1(CNode_3703) = getattr(%para450_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %2(CNode_3704) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %3(CNode_3705) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %4(CNode_3706) = Switch(%3, @✓2↓modules_NormLinear_construct_3707, @✗2↓modules_NormLinear_construct_3708)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %5(CNode_3709) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %6(CNode_3711) = call @3↓modules_NormLinear_construct_3710(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:204/        log_probs3 = self.classifier33(outputs1['predictions'])/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @2↓modules_NormLinear_construct_3561:CNode_3703{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @2↓modules_NormLinear_construct_3561:CNode_3704{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3703, [2]: ValueNode<Float> Float32}
#   3: @2↓modules_NormLinear_construct_3561:CNode_3705{[0]: ValueNode<Primitive> Cond, [1]: CNode_3704, [2]: ValueNode<BoolImm> false}
#   4: @2↓modules_NormLinear_construct_3561:CNode_3706{[0]: ValueNode<Primitive> Switch, [1]: CNode_3705, [2]: ValueNode<FuncGraph> ✓2↓modules_NormLinear_construct_3707, [3]: ValueNode<FuncGraph> ✗2↓modules_NormLinear_construct_3708}
#   5: @2↓modules_NormLinear_construct_3561:CNode_3709{[0]: CNode_3706}
#   6: @2↓modules_NormLinear_construct_3561:CNode_3711{[0]: ValueNode<FuncGraph> 3↓modules_NormLinear_construct_3710, [1]: CNode_3709}
#   7: @2↓modules_NormLinear_construct_3561:CNode_3712{[0]: ValueNode<Primitive> Return, [1]: CNode_3711}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 2↓modules_NormLinear_construct_3568 : 0x393b6130
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @2↓modules_NormLinear_construct_3568 parent: [subgraph @↓modules_NormLinear_construct_3209]() {
  %1(CNode_3713) = getattr(%para451_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %2(CNode_3714) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %3(CNode_3715) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %4(CNode_3716) = Switch(%3, @✓2↓modules_NormLinear_construct_3717, @✗2↓modules_NormLinear_construct_3718)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %5(CNode_3719) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
  %6(CNode_3721) = call @3↓modules_NormLinear_construct_3720(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:202/        log_probs1 = self.classifier11(outputs['predictions'])/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @2↓modules_NormLinear_construct_3568:CNode_3713{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @2↓modules_NormLinear_construct_3568:CNode_3714{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3713, [2]: ValueNode<Float> Float32}
#   3: @2↓modules_NormLinear_construct_3568:CNode_3715{[0]: ValueNode<Primitive> Cond, [1]: CNode_3714, [2]: ValueNode<BoolImm> false}
#   4: @2↓modules_NormLinear_construct_3568:CNode_3716{[0]: ValueNode<Primitive> Switch, [1]: CNode_3715, [2]: ValueNode<FuncGraph> ✓2↓modules_NormLinear_construct_3717, [3]: ValueNode<FuncGraph> ✗2↓modules_NormLinear_construct_3718}
#   5: @2↓modules_NormLinear_construct_3568:CNode_3719{[0]: CNode_3716}
#   6: @2↓modules_NormLinear_construct_3568:CNode_3721{[0]: ValueNode<FuncGraph> 3↓modules_NormLinear_construct_3720, [1]: CNode_3719}
#   7: @2↓modules_NormLinear_construct_3568:CNode_3722{[0]: ValueNode<Primitive> Return, [1]: CNode_3721}


subgraph attr:
training : 1
subgraph instance: ↻✓13↓tfnet_model_TFNetModel_construct_3573 : 0x3945ab80
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↻✓13↓tfnet_model_TFNetModel_construct_3573 parent: [subgraph @↵✓13↓tfnet_model_TFNetModel_construct_3393]() {
  %1(CNode_3723) = call @ms_next_1075(%para468_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %2(CNode_3724) = S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %3(CNode_3725) = Switch(Bool(1), @✓↻✓13↓tfnet_model_TFNetModel_construct_3726, @✗↻✓13↓tfnet_model_TFNetModel_construct_3727)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %4(CNode_3728) = %3()
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %5(CNode_3729) = call @↵✓13↓tfnet_model_TFNetModel_construct_3393(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/train_tfnet_gpu.py:623/                    model_output = model(seq_data, data_len_tensor, is_train=True)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3723{[0]: ValueNode<FuncGraph> ms_next_1075, [1]: param_iter}
#   2: @↻✓13↓tfnet_model_TFNetModel_construct_3573:l{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3723, [2]: ValueNode<Int64Imm> 0}
#   3: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3724{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_3723, [2]: ValueNode<Int64Imm> 1}
#   4: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3730{[0]: ValueNode<ClassType> class 'int', [1]: l}
#   5: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3731{[0]: ValueNode<FuncGraph> ms_max_436, [1]: ValueNode<Int64Imm> 1, [2]: CNode_3730}
#   6: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3732{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: CNode_3731}
#   7: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3733{[0]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-add.15, [1]: param_list, [2]: CNode_3732}
#   8: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3725{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> ✓↻✓13↓tfnet_model_TFNetModel_construct_3726, [3]: ValueNode<FuncGraph> ✗↻✓13↓tfnet_model_TFNetModel_construct_3727}
#   9: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3728{[0]: CNode_3725}
#  10: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3734{[0]: ValueNode<Primitive> Return, [1]: CNode_3729}
#  11: @↻✓13↓tfnet_model_TFNetModel_construct_3573:CNode_3729{[0]: ValueNode<FuncGraph> ↵✓13↓tfnet_model_TFNetModel_construct_3393, [1]: CNode_3724, [2]: CNode_3728}


subgraph attr:
training : 1
subgraph instance: ↓✓13↓tfnet_model_TFNetModel_construct_3574 : 0x3945b350
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @↓✓13↓tfnet_model_TFNetModel_construct_3574 parent: [subgraph @↵✓13↓tfnet_model_TFNetModel_construct_3393]() {
  Return(%para469_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @↓✓13↓tfnet_model_TFNetModel_construct_3574:CNode_3735{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
after_block : 1
subgraph instance: 4↓✓↓ms_min_one_element_3581 : 0x39575240
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @4↓✓↓ms_min_one_element_3581 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3736) = call @exist_tensor_1831(%para257_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
  %2(CNode_3737) = Cond(%1, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
  %3(CNode_3738) = Switch(%2, @✓4↓✓↓ms_min_one_element_3739, @✗4↓✓↓ms_min_one_element_3740)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
  %4(CNode_3741) = %3()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
}
# Order:
#   1: @4↓✓↓ms_min_one_element_3581:CNode_3736{[0]: ValueNode<FuncGraph> exist_tensor_1831, [1]: param_x}
#   2: @4↓✓↓ms_min_one_element_3581:CNode_3737{[0]: ValueNode<Primitive> Cond, [1]: CNode_3736, [2]: ValueNode<BoolImm> false}
#   3: @4↓✓↓ms_min_one_element_3581:CNode_3738{[0]: ValueNode<Primitive> Switch, [1]: CNode_3737, [2]: ValueNode<FuncGraph> ✓4↓✓↓ms_min_one_element_3739, [3]: ValueNode<FuncGraph> ✗4↓✓↓ms_min_one_element_3740}
#   4: @4↓✓↓ms_min_one_element_3581:CNode_3741{[0]: CNode_3738}
#   5: @4↓✓↓ms_min_one_element_3581:CNode_3742{[0]: ValueNode<Primitive> Return, [1]: CNode_3741}


subgraph attr:
after_block : 1
subgraph instance: ↓check_dim_valid_3589 : 0x396fdaf0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1721/    def check_dim_valid(start_dim, end_dim):/
subgraph @↓check_dim_valid_3589() {
  Return(None)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
}
# Order:
#   1: @↓check_dim_valid_3589:CNode_3743{[0]: ValueNode<Primitive> Return, [1]: ValueNode<None> None}


subgraph attr:
subgraph instance: ✓check_axis_valid_3601 : 0x396f9630
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1717/    def check_axis_valid(axis, ndim):/
subgraph @✓check_axis_valid_3601() {
  %1(CNode_3744) = raise[side_effect_io: Bool(1)]("ValueError", "'start_dim' or 'end_dim' out of range.", "None")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1719/            raise ValueError("'start_dim' or 'end_dim' out of range.")/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1719/            raise ValueError("'start_dim' or 'end_dim' out of range.")/
}
# Order:
#   1: @✓check_axis_valid_3601:CNode_3744{[0]: ValueNode<Primitive> raise, [1]: ValueNode<StringImm> ValueError, [2]: ValueNode<StringImm> 'start_dim' or 'end_dim' out of range., [3]: ValueNode<StringImm> None}
#   2: @✓check_axis_valid_3601:CNode_3745{[0]: ValueNode<Primitive> Return, [1]: CNode_3744}


subgraph attr:
subgraph instance: ✗check_axis_valid_3602 : 0x396f73f0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1717/    def check_axis_valid(axis, ndim):/
subgraph @✗check_axis_valid_3602() {
  %1(CNode_3747) = call @↓check_axis_valid_3746()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @✗check_axis_valid_3602:CNode_3747{[0]: ValueNode<FuncGraph> ↓check_axis_valid_3746}
#   2: @✗check_axis_valid_3602:CNode_3748{[0]: ValueNode<Primitive> Return, [1]: CNode_3747}


subgraph attr:
subgraph instance: ↰check_axis_valid_3596 : 0x396f6560
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1717/    def check_axis_valid(axis, ndim):/
subgraph @↰check_axis_valid_3596 parent: [subgraph @check_axis_valid_3429]() {
  %1(CNode_3592) = $(check_axis_valid_3429):S_Prim_negative(%para471_ndim)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  %2(CNode_3593) = $(check_axis_valid_3429):S_Prim_less(%para470_axis, %1)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @↰check_axis_valid_3596:CNode_3749{[0]: ValueNode<Primitive> Return, [1]: CNode_3593}


subgraph attr:
subgraph instance: ↱check_axis_valid_3597 : 0x396f54a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1717/    def check_axis_valid(axis, ndim):/
subgraph @↱check_axis_valid_3597 parent: [subgraph @check_axis_valid_3429]() {
  %1(CNode_3750) = S_Prim_greater_equal(%para470_axis, %para471_ndim)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1718/        if axis < -ndim or axis >= ndim:/
}
# Order:
#   1: @↱check_axis_valid_3597:CNode_3750{[0]: ValueNode<DoSignaturePrimitive> S_Prim_greater_equal, [1]: param_axis, [2]: param_ndim}
#   2: @↱check_axis_valid_3597:CNode_3751{[0]: ValueNode<Primitive> Return, [1]: CNode_3750}


subgraph attr:
subgraph instance: ✓5↓flatten_3613 : 0x392832d0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✓5↓flatten_3613 parent: [subgraph @3↓flatten_2708]() {
  Return(%para423_фinput)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1763/        return input/
}
# Order:
#   1: @✓5↓flatten_3613:CNode_3752{[0]: ValueNode<Primitive> Return, [1]: param_фinput}


subgraph attr:
subgraph instance: ✗5↓flatten_3614 : 0x390837c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1678/def flatten(input, order='C', *, start_dim=1, end_dim=-1):/
subgraph @✗5↓flatten_3614 parent: [subgraph @4↓flatten_3091]() {
  %1(CNode_3754) = call @6↓flatten_3753()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1762/    if start_dim == end_dim:/
}
# Order:
#   1: @✗5↓flatten_3614:CNode_3754{[0]: ValueNode<FuncGraph> 6↓flatten_3753}
#   2: @✗5↓flatten_3614:CNode_3755{[0]: ValueNode<Primitive> Return, [1]: CNode_3754}


subgraph attr:
training : 1
subgraph instance: 4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3617 : 0x37f8ad30
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3617 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3294]() {
  Return(%para464_фoutput)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:745/        return output/
}
# Order:
#   1: @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3617:CNode_3756{[0]: ValueNode<Primitive> Return, [1]: param_фoutput}


subgraph attr:
training : 1
subgraph instance: 4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3630 : 0x372dcb20
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3630 parent: [subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3302]() {
  Return(%para465_фoutput)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:745/        return output/
}
# Order:
#   1: @4↓mindspore_nn_layer_pooling_MaxPool1d_construct_3630:CNode_3757{[0]: ValueNode<Primitive> Return, [1]: param_фoutput}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648 : 0x391415c0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648(%para476_) {
  %1(CNode_3759) = call @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3758()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648:CNode_3759{[0]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3758}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3648:CNode_3760{[0]: ValueNode<Primitive> Return, [1]: CNode_3759}


subgraph attr:
training : 1
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645 : 0x3913a9a0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para455_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3761) = S_Prim_isinstance(%3, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %5(CNode_3762) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %6(CNode_3763) = Switch(%5, @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3764, @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3765)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %7(CNode_3766) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %8(CNode_3768) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3767(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3761{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: output, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3762{[0]: ValueNode<Primitive> Cond, [1]: CNode_3761, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3763{[0]: ValueNode<Primitive> Switch, [1]: CNode_3762, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3764, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3765}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3766{[0]: CNode_3763}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3768{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3767, [1]: CNode_3766}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3645:CNode_3769{[0]: ValueNode<Primitive> Return, [1]: CNode_3768}


subgraph attr:
training : 1
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3646 : 0x39139af0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3646 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para455_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3309):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3646:CNode_3770{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656 : 0x39124fd0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656(%para477_) {
  %1(CNode_3772) = call @✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3771()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:743/        if self.use_pad and not self.return_indices:/
}
# Order:
#   1: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656:CNode_3772{[0]: ValueNode<FuncGraph> ✗3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3771}
#   2: @3↓mindspore_nn_layer_pooling_MaxPool1d_construct_3656:CNode_3773{[0]: ValueNode<Primitive> Return, [1]: CNode_3772}


subgraph attr:
training : 1
subgraph instance: ✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653 : 0x3911e3b0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para457_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  %4(CNode_3774) = S_Prim_isinstance(%3, ClassType)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %5(CNode_3775) = Cond(%4, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %6(CNode_3776) = Switch(%5, @2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3777, @✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3778)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %7(CNode_3779) = %6()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
  %8(CNode_3781) = call @↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3780(%7)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/container.py:294/        for cell in self.cell_list:/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:739/            if isinstance(output, tuple):/
}
# Order:
#   1: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3774{[0]: ValueNode<DoSignaturePrimitive> S_Prim_isinstance, [1]: output, [2]: ValueNode<ClassType> class 'tuple'}
#   2: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3775{[0]: ValueNode<Primitive> Cond, [1]: CNode_3774, [2]: ValueNode<BoolImm> false}
#   3: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3776{[0]: ValueNode<Primitive> Switch, [1]: CNode_3775, [2]: ValueNode<FuncGraph> 2✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3777, [3]: ValueNode<FuncGraph> ✗✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3778}
#   4: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3779{[0]: CNode_3776}
#   5: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3781{[0]: ValueNode<FuncGraph> ↓✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3780, [1]: CNode_3779}
#   6: @✓2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3653:CNode_3782{[0]: ValueNode<Primitive> Return, [1]: CNode_3781}


subgraph attr:
training : 1
subgraph instance: ✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3654 : 0x3911d500
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:721/    def construct(self, x):/
subgraph @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3654 parent: [subgraph @✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312]() {
  %1(x) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_ExpandDims[output_names: ["output"], input_names: ["x", "axis"]](%para457_фx, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:735/            x = self.expand(x, 2)/
  %2(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_MaxPool[pad_mode: I64(2), output_names: ["output"], kernel_size: (I64(1), I64(1), I64(1), I64(2)), format: "NCHW", strides: (I64(1), I64(1), I64(1), I64(2)), input_names: ["x"]](%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:736/            output = self.max_pool(x)/
  %3(output) = $(✗↓mindspore_nn_layer_pooling_MaxPool1d_construct_3312):S_Prim_Squeeze[output_names: ["output"], input_names: ["x"], axis: (I64(2))](%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:737/            output = self.squeeze(output)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:738/        if expand_batch:/
}
# Order:
#   1: @✗2↓mindspore_nn_layer_pooling_MaxPool1d_construct_3654:CNode_3783{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓modules_NormLinear_construct_3666 : 0x3940f600
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @3↓modules_NormLinear_construct_3666 parent: [subgraph @↓modules_NormLinear_construct_3173](%para478_) {
  %1(CNode_3784) = getattr(%para106_classifier55.weight, "dtype")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier55.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %2(CNode_3785) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %3(CNode_3786) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %4(CNode_3787) = Switch(%3, @✓3↓modules_NormLinear_construct_3788, @✗3↓modules_NormLinear_construct_3789)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %5(CNode_3790) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
}
# Order:
#   1: @3↓modules_NormLinear_construct_3666:CNode_3784{[0]: ValueNode<Primitive> getattr, [1]: param_classifier55.weight, [2]: ValueNode<StringImm> dtype}
#   2: @3↓modules_NormLinear_construct_3666:CNode_3785{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3784, [2]: ValueNode<Float> Float32}
#   3: @3↓modules_NormLinear_construct_3666:CNode_3786{[0]: ValueNode<Primitive> Cond, [1]: CNode_3785, [2]: ValueNode<BoolImm> false}
#   4: @3↓modules_NormLinear_construct_3666:CNode_3787{[0]: ValueNode<Primitive> Switch, [1]: CNode_3786, [2]: ValueNode<FuncGraph> ✓3↓modules_NormLinear_construct_3788, [3]: ValueNode<FuncGraph> ✗3↓modules_NormLinear_construct_3789}
#   5: @3↓modules_NormLinear_construct_3666:CNode_3790{[0]: CNode_3787}
#   6: @3↓modules_NormLinear_construct_3666:CNode_3791{[0]: ValueNode<Primitive> Return, [1]: CNode_3790}


subgraph attr:
training : 1
subgraph instance: ✓2↓modules_NormLinear_construct_3663 : 0x3940e380
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓2↓modules_NormLinear_construct_3663 parent: [subgraph @modules_NormLinear_construct_2807]() {
  %1(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para445_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓2↓modules_NormLinear_construct_3663:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   2: @✓2↓modules_NormLinear_construct_3663:CNode_3792{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: ✗2↓modules_NormLinear_construct_3664 : 0x3940d880
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗2↓modules_NormLinear_construct_3664 parent: [subgraph @modules_NormLinear_construct_2807]() {
  Return(%para445_x)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @✗2↓modules_NormLinear_construct_3664:CNode_3793{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
training : 1
subgraph instance: ↓✓↓modules_BiLSTMLayer_construct_3669 : 0x392a9f70
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓✓↓modules_BiLSTMLayer_construct_3669 parent: [subgraph @2✓↓modules_BiLSTMLayer_construct_3503]() {
  %1(CNode_3501) = $(✓↓modules_BiLSTMLayer_construct_3335):getattr(%para446_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %2(T) = $(✓↓modules_BiLSTMLayer_construct_3335):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %3(CNode_3671) = $(2✓↓modules_BiLSTMLayer_construct_3503):call @ms_max_436(I64(1), %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %4(B) = $(✓↓modules_BiLSTMLayer_construct_3335):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %5(CNode_3672) = $(2✓↓modules_BiLSTMLayer_construct_3503):call @ms_max_436(I64(1), %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %6(output_shape) = $(2✓↓modules_BiLSTMLayer_construct_3503):S_Prim_MakeTuple(%3, %5, I64(64))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %7(CNode_3794) = getattr(%para446_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:166/            output = ops.zeros(output_shape, x.dtype)/
  %8(output) = call @zeros_442(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:166/            output = ops.zeros(output_shape, x.dtype)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
}
# Order:
#   1: @↓✓↓modules_BiLSTMLayer_construct_3669:CNode_3794{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @↓✓↓modules_BiLSTMLayer_construct_3669:output{[0]: ValueNode<FuncGraph> zeros_442, [1]: output_shape, [2]: CNode_3794}
#   3: @↓✓↓modules_BiLSTMLayer_construct_3669:CNode_3795{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_rnns_LSTM_construct_3677 : 0x391ef630
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:542/    def construct(self, x, hx=None, seq_length=None):/
subgraph @mindspore_nn_layer_rnns_LSTM_construct_3677 parent: [subgraph @after_grad_108](%para479_x, %para480_hx, %para481_seq_length) {
  %1(CNode_3796) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("x", %para479_x, "LSTM")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:546/        _check_is_tensor("x", x, self.cls_name)/
  %2(CNode_3797) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:542/    def construct(self, x, hx=None, seq_length=None):/
  %3(CNode_3798) = S_Prim_is_not(%para480_hx, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %4(CNode_3799) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %5(CNode_3800) = Switch(%4, @✓mindspore_nn_layer_rnns_LSTM_construct_3801, @✗mindspore_nn_layer_rnns_LSTM_construct_3802)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %6(CNode_3803) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %7(CNode_3805) = call @↓mindspore_nn_layer_rnns_LSTM_construct_3804(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:171/            output, _ = self.rnn(x)/
  %8(CNode_3806) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:171/            output, _ = self.rnn(x)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
}
# Order:
#   1: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3807{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<BoolImm> false, [2]: ValueNode<BoolImm> false}
#   2: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3808{[0]: ValueNode<Primitive> Switch, [1]: CNode_3807, [2]: ValueNode<FuncGraph> ↰mindspore_nn_layer_rnns_LSTM_construct_3809, [3]: ValueNode<FuncGraph> ↱mindspore_nn_layer_rnns_LSTM_construct_3810}
#   3: @mindspore_nn_layer_rnns_LSTM_construct_3677:max_batch_size{[0]: CNode_3808}
#   4: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3811{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<BoolImm> true, [2]: ValueNode<BoolImm> false}
#   5: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3812{[0]: ValueNode<Primitive> Switch, [1]: CNode_3811, [2]: ValueNode<FuncGraph> ↰mindspore_nn_layer_rnns_LSTM_construct_3813, [3]: ValueNode<FuncGraph> ↱mindspore_nn_layer_rnns_LSTM_construct_3814}
#   6: @mindspore_nn_layer_rnns_LSTM_construct_3677:num_directions{[0]: CNode_3812}
#   7: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3796{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> x, [2]: param_x, [3]: ValueNode<StringImm> LSTM}
#   8: @mindspore_nn_layer_rnns_LSTM_construct_3677:x_dtype{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   9: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3798{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_hx, [2]: ValueNode<None> None}
#  10: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3799{[0]: ValueNode<Primitive> Cond, [1]: CNode_3798, [2]: ValueNode<BoolImm> false}
#  11: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3800{[0]: ValueNode<Primitive> Switch, [1]: CNode_3799, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_rnns_LSTM_construct_3801, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_rnns_LSTM_construct_3802}
#  12: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3803{[0]: CNode_3800}
#  13: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3805{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_rnns_LSTM_construct_3804, [1]: CNode_3803}
#  14: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3806{[0]: ValueNode<Primitive> Depend, [1]: CNode_3805, [2]: CNode_3797}
#  15: @mindspore_nn_layer_rnns_LSTM_construct_3677:CNode_3815{[0]: ValueNode<Primitive> Return, [1]: CNode_3806}


subgraph attr:
training : 1
subgraph instance: ✓↓✗↓modules_BiLSTMLayer_construct_3674 : 0x39299610
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓↓✗↓modules_BiLSTMLayer_construct_3674 parent: [subgraph @↓✗↓modules_BiLSTMLayer_construct_3514]() {
  %1(CNode_3817) = call @2↓✗↓modules_BiLSTMLayer_construct_3816()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:175/                forward_out = output[:, :, :self.hidden_size]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:175/                forward_out = output[:, :, :self.hidden_size]/
}
# Order:
#   1: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3818{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   2: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3819{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   3: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3820{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<None> None}
#   4: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3821{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3818, [2]: CNode_3819, [3]: CNode_3820}
#   5: @✓↓✗↓modules_BiLSTMLayer_construct_3674:forward_out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: CNode_3821}
#   6: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3822{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   7: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3823{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   8: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3824{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<Int64Imm> 64, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   9: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3825{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3822, [2]: CNode_3823, [3]: CNode_3824}
#  10: @✓↓✗↓modules_BiLSTMLayer_construct_3674:backward_out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: CNode_3825}
#  11: @✓↓✗↓modules_BiLSTMLayer_construct_3674:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: forward_out, [2]: backward_out}
#  12: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3817{[0]: ValueNode<FuncGraph> 2↓✗↓modules_BiLSTMLayer_construct_3816}
#  13: @✓↓✗↓modules_BiLSTMLayer_construct_3674:CNode_3826{[0]: ValueNode<Primitive> Return, [1]: CNode_3817}


subgraph attr:
training : 1
subgraph instance: ↓✓↓modules_BiLSTMLayer_construct_3686 : 0x390fccf0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @↓✓↓modules_BiLSTMLayer_construct_3686 parent: [subgraph @2✓↓modules_BiLSTMLayer_construct_3533]() {
  %1(CNode_3531) = $(✓↓modules_BiLSTMLayer_construct_3351):getattr(%para448_x, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %2(T) = $(✓↓modules_BiLSTMLayer_construct_3351):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %3(CNode_3688) = $(2✓↓modules_BiLSTMLayer_construct_3533):call @ms_max_436(I64(1), %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %4(B) = $(✓↓modules_BiLSTMLayer_construct_3351):S_Prim_getitem(%1, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
  %5(CNode_3689) = $(2✓↓modules_BiLSTMLayer_construct_3533):call @ms_max_436(I64(1), %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %6(output_shape) = $(2✓↓modules_BiLSTMLayer_construct_3533):S_Prim_MakeTuple(%3, %5, I64(64))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:163/                output_shape = (max(1, T), max(1, B), self.hidden_size)/
  %7(CNode_3827) = getattr(%para448_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:166/            output = ops.zeros(output_shape, x.dtype)/
  %8(output) = call @zeros_442(%6, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:166/            output = ops.zeros(output_shape, x.dtype)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:161/            T, B, C = x.shape/
}
# Order:
#   1: @↓✓↓modules_BiLSTMLayer_construct_3686:CNode_3827{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @↓✓↓modules_BiLSTMLayer_construct_3686:output{[0]: ValueNode<FuncGraph> zeros_442, [1]: output_shape, [2]: CNode_3827}
#   3: @↓✓↓modules_BiLSTMLayer_construct_3686:CNode_3828{[0]: ValueNode<Primitive> Return, [1]: output}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_rnns_LSTM_construct_3694 : 0x392d7b40
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:542/    def construct(self, x, hx=None, seq_length=None):/
subgraph @mindspore_nn_layer_rnns_LSTM_construct_3694 parent: [subgraph @after_grad_108](%para482_x, %para483_hx, %para484_seq_length) {
  %1(CNode_3829) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("x", %para482_x, "LSTM")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:546/        _check_is_tensor("x", x, self.cls_name)/
  %2(CNode_3830) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:542/    def construct(self, x, hx=None, seq_length=None):/
  %3(CNode_3831) = S_Prim_is_not(%para483_hx, None)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %4(CNode_3832) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %5(CNode_3833) = Switch(%4, @✓mindspore_nn_layer_rnns_LSTM_construct_3834, @✗mindspore_nn_layer_rnns_LSTM_construct_3835)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %6(CNode_3836) = %5()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
  %7(CNode_3838) = call @↓mindspore_nn_layer_rnns_LSTM_construct_3837(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:171/            output, _ = self.rnn(x)/
  %8(CNode_3839) = Depend[side_effect_propagate: I64(1)](%7, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:171/            output, _ = self.rnn(x)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/nn/layer/rnns.py:548/        if hx is not None:/
}
# Order:
#   1: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3840{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<BoolImm> false, [2]: ValueNode<BoolImm> false}
#   2: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3841{[0]: ValueNode<Primitive> Switch, [1]: CNode_3840, [2]: ValueNode<FuncGraph> ↰mindspore_nn_layer_rnns_LSTM_construct_3842, [3]: ValueNode<FuncGraph> ↱mindspore_nn_layer_rnns_LSTM_construct_3843}
#   3: @mindspore_nn_layer_rnns_LSTM_construct_3694:max_batch_size{[0]: CNode_3841}
#   4: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3844{[0]: ValueNode<Primitive> Cond, [1]: ValueNode<BoolImm> true, [2]: ValueNode<BoolImm> false}
#   5: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3845{[0]: ValueNode<Primitive> Switch, [1]: CNode_3844, [2]: ValueNode<FuncGraph> ↰mindspore_nn_layer_rnns_LSTM_construct_3846, [3]: ValueNode<FuncGraph> ↱mindspore_nn_layer_rnns_LSTM_construct_3847}
#   6: @mindspore_nn_layer_rnns_LSTM_construct_3694:num_directions{[0]: CNode_3845}
#   7: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3829{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> x, [2]: param_x, [3]: ValueNode<StringImm> LSTM}
#   8: @mindspore_nn_layer_rnns_LSTM_construct_3694:x_dtype{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   9: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3831{[0]: ValueNode<DoSignaturePrimitive> S_Prim_is_not, [1]: param_hx, [2]: ValueNode<None> None}
#  10: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3832{[0]: ValueNode<Primitive> Cond, [1]: CNode_3831, [2]: ValueNode<BoolImm> false}
#  11: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3833{[0]: ValueNode<Primitive> Switch, [1]: CNode_3832, [2]: ValueNode<FuncGraph> ✓mindspore_nn_layer_rnns_LSTM_construct_3834, [3]: ValueNode<FuncGraph> ✗mindspore_nn_layer_rnns_LSTM_construct_3835}
#  12: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3836{[0]: CNode_3833}
#  13: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3838{[0]: ValueNode<FuncGraph> ↓mindspore_nn_layer_rnns_LSTM_construct_3837, [1]: CNode_3836}
#  14: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3839{[0]: ValueNode<Primitive> Depend, [1]: CNode_3838, [2]: CNode_3830}
#  15: @mindspore_nn_layer_rnns_LSTM_construct_3694:CNode_3848{[0]: ValueNode<Primitive> Return, [1]: CNode_3839}


subgraph attr:
training : 1
subgraph instance: ✓↓✗↓modules_BiLSTMLayer_construct_3691 : 0x393657a0
# In file /data/shengteng/training/modules.py:152/    def construct(self, x, lgt=None):/
subgraph @✓↓✗↓modules_BiLSTMLayer_construct_3691 parent: [subgraph @↓✗↓modules_BiLSTMLayer_construct_3544]() {
  %1(CNode_3850) = call @2↓✗↓modules_BiLSTMLayer_construct_3849()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:175/                forward_out = output[:, :, :self.hidden_size]/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:175/                forward_out = output[:, :, :self.hidden_size]/
}
# Order:
#   1: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3851{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   2: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3852{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   3: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3853{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<Int64Imm> 64, [3]: ValueNode<None> None}
#   4: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3854{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3851, [2]: CNode_3852, [3]: CNode_3853}
#   5: @✓↓✗↓modules_BiLSTMLayer_construct_3691:forward_out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: CNode_3854}
#   6: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3855{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   7: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3856{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   8: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3857{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<Int64Imm> 64, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#   9: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3858{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_3855, [2]: CNode_3856, [3]: CNode_3857}
#  10: @✓↓✗↓modules_BiLSTMLayer_construct_3691:backward_out{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: output, [2]: CNode_3858}
#  11: @✓↓✗↓modules_BiLSTMLayer_construct_3691:output{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: forward_out, [2]: backward_out}
#  12: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3850{[0]: ValueNode<FuncGraph> 2↓✗↓modules_BiLSTMLayer_construct_3849}
#  13: @✓↓✗↓modules_BiLSTMLayer_construct_3691:CNode_3859{[0]: ValueNode<Primitive> Return, [1]: CNode_3850}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓modules_NormLinear_construct_3710 : 0x3918db10
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @3↓modules_NormLinear_construct_3710 parent: [subgraph @↓modules_NormLinear_construct_3198](%para485_) {
  %1(CNode_3860) = getattr(%para105_classifier44.weight, "dtype")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier44.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %2(CNode_3861) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %3(CNode_3862) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %4(CNode_3863) = Switch(%3, @✓3↓modules_NormLinear_construct_3864, @✗3↓modules_NormLinear_construct_3865)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %5(CNode_3866) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
}
# Order:
#   1: @3↓modules_NormLinear_construct_3710:CNode_3860{[0]: ValueNode<Primitive> getattr, [1]: param_classifier44.weight, [2]: ValueNode<StringImm> dtype}
#   2: @3↓modules_NormLinear_construct_3710:CNode_3861{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3860, [2]: ValueNode<Float> Float32}
#   3: @3↓modules_NormLinear_construct_3710:CNode_3862{[0]: ValueNode<Primitive> Cond, [1]: CNode_3861, [2]: ValueNode<BoolImm> false}
#   4: @3↓modules_NormLinear_construct_3710:CNode_3863{[0]: ValueNode<Primitive> Switch, [1]: CNode_3862, [2]: ValueNode<FuncGraph> ✓3↓modules_NormLinear_construct_3864, [3]: ValueNode<FuncGraph> ✗3↓modules_NormLinear_construct_3865}
#   5: @3↓modules_NormLinear_construct_3710:CNode_3866{[0]: CNode_3863}
#   6: @3↓modules_NormLinear_construct_3710:CNode_3867{[0]: ValueNode<Primitive> Return, [1]: CNode_3866}


subgraph attr:
training : 1
subgraph instance: ✓2↓modules_NormLinear_construct_3707 : 0x3918c890
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓2↓modules_NormLinear_construct_3707 parent: [subgraph @modules_NormLinear_construct_2804]() {
  %1(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para450_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓2↓modules_NormLinear_construct_3707:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   2: @✓2↓modules_NormLinear_construct_3707:CNode_3868{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: ✗2↓modules_NormLinear_construct_3708 : 0x3918bd90
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗2↓modules_NormLinear_construct_3708 parent: [subgraph @modules_NormLinear_construct_2804]() {
  Return(%para450_x)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @✗2↓modules_NormLinear_construct_3708:CNode_3869{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
after_block : 1
training : 1
subgraph instance: 3↓modules_NormLinear_construct_3720 : 0x393bdca0
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @3↓modules_NormLinear_construct_3720 parent: [subgraph @↓modules_NormLinear_construct_3209](%para486_) {
  %1(CNode_3870) = getattr(%para104_classifier22.weight, "dtype")
      : (<Ref[Tensor[Float32]], (64, 3512), ref_key=:classifier22.weight>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %2(CNode_3871) = S_Prim_not_equal(%1, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %3(CNode_3872) = Cond(%2, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %4(CNode_3873) = Switch(%3, @✓3↓modules_NormLinear_construct_3874, @✗3↓modules_NormLinear_construct_3875)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  %5(CNode_3876) = %4()
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:106/        if self.weight.dtype != ms.float32:/
}
# Order:
#   1: @3↓modules_NormLinear_construct_3720:CNode_3870{[0]: ValueNode<Primitive> getattr, [1]: param_classifier22.weight, [2]: ValueNode<StringImm> dtype}
#   2: @3↓modules_NormLinear_construct_3720:CNode_3871{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_3870, [2]: ValueNode<Float> Float32}
#   3: @3↓modules_NormLinear_construct_3720:CNode_3872{[0]: ValueNode<Primitive> Cond, [1]: CNode_3871, [2]: ValueNode<BoolImm> false}
#   4: @3↓modules_NormLinear_construct_3720:CNode_3873{[0]: ValueNode<Primitive> Switch, [1]: CNode_3872, [2]: ValueNode<FuncGraph> ✓3↓modules_NormLinear_construct_3874, [3]: ValueNode<FuncGraph> ✗3↓modules_NormLinear_construct_3875}
#   5: @3↓modules_NormLinear_construct_3720:CNode_3876{[0]: CNode_3873}
#   6: @3↓modules_NormLinear_construct_3720:CNode_3877{[0]: ValueNode<Primitive> Return, [1]: CNode_3876}


subgraph attr:
training : 1
subgraph instance: ✓2↓modules_NormLinear_construct_3717 : 0x393bca20
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✓2↓modules_NormLinear_construct_3717 parent: [subgraph @modules_NormLinear_construct_2802]() {
  %1(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"], SrcT: F32, DstT: F32](%para451_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:105/            x = ops.cast(x, ms.float32)/
}
# Order:
#   1: @✓2↓modules_NormLinear_construct_3717:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   2: @✓2↓modules_NormLinear_construct_3717:CNode_3878{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: ✗2↓modules_NormLinear_construct_3718 : 0x393bbf20
# In file /data/shengteng/training/modules.py:89/    def construct(self, x):/
subgraph @✗2↓modules_NormLinear_construct_3718 parent: [subgraph @modules_NormLinear_construct_2802]() {
  Return(%para451_x)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/modules.py:104/        if x.dtype != ms.float32:/
}
# Order:
#   1: @✗2↓modules_NormLinear_construct_3718:CNode_3879{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
training : 1
subgraph instance: ✓↻✓13↓tfnet_model_TFNetModel_construct_3726 : 0x39462370
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✓↻✓13↓tfnet_model_TFNetModel_construct_3726 parent: [subgraph @↻✓13↓tfnet_model_TFNetModel_construct_3573]() {
  %1(CNode_3723) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):call @ms_next_1075(%para468_iter)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %2(l) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):S_Prim_getitem(%1, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %3(CNode_3730) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):ClassType(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %4(CNode_3731) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):call @ms_max_436(I64(1), %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %5(CNode_3732) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):S_Prim_make_list(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  %6(CNode_3733) = $(↻✓13↓tfnet_model_TFNetModel_construct_3573):MultitypeFuncGraph_add{(COOTensor, COOTensor), (CSRTensor, CSRTensor), (Number, Number), (String, String), (Tensor, List), (Tuple, Tuple), (Dictionary, Dictionary), (Tensor, Number), (Number, Tensor), (Tuple, Tensor), (Tensor, Tuple), (COOTensor, Tensor), (List, List), (Tensor, COOTensor), (Tensor, Tensor), (List, Tensor), (RowTensor, Tensor), (NoneType, NoneType)}(%para469_list, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @✓↻✓13↓tfnet_model_TFNetModel_construct_3726:CNode_3880{[0]: ValueNode<Primitive> Return, [1]: CNode_3733}


subgraph attr:
training : 1
subgraph instance: ✗↻✓13↓tfnet_model_TFNetModel_construct_3727 : 0x39462c40
# In file /data/shengteng/training/tfnet_model.py:76/    def construct(self, seq_data, data_len=None, is_train=True):/
subgraph @✗↻✓13↓tfnet_model_TFNetModel_construct_3727 parent: [subgraph @↵✓13↓tfnet_model_TFNetModel_construct_3393]() {
  Return(%para469_list)
      : (<null>)
      #scope: (Default)
      # In file /data/shengteng/training/tfnet_model.py:217/            safe_lgt = [max(1, int(l)) for l in lgt]/
}
# Order:
#   1: @✗↻✓13↓tfnet_model_TFNetModel_construct_3727:CNode_3881{[0]: ValueNode<Primitive> Return, [1]: param_list}


subgraph attr:
subgraph instance: ✓4↓✓↓ms_min_one_element_3739 : 0x3957a5e0
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✓4↓✓↓ms_min_one_element_3739 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3882) = S_Prim_raise_type_error[constexpr_prim: Bool(1)]("min() cannot support tensor in list or tuple nested now.")
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2716/            const_utils.raise_type_error(/
  %2(CNode_3883) = StopGradient(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
  %3(CNode_3885) = call @5↓✓↓ms_min_one_element_3884()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  %4(CNode_3886) = Depend[side_effect_propagate: I64(1)](%3, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2716/            const_utils.raise_type_error(/
  Return(%4)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2716/            const_utils.raise_type_error(/
}
# Order:
#   1: @✓4↓✓↓ms_min_one_element_3739:CNode_3882{[0]: ValueNode<DoSignaturePrimitive> S_Prim_raise_type_error, [1]: ValueNode<StringImm> min() cannot support tensor in list or tuple nested now.}
#   2: @✓4↓✓↓ms_min_one_element_3739:CNode_3887{[0]: ValueNode<Primitive> Return, [1]: CNode_3886}
#   3: @✓4↓✓↓ms_min_one_element_3739:CNode_3885{[0]: ValueNode<FuncGraph> 5↓✓↓ms_min_one_element_3884}


subgraph attr:
subgraph instance: ✗4↓✓↓ms_min_one_element_3740 : 0x39577c90
# In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2691/def ms_min_one_element(x):/
subgraph @✗4↓✓↓ms_min_one_element_3740 parent: [subgraph @ms_min_one_element_1301]() {
  %1(CNode_3888) = call @5↓✓↓ms_min_one_element_3884()
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2729/        return ms_min_one_element(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /root/miniconda3/envs/mindspore_gpu_env/lib/python3.9/site-packages/mindspore/_extends/parse/standard_method.py:2715/        if exist_tensor(x):/
}
# Order:
#   1: @✗4↓✓↓ms_min_one_element_3740:CNode_3889{[0]: ValueNode<Primitive> Return, [1]: CNode_3888}
#   2: @✗4↓✓↓ms_min_one_element_3740:CNode_3888{[0]: ValueNode<FuncGraph> 5↓✓↓ms_min_one_element_3884}
