#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„CE-CSLæ•°æ®é¢„å¤„ç†è„šæœ¬ï¼ˆä¼˜åŒ–ç‰ˆ + å¢å¼ºè¡¥ä¸ï¼‰
æ”¹è¿›æ±‡æ€»ï¼š
- argparse å‚æ•°åŒ– data_root / max_frames / size / overwrite
- æ ‡ç­¾è¯»å– pick å¢åŠ  strip()
- video_to_frames å¢åŠ  frame_count==0 å…œåº•é‡‡æ ·é€»è¾‘ï¼ˆåˆ©ç”¨ fps æˆ–å‡è®¾ 25fpsï¼‰
- æ–­ç‚¹ç»­è·‘ï¼šå·²å­˜åœ¨ä¸”æœª --overwrite æ—¶è·³è¿‡é‡æ–°è§£ç 
- æ”¯æŒæ›´å¤šè§†é¢‘æ‰©å±•åå¤§å°å†™ (mp4/avi/mov/mkv)
- ç›¸å¯¹è·¯å¾„å†™å…¥ frames_pathï¼ˆç›¸å¯¹äº data_rootï¼‰æ–¹ä¾¿è¿ç§»
- è¿‡æ»¤å¼‚å¸¸çŸ­è§†é¢‘ (<4 å¸§) è§†ä¸ºåæ ·æœ¬
- è®­ç»ƒ/éªŒè¯é›†ç©ºæ ‡ç­¾å‘Šè­¦
- è¦†ç›–ç»Ÿè®¡ä¿¡æ¯ & ä¸€è‡´æ€§æ£€æŸ¥å…¼å®¹ç›¸å¯¹è·¯å¾„
"""

import os
import csv
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
import cv2
from typing import Dict, Tuple, Optional


def resize_letterbox(img: np.ndarray, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
    """ç­‰æ¯”ç¼©æ”¾å¹¶ç”¨é»‘è¾¹å¡«å……åˆ°ç›®æ ‡å¤§å°ï¼Œé¿å…æ‹‰ä¼¸å˜å½¢ã€‚"""
    th, tw = target_size
    h, w = img.shape[:2]
    if h == 0 or w == 0:
        raise ValueError("éæ³•å›¾åƒå°ºå¯¸ï¼Œhæˆ–wä¸º0")
    scale = min(tw / w, th / h)
    nh, nw = int(h * scale), int(w * scale)
    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_LINEAR)
    canvas = np.zeros((th, tw, 3), dtype=np.uint8)
    top = (th - nh) // 2
    left = (tw - nw) // 2
    canvas[top:top + nh, left:left + nw] = resized
    return canvas


def video_to_frames(
    video_path: str,
    target_size: Tuple[int, int] = (224, 224),
    max_frames: Optional[int] = 96,
    stride: Optional[int] = None,
) -> np.ndarray:
    """å°†è§†é¢‘è½¬æ¢ä¸ºå¸§æ•°ç»„ï¼ˆRGBï¼Œuint8ï¼Œå½¢çŠ¶ (T,H,W,3)ï¼‰ã€‚
    - ä¼˜å…ˆå‡åŒ€é‡‡æ ·åˆ° max_frames
    - è‹¥ CAP_PROP_FRAME_COUNT=0 é‡‡ç”¨ fps ä¼°è®¡ + stride å…œåº•
    - BGR->RGB + letterbox
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0
    fps = cap.get(cv2.CAP_PROP_FPS) or 0

    take_indices_set = None
    dynamic_stride = stride
    if total > 0:
        if max_frames and total > max_frames:
            take_indices = np.linspace(0, total - 1, max_frames).astype(int).tolist()
            take_indices_set = set(take_indices)
    else:
        # æ— æ³•è·å–æ€»å¸§æ•°ï¼Œä½¿ç”¨æ—¶é—´æ­¥é‡‡æ ·å…œåº•ï¼ˆå‡è®¾ ~2 ç§’é—´éš”ï¼‰
        if max_frames and dynamic_stride is None:
            est_fps = fps if fps and fps < 120 else 25
            # ç›®æ ‡ï¼šçº¦ uniform è¦†ç›–ï¼Œå–æ¯ ~ (duration/max_frames) ç§’ï¼›æ— æ€»å¸§æ•°éš¾ä¼°æ—¶ä½¿ç”¨æ—¶é—´é—´éš” 2 ç§’æˆ–ä¼°ç®— stride
            dynamic_stride = max(1, int(round(est_fps * 2 / max_frames)))  # ç®€å•å…œåº•

    frames = []
    idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if take_indices_set is not None:
            if idx in take_indices_set:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames.append(resize_letterbox(rgb, target_size))
        else:
            use_it = False
            if dynamic_stride is not None:
                if idx % dynamic_stride == 0:
                    use_it = True
            else:
                if stride is None or (idx % stride == 0):
                    use_it = True
            if use_it:
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames.append(resize_letterbox(rgb, target_size))
        idx += 1

    cap.release()

    if not frames:
        raise RuntimeError(f"{video_path} æ— æœ‰æ•ˆå¸§")

    return np.stack(frames, axis=0)


def create_label_mapping_from_labelcsv(data_root: Path, use_first_gloss_token: bool = False) -> Dict[str, Dict[str, str]]:
    """
    ä» label/*.csv åˆ›å»ºæ˜ å°„: original_name -> {label_text, gloss, chinese, signer, split}
    å…¼å®¹ä»¥ä¸‹è¡¨å¤´ï¼ˆå¤§å°å†™/ç©ºæ ¼ä¸æ•æ„Ÿï¼‰ï¼š

      - åŸå§‹å: id, video_id, name, ç¼–å·, æ ·æœ¬å, number
      - è¯‘å‘˜: signer, speaker, translator, è¯´è¯äºº, æ‰‹è¯­å‘˜
      - ä¸­æ–‡: chinese, sentence, text, ä¸­æ–‡, ä¸­æ–‡å¥å­, chinese sentences
      - æ‰‹è¯­: gloss, label, æ³¨é‡Š, è¯åºåˆ—
    """
    import re
    def canon(s: str) -> str:
        # å°å†™ + å»æ‰ç©ºç™½ä¸ä¸‹åˆ’çº¿ï¼ˆä¸­æ–‡ä¸å˜ï¼‰
        return re.sub(r"[\s_]+", "", s.strip().lower()) if s is not None else ""

    def pick(row_norm: dict, keys_norm):
        for k in keys_norm:
            if k in row_norm and row_norm[k]:
                return row_norm[k].strip()
        return ""

    label_mapping: Dict[str, Dict[str, str]] = {}
    label_dir = data_root / "label"
    if not label_dir.exists():
        print("è­¦å‘Š: label ç›®å½•ä¸å­˜åœ¨ï¼Œå°†ä¸ç”Ÿæˆæ ‡ç­¾æ˜ å°„")
        return {}

    # åŒä¹‰è¯é›†åˆï¼ˆå·² canonicalizeï¼‰
    id_keys = {"id", "videoid", "name", "ç¼–å·", "æ ·æœ¬å", "number"}
    signer_keys = {"signer", "speaker", "translator", "è¯´è¯äºº", "æ‰‹è¯­å‘˜"}
    chinese_keys = {"chinese", "sentence", "text", "ä¸­æ–‡", "ä¸­æ–‡å¥å­", "chinesesentences"}
    gloss_keys = {"gloss", "label", "æ³¨é‡Š", "è¯åºåˆ—"}

    for split in ["train", "dev", "test"]:
        p = label_dir / f"{split}.csv"
        if not p.exists():
            continue
        with open(p, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                # ç”Ÿæˆ canonicalized çš„é”®->å€¼æ˜ å°„
                row_norm = {canon(k): (v or "").strip() for k, v in row.items()}

                original_name = pick(row_norm, id_keys)
                original_name = original_name.replace(".mp4", "").replace(".avi", "")
                if not original_name:
                    continue

                signer = pick(row_norm, signer_keys)
                chinese = pick(row_norm, chinese_keys)
                gloss = pick(row_norm, gloss_keys)

                if use_first_gloss_token and gloss:
                    # å–ç¬¬1ä¸ª gloss tokenï¼ˆä»¥ / æˆ–ç©ºæ ¼åˆ†å‰²ï¼‰
                    token = gloss.split("/")[0].strip()
                    token = token.split()[0] if token else token
                    gloss = token

                label_text = gloss if gloss else chinese  # ä¼˜å…ˆç”¨ glossï¼›æ²¡æœ‰å°±ç”¨ä¸­æ–‡

                label_mapping[original_name] = {
                    "label_text": label_text,
                    "gloss": gloss,
                    "chinese": chinese,
                    "signer": signer,
                    "split": split,
                }

    print(f"ä» label/*.csv åŠ è½½äº† {len(label_mapping)} æ¡æ ‡ç­¾")
    return label_mapping


def complete_preprocessing(
    data_root: str = "../data/CE-CSL",
    max_frames: int = 96,
    target_size: Tuple[int, int] = (224, 224),
    overwrite: bool = False,
):
    """å®Œæ•´é¢„å¤„ç†æ‰€æœ‰è§†é¢‘ï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘ã€‚"""
    data_path = Path(data_root).resolve()
    video_root = data_path / "video"
    processed_root = data_path / "processed"
    processed_root.mkdir(parents=True, exist_ok=True)

    label_mapping = create_label_mapping_from_labelcsv(data_path, use_first_gloss_token=False)

    for split in ["train", "dev", "test"]:
        print(f"\nğŸ”„ å¤„ç† {split} æ•°æ®é›†...")
        split_video_dir = video_root / split
        split_output_dir = processed_root / split
        split_output_dir.mkdir(parents=True, exist_ok=True)
        if not split_video_dir.exists():
            print(f"è·³è¿‡ {split}: è§†é¢‘ç›®å½•ä¸å­˜åœ¨")
            continue

        # æ”¶é›†è§†é¢‘
        all_videos = []
        translators = sorted([d for d in split_video_dir.iterdir() if d.is_dir()])
        exts = ["*.mp4", "*.MP4", "*.avi", "*.AVI", "*.mov", "*.MOV", "*.mkv", "*.MKV"]
        for translator_dir in translators:
            video_files = []
            for pat in exts:
                video_files.extend(translator_dir.glob(pat))
            video_files = sorted(video_files)
            for vf in video_files:
                all_videos.append({
                    'path': vf,
                    'translator': translator_dir.name,
                    'filename': vf.name,
                    'original_name': vf.stem
                })
        print(f"æ‰¾åˆ° {len(all_videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
        if not all_videos:
            print(f"è­¦å‘Š: {split} æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            continue

        metadata_list = []
        corpus_records = []
        bad_count = 0

        for idx, video_info in enumerate(tqdm(all_videos, desc=f"å¤„ç†{split}è§†é¢‘")):
            video_id = f"{split}_video_{idx:06d}"
            frames_file = split_output_dir / f"{video_id}_frames.npz"
            original_name = video_info['original_name']
            lm = label_mapping.get(original_name, {})
            label_text = lm.get('label_text', '')
            signer = lm.get('signer', video_info['translator'])

            # æ–­ç‚¹ç»­è·‘ï¼šè‹¥å­˜åœ¨ä¸”ä¸è¿‡æœŸ
            if frames_file.exists() and not overwrite:
                try:
                    with np.load(frames_file) as old:
                        n_frames = int(old['frames'].shape[0])
                        frame_shape = old['frames'].shape
                except Exception:
                    pass  # å¤±è´¥åˆ™é‡æ–°è§£ç 
                else:
                    frames_rel = frames_file.relative_to(data_path)
                    metadata = {
                        'video_id': video_id,
                        'translator': video_info['translator'],
                        'original_filename': video_info['filename'],
                        'original_name': original_name,
                        'frames_shape': tuple(int(x) for x in frame_shape),
                        'label': label_text,
                        'frames_path': str(frames_rel),
                        'n_frames': n_frames,
                        'split': split,
                        'signer': signer,
                        'cached': True,
                    }
                    metadata_list.append(metadata)
                    corpus_records.append({
                        'video_id': video_id,
                        'original_name': original_name,
                        'signer': signer,
                        'frames_path': str(frames_rel),
                        'n_frames': n_frames,
                        'label': label_text,
                        'split': split,
                    })
                    continue

            try:
                frames = video_to_frames(str(video_info['path']), target_size=target_size, max_frames=max_frames)
            except Exception as e:
                bad_count += 1
                print(f"[è·³è¿‡] {video_info['path']} å¤±è´¥: {e}")
                continue
            if frames.shape[0] < 4:
                bad_count += 1
                print(f"[è·³è¿‡] {video_info['path']} å¸§æ•°è¿‡å°‘: {frames.shape[0]}")
                continue

            np.savez_compressed(frames_file, frames=frames)
            n_frames = int(frames.shape[0])
            frames_rel = frames_file.relative_to(data_path)

            metadata = {
                'video_id': video_id,
                'translator': video_info['translator'],
                'original_filename': video_info['filename'],
                'original_name': original_name,
                'frames_shape': tuple(int(x) for x in frames.shape),
                'label': label_text,
                'frames_path': str(frames_rel),
                'n_frames': n_frames,
                'split': split,
                'signer': signer,
                'cached': False,
            }
            metadata_list.append(metadata)
            corpus_records.append({
                'video_id': video_id,
                'original_name': original_name,
                'signer': signer,
                'frames_path': str(frames_rel),
                'n_frames': n_frames,
                'label': label_text,
                'split': split,
            })

        metadata_file = split_output_dir / f"{split}_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata_list, f, indent=2, ensure_ascii=False)

        frame_counts = [m['n_frames'] for m in metadata_list]
        stats = {
            'split': split,
            'total_videos_found': len(all_videos),
            'processed_videos': len(metadata_list),
            'bad_videos_skipped': bad_count,
            'translators_dirs': len(translators),
            'avg_frames': float(np.mean(frame_counts)) if frame_counts else 0.0,
            'min_frames': int(np.min(frame_counts)) if frame_counts else 0,
            'max_frames': int(np.max(frame_counts)) if frame_counts else 0,
            'target_size': list(target_size),
            'stored_format': 'npz_compressed',
            'sampling': f'uniform_to_max_frames={max_frames}',
            'overwrite': overwrite,
        }
        stats_file = split_output_dir / f"{split}_stats.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

        corpus_file = data_path / f"{split}.corpus.csv"
        with open(corpus_file, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['video_id', 'original_name', 'signer', 'frames_path', 'n_frames', 'label', 'split']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(corpus_records)

        empty_labels = sum(1 for r in corpus_records if r['split'] in ('train', 'dev') and not r['label'])
        if empty_labels:
            print(f"âš ï¸  {split}: è®­ç»ƒ/éªŒè¯é›†ä¸­å‡ºç°ç©ºæ ‡ç­¾ {empty_labels} æ¡ï¼Œè¯·æ£€æŸ¥ label/*.csv")

        print(f"âœ… {split} å¤„ç†å®Œæˆ:")
        print(f"   - å¤„ç†è§†é¢‘: {len(metadata_list)} ä¸ª (è·³è¿‡åæ ·æœ¬ {bad_count})")
        print(f"   - å…ƒæ•°æ®: {metadata_file}")
        print(f"   - ç»Ÿè®¡: {stats_file}")
        print(f"   - Corpus: {corpus_file}")


def sanity_check_corpus(corpus_csv: Path, data_root: Path):
    """è½»é‡ä¸€è‡´æ€§æ£€æŸ¥ï¼šç»Ÿè®¡è¡Œæ•°ä¸ç¼ºå¤±å¸§æ–‡ä»¶æ•°é‡ï¼ˆæ”¯æŒç›¸å¯¹è·¯å¾„ï¼‰ã€‚"""
    if not corpus_csv.exists():
        print(f"[Check] ç¼ºå¤±: {corpus_csv}")
        return
    rows = 0
    missing = 0
    examples_missing = []
    with open(corpus_csv, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows += 1
            rel = row.get('frames_path', '')
            if not rel:
                missing += 1
                if len(examples_missing) < 5:
                    examples_missing.append(rel)
                continue
            p_abs = (data_root / rel).resolve()
            if not p_abs.exists():
                missing += 1
                if len(examples_missing) < 5:
                    examples_missing.append(rel)
    print(f"[Check] {corpus_csv.name}: rows={rows}, missing_files={missing}")
    if examples_missing:
        print("  ç¤ºä¾‹ç¼ºå¤±ï¼š", examples_missing)


def sanity_check_all(data_root: Path):
    for split in ["train", "dev", "test"]:
        c = data_root / f"{split}.corpus.csv"
        sanity_check_corpus(c, data_root)


def main():
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_root", default="../data/CE-CSL", help="æ•°æ®æ ¹ç›®å½• (å« video/ label/ )")
    ap.add_argument("--max_frames", type=int, default=96, help="ç»Ÿä¸€é‡‡æ ·å¸§æ•° (>0 å‡åŒ€é‡‡æ ·)" )
    ap.add_argument("--size", type=int, nargs=2, default=[224, 224], help="ç›®æ ‡å°ºå¯¸ H W")
    ap.add_argument("--overwrite", action="store_true", help="é‡æ–°è§£ç è¦†ç›–å·²å­˜åœ¨çš„ .npz")
    args = ap.parse_args()

    print("ğŸš€ å¼€å§‹å®Œæ•´çš„CE-CSLæ•°æ®é¢„å¤„ç†...")
    complete_preprocessing(
        data_root=args.data_root,
        max_frames=args.max_frames,
        target_size=tuple(args.size),
        overwrite=args.overwrite,
    )
    print("\nğŸ‰ é¢„å¤„ç†å®Œæˆ!")
    print("\nè¿è¡Œä¸€è‡´æ€§æ£€æŸ¥...")
    sanity_check_all(Path(args.data_root).resolve())


if __name__ == "__main__":
    main()