#!/usr/bin/env python3
"""
cuBLASé”™è¯¯ä¿®å¤è¡¥ä¸
ä¸“é—¨è§£å†³ CUBLAS_STATUS_INVALID_VALUE é”™è¯¯ï¼ˆé”™è¯¯ç 7ï¼‰
"""

import mindspore as ms
import mindspore.ops as ops
import numpy as np

# ===== è°ƒè¯•å¼€å…³ =====
ENABLE_CUBLAS_DEBUG = True  # ç½®ä¸º False å¯å…³é—­è¯¦ç»†æ—¥å¿—
MAX_DEBUG_PRINT = 20        # æœ€å¤šæ‰“å°å‰ N æ¬¡ matmul è°ƒè¯•
_debug_invocations = ms.mutable(0)


def _tensor_stats(t, name):
    """å®‰å…¨è·å–å¼ é‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼Œé¿å…åœ¨å›¾æ¨¡å¼æŠ›å‡ºå¼‚å¸¸ï¼‰"""
    try:
        arr = t.asnumpy()
        return (f"{name}: shape={arr.shape}, dtype={arr.dtype}, min={arr.min():.4e}, "
                f"max={arr.max():.4e}, mean={arr.mean():.4e}, has_nan={np.isnan(arr).any()}, has_inf={np.isinf(arr).any()}")
    except Exception as e:
        return f"{name}: <stats_failed {e}> shape={t.shape} dtype={t.dtype}"


def apply_cublas_fixes():
    """åº”ç”¨cuBLASé”™è¯¯çš„ä¿®å¤æ–¹æ¡ˆ"""
    # ä»…åœ¨æœªè®¾ç½®GPUæ—¶æ‰è°ƒæ•´ï¼Œé¿å…ä¸è®­ç»ƒè„šæœ¬é‡å¤ä¿®æ”¹å†²çª
    try:
        ctx_target = ms.context.get_context("device_target")
        if ctx_target != "GPU":
            ms.context.set_context(
                device_target="GPU",
                mode=ms.context.PYNATIVE_MODE,
                max_device_memory="6GB"
            )
    except Exception:
        pass

    import os
    os.environ.setdefault('CUDA_LAUNCH_BLOCKING', '1')
    os.environ.setdefault('CUBLAS_WORKSPACE_CONFIG', ':4096:8')
    print("âœ“ Applied cuBLAS context fixes")


def validate_tensor_for_matmul(tensor, name="tensor"):
    """éªŒè¯å¼ é‡æ˜¯å¦é€‚åˆçŸ©é˜µä¹˜æ³•"""
    if not isinstance(tensor, ms.Tensor):
        raise TypeError(f"{name} must be a MindSpore Tensor")
    if tensor.dtype not in [ms.float32, ms.float16]:
        print(f"Warning: {name} dtype {tensor.dtype} may cause cuBLAS issues")
    shape = tensor.shape
    for i, dim in enumerate(shape):
        if dim <= 0:
            raise ValueError(f"{name} has invalid dimension {i}: {dim}")
    if len(shape) >= 2:
        M, N = shape[-2], shape[-1]
        if M <= 0 or N <= 0:
            raise ValueError(f"{name} has invalid matrix dimensions: M={M}, N={N}")
        if M % 4 != 0 or N % 4 != 0:
            print(f"Info: {name} dimensions ({M}, {N}) not aligned to 4, may be suboptimal")
    return True


def safe_matmul(a, b, name="matmul"):
    """å®‰å…¨çš„çŸ©é˜µä¹˜æ³•ï¼ˆå…¼å®¹GRAPH_MODEï¼Œå¢åŠ è¯Šæ–­æ—¥å¿—ï¼‰"""
    global _debug_invocations
    try:
        # ====== åŸºç¡€éªŒè¯ ======
        validate_tensor_for_matmul(a, f"{name}_input_a")
        validate_tensor_for_matmul(b, f"{name}_input_b")

        # ====== ç»Ÿä¸€ dtype ======
        if a.dtype != ms.float32:
            a = ops.cast(a, ms.float32)
        if b.dtype != ms.float32:
            b = ops.cast(b, ms.float32)

        a_shape = a.shape
        b_shape = b.shape
        if len(a_shape) < 2 or len(b_shape) < 2:
            raise ValueError(f"Matrices must be at least 2D: a={a_shape}, b={b_shape}")
        if a_shape[-1] != b_shape[-2]:
            raise ValueError(f"Matrix dimension mismatch: a[..., {a_shape[-1]}] @ b[{b_shape[-2]}, ...]")

        M = int(a_shape[-2]); K = int(a_shape[-1]); N = int(b_shape[-1])
        if M <= 0 or K <= 0 or N <= 0:
            raise ValueError(f"Invalid matrix dimensions for cuBLAS: M={M}, K={K}, N={N}")

        # ====== æ•°å€¼å¥åº·æ£€æŸ¥ ======
        debug_print = False
        if ENABLE_CUBLAS_DEBUG and _debug_invocations < MAX_DEBUG_PRINT:
            debug_print = True
            _debug_invocations += 1
        if debug_print:
            print(f"[safe_matmul] #{_debug_invocations} BEGIN {name}")
            print(_tensor_stats(a, f"{name}_A"))
            print(_tensor_stats(b, f"{name}_B"))

        # æ£€æµ‹ NaN / Inf -> æ›¿æ¢ä¸º 0 ä»¥é˜² cuBLAS æŠ¥é”™
        try:
            isnan = ops.isnan(a)
            isinf = ops.isinf(a)
            if ops.reduce_any(isnan) or ops.reduce_any(isinf):
                if debug_print: print(f"{name}: A has NaN/Inf -> zeroing")
                a = ops.select(isnan | isinf, ops.zeros_like(a), a)
            isnan_b = ops.isnan(b)
            isinf_b = ops.isinf(b)
            if ops.reduce_any(isnan_b) or ops.reduce_any(isinf_b):
                if debug_print: print(f"{name}: B has NaN/Inf -> zeroing")
                b = ops.select(isnan_b | isinf_b, ops.zeros_like(b), b)
        except Exception:
            pass

        # ====== ç»´åº¦å¯¹é½è®¡ç®— ======
        pad_M, pad_K, pad_N = M, K, N
        if M % 4 != 0: pad_M = ((M + 3) // 4) * 4
        if K % 4 != 0: pad_K = ((K + 3) // 4) * 4
        if N % 4 != 0: pad_N = ((N + 3) // 4) * 4
        need_padding = (pad_M, pad_K, pad_N) != (M, K, N)
        if need_padding and debug_print:
            print(f"{name}: padding ({M},{K},{N}) -> ({pad_M},{pad_K},{pad_N})")

        # ====== æ‰§è¡Œå¡«å……ï¼ˆä»… concatï¼Œä¸ç”¨åŸåœ°ï¼‰ ======
        if need_padding:
            if pad_M != M:
                rows_add = pad_M - M
                a = ops.concat((a, ops.zeros(a_shape[:-2] + (rows_add, K), a.dtype)), axis=len(a_shape)-2)
            if pad_K != K:
                k_add = pad_K - K
                a = ops.concat((a, ops.zeros(a.shape[:-1] + (k_add,), a.dtype)), axis=len(a.shape)-1)
                b = ops.concat((b, ops.zeros(b_shape[:-2] + (k_add, N), b.dtype)), axis=len(b_shape)-2)
            if pad_N != N:
                n_add = pad_N - N
                b = ops.concat((b, ops.zeros(b.shape[:-1] + (n_add,), b.dtype)), axis=len(b.shape)-1)
            if debug_print:
                print(f"{name}: padded shapes A={a.shape} B={b.shape}")

        # ====== æ‰§è¡Œ matmul ======
        result = ops.matmul(a, b)
        if need_padding:
            result = result[..., :M, :N]

        if debug_print:
            print(_tensor_stats(result, f"{name}_Result"))
            print(f"[safe_matmul] #{_debug_invocations} END {name}\n")
        return result

    except Exception as e:
        print(f"MatMul failed for {name}: {e}")
        print(f"  A shape={a.shape if 'a' in locals() else 'unknown'} B shape={b.shape if 'b' in locals() else 'unknown'}")
        try:
            print(f"  Attempting CPU fallback for {name}...")
            original_device = ms.context.get_context("device_target")
            ms.context.set_context(device_target="CPU")
            cpu_result = ops.matmul(a, b)
            ms.context.set_context(device_target=original_device)
            print(f"  âœ“ CPU fallback successful for {name}")
            return cpu_result
        except Exception as cpu_e:
            print(f"  CPU fallback also failed: {cpu_e}")
            raise e


def fix_batch_processing_shapes(batch_data, expected_batch_size=None):
    """ä¿®å¤æ‰¹æ¬¡å¤„ç†ä¸­çš„å½¢çŠ¶é—®é¢˜"""
    if not isinstance(batch_data, ms.Tensor):
        batch_data = ms.Tensor(batch_data, ms.float32)
    shape = batch_data.shape
    if len(shape) == 0:
        raise ValueError("Empty tensor shape")
    batch_size = int(shape[0])
    if batch_size <= 0:
        raise ValueError(f"Invalid batch size: {batch_size}")
    if expected_batch_size is not None and batch_size != expected_batch_size:
        if batch_size > expected_batch_size:
            batch_data = batch_data[:expected_batch_size]
        else:
            pad_size = expected_batch_size - batch_size
            pad_shape = (pad_size,) + shape[1:]
            pad_tensor = ops.zeros(pad_shape, batch_data.dtype)
            batch_data = ops.concat([batch_data, pad_tensor], axis=0)
    new_shape = []
    for dim in batch_data.shape:
        dim_val = max(1, int(dim))
        if len(new_shape) >= 1:
            dim_val = ((dim_val + 3) // 4) * 4
        new_shape.append(dim_val)
    if tuple(new_shape) != batch_data.shape:
        total_elements = 1
        for dim in batch_data.shape:
            total_elements *= dim
        new_total = 1
        for dim in new_shape:
            new_total *= dim
        if new_total > total_elements:
            pad_elements = new_total - total_elements
            flat_data = ops.reshape(batch_data, (-1,))
            pad_data = ops.zeros((pad_elements,), batch_data.dtype)
            flat_data = ops.concat([flat_data, pad_data], axis=0)
            batch_data = ops.reshape(flat_data, new_shape)
        else:
            batch_data = ops.reshape(batch_data, new_shape)
    return batch_data


def create_safe_linear_layer(input_dim, output_dim, name="linear"):
    """åˆ›å»ºå®‰å…¨çš„çº¿æ€§å±‚ï¼Œé¿å…cuBLASé”™è¯¯"""
    input_dim = max(1, int(input_dim))
    output_dim = max(1, int(output_dim))
    input_dim_aligned = ((input_dim + 3) // 4) * 4
    output_dim_aligned = ((output_dim + 3) // 4) * 4
    limit = np.sqrt(6.0 / (input_dim_aligned + output_dim_aligned))
    weight = np.random.uniform(-limit, limit, (input_dim_aligned, output_dim_aligned)).astype(np.float32)
    if input_dim_aligned != input_dim or output_dim_aligned != output_dim:
        weight = weight[:input_dim, :output_dim]
    weight_tensor = ms.Tensor(weight, ms.float32)
    print(f"âœ“ Created safe linear layer {name}: ({input_dim}, {output_dim})")
    return weight_tensor


def diagnose_cublas_error(error_msg):
    """è¯Šæ–­cuBLASé”™è¯¯å¹¶æä¾›è§£å†³æ–¹æ¡ˆ"""
    solutions = []
    if "CUBLAS_STATUS_INVALID_VALUE" in error_msg or "error 7" in error_msg:
        solutions.extend([
            "1. æ£€æŸ¥çŸ©é˜µç»´åº¦æ˜¯å¦åŒ¹é…",
            "2. ç¡®ä¿æ‰€æœ‰å¼ é‡ä¸ºfloat32ç±»å‹",
            "3. éªŒè¯æ‰¹æ¬¡å¤§å°æ˜¯å¦ä¸ºæ­£æ•°",
            "4. æ£€æŸ¥æ˜¯å¦å­˜åœ¨0ç»´æˆ–è´Ÿç»´åº¦",
            "5. ç¡®ä¿å†…å­˜å¯¹é½ï¼ˆå»ºè®®ç»´åº¦ä¸º4çš„å€æ•°ï¼‰"
        ])
    if "MatMul" in error_msg:
        solutions.extend([
            "6. ä½¿ç”¨safe_matmulå‡½æ•°æ›¿ä»£ç›´æ¥çš„ops.matmul",
            "7. åœ¨çŸ©é˜µä¹˜æ³•å‰æ·»åŠ å½¢çŠ¶éªŒè¯",
            "8. ç¡®ä¿è¾“å…¥å¼ é‡è¿ç»­å­˜å‚¨ï¼ˆä½¿ç”¨.contiguous()å¦‚æœå¯ç”¨ï¼‰"
        ])
    if "For 'MatMul'" in error_msg:
        solutions.extend([
            "9. æ£€æŸ¥çº¿æ€§å±‚çš„è¾“å…¥ç‰¹å¾ç»´åº¦",
            "10. éªŒè¯LSTMè¾“å‡ºç»´åº¦ä¸åˆ†ç±»å™¨è¾“å…¥ç»´åº¦åŒ¹é…",
            "11. ç¡®ä¿æ‰¹æ¬¡å¤„ç†ä¸­æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦ä¸€è‡´"
        ])
    print("ğŸ” cuBLASé”™è¯¯è¯Šæ–­:")
    print(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
    print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
    for solution in solutions:
        print(f"  {solution}")
    return solutions


if __name__ == "__main__":
    print("Testing cuBLAS fixes...")
    apply_cublas_fixes()
    try:
        a = ms.Tensor(np.random.randn(13, 64).astype(np.float32))
        b = ms.Tensor(np.random.randn(64, 3512).astype(np.float32))
        result = safe_matmul(a, b, "test_matmul")
        print(f"âœ“ Safe MatMul test passed: {result.shape}")
    except Exception as e:
        print(f"âœ— Safe MatMul test failed: {e}")
    try:
        batch_data = ms.Tensor(np.random.randn(4, 10, 64).astype(np.float32))
        fixed_data = fix_batch_processing_shapes(batch_data)
        print(f"âœ“ Batch processing fix test passed: {fixed_data.shape}")
    except Exception as e:
        print(f"âœ— Batch processing fix test failed: {e}")
    print("cuBLAS fixes test completed!")
