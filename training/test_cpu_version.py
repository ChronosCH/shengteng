#!/usr/bin/env python3
"""
CPUæµ‹è¯•ç‰ˆæœ¬ - éªŒè¯æ¨¡å‹é€»è¾‘æ˜¯å¦æ­£ç¡®ï¼Œé¿å¼€GPU cuBLASé—®é¢˜
"""

import os
import sys
import numpy as np
import mindspore as ms
import mindspore.ops as ops
from mindspore import context, Tensor

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from tfnet_model import TFNetModel

def test_model_on_cpu():
    """åœ¨CPUä¸Šæµ‹è¯•æ¨¡å‹ä»¥éªŒè¯é€»è¾‘æ­£ç¡®æ€§"""
    
    # è®¾ç½®CPUä¸Šä¸‹æ–‡
    print("Setting up CPU context...")
    context.set_context(mode=context.PYNATIVE_MODE, device_target="CPU")
    
    # åˆ›å»ºæ¨¡å‹ - æŒ‡å®šCPUè®¾å¤‡
    print("Creating TFNet model for CPU...")
    model = TFNetModel(hidden_size=64, word_set_num=100, device_target="CPU")
    
    test_cases = [
        {
            "name": "Normal case - CPU",
            "batch_size": 2,
            "sequence_length": 10,
            "channels": 3,
            "height": 64,
            "width": 64,
            "data_len": [8, 6]
        },
        {
            "name": "Batch size 4 (problematic case) - CPU",
            "batch_size": 4,
            "sequence_length": 12,
            "channels": 3,
            "height": 160,
            "width": 160,
            "data_len": [10, 8, 12, 6]
        },
        {
            "name": "Large batch - CPU",
            "batch_size": 8,
            "sequence_length": 15,
            "channels": 3,
            "height": 128,
            "width": 128,
            "data_len": [12, 10, 15, 8, 14, 9, 13, 11]
        }
    ]
    
    success_count = 0
    
    for i, test_case in enumerate(test_cases):
        print(f"\n--- Test Case {i+1}: {test_case['name']} ---")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            batch_size = test_case['batch_size']
            seq_len = test_case['sequence_length']
            channels = test_case['channels']
            height = test_case['height']
            width = test_case['width']
            data_len = test_case['data_len']
            
            print(f"Input shape: ({batch_size}, {seq_len}, {channels}, {height}, {width})")
            print(f"Data lengths: {data_len}")
            
            # åˆ›å»ºéšæœºè¾“å…¥æ•°æ®
            seq_data = Tensor(np.random.randn(batch_size, seq_len, channels, height, width).astype(np.float32))
            data_len_tensor = data_len
            
            # å‰å‘ä¼ æ’­
            print("Running forward pass...")
            outputs = model(seq_data, data_len_tensor, is_train=True)
            
            # æ£€æŸ¥è¾“å‡º
            log_probs1, log_probs2, log_probs3, log_probs4, log_probs5, lgt_tensor, _, _, _ = outputs
            
            print(f"âœ“ Success! Output shapes:")
            print(f"  log_probs1: {log_probs1.shape}")
            print(f"  log_probs2: {log_probs2.shape}")  
            print(f"  log_probs3: {log_probs3.shape}")
            print(f"  log_probs4: {log_probs4.shape}")
            print(f"  log_probs5: {log_probs5.shape}")
            print(f"  lgt_tensor: {lgt_tensor.shape}")
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«NaNæˆ–Inf
            all_logits = [log_probs1, log_probs2, log_probs3, log_probs4, log_probs5]
            for j, logits in enumerate(all_logits):
                logits_np = logits.asnumpy()
                if np.isnan(logits_np).any():
                    print(f"  Warning: log_probs{j+1} contains NaN values")
                if np.isinf(logits_np).any():
                    print(f"  Warning: log_probs{j+1} contains Inf values")
                    
            success_count += 1
                    
        except Exception as e:
            print(f"âœ— Failed: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n=== CPUæµ‹è¯•ç»“æœ ===")
    print(f"æˆåŠŸ: {success_count}/{len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    
    if success_count == len(test_cases):
        print("âœ“ æ‰€æœ‰CPUæµ‹è¯•é€šè¿‡ï¼æ¨¡å‹é€»è¾‘æ­£ç¡®ã€‚")
        print("GPUé—®é¢˜å¯èƒ½æ˜¯ç”±äºcuBLASåº“æˆ–é©±åŠ¨ç¨‹åºå…¼å®¹æ€§å¯¼è‡´çš„ã€‚")
        return True
    else:
        print("âœ— ä¸€äº›æµ‹è¯•å¤±è´¥ï¼Œæ¨¡å‹é€»è¾‘å¯èƒ½æœ‰é—®é¢˜ã€‚")
        return False

def test_training_compatibility():
    """æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§"""
    print("\n=== æµ‹è¯•è®­ç»ƒæ¨¡å¼å…¼å®¹æ€§ ===")
    
    context.set_context(mode=context.PYNATIVE_MODE, device_target="CPU")
    model = TFNetModel(hidden_size=64, word_set_num=100, device_target="CPU")
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    try:
        model.set_train(True)
        
        # åˆ›å»ºå°æ‰¹é‡æ•°æ®
        batch_size = 2
        seq_len = 8
        seq_data = Tensor(np.random.randn(batch_size, seq_len, 3, 64, 64).astype(np.float32))
        data_len = [6, 8]
        
        # å‰å‘ä¼ æ’­
        outputs = model(seq_data, data_len, is_train=True)
        
        print("âœ“ è®­ç»ƒæ¨¡å¼æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•è¯„ä¼°æ¨¡å¼
        model.set_train(False)
        outputs = model(seq_data, data_len, is_train=False)
        
        print("âœ“ è¯„ä¼°æ¨¡å¼æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âœ— è®­ç»ƒå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("Testing TFNet model on CPU to verify logic correctness...")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    basic_success = test_model_on_cpu()
    
    # æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§
    training_success = test_training_compatibility()
    
    if basic_success and training_success:
        print("\nğŸ‰ CPUæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        print("\nğŸ“‹ å…³äºGPU cuBLASé”™è¯¯çš„è§£å†³å»ºè®®:")
        print("1. GPU cuBLASé”™è¯¯é€šå¸¸æ˜¯ç”±é©±åŠ¨æˆ–åº“ç‰ˆæœ¬ä¸å…¼å®¹å¯¼è‡´")
        print("2. å¯ä»¥å°è¯•ä½¿ç”¨CPUæ¨¡å¼è¿›è¡Œè®­ç»ƒï¼ˆåœ¨é…ç½®ä¸­è®¾ç½®device_target: 'CPU'ï¼‰")
        print("3. æˆ–è€…æ›´æ–°CUDA/cuDNNç‰ˆæœ¬")
        print("4. å¯¹äºè®­ç»ƒï¼Œå¯ä»¥ä¸´æ—¶ä½¿ç”¨CPUæ¨¡å¼ï¼Œè™½ç„¶é€Ÿåº¦è¾ƒæ…¢ä½†å¯ä»¥éªŒè¯ç®—æ³•æ­£ç¡®æ€§")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        
    print("\nCPUæµ‹è¯•å®Œæˆ!")
